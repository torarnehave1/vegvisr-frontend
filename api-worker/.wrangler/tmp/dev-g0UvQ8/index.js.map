{
  "version": 3,
  "sources": ["../../../../node_modules/marked/src/defaults.ts", "../../../../node_modules/marked/src/rules.ts", "../../../../node_modules/marked/src/helpers.ts", "../../../../node_modules/marked/src/Tokenizer.ts", "../../../../node_modules/marked/src/Lexer.ts", "../../../../node_modules/marked/src/Renderer.ts", "../../../../node_modules/marked/src/TextRenderer.ts", "../../../../node_modules/marked/src/Parser.ts", "../../../../node_modules/marked/src/Hooks.ts", "../../../../node_modules/marked/src/Instance.ts", "../../../../node_modules/marked/src/marked.ts", "../../../../node_modules/openai/src/internal/qs/formats.ts", "../../../../node_modules/openai/src/internal/qs/utils.ts", "../../../../node_modules/openai/src/internal/qs/stringify.ts", "../../../../node_modules/openai/src/version.ts", "../../../../node_modules/openai/src/_shims/registry.ts", "../../../../node_modules/openai/src/_shims/MultipartBody.ts", "../../../../node_modules/openai/src/_shims/web-runtime.ts", "../../../../node_modules/openai/_shims/index.mjs", "../../../../node_modules/openai/src/error.ts", "../../../../node_modules/openai/src/internal/decoders/line.ts", "../../../../node_modules/openai/src/internal/stream-utils.ts", "../../../../node_modules/openai/src/streaming.ts", "../../../../node_modules/openai/src/uploads.ts", "../../../../node_modules/openai/src/core.ts", "../../../../node_modules/openai/src/pagination.ts", "../../../../node_modules/openai/src/resource.ts", "../../../../node_modules/openai/src/resources/chat/completions/messages.ts", "../../../../node_modules/openai/src/resources/chat/completions/completions.ts", "../../../../node_modules/openai/src/resources/chat/chat.ts", "../../../../node_modules/openai/src/resources/audio/speech.ts", "../../../../node_modules/openai/src/resources/audio/transcriptions.ts", "../../../../node_modules/openai/src/resources/audio/translations.ts", "../../../../node_modules/openai/src/resources/audio/audio.ts", "../../../../node_modules/openai/src/resources/batches.ts", "../../../../node_modules/openai/src/resources/beta/assistants.ts", "../../../../node_modules/openai/src/lib/RunnableFunction.ts", "../../../../node_modules/openai/src/lib/chatCompletionUtils.ts", "../../../../node_modules/openai/src/lib/EventStream.ts", "../../../../node_modules/openai/src/lib/parser.ts", "../../../../node_modules/openai/src/lib/AbstractChatCompletionRunner.ts", "../../../../node_modules/openai/src/lib/ChatCompletionRunner.ts", "../../../../node_modules/openai/src/_vendor/partial-json-parser/parser.ts", "../../../../node_modules/openai/src/lib/ChatCompletionStream.ts", "../../../../node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts", "../../../../node_modules/openai/src/resources/beta/chat/completions.ts", "../../../../node_modules/openai/src/resources/beta/chat/chat.ts", "../../../../node_modules/openai/src/resources/beta/realtime/sessions.ts", "../../../../node_modules/openai/src/resources/beta/realtime/realtime.ts", "../../../../node_modules/openai/src/lib/AssistantStream.ts", "../../../../node_modules/openai/src/resources/beta/threads/messages.ts", "../../../../node_modules/openai/src/resources/beta/threads/runs/steps.ts", "../../../../node_modules/openai/src/resources/beta/threads/runs/runs.ts", "../../../../node_modules/openai/src/resources/beta/threads/threads.ts", "../../../../node_modules/openai/src/resources/beta/beta.ts", "../../../../node_modules/openai/src/resources/completions.ts", "../../../../node_modules/openai/src/resources/embeddings.ts", "../../../../node_modules/openai/src/resources/files.ts", "../../../../node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts", "../../../../node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts", "../../../../node_modules/openai/src/resources/fine-tuning/fine-tuning.ts", "../../../../node_modules/openai/src/resources/images.ts", "../../../../node_modules/openai/src/resources/models.ts", "../../../../node_modules/openai/src/resources/moderations.ts", "../../../../node_modules/openai/src/lib/ResponsesParser.ts", "../../../../node_modules/openai/src/resources/responses/input-items.ts", "../../../../node_modules/openai/src/lib/responses/ResponseStream.ts", "../../../../node_modules/openai/src/resources/responses/responses.ts", "../../../../node_modules/openai/src/resources/uploads/parts.ts", "../../../../node_modules/openai/src/resources/uploads/uploads.ts", "../../../../node_modules/openai/src/lib/Util.ts", "../../../../node_modules/openai/src/resources/vector-stores/files.ts", "../../../../node_modules/openai/src/resources/vector-stores/file-batches.ts", "../../../../node_modules/openai/src/resources/vector-stores/vector-stores.ts", "../../../../node_modules/openai/src/index.ts", "../../../index.js", "../../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-ie53cl/middleware-insertion-facade.js", "../../../../node_modules/wrangler/templates/middleware/common.ts", "../bundle-ie53cl/middleware-loader.entry.ts"],
  "sourceRoot": "C:\\Users\\torar\\MyApps\\vegvisr-frontend\\api-worker\\.wrangler\\tmp\\dev-g0UvQ8",
  "sourcesContent": ["/**\n * Gets the original marked default options.\n */\nexport function _getDefaults() {\n    return {\n        async: false,\n        breaks: false,\n        extensions: null,\n        gfm: true,\n        hooks: null,\n        pedantic: false,\n        renderer: null,\n        silent: false,\n        tokenizer: null,\n        walkTokens: null,\n    };\n}\nexport let _defaults = _getDefaults();\nexport function changeDefaults(newDefaults) {\n    _defaults = newDefaults;\n}\n", "const noopTest = { exec: () => null };\nfunction edit(regex, opt = '') {\n    let source = typeof regex === 'string' ? regex : regex.source;\n    const obj = {\n        replace: (name, val) => {\n            let valSource = typeof val === 'string' ? val : val.source;\n            valSource = valSource.replace(other.caret, '$1');\n            source = source.replace(name, valSource);\n            return obj;\n        },\n        getRegex: () => {\n            return new RegExp(source, opt);\n        },\n    };\n    return obj;\n}\nexport const other = {\n    codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n    outputLinkReplace: /\\\\([\\[\\]])/g,\n    indentCodeCompensation: /^(\\s+)(?:```)/,\n    beginningSpace: /^\\s+/,\n    endingHash: /#$/,\n    startingSpaceChar: /^ /,\n    endingSpaceChar: / $/,\n    nonSpaceChar: /[^ ]/,\n    newLineCharGlobal: /\\n/g,\n    tabCharGlobal: /\\t/g,\n    multipleSpaceGlobal: /\\s+/g,\n    blankLine: /^[ \\t]*$/,\n    doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n    blockquoteStart: /^ {0,3}>/,\n    blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n    blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n    listReplaceTabs: /^\\t+/,\n    listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n    listIsTask: /^\\[[ xX]\\] /,\n    listReplaceTask: /^\\[[ xX]\\] +/,\n    anyLine: /\\n.*\\n/,\n    hrefBrackets: /^<(.*)>$/,\n    tableDelimiter: /[:|]/,\n    tableAlignChars: /^\\||\\| *$/g,\n    tableRowBlankLine: /\\n[ \\t]*$/,\n    tableAlignRight: /^ *-+: *$/,\n    tableAlignCenter: /^ *:-+: *$/,\n    tableAlignLeft: /^ *:-+ *$/,\n    startATag: /^<a /i,\n    endATag: /^<\\/a>/i,\n    startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n    endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n    startAngleBracket: /^</,\n    endAngleBracket: />$/,\n    pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n    unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n    escapeTest: /[&<>\"']/,\n    escapeReplace: /[&<>\"']/g,\n    escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n    escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n    unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n    caret: /(^|[^\\[])\\^/g,\n    percentDecode: /%25/g,\n    findPipe: /\\|/g,\n    splitPipe: / \\|/,\n    slashPipe: /\\\\\\|/g,\n    carriageReturn: /\\r\\n|\\r/g,\n    spaceLine: /^ +$/gm,\n    notSpaceStart: /^\\S*/,\n    endingNewline: /\\n$/,\n    listItemRegex: (bull) => new RegExp(`^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`),\n    nextBulletRegex: (indent) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`),\n    hrRegex: (indent) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n    fencesBeginRegex: (indent) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n    headingBeginRegex: (indent) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n    htmlBeginRegex: (indent) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, 'i'),\n};\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nconst lheading = edit(lheadingCore)\n    .replace(/bull/g, bullet) // lists can interrupt\n    .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n    .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n    .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n    .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n    .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n    .replace(/\\|table/g, '') // table not in commonmark\n    .getRegex();\nconst lheadingGfm = edit(lheadingCore)\n    .replace(/bull/g, bullet) // lists can interrupt\n    .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n    .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n    .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n    .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n    .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n    .replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/) // table can interrupt\n    .getRegex();\nconst _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/)\n    .replace('label', _blockLabel)\n    .replace('title', /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/)\n    .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n    .replace(/bull/g, bullet)\n    .getRegex();\nconst _tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n    + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n    + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n    + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n    + '|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title'\n    + '|tr|track|ul';\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit('^ {0,3}(?:' // optional indentation\n    + '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n    + '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n    + '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n    + '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n    + '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n    + '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (6)\n    + '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) open tag\n    + '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) closing tag\n    + ')', 'i')\n    .replace('comment', _comment)\n    .replace('tag', _tag)\n    .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n    .getRegex();\nconst paragraph = edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n    .replace('|table', '')\n    .replace('blockquote', ' {0,3}>')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n    .replace('paragraph', paragraph)\n    .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n    blockquote,\n    code: blockCode,\n    def,\n    fences,\n    heading,\n    hr,\n    html,\n    lheading,\n    list,\n    newline,\n    paragraph,\n    table: noopTest,\n    text: blockText,\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit('^ *([^\\\\n ].*)\\\\n' // Header\n    + ' {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)' // Align\n    + '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)') // Cells\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('blockquote', ' {0,3}>')\n    .replace('code', '(?: {4}| {0,3}\\t)[^\\\\n]')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // tables can be interrupted by type (6) html blocks\n    .getRegex();\nconst blockGfm = {\n    ...blockNormal,\n    lheading: lheadingGfm,\n    table: gfmTable,\n    paragraph: edit(_paragraph)\n        .replace('hr', hr)\n        .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n        .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n        .replace('table', gfmTable) // interrupt paragraphs with table\n        .replace('blockquote', ' {0,3}>')\n        .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n        .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n        .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n        .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n        .getRegex(),\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n    ...blockNormal,\n    html: edit('^ *(?:comment *(?:\\\\n|\\\\s*$)'\n        + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n        + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n        .replace('comment', _comment)\n        .replace(/tag/g, '(?!(?:'\n        + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n        + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n        + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n        .getRegex(),\n    def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n    heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n    fences: noopTest, // fences not supported\n    lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n    paragraph: edit(_paragraph)\n        .replace('hr', hr)\n        .replace('heading', ' *#{1,6} *[^\\n]')\n        .replace('lheading', lheading)\n        .replace('|table', '')\n        .replace('blockquote', ' {0,3}>')\n        .replace('|fences', '')\n        .replace('|list', '')\n        .replace('|html', '')\n        .replace('|tag', '')\n        .getRegex(),\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = /[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nconst punctuation = edit(/^((?![*_])punctSpace)/, 'u')\n    .replace(/punctSpace/g, _punctuationOrSpace).getRegex();\n// GFM allows ~ inside strong and em for strikethrough\nconst _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip = /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\nconst emStrongLDelim = edit(emStrongLDelimCore, 'u')\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst emStrongLDelimGfm = edit(emStrongLDelimCore, 'u')\n    .replace(/punct/g, _punctuationGfmStrongEm)\n    .getRegex();\nconst emStrongRDelimAstCore = '^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)' // Skip orphan inside strong\n    + '|[^*]+(?=[^*])' // Consume to delim\n    + '|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)' // (1) #*** can only be a Right Delimiter\n    + '|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)' // (2) a***#, a*** can only be a Right Delimiter\n    + '|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)' // (3) #***a, ***a can only be Left Delimiter\n    + '|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)' // (4) ***# can only be Left Delimiter\n    + '|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)' // (5) #***# can be either Left or Right Delimiter\n    + '|notPunctSpace(\\\\*+)(?=notPunctSpace)'; // (6) a***a can be either Left or Right Delimiter\nconst emStrongRDelimAst = edit(emStrongRDelimAstCore, 'gu')\n    .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n    .replace(/punctSpace/g, _punctuationOrSpace)\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, 'gu')\n    .replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm)\n    .replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm)\n    .replace(/punct/g, _punctuationGfmStrongEm)\n    .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit('^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)' // Skip orphan inside strong\n    + '|[^_]+(?=[^_])' // Consume to delim\n    + '|(?!_)punct(_+)(?=[\\\\s]|$)' // (1) #___ can only be a Right Delimiter\n    + '|notPunctSpace(_+)(?!_)(?=punctSpace|$)' // (2) a___#, a___ can only be a Right Delimiter\n    + '|(?!_)punctSpace(_+)(?=notPunctSpace)' // (3) #___a, ___a can only be Left Delimiter\n    + '|[\\\\s](_+)(?!_)(?=punct)' // (4) ___# can only be Left Delimiter\n    + '|(?!_)punct(_+)(?!_)(?=punct)', 'gu') // (5) #___# can be either Left or Right Delimiter\n    .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n    .replace(/punctSpace/g, _punctuationOrSpace)\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst anyPunctuation = edit(/\\\\(punct)/, 'gu')\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n    .replace('scheme', /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n    .replace('email', /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/)\n    .getRegex();\nconst _inlineComment = edit(_comment).replace('(?:-->|$)', '-->').getRegex();\nconst tag = edit('^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>') // CDATA section\n    .replace('comment', _inlineComment)\n    .replace('attribute', /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/)\n    .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n    .replace('label', _inlineLabel)\n    .replace('href', /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n    .replace('title', /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/)\n    .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n    .replace('label', _inlineLabel)\n    .replace('ref', _blockLabel)\n    .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n    .replace('ref', _blockLabel)\n    .getRegex();\nconst reflinkSearch = edit('reflink|nolink(?!\\\\()', 'g')\n    .replace('reflink', reflink)\n    .replace('nolink', nolink)\n    .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n    _backpedal: noopTest, // only used for GFM url\n    anyPunctuation,\n    autolink,\n    blockSkip,\n    br,\n    code: inlineCode,\n    del: noopTest,\n    emStrongLDelim,\n    emStrongRDelimAst,\n    emStrongRDelimUnd,\n    escape,\n    link,\n    nolink,\n    punctuation,\n    reflink,\n    reflinkSearch,\n    tag,\n    text: inlineText,\n    url: noopTest,\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n    ...inlineNormal,\n    link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n        .replace('label', _inlineLabel)\n        .getRegex(),\n    reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n        .replace('label', _inlineLabel)\n        .getRegex(),\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n    ...inlineNormal,\n    emStrongRDelimAst: emStrongRDelimAstGfm,\n    emStrongLDelim: emStrongLDelimGfm,\n    url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, 'i')\n        .replace('email', /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/)\n        .getRegex(),\n    _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n    del: /^(~~?)(?=[^\\s~])((?:\\\\.|[^\\\\])*?(?:\\\\.|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n    text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n    ...inlineGfm,\n    br: edit(br).replace('{2,}', '*').getRegex(),\n    text: edit(inlineGfm.text)\n        .replace('\\\\b_', '\\\\b_| {2,}\\\\n')\n        .replace(/\\{2,\\}/g, '*')\n        .getRegex(),\n};\n/**\n * exports\n */\nexport const block = {\n    normal: blockNormal,\n    gfm: blockGfm,\n    pedantic: blockPedantic,\n};\nexport const inline = {\n    normal: inlineNormal,\n    gfm: inlineGfm,\n    breaks: inlineBreaks,\n    pedantic: inlinePedantic,\n};\n", "import { other } from './rules.ts';\n/**\n * Helpers\n */\nconst escapeReplacements = {\n    '&': '&amp;',\n    '<': '&lt;',\n    '>': '&gt;',\n    '\"': '&quot;',\n    \"'\": '&#39;',\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nexport function escape(html, encode) {\n    if (encode) {\n        if (other.escapeTest.test(html)) {\n            return html.replace(other.escapeReplace, getEscapeReplacement);\n        }\n    }\n    else {\n        if (other.escapeTestNoEncode.test(html)) {\n            return html.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n        }\n    }\n    return html;\n}\nexport function unescape(html) {\n    // explicitly match decimal, hex, and named HTML entities\n    return html.replace(other.unescapeTest, (_, n) => {\n        n = n.toLowerCase();\n        if (n === 'colon')\n            return ':';\n        if (n.charAt(0) === '#') {\n            return n.charAt(1) === 'x'\n                ? String.fromCharCode(parseInt(n.substring(2), 16))\n                : String.fromCharCode(+n.substring(1));\n        }\n        return '';\n    });\n}\nexport function cleanUrl(href) {\n    try {\n        href = encodeURI(href).replace(other.percentDecode, '%');\n    }\n    catch {\n        return null;\n    }\n    return href;\n}\nexport function splitCells(tableRow, count) {\n    // ensure that every cell-delimiting pipe has a space\n    // before it to distinguish it from an escaped pipe\n    const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n        let escaped = false;\n        let curr = offset;\n        while (--curr >= 0 && str[curr] === '\\\\')\n            escaped = !escaped;\n        if (escaped) {\n            // odd number of slashes means | is escaped\n            // so we leave it alone\n            return '|';\n        }\n        else {\n            // add space before unescaped |\n            return ' |';\n        }\n    }), cells = row.split(other.splitPipe);\n    let i = 0;\n    // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n    if (!cells[0].trim()) {\n        cells.shift();\n    }\n    if (cells.length > 0 && !cells.at(-1)?.trim()) {\n        cells.pop();\n    }\n    if (count) {\n        if (cells.length > count) {\n            cells.splice(count);\n        }\n        else {\n            while (cells.length < count)\n                cells.push('');\n        }\n    }\n    for (; i < cells.length; i++) {\n        // leading or trailing whitespace is ignored per the gfm spec\n        cells[i] = cells[i].trim().replace(other.slashPipe, '|');\n    }\n    return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nexport function rtrim(str, c, invert) {\n    const l = str.length;\n    if (l === 0) {\n        return '';\n    }\n    // Length of suffix matching the invert condition.\n    let suffLen = 0;\n    // Step left until we fail to match the invert condition.\n    while (suffLen < l) {\n        const currChar = str.charAt(l - suffLen - 1);\n        if (currChar === c && !invert) {\n            suffLen++;\n        }\n        else if (currChar !== c && invert) {\n            suffLen++;\n        }\n        else {\n            break;\n        }\n    }\n    return str.slice(0, l - suffLen);\n}\nexport function findClosingBracket(str, b) {\n    if (str.indexOf(b[1]) === -1) {\n        return -1;\n    }\n    let level = 0;\n    for (let i = 0; i < str.length; i++) {\n        if (str[i] === '\\\\') {\n            i++;\n        }\n        else if (str[i] === b[0]) {\n            level++;\n        }\n        else if (str[i] === b[1]) {\n            level--;\n            if (level < 0) {\n                return i;\n            }\n        }\n    }\n    return -1;\n}\n", "import { _defaults } from './defaults.ts';\nimport { rtrim, splitCells, findClosingBracket, } from './helpers.ts';\nfunction outputLink(cap, link, raw, lexer, rules) {\n    const href = link.href;\n    const title = link.title || null;\n    const text = cap[1].replace(rules.other.outputLinkReplace, '$1');\n    if (cap[0].charAt(0) !== '!') {\n        lexer.state.inLink = true;\n        const token = {\n            type: 'link',\n            raw,\n            href,\n            title,\n            text,\n            tokens: lexer.inlineTokens(text),\n        };\n        lexer.state.inLink = false;\n        return token;\n    }\n    return {\n        type: 'image',\n        raw,\n        href,\n        title,\n        text,\n    };\n}\nfunction indentCodeCompensation(raw, text, rules) {\n    const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n    if (matchIndentToCode === null) {\n        return text;\n    }\n    const indentToCode = matchIndentToCode[1];\n    return text\n        .split('\\n')\n        .map(node => {\n        const matchIndentInNode = node.match(rules.other.beginningSpace);\n        if (matchIndentInNode === null) {\n            return node;\n        }\n        const [indentInNode] = matchIndentInNode;\n        if (indentInNode.length >= indentToCode.length) {\n            return node.slice(indentToCode.length);\n        }\n        return node;\n    })\n        .join('\\n');\n}\n/**\n * Tokenizer\n */\nexport class _Tokenizer {\n    options;\n    rules; // set by the lexer\n    lexer; // set by the lexer\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    space(src) {\n        const cap = this.rules.block.newline.exec(src);\n        if (cap && cap[0].length > 0) {\n            return {\n                type: 'space',\n                raw: cap[0],\n            };\n        }\n    }\n    code(src) {\n        const cap = this.rules.block.code.exec(src);\n        if (cap) {\n            const text = cap[0].replace(this.rules.other.codeRemoveIndent, '');\n            return {\n                type: 'code',\n                raw: cap[0],\n                codeBlockStyle: 'indented',\n                text: !this.options.pedantic\n                    ? rtrim(text, '\\n')\n                    : text,\n            };\n        }\n    }\n    fences(src) {\n        const cap = this.rules.block.fences.exec(src);\n        if (cap) {\n            const raw = cap[0];\n            const text = indentCodeCompensation(raw, cap[3] || '', this.rules);\n            return {\n                type: 'code',\n                raw,\n                lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, '$1') : cap[2],\n                text,\n            };\n        }\n    }\n    heading(src) {\n        const cap = this.rules.block.heading.exec(src);\n        if (cap) {\n            let text = cap[2].trim();\n            // remove trailing #s\n            if (this.rules.other.endingHash.test(text)) {\n                const trimmed = rtrim(text, '#');\n                if (this.options.pedantic) {\n                    text = trimmed.trim();\n                }\n                else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n                    // CommonMark requires space before trailing #s\n                    text = trimmed.trim();\n                }\n            }\n            return {\n                type: 'heading',\n                raw: cap[0],\n                depth: cap[1].length,\n                text,\n                tokens: this.lexer.inline(text),\n            };\n        }\n    }\n    hr(src) {\n        const cap = this.rules.block.hr.exec(src);\n        if (cap) {\n            return {\n                type: 'hr',\n                raw: rtrim(cap[0], '\\n'),\n            };\n        }\n    }\n    blockquote(src) {\n        const cap = this.rules.block.blockquote.exec(src);\n        if (cap) {\n            let lines = rtrim(cap[0], '\\n').split('\\n');\n            let raw = '';\n            let text = '';\n            const tokens = [];\n            while (lines.length > 0) {\n                let inBlockquote = false;\n                const currentLines = [];\n                let i;\n                for (i = 0; i < lines.length; i++) {\n                    // get lines up to a continuation\n                    if (this.rules.other.blockquoteStart.test(lines[i])) {\n                        currentLines.push(lines[i]);\n                        inBlockquote = true;\n                    }\n                    else if (!inBlockquote) {\n                        currentLines.push(lines[i]);\n                    }\n                    else {\n                        break;\n                    }\n                }\n                lines = lines.slice(i);\n                const currentRaw = currentLines.join('\\n');\n                const currentText = currentRaw\n                    // precede setext continuation with 4 spaces so it isn't a setext\n                    .replace(this.rules.other.blockquoteSetextReplace, '\\n    $1')\n                    .replace(this.rules.other.blockquoteSetextReplace2, '');\n                raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n                text = text ? `${text}\\n${currentText}` : currentText;\n                // parse blockquote lines as top level tokens\n                // merge paragraphs if this is a continuation\n                const top = this.lexer.state.top;\n                this.lexer.state.top = true;\n                this.lexer.blockTokens(currentText, tokens, true);\n                this.lexer.state.top = top;\n                // if there is no continuation then we are done\n                if (lines.length === 0) {\n                    break;\n                }\n                const lastToken = tokens.at(-1);\n                if (lastToken?.type === 'code') {\n                    // blockquote continuation cannot be preceded by a code block\n                    break;\n                }\n                else if (lastToken?.type === 'blockquote') {\n                    // include continuation in nested blockquote\n                    const oldToken = lastToken;\n                    const newText = oldToken.raw + '\\n' + lines.join('\\n');\n                    const newToken = this.blockquote(newText);\n                    tokens[tokens.length - 1] = newToken;\n                    raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n                    text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n                    break;\n                }\n                else if (lastToken?.type === 'list') {\n                    // include continuation in nested list\n                    const oldToken = lastToken;\n                    const newText = oldToken.raw + '\\n' + lines.join('\\n');\n                    const newToken = this.list(newText);\n                    tokens[tokens.length - 1] = newToken;\n                    raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n                    text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n                    lines = newText.substring(tokens.at(-1).raw.length).split('\\n');\n                    continue;\n                }\n            }\n            return {\n                type: 'blockquote',\n                raw,\n                tokens,\n                text,\n            };\n        }\n    }\n    list(src) {\n        let cap = this.rules.block.list.exec(src);\n        if (cap) {\n            let bull = cap[1].trim();\n            const isordered = bull.length > 1;\n            const list = {\n                type: 'list',\n                raw: '',\n                ordered: isordered,\n                start: isordered ? +bull.slice(0, -1) : '',\n                loose: false,\n                items: [],\n            };\n            bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n            if (this.options.pedantic) {\n                bull = isordered ? bull : '[*+-]';\n            }\n            // Get next list item\n            const itemRegex = this.rules.other.listItemRegex(bull);\n            let endsWithBlankLine = false;\n            // Check if current bullet point can start a new List Item\n            while (src) {\n                let endEarly = false;\n                let raw = '';\n                let itemContents = '';\n                if (!(cap = itemRegex.exec(src))) {\n                    break;\n                }\n                if (this.rules.block.hr.test(src)) { // End list if bullet was actually HR (possibly move into itemRegex?)\n                    break;\n                }\n                raw = cap[0];\n                src = src.substring(raw.length);\n                let line = cap[2].split('\\n', 1)[0].replace(this.rules.other.listReplaceTabs, (t) => ' '.repeat(3 * t.length));\n                let nextLine = src.split('\\n', 1)[0];\n                let blankLine = !line.trim();\n                let indent = 0;\n                if (this.options.pedantic) {\n                    indent = 2;\n                    itemContents = line.trimStart();\n                }\n                else if (blankLine) {\n                    indent = cap[1].length + 1;\n                }\n                else {\n                    indent = cap[2].search(this.rules.other.nonSpaceChar); // Find first non-space char\n                    indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n                    itemContents = line.slice(indent);\n                    indent += cap[1].length;\n                }\n                if (blankLine && this.rules.other.blankLine.test(nextLine)) { // Items begin with at most one blank line\n                    raw += nextLine + '\\n';\n                    src = src.substring(nextLine.length + 1);\n                    endEarly = true;\n                }\n                if (!endEarly) {\n                    const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n                    const hrRegex = this.rules.other.hrRegex(indent);\n                    const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n                    const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n                    const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n                    // Check if following lines should be included in List Item\n                    while (src) {\n                        const rawLine = src.split('\\n', 1)[0];\n                        let nextLineWithoutTabs;\n                        nextLine = rawLine;\n                        // Re-align to follow commonmark nesting rules\n                        if (this.options.pedantic) {\n                            nextLine = nextLine.replace(this.rules.other.listReplaceNesting, '  ');\n                            nextLineWithoutTabs = nextLine;\n                        }\n                        else {\n                            nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, '    ');\n                        }\n                        // End list item if found code fences\n                        if (fencesBeginRegex.test(nextLine)) {\n                            break;\n                        }\n                        // End list item if found start of new heading\n                        if (headingBeginRegex.test(nextLine)) {\n                            break;\n                        }\n                        // End list item if found start of html block\n                        if (htmlBeginRegex.test(nextLine)) {\n                            break;\n                        }\n                        // End list item if found start of new bullet\n                        if (nextBulletRegex.test(nextLine)) {\n                            break;\n                        }\n                        // Horizontal rule found\n                        if (hrRegex.test(nextLine)) {\n                            break;\n                        }\n                        if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) { // Dedent if possible\n                            itemContents += '\\n' + nextLineWithoutTabs.slice(indent);\n                        }\n                        else {\n                            // not enough indentation\n                            if (blankLine) {\n                                break;\n                            }\n                            // paragraph continuation unless last line was a different block level element\n                            if (line.replace(this.rules.other.tabCharGlobal, '    ').search(this.rules.other.nonSpaceChar) >= 4) { // indented code block\n                                break;\n                            }\n                            if (fencesBeginRegex.test(line)) {\n                                break;\n                            }\n                            if (headingBeginRegex.test(line)) {\n                                break;\n                            }\n                            if (hrRegex.test(line)) {\n                                break;\n                            }\n                            itemContents += '\\n' + nextLine;\n                        }\n                        if (!blankLine && !nextLine.trim()) { // Check if current line is blank\n                            blankLine = true;\n                        }\n                        raw += rawLine + '\\n';\n                        src = src.substring(rawLine.length + 1);\n                        line = nextLineWithoutTabs.slice(indent);\n                    }\n                }\n                if (!list.loose) {\n                    // If the previous item ended with a blank line, the list is loose\n                    if (endsWithBlankLine) {\n                        list.loose = true;\n                    }\n                    else if (this.rules.other.doubleBlankLine.test(raw)) {\n                        endsWithBlankLine = true;\n                    }\n                }\n                let istask = null;\n                let ischecked;\n                // Check for task list items\n                if (this.options.gfm) {\n                    istask = this.rules.other.listIsTask.exec(itemContents);\n                    if (istask) {\n                        ischecked = istask[0] !== '[ ] ';\n                        itemContents = itemContents.replace(this.rules.other.listReplaceTask, '');\n                    }\n                }\n                list.items.push({\n                    type: 'list_item',\n                    raw,\n                    task: !!istask,\n                    checked: ischecked,\n                    loose: false,\n                    text: itemContents,\n                    tokens: [],\n                });\n                list.raw += raw;\n            }\n            // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n            const lastItem = list.items.at(-1);\n            if (lastItem) {\n                lastItem.raw = lastItem.raw.trimEnd();\n                lastItem.text = lastItem.text.trimEnd();\n            }\n            else {\n                // not a list since there were no items\n                return;\n            }\n            list.raw = list.raw.trimEnd();\n            // Item child tokens handled here at end because we needed to have the final item to trim it first\n            for (let i = 0; i < list.items.length; i++) {\n                this.lexer.state.top = false;\n                list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n                if (!list.loose) {\n                    // Check if list should be loose\n                    const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n                    const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n                    list.loose = hasMultipleLineBreaks;\n                }\n            }\n            // Set all items to loose if list is loose\n            if (list.loose) {\n                for (let i = 0; i < list.items.length; i++) {\n                    list.items[i].loose = true;\n                }\n            }\n            return list;\n        }\n    }\n    html(src) {\n        const cap = this.rules.block.html.exec(src);\n        if (cap) {\n            const token = {\n                type: 'html',\n                block: true,\n                raw: cap[0],\n                pre: cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style',\n                text: cap[0],\n            };\n            return token;\n        }\n    }\n    def(src) {\n        const cap = this.rules.block.def.exec(src);\n        if (cap) {\n            const tag = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, ' ');\n            const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, '$1').replace(this.rules.inline.anyPunctuation, '$1') : '';\n            const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, '$1') : cap[3];\n            return {\n                type: 'def',\n                tag,\n                raw: cap[0],\n                href,\n                title,\n            };\n        }\n    }\n    table(src) {\n        const cap = this.rules.block.table.exec(src);\n        if (!cap) {\n            return;\n        }\n        if (!this.rules.other.tableDelimiter.test(cap[2])) {\n            // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n            return;\n        }\n        const headers = splitCells(cap[1]);\n        const aligns = cap[2].replace(this.rules.other.tableAlignChars, '').split('|');\n        const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, '').split('\\n') : [];\n        const item = {\n            type: 'table',\n            raw: cap[0],\n            header: [],\n            align: [],\n            rows: [],\n        };\n        if (headers.length !== aligns.length) {\n            // header and align columns must be equal, rows can be different.\n            return;\n        }\n        for (const align of aligns) {\n            if (this.rules.other.tableAlignRight.test(align)) {\n                item.align.push('right');\n            }\n            else if (this.rules.other.tableAlignCenter.test(align)) {\n                item.align.push('center');\n            }\n            else if (this.rules.other.tableAlignLeft.test(align)) {\n                item.align.push('left');\n            }\n            else {\n                item.align.push(null);\n            }\n        }\n        for (let i = 0; i < headers.length; i++) {\n            item.header.push({\n                text: headers[i],\n                tokens: this.lexer.inline(headers[i]),\n                header: true,\n                align: item.align[i],\n            });\n        }\n        for (const row of rows) {\n            item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n                return {\n                    text: cell,\n                    tokens: this.lexer.inline(cell),\n                    header: false,\n                    align: item.align[i],\n                };\n            }));\n        }\n        return item;\n    }\n    lheading(src) {\n        const cap = this.rules.block.lheading.exec(src);\n        if (cap) {\n            return {\n                type: 'heading',\n                raw: cap[0],\n                depth: cap[2].charAt(0) === '=' ? 1 : 2,\n                text: cap[1],\n                tokens: this.lexer.inline(cap[1]),\n            };\n        }\n    }\n    paragraph(src) {\n        const cap = this.rules.block.paragraph.exec(src);\n        if (cap) {\n            const text = cap[1].charAt(cap[1].length - 1) === '\\n'\n                ? cap[1].slice(0, -1)\n                : cap[1];\n            return {\n                type: 'paragraph',\n                raw: cap[0],\n                text,\n                tokens: this.lexer.inline(text),\n            };\n        }\n    }\n    text(src) {\n        const cap = this.rules.block.text.exec(src);\n        if (cap) {\n            return {\n                type: 'text',\n                raw: cap[0],\n                text: cap[0],\n                tokens: this.lexer.inline(cap[0]),\n            };\n        }\n    }\n    escape(src) {\n        const cap = this.rules.inline.escape.exec(src);\n        if (cap) {\n            return {\n                type: 'escape',\n                raw: cap[0],\n                text: cap[1],\n            };\n        }\n    }\n    tag(src) {\n        const cap = this.rules.inline.tag.exec(src);\n        if (cap) {\n            if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n                this.lexer.state.inLink = true;\n            }\n            else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n                this.lexer.state.inLink = false;\n            }\n            if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n                this.lexer.state.inRawBlock = true;\n            }\n            else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n                this.lexer.state.inRawBlock = false;\n            }\n            return {\n                type: 'html',\n                raw: cap[0],\n                inLink: this.lexer.state.inLink,\n                inRawBlock: this.lexer.state.inRawBlock,\n                block: false,\n                text: cap[0],\n            };\n        }\n    }\n    link(src) {\n        const cap = this.rules.inline.link.exec(src);\n        if (cap) {\n            const trimmedUrl = cap[2].trim();\n            if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n                // commonmark requires matching angle brackets\n                if (!(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n                    return;\n                }\n                // ending angle bracket cannot be escaped\n                const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n                if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n                    return;\n                }\n            }\n            else {\n                // find closing parenthesis\n                const lastParenIndex = findClosingBracket(cap[2], '()');\n                if (lastParenIndex > -1) {\n                    const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n                    const linkLen = start + cap[1].length + lastParenIndex;\n                    cap[2] = cap[2].substring(0, lastParenIndex);\n                    cap[0] = cap[0].substring(0, linkLen).trim();\n                    cap[3] = '';\n                }\n            }\n            let href = cap[2];\n            let title = '';\n            if (this.options.pedantic) {\n                // split pedantic href and title\n                const link = this.rules.other.pedanticHrefTitle.exec(href);\n                if (link) {\n                    href = link[1];\n                    title = link[3];\n                }\n            }\n            else {\n                title = cap[3] ? cap[3].slice(1, -1) : '';\n            }\n            href = href.trim();\n            if (this.rules.other.startAngleBracket.test(href)) {\n                if (this.options.pedantic && !(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n                    // pedantic allows starting angle bracket without ending angle bracket\n                    href = href.slice(1);\n                }\n                else {\n                    href = href.slice(1, -1);\n                }\n            }\n            return outputLink(cap, {\n                href: href ? href.replace(this.rules.inline.anyPunctuation, '$1') : href,\n                title: title ? title.replace(this.rules.inline.anyPunctuation, '$1') : title,\n            }, cap[0], this.lexer, this.rules);\n        }\n    }\n    reflink(src, links) {\n        let cap;\n        if ((cap = this.rules.inline.reflink.exec(src))\n            || (cap = this.rules.inline.nolink.exec(src))) {\n            const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, ' ');\n            const link = links[linkString.toLowerCase()];\n            if (!link) {\n                const text = cap[0].charAt(0);\n                return {\n                    type: 'text',\n                    raw: text,\n                    text,\n                };\n            }\n            return outputLink(cap, link, cap[0], this.lexer, this.rules);\n        }\n    }\n    emStrong(src, maskedSrc, prevChar = '') {\n        let match = this.rules.inline.emStrongLDelim.exec(src);\n        if (!match)\n            return;\n        // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n        if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric))\n            return;\n        const nextChar = match[1] || match[2] || '';\n        if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n            // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n            const lLength = [...match[0]].length - 1;\n            let rDelim, rLength, delimTotal = lLength, midDelimTotal = 0;\n            const endReg = match[0][0] === '*' ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n            endReg.lastIndex = 0;\n            // Clip maskedSrc to same section of string as src (move to lexer?)\n            maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n            while ((match = endReg.exec(maskedSrc)) != null) {\n                rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n                if (!rDelim)\n                    continue; // skip single * in __abc*abc__\n                rLength = [...rDelim].length;\n                if (match[3] || match[4]) { // found another Left Delim\n                    delimTotal += rLength;\n                    continue;\n                }\n                else if (match[5] || match[6]) { // either Left or Right Delim\n                    if (lLength % 3 && !((lLength + rLength) % 3)) {\n                        midDelimTotal += rLength;\n                        continue; // CommonMark Emphasis Rules 9-10\n                    }\n                }\n                delimTotal -= rLength;\n                if (delimTotal > 0)\n                    continue; // Haven't found enough closing delimiters\n                // Remove extra characters. *a*** -> *a*\n                rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n                // char length can be >1 for unicode characters;\n                const lastCharLength = [...match[0]][0].length;\n                const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n                // Create `em` if smallest delimiter has odd char count. *a***\n                if (Math.min(lLength, rLength) % 2) {\n                    const text = raw.slice(1, -1);\n                    return {\n                        type: 'em',\n                        raw,\n                        text,\n                        tokens: this.lexer.inlineTokens(text),\n                    };\n                }\n                // Create 'strong' if smallest delimiter has even char count. **a***\n                const text = raw.slice(2, -2);\n                return {\n                    type: 'strong',\n                    raw,\n                    text,\n                    tokens: this.lexer.inlineTokens(text),\n                };\n            }\n        }\n    }\n    codespan(src) {\n        const cap = this.rules.inline.code.exec(src);\n        if (cap) {\n            let text = cap[2].replace(this.rules.other.newLineCharGlobal, ' ');\n            const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n            const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n            if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n                text = text.substring(1, text.length - 1);\n            }\n            return {\n                type: 'codespan',\n                raw: cap[0],\n                text,\n            };\n        }\n    }\n    br(src) {\n        const cap = this.rules.inline.br.exec(src);\n        if (cap) {\n            return {\n                type: 'br',\n                raw: cap[0],\n            };\n        }\n    }\n    del(src) {\n        const cap = this.rules.inline.del.exec(src);\n        if (cap) {\n            return {\n                type: 'del',\n                raw: cap[0],\n                text: cap[2],\n                tokens: this.lexer.inlineTokens(cap[2]),\n            };\n        }\n    }\n    autolink(src) {\n        const cap = this.rules.inline.autolink.exec(src);\n        if (cap) {\n            let text, href;\n            if (cap[2] === '@') {\n                text = cap[1];\n                href = 'mailto:' + text;\n            }\n            else {\n                text = cap[1];\n                href = text;\n            }\n            return {\n                type: 'link',\n                raw: cap[0],\n                text,\n                href,\n                tokens: [\n                    {\n                        type: 'text',\n                        raw: text,\n                        text,\n                    },\n                ],\n            };\n        }\n    }\n    url(src) {\n        let cap;\n        if (cap = this.rules.inline.url.exec(src)) {\n            let text, href;\n            if (cap[2] === '@') {\n                text = cap[0];\n                href = 'mailto:' + text;\n            }\n            else {\n                // do extended autolink path validation\n                let prevCapZero;\n                do {\n                    prevCapZero = cap[0];\n                    cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? '';\n                } while (prevCapZero !== cap[0]);\n                text = cap[0];\n                if (cap[1] === 'www.') {\n                    href = 'http://' + cap[0];\n                }\n                else {\n                    href = cap[0];\n                }\n            }\n            return {\n                type: 'link',\n                raw: cap[0],\n                text,\n                href,\n                tokens: [\n                    {\n                        type: 'text',\n                        raw: text,\n                        text,\n                    },\n                ],\n            };\n        }\n    }\n    inlineText(src) {\n        const cap = this.rules.inline.text.exec(src);\n        if (cap) {\n            const escaped = this.lexer.state.inRawBlock;\n            return {\n                type: 'text',\n                raw: cap[0],\n                text: cap[0],\n                escaped,\n            };\n        }\n    }\n}\n", "import { _Tokenizer } from './Tokenizer.ts';\nimport { _defaults } from './defaults.ts';\nimport { other, block, inline } from './rules.ts';\n/**\n * Block Lexer\n */\nexport class _Lexer {\n    tokens;\n    options;\n    state;\n    tokenizer;\n    inlineQueue;\n    constructor(options) {\n        // TokenList cannot be created in one go\n        this.tokens = [];\n        this.tokens.links = Object.create(null);\n        this.options = options || _defaults;\n        this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n        this.tokenizer = this.options.tokenizer;\n        this.tokenizer.options = this.options;\n        this.tokenizer.lexer = this;\n        this.inlineQueue = [];\n        this.state = {\n            inLink: false,\n            inRawBlock: false,\n            top: true,\n        };\n        const rules = {\n            other,\n            block: block.normal,\n            inline: inline.normal,\n        };\n        if (this.options.pedantic) {\n            rules.block = block.pedantic;\n            rules.inline = inline.pedantic;\n        }\n        else if (this.options.gfm) {\n            rules.block = block.gfm;\n            if (this.options.breaks) {\n                rules.inline = inline.breaks;\n            }\n            else {\n                rules.inline = inline.gfm;\n            }\n        }\n        this.tokenizer.rules = rules;\n    }\n    /**\n     * Expose Rules\n     */\n    static get rules() {\n        return {\n            block,\n            inline,\n        };\n    }\n    /**\n     * Static Lex Method\n     */\n    static lex(src, options) {\n        const lexer = new _Lexer(options);\n        return lexer.lex(src);\n    }\n    /**\n     * Static Lex Inline Method\n     */\n    static lexInline(src, options) {\n        const lexer = new _Lexer(options);\n        return lexer.inlineTokens(src);\n    }\n    /**\n     * Preprocessing\n     */\n    lex(src) {\n        src = src.replace(other.carriageReturn, '\\n');\n        this.blockTokens(src, this.tokens);\n        for (let i = 0; i < this.inlineQueue.length; i++) {\n            const next = this.inlineQueue[i];\n            this.inlineTokens(next.src, next.tokens);\n        }\n        this.inlineQueue = [];\n        return this.tokens;\n    }\n    blockTokens(src, tokens = [], lastParagraphClipped = false) {\n        if (this.options.pedantic) {\n            src = src.replace(other.tabCharGlobal, '    ').replace(other.spaceLine, '');\n        }\n        while (src) {\n            let token;\n            if (this.options.extensions?.block?.some((extTokenizer) => {\n                if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n                    src = src.substring(token.raw.length);\n                    tokens.push(token);\n                    return true;\n                }\n                return false;\n            })) {\n                continue;\n            }\n            // newline\n            if (token = this.tokenizer.space(src)) {\n                src = src.substring(token.raw.length);\n                const lastToken = tokens.at(-1);\n                if (token.raw.length === 1 && lastToken !== undefined) {\n                    // if there's a single \\n as a spacer, it's terminating the last line,\n                    // so move it there so that we don't get unnecessary paragraph tags\n                    lastToken.raw += '\\n';\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // code\n            if (token = this.tokenizer.code(src)) {\n                src = src.substring(token.raw.length);\n                const lastToken = tokens.at(-1);\n                // An indented code block cannot interrupt a paragraph.\n                if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue.at(-1).src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // fences\n            if (token = this.tokenizer.fences(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // heading\n            if (token = this.tokenizer.heading(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // hr\n            if (token = this.tokenizer.hr(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // blockquote\n            if (token = this.tokenizer.blockquote(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // list\n            if (token = this.tokenizer.list(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // html\n            if (token = this.tokenizer.html(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // def\n            if (token = this.tokenizer.def(src)) {\n                src = src.substring(token.raw.length);\n                const lastToken = tokens.at(-1);\n                if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.raw;\n                    this.inlineQueue.at(-1).src = lastToken.text;\n                }\n                else if (!this.tokens.links[token.tag]) {\n                    this.tokens.links[token.tag] = {\n                        href: token.href,\n                        title: token.title,\n                    };\n                }\n                continue;\n            }\n            // table (gfm)\n            if (token = this.tokenizer.table(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // lheading\n            if (token = this.tokenizer.lheading(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // top-level paragraph\n            // prevent paragraph consuming extensions by clipping 'src' to extension start\n            let cutSrc = src;\n            if (this.options.extensions?.startBlock) {\n                let startIndex = Infinity;\n                const tempSrc = src.slice(1);\n                let tempStart;\n                this.options.extensions.startBlock.forEach((getStartIndex) => {\n                    tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n                    if (typeof tempStart === 'number' && tempStart >= 0) {\n                        startIndex = Math.min(startIndex, tempStart);\n                    }\n                });\n                if (startIndex < Infinity && startIndex >= 0) {\n                    cutSrc = src.substring(0, startIndex + 1);\n                }\n            }\n            if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n                const lastToken = tokens.at(-1);\n                if (lastParagraphClipped && lastToken?.type === 'paragraph') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue.pop();\n                    this.inlineQueue.at(-1).src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                lastParagraphClipped = cutSrc.length !== src.length;\n                src = src.substring(token.raw.length);\n                continue;\n            }\n            // text\n            if (token = this.tokenizer.text(src)) {\n                src = src.substring(token.raw.length);\n                const lastToken = tokens.at(-1);\n                if (lastToken?.type === 'text') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue.pop();\n                    this.inlineQueue.at(-1).src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            if (src) {\n                const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n                if (this.options.silent) {\n                    console.error(errMsg);\n                    break;\n                }\n                else {\n                    throw new Error(errMsg);\n                }\n            }\n        }\n        this.state.top = true;\n        return tokens;\n    }\n    inline(src, tokens = []) {\n        this.inlineQueue.push({ src, tokens });\n        return tokens;\n    }\n    /**\n     * Lexing/Compiling\n     */\n    inlineTokens(src, tokens = []) {\n        // String with links masked to avoid interference with em and strong\n        let maskedSrc = src;\n        let match = null;\n        // Mask out reflinks\n        if (this.tokens.links) {\n            const links = Object.keys(this.tokens.links);\n            if (links.length > 0) {\n                while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n                    if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n                        maskedSrc = maskedSrc.slice(0, match.index)\n                            + '[' + 'a'.repeat(match[0].length - 2) + ']'\n                            + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n                    }\n                }\n            }\n        }\n        // Mask out other blocks\n        while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n            maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n        }\n        // Mask out escaped characters\n        while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n            maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n        }\n        let keepPrevChar = false;\n        let prevChar = '';\n        while (src) {\n            if (!keepPrevChar) {\n                prevChar = '';\n            }\n            keepPrevChar = false;\n            let token;\n            // extensions\n            if (this.options.extensions?.inline?.some((extTokenizer) => {\n                if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n                    src = src.substring(token.raw.length);\n                    tokens.push(token);\n                    return true;\n                }\n                return false;\n            })) {\n                continue;\n            }\n            // escape\n            if (token = this.tokenizer.escape(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // tag\n            if (token = this.tokenizer.tag(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // link\n            if (token = this.tokenizer.link(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // reflink, nolink\n            if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n                src = src.substring(token.raw.length);\n                const lastToken = tokens.at(-1);\n                if (token.type === 'text' && lastToken?.type === 'text') {\n                    lastToken.raw += token.raw;\n                    lastToken.text += token.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // em & strong\n            if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // code\n            if (token = this.tokenizer.codespan(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // br\n            if (token = this.tokenizer.br(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // del (gfm)\n            if (token = this.tokenizer.del(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // autolink\n            if (token = this.tokenizer.autolink(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // url (gfm)\n            if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // text\n            // prevent inlineText consuming extensions by clipping 'src' to extension start\n            let cutSrc = src;\n            if (this.options.extensions?.startInline) {\n                let startIndex = Infinity;\n                const tempSrc = src.slice(1);\n                let tempStart;\n                this.options.extensions.startInline.forEach((getStartIndex) => {\n                    tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n                    if (typeof tempStart === 'number' && tempStart >= 0) {\n                        startIndex = Math.min(startIndex, tempStart);\n                    }\n                });\n                if (startIndex < Infinity && startIndex >= 0) {\n                    cutSrc = src.substring(0, startIndex + 1);\n                }\n            }\n            if (token = this.tokenizer.inlineText(cutSrc)) {\n                src = src.substring(token.raw.length);\n                if (token.raw.slice(-1) !== '_') { // Track prevChar before string of ____ started\n                    prevChar = token.raw.slice(-1);\n                }\n                keepPrevChar = true;\n                const lastToken = tokens.at(-1);\n                if (lastToken?.type === 'text') {\n                    lastToken.raw += token.raw;\n                    lastToken.text += token.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            if (src) {\n                const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n                if (this.options.silent) {\n                    console.error(errMsg);\n                    break;\n                }\n                else {\n                    throw new Error(errMsg);\n                }\n            }\n        }\n        return tokens;\n    }\n}\n", "import { _defaults } from './defaults.ts';\nimport { cleanUrl, escape, } from './helpers.ts';\nimport { other } from './rules.ts';\n/**\n * Renderer\n */\nexport class _Renderer {\n    options;\n    parser; // set by the parser\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    space(token) {\n        return '';\n    }\n    code({ text, lang, escaped }) {\n        const langString = (lang || '').match(other.notSpaceStart)?.[0];\n        const code = text.replace(other.endingNewline, '') + '\\n';\n        if (!langString) {\n            return '<pre><code>'\n                + (escaped ? code : escape(code, true))\n                + '</code></pre>\\n';\n        }\n        return '<pre><code class=\"language-'\n            + escape(langString)\n            + '\">'\n            + (escaped ? code : escape(code, true))\n            + '</code></pre>\\n';\n    }\n    blockquote({ tokens }) {\n        const body = this.parser.parse(tokens);\n        return `<blockquote>\\n${body}</blockquote>\\n`;\n    }\n    html({ text }) {\n        return text;\n    }\n    heading({ tokens, depth }) {\n        return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n    }\n    hr(token) {\n        return '<hr>\\n';\n    }\n    list(token) {\n        const ordered = token.ordered;\n        const start = token.start;\n        let body = '';\n        for (let j = 0; j < token.items.length; j++) {\n            const item = token.items[j];\n            body += this.listitem(item);\n        }\n        const type = ordered ? 'ol' : 'ul';\n        const startAttr = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n        return '<' + type + startAttr + '>\\n' + body + '</' + type + '>\\n';\n    }\n    listitem(item) {\n        let itemBody = '';\n        if (item.task) {\n            const checkbox = this.checkbox({ checked: !!item.checked });\n            if (item.loose) {\n                if (item.tokens[0]?.type === 'paragraph') {\n                    item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n                    if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n                        item.tokens[0].tokens[0].text = checkbox + ' ' + escape(item.tokens[0].tokens[0].text);\n                        item.tokens[0].tokens[0].escaped = true;\n                    }\n                }\n                else {\n                    item.tokens.unshift({\n                        type: 'text',\n                        raw: checkbox + ' ',\n                        text: checkbox + ' ',\n                        escaped: true,\n                    });\n                }\n            }\n            else {\n                itemBody += checkbox + ' ';\n            }\n        }\n        itemBody += this.parser.parse(item.tokens, !!item.loose);\n        return `<li>${itemBody}</li>\\n`;\n    }\n    checkbox({ checked }) {\n        return '<input '\n            + (checked ? 'checked=\"\" ' : '')\n            + 'disabled=\"\" type=\"checkbox\">';\n    }\n    paragraph({ tokens }) {\n        return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n    }\n    table(token) {\n        let header = '';\n        // header\n        let cell = '';\n        for (let j = 0; j < token.header.length; j++) {\n            cell += this.tablecell(token.header[j]);\n        }\n        header += this.tablerow({ text: cell });\n        let body = '';\n        for (let j = 0; j < token.rows.length; j++) {\n            const row = token.rows[j];\n            cell = '';\n            for (let k = 0; k < row.length; k++) {\n                cell += this.tablecell(row[k]);\n            }\n            body += this.tablerow({ text: cell });\n        }\n        if (body)\n            body = `<tbody>${body}</tbody>`;\n        return '<table>\\n'\n            + '<thead>\\n'\n            + header\n            + '</thead>\\n'\n            + body\n            + '</table>\\n';\n    }\n    tablerow({ text }) {\n        return `<tr>\\n${text}</tr>\\n`;\n    }\n    tablecell(token) {\n        const content = this.parser.parseInline(token.tokens);\n        const type = token.header ? 'th' : 'td';\n        const tag = token.align\n            ? `<${type} align=\"${token.align}\">`\n            : `<${type}>`;\n        return tag + content + `</${type}>\\n`;\n    }\n    /**\n     * span level renderer\n     */\n    strong({ tokens }) {\n        return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n    }\n    em({ tokens }) {\n        return `<em>${this.parser.parseInline(tokens)}</em>`;\n    }\n    codespan({ text }) {\n        return `<code>${escape(text, true)}</code>`;\n    }\n    br(token) {\n        return '<br>';\n    }\n    del({ tokens }) {\n        return `<del>${this.parser.parseInline(tokens)}</del>`;\n    }\n    link({ href, title, tokens }) {\n        const text = this.parser.parseInline(tokens);\n        const cleanHref = cleanUrl(href);\n        if (cleanHref === null) {\n            return text;\n        }\n        href = cleanHref;\n        let out = '<a href=\"' + href + '\"';\n        if (title) {\n            out += ' title=\"' + (escape(title)) + '\"';\n        }\n        out += '>' + text + '</a>';\n        return out;\n    }\n    image({ href, title, text }) {\n        const cleanHref = cleanUrl(href);\n        if (cleanHref === null) {\n            return escape(text);\n        }\n        href = cleanHref;\n        let out = `<img src=\"${href}\" alt=\"${text}\"`;\n        if (title) {\n            out += ` title=\"${escape(title)}\"`;\n        }\n        out += '>';\n        return out;\n    }\n    text(token) {\n        return 'tokens' in token && token.tokens\n            ? this.parser.parseInline(token.tokens)\n            : ('escaped' in token && token.escaped ? token.text : escape(token.text));\n    }\n}\n", "/**\n * TextRenderer\n * returns only the textual part of the token\n */\nexport class _TextRenderer {\n    // no need for block level renderers\n    strong({ text }) {\n        return text;\n    }\n    em({ text }) {\n        return text;\n    }\n    codespan({ text }) {\n        return text;\n    }\n    del({ text }) {\n        return text;\n    }\n    html({ text }) {\n        return text;\n    }\n    text({ text }) {\n        return text;\n    }\n    link({ text }) {\n        return '' + text;\n    }\n    image({ text }) {\n        return '' + text;\n    }\n    br() {\n        return '';\n    }\n}\n", "import { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _defaults } from './defaults.ts';\n/**\n * Parsing & Compiling\n */\nexport class _Parser {\n    options;\n    renderer;\n    textRenderer;\n    constructor(options) {\n        this.options = options || _defaults;\n        this.options.renderer = this.options.renderer || new _Renderer();\n        this.renderer = this.options.renderer;\n        this.renderer.options = this.options;\n        this.renderer.parser = this;\n        this.textRenderer = new _TextRenderer();\n    }\n    /**\n     * Static Parse Method\n     */\n    static parse(tokens, options) {\n        const parser = new _Parser(options);\n        return parser.parse(tokens);\n    }\n    /**\n     * Static Parse Inline Method\n     */\n    static parseInline(tokens, options) {\n        const parser = new _Parser(options);\n        return parser.parseInline(tokens);\n    }\n    /**\n     * Parse Loop\n     */\n    parse(tokens, top = true) {\n        let out = '';\n        for (let i = 0; i < tokens.length; i++) {\n            const anyToken = tokens[i];\n            // Run any renderer extensions\n            if (this.options.extensions?.renderers?.[anyToken.type]) {\n                const genericToken = anyToken;\n                const ret = this.options.extensions.renderers[genericToken.type].call({ parser: this }, genericToken);\n                if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'paragraph', 'text'].includes(genericToken.type)) {\n                    out += ret || '';\n                    continue;\n                }\n            }\n            const token = anyToken;\n            switch (token.type) {\n                case 'space': {\n                    out += this.renderer.space(token);\n                    continue;\n                }\n                case 'hr': {\n                    out += this.renderer.hr(token);\n                    continue;\n                }\n                case 'heading': {\n                    out += this.renderer.heading(token);\n                    continue;\n                }\n                case 'code': {\n                    out += this.renderer.code(token);\n                    continue;\n                }\n                case 'table': {\n                    out += this.renderer.table(token);\n                    continue;\n                }\n                case 'blockquote': {\n                    out += this.renderer.blockquote(token);\n                    continue;\n                }\n                case 'list': {\n                    out += this.renderer.list(token);\n                    continue;\n                }\n                case 'html': {\n                    out += this.renderer.html(token);\n                    continue;\n                }\n                case 'paragraph': {\n                    out += this.renderer.paragraph(token);\n                    continue;\n                }\n                case 'text': {\n                    let textToken = token;\n                    let body = this.renderer.text(textToken);\n                    while (i + 1 < tokens.length && tokens[i + 1].type === 'text') {\n                        textToken = tokens[++i];\n                        body += '\\n' + this.renderer.text(textToken);\n                    }\n                    if (top) {\n                        out += this.renderer.paragraph({\n                            type: 'paragraph',\n                            raw: body,\n                            text: body,\n                            tokens: [{ type: 'text', raw: body, text: body, escaped: true }],\n                        });\n                    }\n                    else {\n                        out += body;\n                    }\n                    continue;\n                }\n                default: {\n                    const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n                    if (this.options.silent) {\n                        console.error(errMsg);\n                        return '';\n                    }\n                    else {\n                        throw new Error(errMsg);\n                    }\n                }\n            }\n        }\n        return out;\n    }\n    /**\n     * Parse Inline Tokens\n     */\n    parseInline(tokens, renderer = this.renderer) {\n        let out = '';\n        for (let i = 0; i < tokens.length; i++) {\n            const anyToken = tokens[i];\n            // Run any renderer extensions\n            if (this.options.extensions?.renderers?.[anyToken.type]) {\n                const ret = this.options.extensions.renderers[anyToken.type].call({ parser: this }, anyToken);\n                if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(anyToken.type)) {\n                    out += ret || '';\n                    continue;\n                }\n            }\n            const token = anyToken;\n            switch (token.type) {\n                case 'escape': {\n                    out += renderer.text(token);\n                    break;\n                }\n                case 'html': {\n                    out += renderer.html(token);\n                    break;\n                }\n                case 'link': {\n                    out += renderer.link(token);\n                    break;\n                }\n                case 'image': {\n                    out += renderer.image(token);\n                    break;\n                }\n                case 'strong': {\n                    out += renderer.strong(token);\n                    break;\n                }\n                case 'em': {\n                    out += renderer.em(token);\n                    break;\n                }\n                case 'codespan': {\n                    out += renderer.codespan(token);\n                    break;\n                }\n                case 'br': {\n                    out += renderer.br(token);\n                    break;\n                }\n                case 'del': {\n                    out += renderer.del(token);\n                    break;\n                }\n                case 'text': {\n                    out += renderer.text(token);\n                    break;\n                }\n                default: {\n                    const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n                    if (this.options.silent) {\n                        console.error(errMsg);\n                        return '';\n                    }\n                    else {\n                        throw new Error(errMsg);\n                    }\n                }\n            }\n        }\n        return out;\n    }\n}\n", "import { _defaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nexport class _Hooks {\n    options;\n    block;\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    static passThroughHooks = new Set([\n        'preprocess',\n        'postprocess',\n        'processAllTokens',\n    ]);\n    /**\n     * Process markdown before marked\n     */\n    preprocess(markdown) {\n        return markdown;\n    }\n    /**\n     * Process HTML after marked is finished\n     */\n    postprocess(html) {\n        return html;\n    }\n    /**\n     * Process all tokens before walk tokens\n     */\n    processAllTokens(tokens) {\n        return tokens;\n    }\n    /**\n     * Provide function to tokenize markdown\n     */\n    provideLexer() {\n        return this.block ? _Lexer.lex : _Lexer.lexInline;\n    }\n    /**\n     * Provide function to parse tokens\n     */\n    provideParser() {\n        return this.block ? _Parser.parse : _Parser.parseInline;\n    }\n}\n", "import { _getDefaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { escape } from './helpers.ts';\nexport class Marked {\n    defaults = _getDefaults();\n    options = this.setOptions;\n    parse = this.parseMarkdown(true);\n    parseInline = this.parseMarkdown(false);\n    Parser = _Parser;\n    Renderer = _Renderer;\n    TextRenderer = _TextRenderer;\n    Lexer = _Lexer;\n    Tokenizer = _Tokenizer;\n    Hooks = _Hooks;\n    constructor(...args) {\n        this.use(...args);\n    }\n    /**\n     * Run callback for every token\n     */\n    walkTokens(tokens, callback) {\n        let values = [];\n        for (const token of tokens) {\n            values = values.concat(callback.call(this, token));\n            switch (token.type) {\n                case 'table': {\n                    const tableToken = token;\n                    for (const cell of tableToken.header) {\n                        values = values.concat(this.walkTokens(cell.tokens, callback));\n                    }\n                    for (const row of tableToken.rows) {\n                        for (const cell of row) {\n                            values = values.concat(this.walkTokens(cell.tokens, callback));\n                        }\n                    }\n                    break;\n                }\n                case 'list': {\n                    const listToken = token;\n                    values = values.concat(this.walkTokens(listToken.items, callback));\n                    break;\n                }\n                default: {\n                    const genericToken = token;\n                    if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n                        this.defaults.extensions.childTokens[genericToken.type].forEach((childTokens) => {\n                            const tokens = genericToken[childTokens].flat(Infinity);\n                            values = values.concat(this.walkTokens(tokens, callback));\n                        });\n                    }\n                    else if (genericToken.tokens) {\n                        values = values.concat(this.walkTokens(genericToken.tokens, callback));\n                    }\n                }\n            }\n        }\n        return values;\n    }\n    use(...args) {\n        const extensions = this.defaults.extensions || { renderers: {}, childTokens: {} };\n        args.forEach((pack) => {\n            // copy options to new object\n            const opts = { ...pack };\n            // set async to true if it was set to true before\n            opts.async = this.defaults.async || opts.async || false;\n            // ==-- Parse \"addon\" extensions --== //\n            if (pack.extensions) {\n                pack.extensions.forEach((ext) => {\n                    if (!ext.name) {\n                        throw new Error('extension name required');\n                    }\n                    if ('renderer' in ext) { // Renderer extensions\n                        const prevRenderer = extensions.renderers[ext.name];\n                        if (prevRenderer) {\n                            // Replace extension with func to run new extension but fall back if false\n                            extensions.renderers[ext.name] = function (...args) {\n                                let ret = ext.renderer.apply(this, args);\n                                if (ret === false) {\n                                    ret = prevRenderer.apply(this, args);\n                                }\n                                return ret;\n                            };\n                        }\n                        else {\n                            extensions.renderers[ext.name] = ext.renderer;\n                        }\n                    }\n                    if ('tokenizer' in ext) { // Tokenizer Extensions\n                        if (!ext.level || (ext.level !== 'block' && ext.level !== 'inline')) {\n                            throw new Error(\"extension level must be 'block' or 'inline'\");\n                        }\n                        const extLevel = extensions[ext.level];\n                        if (extLevel) {\n                            extLevel.unshift(ext.tokenizer);\n                        }\n                        else {\n                            extensions[ext.level] = [ext.tokenizer];\n                        }\n                        if (ext.start) { // Function to check for start of token\n                            if (ext.level === 'block') {\n                                if (extensions.startBlock) {\n                                    extensions.startBlock.push(ext.start);\n                                }\n                                else {\n                                    extensions.startBlock = [ext.start];\n                                }\n                            }\n                            else if (ext.level === 'inline') {\n                                if (extensions.startInline) {\n                                    extensions.startInline.push(ext.start);\n                                }\n                                else {\n                                    extensions.startInline = [ext.start];\n                                }\n                            }\n                        }\n                    }\n                    if ('childTokens' in ext && ext.childTokens) { // Child tokens to be visited by walkTokens\n                        extensions.childTokens[ext.name] = ext.childTokens;\n                    }\n                });\n                opts.extensions = extensions;\n            }\n            // ==-- Parse \"overwrite\" extensions --== //\n            if (pack.renderer) {\n                const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n                for (const prop in pack.renderer) {\n                    if (!(prop in renderer)) {\n                        throw new Error(`renderer '${prop}' does not exist`);\n                    }\n                    if (['options', 'parser'].includes(prop)) {\n                        // ignore options property\n                        continue;\n                    }\n                    const rendererProp = prop;\n                    const rendererFunc = pack.renderer[rendererProp];\n                    const prevRenderer = renderer[rendererProp];\n                    // Replace renderer with func to run extension, but fall back if false\n                    renderer[rendererProp] = (...args) => {\n                        let ret = rendererFunc.apply(renderer, args);\n                        if (ret === false) {\n                            ret = prevRenderer.apply(renderer, args);\n                        }\n                        return ret || '';\n                    };\n                }\n                opts.renderer = renderer;\n            }\n            if (pack.tokenizer) {\n                const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n                for (const prop in pack.tokenizer) {\n                    if (!(prop in tokenizer)) {\n                        throw new Error(`tokenizer '${prop}' does not exist`);\n                    }\n                    if (['options', 'rules', 'lexer'].includes(prop)) {\n                        // ignore options, rules, and lexer properties\n                        continue;\n                    }\n                    const tokenizerProp = prop;\n                    const tokenizerFunc = pack.tokenizer[tokenizerProp];\n                    const prevTokenizer = tokenizer[tokenizerProp];\n                    // Replace tokenizer with func to run extension, but fall back if false\n                    // @ts-expect-error cannot type tokenizer function dynamically\n                    tokenizer[tokenizerProp] = (...args) => {\n                        let ret = tokenizerFunc.apply(tokenizer, args);\n                        if (ret === false) {\n                            ret = prevTokenizer.apply(tokenizer, args);\n                        }\n                        return ret;\n                    };\n                }\n                opts.tokenizer = tokenizer;\n            }\n            // ==-- Parse Hooks extensions --== //\n            if (pack.hooks) {\n                const hooks = this.defaults.hooks || new _Hooks();\n                for (const prop in pack.hooks) {\n                    if (!(prop in hooks)) {\n                        throw new Error(`hook '${prop}' does not exist`);\n                    }\n                    if (['options', 'block'].includes(prop)) {\n                        // ignore options and block properties\n                        continue;\n                    }\n                    const hooksProp = prop;\n                    const hooksFunc = pack.hooks[hooksProp];\n                    const prevHook = hooks[hooksProp];\n                    if (_Hooks.passThroughHooks.has(prop)) {\n                        // @ts-expect-error cannot type hook function dynamically\n                        hooks[hooksProp] = (arg) => {\n                            if (this.defaults.async) {\n                                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret => {\n                                    return prevHook.call(hooks, ret);\n                                });\n                            }\n                            const ret = hooksFunc.call(hooks, arg);\n                            return prevHook.call(hooks, ret);\n                        };\n                    }\n                    else {\n                        // @ts-expect-error cannot type hook function dynamically\n                        hooks[hooksProp] = (...args) => {\n                            let ret = hooksFunc.apply(hooks, args);\n                            if (ret === false) {\n                                ret = prevHook.apply(hooks, args);\n                            }\n                            return ret;\n                        };\n                    }\n                }\n                opts.hooks = hooks;\n            }\n            // ==-- Parse WalkTokens extensions --== //\n            if (pack.walkTokens) {\n                const walkTokens = this.defaults.walkTokens;\n                const packWalktokens = pack.walkTokens;\n                opts.walkTokens = function (token) {\n                    let values = [];\n                    values.push(packWalktokens.call(this, token));\n                    if (walkTokens) {\n                        values = values.concat(walkTokens.call(this, token));\n                    }\n                    return values;\n                };\n            }\n            this.defaults = { ...this.defaults, ...opts };\n        });\n        return this;\n    }\n    setOptions(opt) {\n        this.defaults = { ...this.defaults, ...opt };\n        return this;\n    }\n    lexer(src, options) {\n        return _Lexer.lex(src, options ?? this.defaults);\n    }\n    parser(tokens, options) {\n        return _Parser.parse(tokens, options ?? this.defaults);\n    }\n    parseMarkdown(blockType) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const parse = (src, options) => {\n            const origOpt = { ...options };\n            const opt = { ...this.defaults, ...origOpt };\n            const throwError = this.onError(!!opt.silent, !!opt.async);\n            // throw error if an extension set async to true but parse was called with async: false\n            if (this.defaults.async === true && origOpt.async === false) {\n                return throwError(new Error('marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.'));\n            }\n            // throw error in case of non string input\n            if (typeof src === 'undefined' || src === null) {\n                return throwError(new Error('marked(): input parameter is undefined or null'));\n            }\n            if (typeof src !== 'string') {\n                return throwError(new Error('marked(): input parameter is of type '\n                    + Object.prototype.toString.call(src) + ', string expected'));\n            }\n            if (opt.hooks) {\n                opt.hooks.options = opt;\n                opt.hooks.block = blockType;\n            }\n            const lexer = opt.hooks ? opt.hooks.provideLexer() : (blockType ? _Lexer.lex : _Lexer.lexInline);\n            const parser = opt.hooks ? opt.hooks.provideParser() : (blockType ? _Parser.parse : _Parser.parseInline);\n            if (opt.async) {\n                return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n                    .then(src => lexer(src, opt))\n                    .then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens)\n                    .then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens)\n                    .then(tokens => parser(tokens, opt))\n                    .then(html => opt.hooks ? opt.hooks.postprocess(html) : html)\n                    .catch(throwError);\n            }\n            try {\n                if (opt.hooks) {\n                    src = opt.hooks.preprocess(src);\n                }\n                let tokens = lexer(src, opt);\n                if (opt.hooks) {\n                    tokens = opt.hooks.processAllTokens(tokens);\n                }\n                if (opt.walkTokens) {\n                    this.walkTokens(tokens, opt.walkTokens);\n                }\n                let html = parser(tokens, opt);\n                if (opt.hooks) {\n                    html = opt.hooks.postprocess(html);\n                }\n                return html;\n            }\n            catch (e) {\n                return throwError(e);\n            }\n        };\n        return parse;\n    }\n    onError(silent, async) {\n        return (e) => {\n            e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n            if (silent) {\n                const msg = '<p>An error occurred:</p><pre>'\n                    + escape(e.message + '', true)\n                    + '</pre>';\n                if (async) {\n                    return Promise.resolve(msg);\n                }\n                return msg;\n            }\n            if (async) {\n                return Promise.reject(e);\n            }\n            throw e;\n        };\n    }\n}\n", "import { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { Marked } from './Instance.ts';\nimport { _getDefaults, changeDefaults, _defaults, } from './defaults.ts';\nconst markedInstance = new Marked();\nexport function marked(src, opt) {\n    return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options =\n    marked.setOptions = function (options) {\n        markedInstance.setOptions(options);\n        marked.defaults = markedInstance.defaults;\n        changeDefaults(marked.defaults);\n        return marked;\n    };\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n    markedInstance.use(...args);\n    marked.defaults = markedInstance.defaults;\n    changeDefaults(marked.defaults);\n    return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n    return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nexport const options = marked.options;\nexport const setOptions = marked.setOptions;\nexport const use = marked.use;\nexport const walkTokens = marked.walkTokens;\nexport const parseInline = marked.parseInline;\nexport const parse = marked;\nexport const parser = _Parser.parse;\nexport const lexer = _Lexer.lex;\nexport { _defaults as defaults, _getDefaults as getDefaults } from './defaults.ts';\nexport { _Lexer as Lexer } from './Lexer.ts';\nexport { _Parser as Parser } from './Parser.ts';\nexport { _Tokenizer as Tokenizer } from './Tokenizer.ts';\nexport { _Renderer as Renderer } from './Renderer.ts';\nexport { _TextRenderer as TextRenderer } from './TextRenderer.ts';\nexport { _Hooks as Hooks } from './Hooks.ts';\nexport { Marked } from './Instance.ts';\n", "import type { Format } from './types';\n\nexport const default_format: Format = 'RFC3986';\nexport const formatters: Record<Format, (str: PropertyKey) => string> = {\n  RFC1738: (v: PropertyKey) => String(v).replace(/%20/g, '+'),\n  RFC3986: (v: PropertyKey) => String(v),\n};\nexport const RFC1738 = 'RFC1738';\nexport const RFC3986 = 'RFC3986';\n", "import { RFC1738 } from './formats';\nimport type { DefaultEncoder, Format } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\nconst is_array = Array.isArray;\n\nconst hex_table = (() => {\n  const array = [];\n  for (let i = 0; i < 256; ++i) {\n    array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n  }\n\n  return array;\n})();\n\nfunction compact_queue<T extends Record<string, any>>(queue: Array<{ obj: T; prop: string }>) {\n  while (queue.length > 1) {\n    const item = queue.pop();\n    if (!item) continue;\n\n    const obj = item.obj[item.prop];\n\n    if (is_array(obj)) {\n      const compacted: unknown[] = [];\n\n      for (let j = 0; j < obj.length; ++j) {\n        if (typeof obj[j] !== 'undefined') {\n          compacted.push(obj[j]);\n        }\n      }\n\n      // @ts-ignore\n      item.obj[item.prop] = compacted;\n    }\n  }\n}\n\nfunction array_to_object(source: any[], options: { plainObjects: boolean }) {\n  const obj = options && options.plainObjects ? Object.create(null) : {};\n  for (let i = 0; i < source.length; ++i) {\n    if (typeof source[i] !== 'undefined') {\n      obj[i] = source[i];\n    }\n  }\n\n  return obj;\n}\n\nexport function merge(\n  target: any,\n  source: any,\n  options: { plainObjects?: boolean; allowPrototypes?: boolean } = {},\n) {\n  if (!source) {\n    return target;\n  }\n\n  if (typeof source !== 'object') {\n    if (is_array(target)) {\n      target.push(source);\n    } else if (target && typeof target === 'object') {\n      if (\n        (options && (options.plainObjects || options.allowPrototypes)) ||\n        !has.call(Object.prototype, source)\n      ) {\n        target[source] = true;\n      }\n    } else {\n      return [target, source];\n    }\n\n    return target;\n  }\n\n  if (!target || typeof target !== 'object') {\n    return [target].concat(source);\n  }\n\n  let mergeTarget = target;\n  if (is_array(target) && !is_array(source)) {\n    // @ts-ignore\n    mergeTarget = array_to_object(target, options);\n  }\n\n  if (is_array(target) && is_array(source)) {\n    source.forEach(function (item, i) {\n      if (has.call(target, i)) {\n        const targetItem = target[i];\n        if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n          target[i] = merge(targetItem, item, options);\n        } else {\n          target.push(item);\n        }\n      } else {\n        target[i] = item;\n      }\n    });\n    return target;\n  }\n\n  return Object.keys(source).reduce(function (acc, key) {\n    const value = source[key];\n\n    if (has.call(acc, key)) {\n      acc[key] = merge(acc[key], value, options);\n    } else {\n      acc[key] = value;\n    }\n    return acc;\n  }, mergeTarget);\n}\n\nexport function assign_single_source(target: any, source: any) {\n  return Object.keys(source).reduce(function (acc, key) {\n    acc[key] = source[key];\n    return acc;\n  }, target);\n}\n\nexport function decode(str: string, _: any, charset: string) {\n  const strWithoutPlus = str.replace(/\\+/g, ' ');\n  if (charset === 'iso-8859-1') {\n    // unescape never throws, no try...catch needed:\n    return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n  }\n  // utf-8\n  try {\n    return decodeURIComponent(strWithoutPlus);\n  } catch (e) {\n    return strWithoutPlus;\n  }\n}\n\nconst limit = 1024;\n\nexport const encode: (\n  str: any,\n  defaultEncoder: DefaultEncoder,\n  charset: string,\n  type: 'key' | 'value',\n  format: Format,\n) => string = (str, _defaultEncoder, charset, _kind, format: Format) => {\n  // This code was originally written by Brian White for the io.js core querystring library.\n  // It has been adapted here for stricter adherence to RFC 3986\n  if (str.length === 0) {\n    return str;\n  }\n\n  let string = str;\n  if (typeof str === 'symbol') {\n    string = Symbol.prototype.toString.call(str);\n  } else if (typeof str !== 'string') {\n    string = String(str);\n  }\n\n  if (charset === 'iso-8859-1') {\n    return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n      return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n    });\n  }\n\n  let out = '';\n  for (let j = 0; j < string.length; j += limit) {\n    const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n    const arr = [];\n\n    for (let i = 0; i < segment.length; ++i) {\n      let c = segment.charCodeAt(i);\n      if (\n        c === 0x2d || // -\n        c === 0x2e || // .\n        c === 0x5f || // _\n        c === 0x7e || // ~\n        (c >= 0x30 && c <= 0x39) || // 0-9\n        (c >= 0x41 && c <= 0x5a) || // a-z\n        (c >= 0x61 && c <= 0x7a) || // A-Z\n        (format === RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n      ) {\n        arr[arr.length] = segment.charAt(i);\n        continue;\n      }\n\n      if (c < 0x80) {\n        arr[arr.length] = hex_table[c];\n        continue;\n      }\n\n      if (c < 0x800) {\n        arr[arr.length] = hex_table[0xc0 | (c >> 6)]! + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      if (c < 0xd800 || c >= 0xe000) {\n        arr[arr.length] =\n          hex_table[0xe0 | (c >> 12)]! + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      i += 1;\n      c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n\n      arr[arr.length] =\n        hex_table[0xf0 | (c >> 18)]! +\n        hex_table[0x80 | ((c >> 12) & 0x3f)] +\n        hex_table[0x80 | ((c >> 6) & 0x3f)] +\n        hex_table[0x80 | (c & 0x3f)];\n    }\n\n    out += arr.join('');\n  }\n\n  return out;\n};\n\nexport function compact(value: any) {\n  const queue = [{ obj: { o: value }, prop: 'o' }];\n  const refs = [];\n\n  for (let i = 0; i < queue.length; ++i) {\n    const item = queue[i];\n    // @ts-ignore\n    const obj = item.obj[item.prop];\n\n    const keys = Object.keys(obj);\n    for (let j = 0; j < keys.length; ++j) {\n      const key = keys[j]!;\n      const val = obj[key];\n      if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n        queue.push({ obj: obj, prop: key });\n        refs.push(val);\n      }\n    }\n  }\n\n  compact_queue(queue);\n\n  return value;\n}\n\nexport function is_regexp(obj: any) {\n  return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\n\nexport function is_buffer(obj: any) {\n  if (!obj || typeof obj !== 'object') {\n    return false;\n  }\n\n  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\n\nexport function combine(a: any, b: any) {\n  return [].concat(a, b);\n}\n\nexport function maybe_map<T>(val: T[], fn: (v: T) => T) {\n  if (is_array(val)) {\n    const mapped = [];\n    for (let i = 0; i < val.length; i += 1) {\n      mapped.push(fn(val[i]!));\n    }\n    return mapped;\n  }\n  return fn(val);\n}\n", "import { encode, is_buffer, maybe_map } from './utils';\nimport { default_format, formatters } from './formats';\nimport type { NonNullableProperties, StringifyOptions } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\n\nconst array_prefix_generators = {\n  brackets(prefix: PropertyKey) {\n    return String(prefix) + '[]';\n  },\n  comma: 'comma',\n  indices(prefix: PropertyKey, key: string) {\n    return String(prefix) + '[' + key + ']';\n  },\n  repeat(prefix: PropertyKey) {\n    return String(prefix);\n  },\n};\n\nconst is_array = Array.isArray;\nconst push = Array.prototype.push;\nconst push_to_array = function (arr: any[], value_or_array: any) {\n  push.apply(arr, is_array(value_or_array) ? value_or_array : [value_or_array]);\n};\n\nconst to_ISO = Date.prototype.toISOString;\n\nconst defaults = {\n  addQueryPrefix: false,\n  allowDots: false,\n  allowEmptyArrays: false,\n  arrayFormat: 'indices',\n  charset: 'utf-8',\n  charsetSentinel: false,\n  delimiter: '&',\n  encode: true,\n  encodeDotInKeys: false,\n  encoder: encode,\n  encodeValuesOnly: false,\n  format: default_format,\n  formatter: formatters[default_format],\n  /** @deprecated */\n  indices: false,\n  serializeDate(date) {\n    return to_ISO.call(date);\n  },\n  skipNulls: false,\n  strictNullHandling: false,\n} as NonNullableProperties<StringifyOptions & { formatter: (typeof formatters)['RFC1738'] }>;\n\nfunction is_non_nullish_primitive(v: unknown): v is string | number | boolean | symbol | bigint {\n  return (\n    typeof v === 'string' ||\n    typeof v === 'number' ||\n    typeof v === 'boolean' ||\n    typeof v === 'symbol' ||\n    typeof v === 'bigint'\n  );\n}\n\nconst sentinel = {};\n\nfunction inner_stringify(\n  object: any,\n  prefix: PropertyKey,\n  generateArrayPrefix: StringifyOptions['arrayFormat'] | ((prefix: string, key: string) => string),\n  commaRoundTrip: boolean,\n  allowEmptyArrays: boolean,\n  strictNullHandling: boolean,\n  skipNulls: boolean,\n  encodeDotInKeys: boolean,\n  encoder: StringifyOptions['encoder'],\n  filter: StringifyOptions['filter'],\n  sort: StringifyOptions['sort'],\n  allowDots: StringifyOptions['allowDots'],\n  serializeDate: StringifyOptions['serializeDate'],\n  format: StringifyOptions['format'],\n  formatter: StringifyOptions['formatter'],\n  encodeValuesOnly: boolean,\n  charset: StringifyOptions['charset'],\n  sideChannel: WeakMap<any, any>,\n) {\n  let obj = object;\n\n  let tmp_sc = sideChannel;\n  let step = 0;\n  let find_flag = false;\n  while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n    // Where object last appeared in the ref tree\n    const pos = tmp_sc.get(object);\n    step += 1;\n    if (typeof pos !== 'undefined') {\n      if (pos === step) {\n        throw new RangeError('Cyclic object value');\n      } else {\n        find_flag = true; // Break while\n      }\n    }\n    if (typeof tmp_sc.get(sentinel) === 'undefined') {\n      step = 0;\n    }\n  }\n\n  if (typeof filter === 'function') {\n    obj = filter(prefix, obj);\n  } else if (obj instanceof Date) {\n    obj = serializeDate?.(obj);\n  } else if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    obj = maybe_map(obj, function (value) {\n      if (value instanceof Date) {\n        return serializeDate?.(value);\n      }\n      return value;\n    });\n  }\n\n  if (obj === null) {\n    if (strictNullHandling) {\n      return encoder && !encodeValuesOnly ?\n          // @ts-expect-error\n          encoder(prefix, defaults.encoder, charset, 'key', format)\n        : prefix;\n    }\n\n    obj = '';\n  }\n\n  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {\n    if (encoder) {\n      const key_value =\n        encodeValuesOnly ? prefix\n          // @ts-expect-error\n        : encoder(prefix, defaults.encoder, charset, 'key', format);\n      return [\n        formatter?.(key_value) +\n          '=' +\n          // @ts-expect-error\n          formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n      ];\n    }\n    return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n  }\n\n  const values: string[] = [];\n\n  if (typeof obj === 'undefined') {\n    return values;\n  }\n\n  let obj_keys;\n  if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    // we need to join elements in\n    if (encodeValuesOnly && encoder) {\n      // @ts-expect-error values only\n      obj = maybe_map(obj, encoder);\n    }\n    obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n  } else if (is_array(filter)) {\n    obj_keys = filter;\n  } else {\n    const keys = Object.keys(obj);\n    obj_keys = sort ? keys.sort(sort) : keys;\n  }\n\n  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n\n  const adjusted_prefix =\n    commaRoundTrip && is_array(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n\n  if (allowEmptyArrays && is_array(obj) && obj.length === 0) {\n    return adjusted_prefix + '[]';\n  }\n\n  for (let j = 0; j < obj_keys.length; ++j) {\n    const key = obj_keys[j];\n    const value =\n      // @ts-ignore\n      typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key as any];\n\n    if (skipNulls && value === null) {\n      continue;\n    }\n\n    // @ts-ignore\n    const encoded_key = allowDots && encodeDotInKeys ? (key as any).replace(/\\./g, '%2E') : key;\n    const key_prefix =\n      is_array(obj) ?\n        typeof generateArrayPrefix === 'function' ?\n          generateArrayPrefix(adjusted_prefix, encoded_key)\n        : adjusted_prefix\n      : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n\n    sideChannel.set(object, step);\n    const valueSideChannel = new WeakMap();\n    valueSideChannel.set(sentinel, sideChannel);\n    push_to_array(\n      values,\n      inner_stringify(\n        value,\n        key_prefix,\n        generateArrayPrefix,\n        commaRoundTrip,\n        allowEmptyArrays,\n        strictNullHandling,\n        skipNulls,\n        encodeDotInKeys,\n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && is_array(obj) ? null : encoder,\n        filter,\n        sort,\n        allowDots,\n        serializeDate,\n        format,\n        formatter,\n        encodeValuesOnly,\n        charset,\n        valueSideChannel,\n      ),\n    );\n  }\n\n  return values;\n}\n\nfunction normalize_stringify_options(\n  opts: StringifyOptions = defaults,\n): NonNullableProperties<Omit<StringifyOptions, 'indices'>> & { indices?: boolean } {\n  if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n    throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n  }\n\n  if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n    throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n  }\n\n  if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n    throw new TypeError('Encoder has to be a function.');\n  }\n\n  const charset = opts.charset || defaults.charset;\n  if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n    throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n  }\n\n  let format = default_format;\n  if (typeof opts.format !== 'undefined') {\n    if (!has.call(formatters, opts.format)) {\n      throw new TypeError('Unknown format option provided.');\n    }\n    format = opts.format;\n  }\n  const formatter = formatters[format];\n\n  let filter = defaults.filter;\n  if (typeof opts.filter === 'function' || is_array(opts.filter)) {\n    filter = opts.filter;\n  }\n\n  let arrayFormat: StringifyOptions['arrayFormat'];\n  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n    arrayFormat = opts.arrayFormat;\n  } else if ('indices' in opts) {\n    arrayFormat = opts.indices ? 'indices' : 'repeat';\n  } else {\n    arrayFormat = defaults.arrayFormat;\n  }\n\n  if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n    throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n  }\n\n  const allowDots =\n    typeof opts.allowDots === 'undefined' ?\n      !!opts.encodeDotInKeys === true ?\n        true\n      : defaults.allowDots\n    : !!opts.allowDots;\n\n  return {\n    addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n    // @ts-ignore\n    allowDots: allowDots,\n    allowEmptyArrays:\n      typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n    arrayFormat: arrayFormat,\n    charset: charset,\n    charsetSentinel:\n      typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n    commaRoundTrip: !!opts.commaRoundTrip,\n    delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n    encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n    encodeDotInKeys:\n      typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n    encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n    encodeValuesOnly:\n      typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n    filter: filter,\n    format: format,\n    formatter: formatter,\n    serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n    skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n    // @ts-ignore\n    sort: typeof opts.sort === 'function' ? opts.sort : null,\n    strictNullHandling:\n      typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n  };\n}\n\nexport function stringify(object: any, opts: StringifyOptions = {}) {\n  let obj = object;\n  const options = normalize_stringify_options(opts);\n\n  let obj_keys: PropertyKey[] | undefined;\n  let filter;\n\n  if (typeof options.filter === 'function') {\n    filter = options.filter;\n    obj = filter('', obj);\n  } else if (is_array(options.filter)) {\n    filter = options.filter;\n    obj_keys = filter;\n  }\n\n  const keys: string[] = [];\n\n  if (typeof obj !== 'object' || obj === null) {\n    return '';\n  }\n\n  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n  const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n  if (!obj_keys) {\n    obj_keys = Object.keys(obj);\n  }\n\n  if (options.sort) {\n    obj_keys.sort(options.sort);\n  }\n\n  const sideChannel = new WeakMap();\n  for (let i = 0; i < obj_keys.length; ++i) {\n    const key = obj_keys[i]!;\n\n    if (options.skipNulls && obj[key] === null) {\n      continue;\n    }\n    push_to_array(\n      keys,\n      inner_stringify(\n        obj[key],\n        key,\n        // @ts-expect-error\n        generateArrayPrefix,\n        commaRoundTrip,\n        options.allowEmptyArrays,\n        options.strictNullHandling,\n        options.skipNulls,\n        options.encodeDotInKeys,\n        options.encode ? options.encoder : null,\n        options.filter,\n        options.sort,\n        options.allowDots,\n        options.serializeDate,\n        options.format,\n        options.formatter,\n        options.encodeValuesOnly,\n        options.charset,\n        sideChannel,\n      ),\n    );\n  }\n\n  const joined = keys.join(options.delimiter);\n  let prefix = options.addQueryPrefix === true ? '?' : '';\n\n  if (options.charsetSentinel) {\n    if (options.charset === 'iso-8859-1') {\n      // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n      prefix += 'utf8=%26%2310003%3B&';\n    } else {\n      // encodeURIComponent('\u2713')\n      prefix += 'utf8=%E2%9C%93&';\n    }\n  }\n\n  return joined.length > 0 ? prefix + joined : '';\n}\n", "export const VERSION = '4.87.3'; // x-release-please-version\n", "/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport { type RequestOptions } from '../core';\n\nexport interface Shims {\n  kind: string;\n  fetch: any;\n  Request: any;\n  Response: any;\n  Headers: any;\n  FormData: any;\n  Blob: any;\n  File: any;\n  ReadableStream: any;\n  getMultipartRequestOptions: <T = Record<string, unknown>>(\n    form: Shims['FormData'],\n    opts: RequestOptions<T>,\n  ) => Promise<RequestOptions<T>>;\n  getDefaultAgent: (url: string) => any;\n  fileFromPath:\n    | ((path: string, filename?: string, options?: {}) => Promise<Shims['File']>)\n    | ((path: string, options?: {}) => Promise<Shims['File']>);\n  isFsReadStream: (value: any) => boolean;\n}\n\nexport let auto = false;\nexport let kind: Shims['kind'] | undefined = undefined;\nexport let fetch: Shims['fetch'] | undefined = undefined;\nexport let Request: Shims['Request'] | undefined = undefined;\nexport let Response: Shims['Response'] | undefined = undefined;\nexport let Headers: Shims['Headers'] | undefined = undefined;\nexport let FormData: Shims['FormData'] | undefined = undefined;\nexport let Blob: Shims['Blob'] | undefined = undefined;\nexport let File: Shims['File'] | undefined = undefined;\nexport let ReadableStream: Shims['ReadableStream'] | undefined = undefined;\nexport let getMultipartRequestOptions: Shims['getMultipartRequestOptions'] | undefined = undefined;\nexport let getDefaultAgent: Shims['getDefaultAgent'] | undefined = undefined;\nexport let fileFromPath: Shims['fileFromPath'] | undefined = undefined;\nexport let isFsReadStream: Shims['isFsReadStream'] | undefined = undefined;\n\nexport function setShims(shims: Shims, options: { auto: boolean } = { auto: false }) {\n  if (auto) {\n    throw new Error(\n      `you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`,\n    );\n  }\n  if (kind) {\n    throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\n  }\n  auto = options.auto;\n  kind = shims.kind;\n  fetch = shims.fetch;\n  Request = shims.Request;\n  Response = shims.Response;\n  Headers = shims.Headers;\n  FormData = shims.FormData;\n  Blob = shims.Blob;\n  File = shims.File;\n  ReadableStream = shims.ReadableStream;\n  getMultipartRequestOptions = shims.getMultipartRequestOptions;\n  getDefaultAgent = shims.getDefaultAgent;\n  fileFromPath = shims.fileFromPath;\n  isFsReadStream = shims.isFsReadStream;\n}\n", "/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nexport class MultipartBody {\n  constructor(public body: any) {}\n  get [Symbol.toStringTag](): string {\n    return 'MultipartBody';\n  }\n}\n", "/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport { MultipartBody } from './MultipartBody';\nimport { type RequestOptions } from '../core';\nimport { type Shims } from './registry';\n\nexport function getRuntime({ manuallyImported }: { manuallyImported?: boolean } = {}): Shims {\n  const recommendation =\n    manuallyImported ?\n      `You may need to use polyfills`\n    : `Add one of these imports before your first \\`import \u2026 from 'openai'\\`:\n- \\`import 'openai/shims/node'\\` (if you're running on Node)\n- \\`import 'openai/shims/web'\\` (otherwise)\n`;\n\n  let _fetch, _Request, _Response, _Headers;\n  try {\n    // @ts-ignore\n    _fetch = fetch;\n    // @ts-ignore\n    _Request = Request;\n    // @ts-ignore\n    _Response = Response;\n    // @ts-ignore\n    _Headers = Headers;\n  } catch (error) {\n    throw new Error(\n      `this environment is missing the following Web Fetch API type: ${\n        (error as any).message\n      }. ${recommendation}`,\n    );\n  }\n\n  return {\n    kind: 'web',\n    fetch: _fetch,\n    Request: _Request,\n    Response: _Response,\n    Headers: _Headers,\n    FormData:\n      // @ts-ignore\n      typeof FormData !== 'undefined' ? FormData : (\n        class FormData {\n          // @ts-ignore\n          constructor() {\n            throw new Error(\n              `file uploads aren't supported in this environment yet as 'FormData' is undefined. ${recommendation}`,\n            );\n          }\n        }\n      ),\n    Blob:\n      typeof Blob !== 'undefined' ? Blob : (\n        class Blob {\n          constructor() {\n            throw new Error(\n              `file uploads aren't supported in this environment yet as 'Blob' is undefined. ${recommendation}`,\n            );\n          }\n        }\n      ),\n    File:\n      // @ts-ignore\n      typeof File !== 'undefined' ? File : (\n        class File {\n          // @ts-ignore\n          constructor() {\n            throw new Error(\n              `file uploads aren't supported in this environment yet as 'File' is undefined. ${recommendation}`,\n            );\n          }\n        }\n      ),\n    ReadableStream:\n      // @ts-ignore\n      typeof ReadableStream !== 'undefined' ? ReadableStream : (\n        class ReadableStream {\n          // @ts-ignore\n          constructor() {\n            throw new Error(\n              `streaming isn't supported in this environment yet as 'ReadableStream' is undefined. ${recommendation}`,\n            );\n          }\n        }\n      ),\n    getMultipartRequestOptions: async <T = Record<string, unknown>>(\n      // @ts-ignore\n      form: FormData,\n      opts: RequestOptions<T>,\n    ): Promise<RequestOptions<T>> => ({\n      ...opts,\n      body: new MultipartBody(form) as any,\n    }),\n    getDefaultAgent: (url: string) => undefined,\n    fileFromPath: () => {\n      throw new Error(\n        'The `fileFromPath` function is only supported in Node. See the README for more details: https://www.github.com/openai/openai-node#file-uploads',\n      );\n    },\n    isFsReadStream: (value: any) => false,\n  };\n}\n", "/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as shims from './registry.mjs';\nimport * as auto from 'openai/_shims/auto/runtime';\nif (!shims.kind) shims.setShims(auto.getRuntime(), { auto: true });\nexport * from './registry.mjs';\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError, Headers } from './core';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError<\n  TStatus extends number | undefined = number | undefined,\n  THeaders extends Headers | undefined = Headers | undefined,\n  TError extends Object | undefined = Object | undefined,\n> extends OpenAIError {\n  /** HTTP status for the response that caused the error */\n  readonly status: TStatus;\n  /** HTTP headers for the response that caused the error */\n  readonly headers: THeaders;\n  /** JSON body of the response that caused the error */\n  readonly error: TError;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly request_id: string | null | undefined;\n\n  constructor(status: TStatus, error: TError, message: string | undefined, headers: THeaders) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.request_id = headers?.['x-request-id'];\n    this.error = error;\n\n    const data = error as Record<string, any>;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    if (!status || !headers) {\n      return new APIConnectionError({ message, cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError<undefined, undefined, undefined> {\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError<undefined, undefined, undefined> {\n  constructor({ message, cause }: { message?: string | undefined; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError<400, Headers> {}\n\nexport class AuthenticationError extends APIError<401, Headers> {}\n\nexport class PermissionDeniedError extends APIError<403, Headers> {}\n\nexport class NotFoundError extends APIError<404, Headers> {}\n\nexport class ConflictError extends APIError<409, Headers> {}\n\nexport class UnprocessableEntityError extends APIError<422, Headers> {}\n\nexport class RateLimitError extends APIError<429, Headers> {}\n\nexport class InternalServerError extends APIError<number, Headers> {}\n\nexport class LengthFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the length limit was reached`);\n  }\n}\n\nexport class ContentFilterFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the request was rejected by the content filter`);\n  }\n}\n", "import { OpenAIError } from '../../error';\n\nexport type Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  buffer: Uint8Array;\n  #carriageReturnIndex: number | null;\n  textDecoder: any; // TextDecoder found in browsers; not typed to avoid pulling in either \"dom\" or \"node\" types.\n\n  constructor() {\n    this.buffer = new Uint8Array();\n    this.#carriageReturnIndex = null;\n  }\n\n  decode(chunk: Bytes): string[] {\n    if (chunk == null) {\n      return [];\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(this.buffer.length + binaryChunk.length);\n    newData.set(this.buffer);\n    newData.set(binaryChunk, this.buffer.length);\n    this.buffer = newData;\n\n    const lines: string[] = [];\n    let patternIndex;\n    while ((patternIndex = findNewlineIndex(this.buffer, this.#carriageReturnIndex)) != null) {\n      if (patternIndex.carriage && this.#carriageReturnIndex == null) {\n        // skip until we either get a corresponding `\\n`, a new `\\r` or nothing\n        this.#carriageReturnIndex = patternIndex.index;\n        continue;\n      }\n\n      // we got double \\r or \\rtext\\n\n      if (\n        this.#carriageReturnIndex != null &&\n        (patternIndex.index !== this.#carriageReturnIndex + 1 || patternIndex.carriage)\n      ) {\n        lines.push(this.decodeText(this.buffer.slice(0, this.#carriageReturnIndex - 1)));\n        this.buffer = this.buffer.slice(this.#carriageReturnIndex);\n        this.#carriageReturnIndex = null;\n        continue;\n      }\n\n      const endIndex =\n        this.#carriageReturnIndex !== null ? patternIndex.preceding - 1 : patternIndex.preceding;\n\n      const line = this.decodeText(this.buffer.slice(0, endIndex));\n      lines.push(line);\n\n      this.buffer = this.buffer.slice(patternIndex.index);\n      this.#carriageReturnIndex = null;\n    }\n\n    return lines;\n  }\n\n  decodeText(bytes: Bytes): string {\n    if (bytes == null) return '';\n    if (typeof bytes === 'string') return bytes;\n\n    // Node:\n    if (typeof Buffer !== 'undefined') {\n      if (bytes instanceof Buffer) {\n        return bytes.toString();\n      }\n      if (bytes instanceof Uint8Array) {\n        return Buffer.from(bytes).toString();\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`,\n      );\n    }\n\n    // Browser\n    if (typeof TextDecoder !== 'undefined') {\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n        this.textDecoder ??= new TextDecoder('utf8');\n        return this.textDecoder.decode(bytes);\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array/ArrayBuffer (${\n          (bytes as any).constructor.name\n        }) in a web platform. Please report this error.`,\n      );\n    }\n\n    throw new OpenAIError(\n      `Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`,\n    );\n  }\n\n  flush(): string[] {\n    if (!this.buffer.length) {\n      return [];\n    }\n    return this.decode('\\n');\n  }\n}\n\n/**\n * This function searches the buffer for the end patterns, (\\r or \\n)\n * and returns an object with the index preceding the matched newline and the\n * index after the newline char. `null` is returned if no new line is found.\n *\n * ```ts\n * findNewLineIndex('abc\\ndef') -> { preceding: 2, index: 3 }\n * ```\n */\nfunction findNewlineIndex(\n  buffer: Uint8Array,\n  startIndex: number | null,\n): { preceding: number; index: number; carriage: boolean } | null {\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = startIndex ?? 0; i < buffer.length; i++) {\n    if (buffer[i] === newline) {\n      return { preceding: i, index: i + 1, carriage: false };\n    }\n\n    if (buffer[i] === carriage) {\n      return { preceding: i, index: i + 1, carriage: true };\n    }\n  }\n\n  return null;\n}\n\nexport function findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 1; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n", "/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function ReadableStreamToAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n", "import { ReadableStream, type Response } from './_shims/index';\nimport { OpenAIError } from './error';\nimport { findDoubleNewlineIndex, LineDecoder } from './internal/decoders/line';\nimport { ReadableStreamToAsyncIterable } from './internal/stream-utils';\n\nimport { APIError } from './error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n  ) {\n    this.controller = controller;\n  }\n\n  static fromSSEResponse<Item>(response: Response, controller: AbortController): Stream<Item> {\n    let consumed = false;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null || sse.event.startsWith('response.')) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, undefined);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(readableStream: ReadableStream, controller: AbortController): Stream<Item> {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = ReadableStreamToAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller),\n      new Stream(() => teeIterator(right), this.controller),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n    const encoder = new TextEncoder();\n\n    return new ReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = ReadableStreamToAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n", "import { type RequestOptions } from './core';\nimport {\n  FormData,\n  File,\n  type Blob,\n  type FilePropertyBag,\n  getMultipartRequestOptions,\n  type FsReadStream,\n  isFsReadStream,\n} from './_shims/index';\nimport { MultipartBody } from './_shims/MultipartBody';\nexport { fileFromPath } from './_shims/index';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | Uint8Array | DataView;\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | Uint8Array | DataView;\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = FileLike | ResponseLike | FsReadStream;\n\n/**\n * Intended to match web.Blob, node.Blob, node-fetch.Blob, etc.\n */\nexport interface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n  // unfortunately @types/node-fetch@^2.6.4 doesn't type the arrayBuffer method\n}\n\n/**\n * Intended to match web.File, node.File, node-fetch.File, etc.\n */\nexport interface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name: string;\n}\n\n/**\n * Intended to match web.Response, node.Response, node-fetch.Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nexport const isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport const isFileLike = (value: any): value is FileLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\n * adds the arrayBuffer() method type because it is available and used at runtime\n */\nexport const isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\nexport const isUploadable = (value: any): value is Uploadable => {\n  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);\n};\n\nexport type ToFileInput = Uploadable | Exclude<BlobLikePart, string> | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<FileLike> {\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // If we've been given a `File` we don't need to do anything\n  if (isFileLike(value)) {\n    return value;\n  }\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file';\n\n    // we need to convert the `Blob` into an array buffer because the `Blob` class\n    // that `node-fetch` defines is incompatible with the web standard which results\n    // in `new File` interpreting it as a string instead of binary data.\n    const data = isBlobLike(blob) ? [(await blob.arrayBuffer()) as any] : [blob];\n\n    return new File(data, name, options);\n  }\n\n  const bits = await getBytes(value);\n\n  name ||= getName(value) ?? 'unknown_file';\n\n  if (!options?.type) {\n    const type = (bits[0] as any)?.type;\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return new File(bits, name, options);\n}\n\nasync function getBytes(value: ToFileInput): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(await value.arrayBuffer());\n  } else if (\n    isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(chunk as BlobPart); // TODO, consider validating?\n    }\n  } else {\n    throw new Error(\n      `Unexpected data type: ${typeof value}; constructor: ${value?.constructor\n        ?.name}; props: ${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: any): string {\n  const props = Object.getOwnPropertyNames(value);\n  return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n\nfunction getName(value: any): string | undefined {\n  return (\n    getStringFromMaybeBuffer(value.name) ||\n    getStringFromMaybeBuffer(value.filename) ||\n    // For fs.ReadStream\n    getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop()\n  );\n}\n\nconst getStringFromMaybeBuffer = (x: string | Buffer | unknown): string | undefined => {\n  if (typeof x === 'string') return x;\n  if (typeof Buffer !== 'undefined' && x instanceof Buffer) return String(x);\n  return undefined;\n};\n\nconst isAsyncIterableIterator = (value: any): value is AsyncIterableIterator<unknown> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\nexport const isMultipartBody = (body: any): body is MultipartBody =>\n  body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const multipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const createForm = async <T = Record<string, unknown>>(body: T | undefined): Promise<FormData> => {\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (isUploadable(value)) {\n    const file = await toFile(value);\n    form.append(key, file as File);\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n", "import { VERSION } from './version';\nimport { Stream } from './streaming';\nimport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n} from './error';\nimport {\n  kind as shimsKind,\n  type Readable,\n  getDefaultAgent,\n  type Agent,\n  fetch,\n  type RequestInfo,\n  type RequestInit,\n  type Response,\n  type HeadersInit,\n} from './_shims/index';\nexport { type Response };\nimport { BlobLike, isBlobLike, isMultipartBody } from './uploads';\nexport {\n  maybeMultipartFormRequestOptions,\n  multipartFormRequestOptions,\n  createForm,\n  type Uploadable,\n} from './uploads';\n\nexport type Fetch = (url: RequestInfo, init?: RequestInit) => Promise<Response>;\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\ntype APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n};\n\nasync function defaultParseResponse<T>(props: APIResponseProps): Promise<WithRequestID<T>> {\n  const { response } = props;\n  if (props.options.stream) {\n    debug('response', response.status, response.url, response.headers, response.body);\n\n    // Note: there is an invariant here that isn't represented in the type system\n    // that if you set `stream: true` the response type must also be `Stream<T>`\n\n    if (props.options.__streamClass) {\n      return props.options.__streamClass.fromSSEResponse(response, props.controller) as any;\n    }\n\n    return Stream.fromSSEResponse(response, props.controller) as any;\n  }\n\n  // fetch refuses to read the body when the status code is 204.\n  if (response.status === 204) {\n    return null as WithRequestID<T>;\n  }\n\n  if (props.options.__binaryResponse) {\n    return response as unknown as WithRequestID<T>;\n  }\n\n  const contentType = response.headers.get('content-type');\n  const mediaType = contentType?.split(';')[0]?.trim();\n  const isJSON = mediaType?.includes('application/json') || mediaType?.endsWith('+json');\n  if (isJSON) {\n    const json = await response.json();\n\n    debug('response', response.status, response.url, response.headers, json);\n\n    return _addRequestID(json, response);\n  }\n\n  const text = await response.text();\n  debug('response', response.status, response.url, response.headers, text);\n\n  // TODO handle blob, arraybuffer, other content types, etc.\n  return text as unknown as WithRequestID<T>;\n}\n\ntype WithRequestID<T> =\n  T extends Array<any> | Response | AbstractPage<any> ? T\n  : T extends Record<string, any> ? T & { _request_id?: string | null }\n  : T;\n\nfunction _addRequestID<T>(value: T, response: Response): WithRequestID<T> {\n  if (!value || typeof value !== 'object' || Array.isArray(value)) {\n    return value as WithRequestID<T>;\n  }\n\n  return Object.defineProperty(value, '_request_id', {\n    value: response.headers.get('x-request-id'),\n    enumerable: false,\n  }) as WithRequestID<T>;\n}\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<WithRequestID<T>> {\n  private parsedPromise: Promise<WithRequestID<T>> | undefined;\n\n  constructor(\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (\n      props: APIResponseProps,\n    ) => PromiseOrValue<WithRequestID<T>> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n  }\n\n  _thenUnwrap<U>(transform: (data: T, props: APIResponseProps) => U): APIPromise<U> {\n    return new APIPromise(this.responsePromise, async (props) =>\n      _addRequestID(transform(await this.parseResponse(props), props), props.response),\n    );\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   * \uD83D\uDC4B Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import \u2026 from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n\n  /**\n   * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n   * returned via the X-Request-ID header which is useful for debugging requests and reporting\n   * issues to OpenAI.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *\n   * \uD83D\uDC4B Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import \u2026 from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  async withResponse(): Promise<{ data: T; response: Response; request_id: string | null | undefined }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response, request_id: response.headers.get('x-request-id') };\n  }\n\n  private parse(): Promise<WithRequestID<T>> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then(this.parseResponse) as any as Promise<WithRequestID<T>>;\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = WithRequestID<T>, TResult2 = never>(\n    onfulfilled?: ((value: WithRequestID<T>) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<WithRequestID<T> | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<WithRequestID<T>> {\n    return this.parse().finally(onfinally);\n  }\n}\n\nexport abstract class APIClient {\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  httpAgent: Agent | undefined;\n\n  private fetch: Fetch;\n  protected idempotencyHeader?: string;\n\n  constructor({\n    baseURL,\n    maxRetries = 2,\n    timeout = 600000, // 10 minutes\n    httpAgent,\n    fetch: overriddenFetch,\n  }: {\n    baseURL: string;\n    maxRetries?: number | undefined;\n    timeout: number | undefined;\n    httpAgent: Agent | undefined;\n    fetch: Fetch | undefined;\n  }) {\n    this.baseURL = baseURL;\n    this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\n    this.timeout = validatePositiveInteger('timeout', timeout);\n    this.httpAgent = httpAgent;\n\n    this.fetch = overriddenFetch ?? fetch;\n  }\n\n  protected authHeaders(opts: FinalRequestOptions): Headers {\n    return {};\n  }\n\n  /**\n   * Override this to add your own default headers, for example:\n   *\n   *  {\n   *    ...super.defaultHeaders(),\n   *    Authorization: 'Bearer 123',\n   *  }\n   */\n  protected defaultHeaders(opts: FinalRequestOptions): Headers {\n    return {\n      Accept: 'application/json',\n      'Content-Type': 'application/json',\n      'User-Agent': this.getUserAgent(),\n      ...getPlatformHeaders(),\n      ...this.authHeaders(opts),\n    };\n  }\n\n  protected abstract defaultQuery(): DefaultQuery | undefined;\n\n  /**\n   * Override this to add your own headers validation:\n   */\n  protected validateHeaders(headers: Headers, customHeaders: Headers) {}\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  get<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Req, Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions<Req>>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then(async (opts) => {\n        const body =\n          opts && isBlobLike(opts?.body) ? new DataView(await opts.body.arrayBuffer())\n          : opts?.body instanceof DataView ? opts.body\n          : opts?.body instanceof ArrayBuffer ? new DataView(opts.body)\n          : opts && ArrayBuffer.isView(opts?.body) ? new DataView(opts.body.buffer)\n          : opts?.body;\n        return { method, path, ...opts, body };\n      }),\n    );\n  }\n\n  getAPIList<Item, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions<any>,\n  ): PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  private calculateContentLength(body: unknown): string | null {\n    if (typeof body === 'string') {\n      if (typeof Buffer !== 'undefined') {\n        return Buffer.byteLength(body, 'utf8').toString();\n      }\n\n      if (typeof TextEncoder !== 'undefined') {\n        const encoder = new TextEncoder();\n        const encoded = encoder.encode(body);\n        return encoded.length.toString();\n      }\n    } else if (ArrayBuffer.isView(body)) {\n      return body.byteLength.toString();\n    }\n\n    return null;\n  }\n\n  buildRequest<Req>(\n    options: FinalRequestOptions<Req>,\n    { retryCount = 0 }: { retryCount?: number } = {},\n  ): { req: RequestInit; url: string; timeout: number } {\n    options = { ...options };\n    const { method, path, query, headers: headers = {} } = options;\n\n    const body =\n      ArrayBuffer.isView(options.body) || (options.__binaryRequest && typeof options.body === 'string') ?\n        options.body\n      : isMultipartBody(options.body) ? options.body.body\n      : options.body ? JSON.stringify(options.body, null, 2)\n      : null;\n    const contentLength = this.calculateContentLength(body);\n\n    const url = this.buildURL(path!, query);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    options.timeout = options.timeout ?? this.timeout;\n    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);\n    const minAgentTimeout = options.timeout + 1000;\n    if (\n      typeof (httpAgent as any)?.options?.timeout === 'number' &&\n      minAgentTimeout > ((httpAgent as any).options.timeout ?? 0)\n    ) {\n      // Allow any given request to bump our agent active socket timeout.\n      // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\n      // and without mutating agent we would need to create more of them.\n      // This tradeoff optimizes for performance.\n      (httpAgent as any).options.timeout = minAgentTimeout;\n    }\n\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      headers[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const reqHeaders = this.buildHeaders({ options, headers, contentLength, retryCount });\n\n    const req: RequestInit = {\n      method,\n      ...(body && { body: body as any }),\n      headers: reqHeaders,\n      ...(httpAgent && { agent: httpAgent }),\n      // @ts-ignore node-fetch uses a custom AbortSignal type that is\n      // not compatible with standard web types\n      signal: options.signal ?? null,\n    };\n\n    return { req, url, timeout: options.timeout };\n  }\n\n  private buildHeaders({\n    options,\n    headers,\n    contentLength,\n    retryCount,\n  }: {\n    options: FinalRequestOptions;\n    headers: Record<string, string | null | undefined>;\n    contentLength: string | null | undefined;\n    retryCount: number;\n  }): Record<string, string> {\n    const reqHeaders: Record<string, string> = {};\n    if (contentLength) {\n      reqHeaders['content-length'] = contentLength;\n    }\n\n    const defaultHeaders = this.defaultHeaders(options);\n    applyHeadersMut(reqHeaders, defaultHeaders);\n    applyHeadersMut(reqHeaders, headers);\n\n    // let builtin fetch set the Content-Type for multipart bodies\n    if (isMultipartBody(options.body) && shimsKind !== 'node') {\n      delete reqHeaders['content-type'];\n    }\n\n    // Don't set theses headers if they were already set or removed through default headers or by the caller.\n    // We check `defaultHeaders` and `headers`, which can contain nulls, instead of `reqHeaders` to account\n    // for the removal case.\n    if (\n      getHeader(defaultHeaders, 'x-stainless-retry-count') === undefined &&\n      getHeader(headers, 'x-stainless-retry-count') === undefined\n    ) {\n      reqHeaders['x-stainless-retry-count'] = String(retryCount);\n    }\n    if (\n      getHeader(defaultHeaders, 'x-stainless-timeout') === undefined &&\n      getHeader(headers, 'x-stainless-timeout') === undefined &&\n      options.timeout\n    ) {\n      reqHeaders['x-stainless-timeout'] = String(options.timeout);\n    }\n\n    this.validateHeaders(reqHeaders, headers);\n\n    return reqHeaders;\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {}\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  protected parseHeaders(headers: HeadersInit | null | undefined): Record<string, string> {\n    return (\n      !headers ? {}\n      : Symbol.iterator in headers ?\n        Object.fromEntries(Array.from(headers as Iterable<string[]>).map((header) => [...header]))\n      : { ...headers }\n    );\n  }\n\n  protected makeStatusError(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    return APIError.generate(status, error, message, headers);\n  }\n\n  request<Req, Rsp>(\n    options: PromiseOrValue<FinalRequestOptions<Req>>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this.makeRequest(options, remainingRetries));\n  }\n\n  private async makeRequest<Req>(\n    optionsInput: PromiseOrValue<FinalRequestOptions<Req>>,\n    retriesRemaining: number | null,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    const maxRetries = options.maxRetries ?? this.maxRetries;\n    if (retriesRemaining == null) {\n      retriesRemaining = maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = this.buildRequest(options, { retryCount: maxRetries - retriesRemaining });\n\n    await this.prepareRequest(req, { url, options });\n\n    debug('request', url, options, req.headers);\n\n    if (options.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n\n    if (response instanceof Error) {\n      if (options.signal?.aborted) {\n        throw new APIUserAbortError();\n      }\n      if (retriesRemaining) {\n        return this.retryRequest(options, retriesRemaining);\n      }\n      if (response.name === 'AbortError') {\n        throw new APIConnectionTimeoutError();\n      }\n      throw new APIConnectionError({ cause: response });\n    }\n\n    const responseHeaders = createResponseHeaders(response.headers);\n\n    if (!response.ok) {\n      if (retriesRemaining && this.shouldRetry(response)) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n        debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\n        return this.retryRequest(options, retriesRemaining, responseHeaders);\n      }\n\n      const errText = await response.text().catch((e) => castToError(e).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\n\n      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\n      throw err;\n    }\n\n    return { response, options, controller };\n  }\n\n  requestAPIList<Item = unknown, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null);\n    return new PagePromise<PageClass, Item>(this, request, Page);\n  }\n\n  buildURL<Req>(path: string, query: Req | null | undefined): string {\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query } as Req;\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return Object.entries(query)\n      .filter(([_, value]) => typeof value !== 'undefined')\n      .map(([key, value]) => {\n        if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n          return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n        }\n        if (value === null) {\n          return `${encodeURIComponent(key)}=`;\n        }\n        throw new OpenAIError(\n          `Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`,\n        );\n      })\n      .join('&');\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    const fetchOptions = {\n      signal: controller.signal as any,\n      ...options,\n    };\n    if (fetchOptions.method) {\n      // Custom methods like 'patch' need to be uppercased\n      // See https://github.com/nodejs/undici/issues/2294\n      fetchOptions.method = fetchOptions.method.toUpperCase();\n    }\n\n    return (\n      // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n      this.fetch.call(undefined, url, fetchOptions).finally(() => {\n        clearTimeout(timeout);\n      })\n    );\n  }\n\n  private shouldRetry(response: Response): boolean {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.['retry-after'];\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n}\n\nexport type PageInfo = { url: URL } | { params: Record<string, unknown> | null };\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: APIClient;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: APIClient, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  /**\n   * @deprecated Use nextPageInfo instead\n   */\n  abstract nextPageParams(): Partial<Record<string, unknown>> | null;\n  abstract nextPageInfo(): PageInfo | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageInfo() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextInfo = this.nextPageInfo();\n    if (!nextInfo) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n    const nextOptions = { ...this.options };\n    if ('params' in nextInfo && typeof nextOptions.query === 'object') {\n      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\n    } else if ('url' in nextInfo) {\n      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\n      for (const [key, value] of params) {\n        nextInfo.url.searchParams.set(key, value as any);\n      }\n      nextOptions.query = undefined;\n      nextOptions.path = nextInfo.url.toString();\n    }\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages(): AsyncGenerator<this> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let page: this = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: APIClient,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      request,\n      async (props) =>\n        new Page(\n          client,\n          props.response,\n          await defaultParseResponse(props),\n          props.options,\n        ) as WithRequestID<PageClass>,\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport const createResponseHeaders = (\n  headers: Awaited<ReturnType<Fetch>>['headers'],\n): Record<string, string> => {\n  return new Proxy(\n    Object.fromEntries(\n      // @ts-ignore\n      headers.entries(),\n    ),\n    {\n      get(target, name) {\n        const key = name.toString();\n        return target[key.toLowerCase()] || target[key];\n      },\n    },\n  );\n};\n\ntype HTTPMethod = 'get' | 'post' | 'put' | 'patch' | 'delete';\n\nexport type RequestClient = { fetch: Fetch };\nexport type Headers = Record<string, string | null | undefined>;\nexport type DefaultQuery = Record<string, string | undefined>;\nexport type KeysEnum<T> = { [P in keyof Required<T>]: true };\n\nexport type RequestOptions<\n  Req = unknown | Record<string, unknown> | Readable | BlobLike | ArrayBufferView | ArrayBuffer,\n> = {\n  method?: HTTPMethod;\n  path?: string;\n  query?: Req | undefined;\n  body?: Req | null | undefined;\n  headers?: Headers | undefined;\n\n  maxRetries?: number;\n  stream?: boolean | undefined;\n  timeout?: number;\n  httpAgent?: Agent;\n  signal?: AbortSignal | undefined | null;\n  idempotencyKey?: string;\n\n  __metadata?: Record<string, unknown>;\n  __binaryRequest?: boolean | undefined;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\n// This is required so that we can determine if a given object matches the RequestOptions\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\n// compiler such that any missing / extraneous keys will cause an error.\nconst requestOptionsKeys: KeysEnum<RequestOptions> = {\n  method: true,\n  path: true,\n  query: true,\n  body: true,\n  headers: true,\n\n  maxRetries: true,\n  stream: true,\n  timeout: true,\n  httpAgent: true,\n  signal: true,\n  idempotencyKey: true,\n\n  __metadata: true,\n  __binaryRequest: true,\n  __binaryResponse: true,\n  __streamClass: true,\n};\n\nexport const isRequestOptions = (obj: unknown): obj is RequestOptions => {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    !isEmptyObj(obj) &&\n    Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k))\n  );\n};\n\nexport type FinalRequestOptions<Req = unknown | Record<string, unknown> | Readable | DataView> =\n  RequestOptions<Req> & {\n    method: HTTPMethod;\n    path: string;\n  };\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n  // Check if Node.js\n  if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(process.platform),\n      'X-Stainless-Arch': normalizeArch(process.arch),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nconst getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n\n// https://url.spec.whatwg.org/#url-scheme-string\nconst startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;\nconst isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\n\nconst validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  if (typeof err === 'object' && err !== null) {\n    try {\n      return new Error(JSON.stringify(err));\n    } catch {}\n  }\n  return new Error(err);\n};\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  return value;\n};\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof process !== 'undefined') {\n    return process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof Deno !== 'undefined') {\n    return Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn(obj: Object, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\n/**\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\n * using lower-case for all properties,\n * ignoring any keys with undefined values,\n * and deleting any keys with null values.\n */\nfunction applyHeadersMut(targetHeaders: Headers, newHeaders: Headers): void {\n  for (const k in newHeaders) {\n    if (!hasOwn(newHeaders, k)) continue;\n    const lowerKey = k.toLowerCase();\n    if (!lowerKey) continue;\n\n    const val = newHeaders[k];\n\n    if (val === null) {\n      delete targetHeaders[lowerKey];\n    } else if (val !== undefined) {\n      targetHeaders[lowerKey] = val;\n    }\n  }\n}\n\nconst SENSITIVE_HEADERS = new Set(['authorization', 'api-key']);\n\nexport function debug(action: string, ...args: any[]) {\n  if (typeof process !== 'undefined' && process?.env?.['DEBUG'] === 'true') {\n    const modifiedArgs = args.map((arg) => {\n      if (!arg) {\n        return arg;\n      }\n\n      // Check for sensitive headers in request body 'headers' object\n      if (arg['headers']) {\n        // clone so we don't mutate\n        const modifiedArg = { ...arg, headers: { ...arg['headers'] } };\n\n        for (const header in arg['headers']) {\n          if (SENSITIVE_HEADERS.has(header.toLowerCase())) {\n            modifiedArg['headers'][header] = 'REDACTED';\n          }\n        }\n\n        return modifiedArg;\n      }\n\n      let modifiedArg = null;\n\n      // Check for sensitive headers in headers object\n      for (const header in arg) {\n        if (SENSITIVE_HEADERS.has(header.toLowerCase())) {\n          // avoid making a copy until we need to\n          modifiedArg ??= { ...arg };\n          modifiedArg[header] = 'REDACTED';\n        }\n      }\n\n      return modifiedArg ?? arg;\n    });\n    console.log(`OpenAI:DEBUG:${action}`, ...modifiedArgs);\n  }\n}\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nconst uuid4 = () => {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n    const r = (Math.random() * 16) | 0;\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n};\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\nexport interface HeadersProtocol {\n  get: (header: string) => string | null | undefined;\n}\nexport type HeadersLike = Record<string, string | string[] | undefined> | HeadersProtocol;\n\nexport const isHeadersProtocol = (headers: any): headers is HeadersProtocol => {\n  return typeof headers?.get === 'function';\n};\n\nexport const getRequiredHeader = (headers: HeadersLike | Headers, header: string): string => {\n  const foundHeader = getHeader(headers, header);\n  if (foundHeader === undefined) {\n    throw new Error(`Could not find ${header} header`);\n  }\n  return foundHeader;\n};\n\nexport const getHeader = (headers: HeadersLike | Headers, header: string): string | undefined => {\n  const lowerCasedHeader = header.toLowerCase();\n  if (isHeadersProtocol(headers)) {\n    // to deal with the case where the header looks like Stainless-Event-Id\n    const intercapsHeader =\n      header[0]?.toUpperCase() +\n      header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\n    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\n      const value = headers.get(key);\n      if (value) {\n        return value;\n      }\n    }\n  }\n\n  for (const [key, value] of Object.entries(headers)) {\n    if (key.toLowerCase() === lowerCasedHeader) {\n      if (Array.isArray(value)) {\n        if (value.length <= 1) return value[0];\n        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\n        return value[0];\n      }\n      return value;\n    }\n  }\n\n  return undefined;\n};\n\n/**\n * Encodes a string to Base64 format.\n */\nexport const toBase64 = (str: string | null | undefined): string => {\n  if (!str) return '';\n  if (typeof Buffer !== 'undefined') {\n    return Buffer.from(str).toString('base64');\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(str);\n  }\n\n  throw new OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { AbstractPage, Response, APIClient, FinalRequestOptions, PageInfo } from './core';\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: APIClient, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  /**\n   * This page represents a response that isn't actually paginated at the API level\n   * so there will never be any next page params.\n   */\n  nextPageParams(): null {\n    return null;\n  }\n\n  nextPageInfo(): null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n\n  has_more: boolean;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  constructor(\n    client: APIClient,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.has_more = body.has_more || false;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  override hasNextPage(): boolean {\n    if (this.has_more === false) {\n      return false;\n    }\n\n    return super.hasNextPage();\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  nextPageParams(): Partial<CursorPageParams> | null {\n    const info = this.nextPageInfo();\n    if (!info) return null;\n    if ('params' in info) return info.params;\n    const params = Object.fromEntries(info.url.searchParams);\n    if (!Object.keys(params).length) return null;\n    return params;\n  }\n\n  nextPageInfo(): PageInfo | null {\n    const data = this.getPaginatedItems();\n    if (!data.length) {\n      return null;\n    }\n\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return { params: { after: id } };\n  }\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { OpenAI } from './index';\n\nexport class APIResource {\n  protected _client: OpenAI;\n\n  constructor(client: OpenAI) {\n    this._client = client;\n  }\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as CompletionsAPI from './completions';\nimport { ChatCompletionStoreMessagesPage } from './completions';\nimport { type CursorPageParams } from '../../../pagination';\n\nexport class Messages extends APIResource {\n  /**\n   * Get the messages in a stored chat completion. Only Chat Completions that have\n   * been created with the `store` parameter set to `true` will be returned.\n   */\n  list(\n    completionId: string,\n    query?: MessageListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<ChatCompletionStoreMessagesPage, CompletionsAPI.ChatCompletionStoreMessage>;\n  list(\n    completionId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<ChatCompletionStoreMessagesPage, CompletionsAPI.ChatCompletionStoreMessage>;\n  list(\n    completionId: string,\n    query: MessageListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<ChatCompletionStoreMessagesPage, CompletionsAPI.ChatCompletionStoreMessage> {\n    if (isRequestOptions(query)) {\n      return this.list(completionId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/chat/completions/${completionId}/messages`,\n      ChatCompletionStoreMessagesPage,\n      { query, ...options },\n    );\n  }\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * Sort order for messages by timestamp. Use `asc` for ascending order or `desc`\n   * for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Messages {\n  export { type MessageListParams as MessageListParams };\n}\n\nexport { ChatCompletionStoreMessagesPage };\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { APIPromise } from '../../../core';\nimport * as Core from '../../../core';\nimport * as CompletionsCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../../completions';\nimport * as Shared from '../../shared';\nimport * as MessagesAPI from './messages';\nimport { MessageListParams, Messages } from './messages';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\nimport { Stream } from '../../../streaming';\n\nexport class Completions extends APIResource {\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * **Starting a new project?** We recommend trying\n   * [Responses](https://platform.openai.com/docs/api-reference/responses) to take\n   * advantage of the latest OpenAI platform features. Compare\n   * [Chat Completions with Responses](https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses).\n   *\n   * ---\n   *\n   * Creates a model response for the given chat conversation. Learn more in the\n   * [text generation](https://platform.openai.com/docs/guides/text-generation),\n   * [vision](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio) guides.\n   *\n   * Parameter support can differ depending on the model used to generate the\n   * response, particularly for newer reasoning models. Parameters that are only\n   * supported for reasoning models are noted below. For the current state of\n   * unsupported parameters in reasoning models,\n   * [refer to the reasoning guide](https://platform.openai.com/docs/guides/reasoning).\n   */\n  create(\n    body: ChatCompletionCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n\n  /**\n   * Get a stored chat completion. Only Chat Completions that have been created with\n   * the `store` parameter set to `true` will be returned.\n   */\n  retrieve(completionId: string, options?: Core.RequestOptions): Core.APIPromise<ChatCompletion> {\n    return this._client.get(`/chat/completions/${completionId}`, options);\n  }\n\n  /**\n   * Modify a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be modified. Currently, the only\n   * supported modification is to update the `metadata` field.\n   */\n  update(\n    completionId: string,\n    body: ChatCompletionUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ChatCompletion> {\n    return this._client.post(`/chat/completions/${completionId}`, { body, ...options });\n  }\n\n  /**\n   * List stored Chat Completions. Only Chat Completions that have been stored with\n   * the `store` parameter set to `true` will be returned.\n   */\n  list(\n    query?: ChatCompletionListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<ChatCompletionsPage, ChatCompletion>;\n  list(options?: Core.RequestOptions): Core.PagePromise<ChatCompletionsPage, ChatCompletion>;\n  list(\n    query: ChatCompletionListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<ChatCompletionsPage, ChatCompletion> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/chat/completions', ChatCompletionsPage, { query, ...options });\n  }\n\n  /**\n   * Delete a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be deleted.\n   */\n  del(completionId: string, options?: Core.RequestOptions): Core.APIPromise<ChatCompletionDeleted> {\n    return this._client.delete(`/chat/completions/${completionId}`, options);\n  }\n}\n\nexport class ChatCompletionsPage extends CursorPage<ChatCompletion> {}\n\nexport class ChatCompletionStoreMessagesPage extends CursorPage<ChatCompletionStoreMessage> {}\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * The service tier used for processing the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: CompletionsCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Messages sent by the model in response to user messages.\n */\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAssistantMessageParam.Audio | null;\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | Array<ChatCompletionContentPartText | ChatCompletionContentPartRefusal> | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The refusal message by the assistant.\n   */\n  refusal?: string | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  export interface Audio {\n    /**\n     * Unique identifier for a previous audio response from the model.\n     */\n    id: string;\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * If the audio output modality is requested, this object contains data about the\n * audio response from the model.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudio {\n  /**\n   * Unique identifier for this audio response.\n   */\n  id: string;\n\n  /**\n   * Base64 encoded audio bytes generated by the model, in the format specified in\n   * the request.\n   */\n  data: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when this audio response will no longer be\n   * accessible on the server for use in multi-turn conversations.\n   */\n  expires_at: number;\n\n  /**\n   * Transcript of the audio generated by the model.\n   */\n  transcript: string;\n}\n\n/**\n * Parameters for audio output. Required when audio output is requested with\n * `modalities: [\"audio\"]`.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudioParam {\n  /**\n   * Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`, `opus`,\n   * or `pcm16`.\n   */\n  format: 'wav' | 'mp3' | 'flac' | 'opus' | 'pcm16';\n\n  /**\n   * The voice the model uses to respond. Supported voices are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo`, `sage`, and `shimmer`.\n   */\n  voice: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by the model,\n * based on the provided input.\n * [Learn more](https://platform.openai.com/docs/guides/streaming-responses).\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * The service tier used for processing the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value except for the last chunk which contains the token usage\n   * statistics for the entire request.\n   */\n  usage?: CompletionsAPI.CompletionUsage | null;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The refusal message generated by the model.\n       */\n      refusal?: string | null;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'developer' | 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport type ChatCompletionContentPart =\n  | ChatCompletionContentPartText\n  | ChatCompletionContentPartImage\n  | ChatCompletionContentPartInputAudio\n  | ChatCompletionContentPart.File;\n\nexport namespace ChatCompletionContentPart {\n  /**\n   * Learn about [file inputs](https://platform.openai.com/docs/guides/text) for text\n   * generation.\n   */\n  export interface File {\n    file: File.File;\n\n    /**\n     * The type of the content part. Always `file`.\n     */\n    type: 'file';\n  }\n\n  export namespace File {\n    export interface File {\n      /**\n       * The base64 encoded file data, used when passing the file to the model as a\n       * string.\n       */\n      file_data?: string;\n\n      /**\n       * The ID of an uploaded file to use as input.\n       */\n      file_id?: string;\n\n      /**\n       * The name of the file, used when passing the file to the model as a string.\n       */\n      file_name?: string;\n    }\n  }\n}\n\n/**\n * Learn about [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\n/**\n * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionContentPartInputAudio {\n  input_audio: ChatCompletionContentPartInputAudio.InputAudio;\n\n  /**\n   * The type of the content part. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ChatCompletionContentPartInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64 encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n     */\n    format: 'wav' | 'mp3';\n  }\n}\n\nexport interface ChatCompletionContentPartRefusal {\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'refusal';\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\nexport interface ChatCompletionDeleted {\n  /**\n   * The ID of the chat completion that was deleted.\n   */\n  id: string;\n\n  /**\n   * Whether the chat completion was deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The type of object being deleted.\n   */\n  object: 'chat.completion.deleted';\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport interface ChatCompletionDeveloperMessageParam {\n  /**\n   * The contents of the developer message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `developer`.\n   */\n  role: 'developer';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * Annotations for the message, when applicable, as when using the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  annotations?: Array<ChatCompletionMessage.Annotation>;\n\n  /**\n   * If the audio output modality is requested, this object contains data about the\n   * audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudio | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * A URL citation when using web search.\n   */\n  export interface Annotation {\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * A URL citation when using web search.\n     */\n    url_citation: Annotation.URLCitation;\n  }\n\n  export namespace Annotation {\n    /**\n     * A URL citation when using web search.\n     */\n    export interface URLCitation {\n      /**\n       * The index of the last character of the URL citation in the message.\n       */\n      end_index: number;\n\n      /**\n       * The index of the first character of the URL citation in the message.\n       */\n      start_index: number;\n\n      /**\n       * The title of the web resource.\n       */\n      title: string;\n\n      /**\n       * The URL of the web resource.\n       */\n      url: string;\n    }\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport type ChatCompletionMessageParam =\n  | ChatCompletionDeveloperMessageParam\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\nexport interface ChatCompletionMessageToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\nexport type ChatCompletionModality = 'text' | 'audio';\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Static predicted output content, such as the content of a text file that is\n * being regenerated.\n */\nexport interface ChatCompletionPredictionContent {\n  /**\n   * The content that should be matched when generating a model response. If\n   * generated tokens would match this content, the entire model response can be\n   * returned much more quickly.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The type of the predicted content you want to provide. This type is currently\n   * always `content`.\n   */\n  type: 'content';\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'developer' | 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionStoreMessage extends ChatCompletionMessage {\n  /**\n   * The identifier of the chat message.\n   */\n  id: string;\n}\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array. All other chunks\n   * will also include a `usage` field, but with a null value.\n   */\n  include_usage?: boolean;\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, use `developer` messages\n * for this purpose instead.\n */\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\nexport interface ChatCompletionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption = 'none' | 'auto' | 'required' | ChatCompletionNamedToolChoice;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\n/**\n * Messages sent by an end user, containing prompts or additional context\n * information.\n */\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * @deprecated ChatCompletionMessageParam should be used instead\n */\nexport type CreateChatCompletionRequestMessage = ChatCompletionMessageParam;\n\nexport type ChatCompletionReasoningEffort = Shared.ReasoningEffort | null;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far. Depending on the\n   * [model](https://platform.openai.com/docs/models) you use, different message\n   * types (modalities) are supported, like\n   * [text](https://platform.openai.com/docs/guides/text-generation),\n   * [images](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o1`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * Parameters for audio output. Required when audio output is requested with\n   * `modalities: [\"audio\"]`.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudioParam | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model.\n   *\n   * `none` means the model will not call a function and instead generates a message.\n   *\n   * `auto` means the model can pick between generating a message or calling a\n   * function.\n   *\n   * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n   * to call that function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a completion,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the chat\n   * completion. This value can be used to control\n   * [costs](https://openai.com/api/pricing/) for text generated via API.\n   *\n   * This value is now deprecated in favor of `max_completion_tokens`, and is not\n   * compatible with\n   * [o1 series models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Output types that you would like the model to generate. Most models are capable\n   * of generating text, which is the default:\n   *\n   * `[\"text\"]`\n   *\n   * The `gpt-4o-audio-preview` model can also be used to\n   * [generate audio](https://platform.openai.com/docs/guides/audio). To request that\n   * this model generate both text and audio responses, you can use:\n   *\n   * `[\"text\", \"audio\"]`\n   */\n  modalities?: Array<'text' | 'audio'> | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Static predicted output content, such as the content of a text file that is\n   * being regenerated.\n   */\n  prediction?: ChatCompletionPredictionContent | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * **o-series models only**\n   *\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `low`, `medium`, and `high`. Reducing reasoning effort can\n   * result in faster responses and fewer tokens used on reasoning in a response.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  response_format?:\n    | Shared.ResponseFormatText\n    | Shared.ResponseFormatJSONSchema\n    | Shared.ResponseFormatJSONObject;\n\n  /**\n   * This feature is in Beta. If specified, our system will make a best effort to\n   * sample deterministically, such that repeated requests with the same `seed` and\n   * parameters should return the same result. Determinism is not guaranteed, and you\n   * should refer to the `system_fingerprint` response parameter to monitor changes\n   * in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', and the Project is Scale tier enabled, the system will\n   *   utilize scale tier credits until they are exhausted.\n   * - If set to 'auto', and the Project is not Scale tier enabled, the request will\n   *   be processed using the default service tier with a lower uptime SLA and no\n   *   latency guarentee.\n   * - If set to 'default', the request will be processed using the default service\n   *   tier with a lower uptime SLA and no latency guarentee.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether or not to store the output of this chat completion request for use in\n   * our [model distillation](https://platform.openai.com/docs/guides/distillation)\n   * or [evals](https://platform.openai.com/docs/guides/evals) products.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. Currently, only functions are supported as a\n   * tool. Use this to provide a list of functions the model may generate JSON inputs\n   * for. A max of 128 functions are supported.\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  web_search_options?: ChatCompletionCreateParams.WebSearchOptions;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  export interface WebSearchOptions {\n    /**\n     * High level guidance for the amount of context window space to use for the\n     * search. One of `low`, `medium`, or `high`. `medium` is the default.\n     */\n    search_context_size?: 'low' | 'medium' | 'high';\n\n    /**\n     * Approximate location parameters for the search.\n     */\n    user_location?: WebSearchOptions.UserLocation | null;\n  }\n\n  export namespace WebSearchOptions {\n    /**\n     * Approximate location parameters for the search.\n     */\n    export interface UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      approximate: UserLocation.Approximate;\n\n      /**\n       * The type of location approximation. Always `approximate`.\n       */\n      type: 'approximate';\n    }\n\n    export namespace UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      export interface Approximate {\n        /**\n         * Free text input for the city of the user, e.g. `San Francisco`.\n         */\n        city?: string;\n\n        /**\n         * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n         * the user, e.g. `US`.\n         */\n        country?: string;\n\n        /**\n         * Free text input for the region of the user, e.g. `California`.\n         */\n        region?: string;\n\n        /**\n         * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n         * user, e.g. `America/Los_Angeles`.\n         */\n        timezone?: string;\n      }\n    }\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParams instead\n */\nexport type CompletionCreateParams = ChatCompletionCreateParams;\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: false | null;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsNonStreaming instead\n */\nexport type CompletionCreateParamsNonStreaming = ChatCompletionCreateParamsNonStreaming;\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream: true;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsStreaming instead\n */\nexport type CompletionCreateParamsStreaming = ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n}\n\n/**\n * @deprecated Use ChatCompletionUpdateParams instead\n */\nexport type CompletionUpdateParams = ChatCompletionUpdateParams;\n\nexport interface ChatCompletionListParams extends CursorPageParams {\n  /**\n   * A list of metadata keys to filter the Chat Completions by. Example:\n   *\n   * `metadata[key1]=value1&metadata[key2]=value2`\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The model used to generate the Chat Completions.\n   */\n  model?: string;\n\n  /**\n   * Sort order for Chat Completions by timestamp. Use `asc` for ascending order or\n   * `desc` for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\n/**\n * @deprecated Use ChatCompletionListParams instead\n */\nexport type CompletionListParams = ChatCompletionListParams;\n\nCompletions.ChatCompletionsPage = ChatCompletionsPage;\nCompletions.Messages = Messages;\n\nexport declare namespace Completions {\n  export {\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type CreateChatCompletionRequestMessage as CreateChatCompletionRequestMessage,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type CompletionCreateParams as CompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type CompletionUpdateParams as CompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n    type CompletionListParams as CompletionListParams,\n  };\n\n  export { Messages as Messages, type MessageListParams as MessageListParams };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Shared from '../shared';\nimport * as CompletionsAPI from './completions/completions';\nimport {\n  ChatCompletion,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionPredictionContent,\n  ChatCompletionReasoningEffort,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  CompletionListParams,\n  CompletionUpdateParams,\n  Completions,\n  CreateChatCompletionRequestMessage,\n} from './completions/completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel = Shared.ChatModel;\n\nChat.Completions = Completions;\nChat.ChatCompletionsPage = ChatCompletionsPage;\n\nexport declare namespace Chat {\n  export { type ChatModel as ChatModel };\n\n  export {\n    Completions as Completions,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type CreateChatCompletionRequestMessage as CreateChatCompletionRequestMessage,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type CompletionCreateParams as CompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type CompletionUpdateParams as CompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n    type CompletionListParams as CompletionListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport { type Response } from '../../_shims/index';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   */\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.post('/audio/speech', {\n      body,\n      ...options,\n      headers: { Accept: 'application/octet-stream', ...options?.headers },\n      __binaryResponse: true,\n    });\n  }\n}\n\nexport type SpeechModel = 'tts-1' | 'tts-1-hd';\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models#tts):\n   * `tts-1` or `tts-1-hd`\n   */\n  model: (string & {}) | SpeechModel;\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`, `ash`,\n   * `coral`, `echo`, `fable`, `onyx`, `nova`, `sage` and `shimmer`. Previews of the\n   * voices are available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech#voice-options).\n   */\n  voice: 'alloy' | 'ash' | 'coral' | 'echo' | 'fable' | 'onyx' | 'nova' | 'sage' | 'shimmer';\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n}\n\nexport declare namespace Speech {\n  export { type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as AudioAPI from './audio';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(\n    body: TranscriptionCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionVerbose>;\n  create(\n    body: TranscriptionCreateParams<'srt' | 'vtt' | 'text'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionCreateResponse | string> {\n    return this._client.post(\n      '/audio/transcriptions',\n      Core.multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }),\n    );\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n}\n\nexport interface TranscriptionSegment {\n  /**\n   * Unique identifier of the segment.\n   */\n  id: number;\n\n  /**\n   * Average logprob of the segment. If the value is lower than -1, consider the\n   * logprobs failed.\n   */\n  avg_logprob: number;\n\n  /**\n   * Compression ratio of the segment. If the value is greater than 2.4, consider the\n   * compression failed.\n   */\n  compression_ratio: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Probability of no speech in the segment. If the value is higher than 1.0 and the\n   * `avg_logprob` is below -1, consider this segment silent.\n   */\n  no_speech_prob: number;\n\n  /**\n   * Seek offset of the segment.\n   */\n  seek: number;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Temperature parameter used for generating the segment.\n   */\n  temperature: number;\n\n  /**\n   * Text content of the segment.\n   */\n  text: string;\n\n  /**\n   * Array of token IDs for the text content.\n   */\n  tokens: Array<number>;\n}\n\n/**\n * Represents a verbose json transcription response returned by model, based on the\n * provided input.\n */\nexport interface TranscriptionVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the input audio.\n   */\n  language: string;\n\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * Segments of the transcribed text and their corresponding details.\n   */\n  segments?: Array<TranscriptionSegment>;\n\n  /**\n   * Extracted words and their corresponding timestamps.\n   */\n  words?: Array<TranscriptionWord>;\n}\n\nexport interface TranscriptionWord {\n  /**\n   * End time of the word in seconds.\n   */\n  end: number;\n\n  /**\n   * Start time of the word in seconds.\n   */\n  start: number;\n\n  /**\n   * The text content of the word.\n   */\n  word: string;\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport type TranscriptionCreateResponse = Transcription | TranscriptionVerbose;\n\nexport interface TranscriptionCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n   * format will improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should match the audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport declare namespace Transcriptions {\n  export {\n    type Transcription as Transcription,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as AudioAPI from './audio';\nimport * as TranscriptionsAPI from './transcriptions';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   */\n  create(\n    body: TranslationCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationVerbose>;\n  create(\n    body: TranslationCreateParams<'text' | 'srt' | 'vtt'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationCreateResponse | string> {\n    return this._client.post(\n      '/audio/translations',\n      Core.multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }),\n    );\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the output translation (always `english`).\n   */\n  language: string;\n\n  /**\n   * The translated text.\n   */\n  text: string;\n\n  /**\n   * Segments of the translated text and their corresponding details.\n   */\n  segments?: Array<TranscriptionsAPI.TranscriptionSegment>;\n}\n\nexport type TranslationCreateResponse = Translation | TranslationVerbose;\n\nexport interface TranslationCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport declare namespace Translations {\n  export {\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as SpeechAPI from './speech';\nimport { Speech, SpeechCreateParams, SpeechModel } from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport {\n  Transcription,\n  TranscriptionCreateParams,\n  TranscriptionCreateResponse,\n  TranscriptionSegment,\n  TranscriptionVerbose,\n  TranscriptionWord,\n  Transcriptions,\n} from './transcriptions';\nimport * as TranslationsAPI from './translations';\nimport {\n  Translation,\n  TranslationCreateParams,\n  TranslationCreateResponse,\n  TranslationVerbose,\n  Translations,\n} from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel = 'whisper-1';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, or `vtt`.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;\n\nexport declare namespace Audio {\n  export { type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Transcriptions as Transcriptions,\n    type Transcription as Transcription,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n  };\n\n  export {\n    Translations as Translations,\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n\n  export { Speech as Speech, type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport * as Core from '../core';\nimport * as BatchesAPI from './batches';\nimport * as Shared from './shared';\nimport { CursorPage, type CursorPageParams } from '../pagination';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.get(`/batches/${batchId}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(query?: BatchListParams, options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(\n    query: BatchListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<BatchesPage, Batch> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post(`/batches/${batchId}/cancel`, options);\n  }\n}\n\nexport class BatchesPage extends CursorPage<Batch> {}\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.\n   * Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000\n   * embedding inputs across all requests in the batch.\n   */\n  endpoint: '/v1/chat/completions' | '/v1/embeddings' | '/v1/completions';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 200 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nBatches.BatchesPage = BatchesPage;\n\nexport declare namespace Batches {\n  export {\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as Shared from '../shared';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { CursorPage, type CursorPageParams } from '../../pagination';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   */\n  create(body: AssistantCreateParams, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   */\n  retrieve(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.get(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   */\n  update(\n    assistantId: string,\n    body: AssistantUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Assistant> {\n    return this._client.post(`/assistants/${assistantId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   */\n  list(\n    query?: AssistantListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant>;\n  list(options?: Core.RequestOptions): Core.PagePromise<AssistantsPage, Assistant>;\n  list(\n    query: AssistantListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/assistants', AssistantsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   */\n  del(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<AssistantDeleted> {\n    return this._client.delete(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class AssistantsPage extends CursorPage<Assistant> {}\n\n/**\n * Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n\n    /**\n     * Whether to enable input audio transcription.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes#api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between\n     * 1 and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    max_num_results?: number;\n\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    export interface RankingOptions {\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker?: 'auto' | 'default_2024_08_21';\n    }\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n * is created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n\n  /**\n   * Whether to enable input audio transcription.\n   */\n  enabled?: boolean;\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * **o-series models only**\n   *\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `low`, `medium`, and `high`. Reducing reasoning effort can\n   * result in faster responses and fewer tokens used on reasoning in a response.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model?:\n    | (string & {})\n    | 'o3-mini'\n    | 'o3-mini-2025-01-31'\n    | 'o1'\n    | 'o1-2024-12-17'\n    | 'gpt-4o'\n    | 'gpt-4o-2024-11-20'\n    | 'gpt-4o-2024-08-06'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4o-mini'\n    | 'gpt-4o-mini-2024-07-18'\n    | 'gpt-4.5-preview'\n    | 'gpt-4.5-preview-2025-02-27'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613';\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * **o-series models only**\n   *\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `low`, `medium`, and `high`. Reducing reasoning effort can\n   * result in faster responses and fewer tokens used on reasoning in a response.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nAssistants.AssistantsPage = AssistantsPage;\n\nexport declare namespace Assistants {\n  export {\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n}\n", "import { type ChatCompletionRunner } from './ChatCompletionRunner';\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\nimport { JSONSchema } from './jsonschema';\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\nexport type RunnableFunctionWithParse<Args extends object> = {\n  /**\n   * @param args the return value from `parse`.\n   * @param runner the runner evaluating this callback.\n   * @returns a string to send back to OpenAI.\n   */\n  function: (\n    args: Args,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * @param input the raw args from the OpenAI function call.\n   * @returns the parsed arguments to pass to `function`\n   */\n  parse: (input: string) => PromiseOrValue<Args>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunctionWithoutParse = {\n  /**\n   * @param args the raw args from the OpenAI function call.\n   * @returns a string to send back to OpenAI\n   */\n  function: (\n    args: string,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunction<Args extends object | string> =\n  Args extends string ? RunnableFunctionWithoutParse\n  : Args extends object ? RunnableFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunction<Args extends object | string> =\n  Args extends string ? RunnableToolFunctionWithoutParse\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunctionWithoutParse = {\n  type: 'function';\n  function: RunnableFunctionWithoutParse;\n};\nexport type RunnableToolFunctionWithParse<Args extends object> = {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n};\n\nexport function isRunnableFunctionWithParse<Args extends object>(\n  fn: any,\n): fn is RunnableFunctionWithParse<Args> {\n  return typeof (fn as any).parse === 'function';\n}\n\nexport type BaseFunctionsArgs = readonly (object | string)[];\n\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n *\n * @deprecated - please use ParsingToolFunction instead.\n */\nexport class ParsingFunction<Args extends object> {\n  function: RunnableFunctionWithParse<Args>['function'];\n  parse: RunnableFunctionWithParse<Args>['parse'];\n  parameters: RunnableFunctionWithParse<Args>['parameters'];\n  description: RunnableFunctionWithParse<Args>['description'];\n  name?: RunnableFunctionWithParse<Args>['name'];\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.function = input.function;\n    this.parse = input.parse;\n    this.parameters = input.parameters;\n    this.description = input.description;\n    this.name = input.name;\n  }\n}\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nexport class ParsingToolFunction<Args extends object> {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.type = 'function';\n    this.function = input;\n  }\n}\n", "import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from '../resources';\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isFunctionMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionFunctionMessageParam => {\n  return message?.role === 'function';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n", "import { APIUserAbortError, OpenAIError } from '../error';\n\nexport class EventStream<EventTypes extends BaseEvents> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: {\n    [Event in keyof EventTypes]?: EventListeners<EventTypes, Event>;\n  } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(this: EventStream<EventTypes>, executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError.bind(this));\n    }, 0);\n  }\n\n  protected _connected(this: EventStream<EventTypes>) {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof EventTypes>(\n    event: Event,\n  ): Promise<\n    EventParameters<EventTypes, Event> extends [infer Param] ? Param\n    : EventParameters<EventTypes, Event> extends [] ? void\n    : EventParameters<EventTypes, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError(this: EventStream<EventTypes>, error: unknown) {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  }\n\n  _emit<Event extends keyof BaseEvents>(event: Event, ...args: EventParameters<BaseEvents, Event>): void;\n  _emit<Event extends keyof EventTypes>(event: Event, ...args: EventParameters<EventTypes, Event>): void;\n  _emit<Event extends keyof EventTypes>(\n    this: EventStream<EventTypes>,\n    event: Event,\n    ...args: EventParameters<EventTypes, Event>\n  ) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: EventListeners<EventTypes, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...(args as any)));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal(): void {}\n}\n\ntype EventListener<Events, EventType extends keyof Events> = Events[EventType];\n\ntype EventListeners<Events, EventType extends keyof Events> = Array<{\n  listener: EventListener<Events, EventType>;\n  once?: boolean;\n}>;\n\nexport type EventParameters<Events, EventType extends keyof Events> = {\n  [Event in EventType]: EventListener<Events, EventType> extends (...args: infer P) => any ? P : never;\n}[EventType];\n\nexport interface BaseEvents {\n  connect: () => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n", "import {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessageToolCall,\n  ChatCompletionTool,\n} from '../resources/chat/completions';\nimport {\n  ChatCompletionStreamingToolRunnerParams,\n  ChatCompletionStreamParams,\n  ChatCompletionToolRunnerParams,\n  ParsedChatCompletion,\n  ParsedChoice,\n  ParsedFunctionToolCall,\n} from '../resources/beta/chat/completions';\nimport { ResponseFormatJSONSchema } from '../resources/shared';\nimport { ContentFilterFinishReasonError, LengthFinishReasonError, OpenAIError } from '../error';\nimport { type ResponseFormatTextJSONSchemaConfig } from '../resources/responses/responses';\n\ntype AnyChatCompletionCreateParams =\n  | ChatCompletionCreateParams\n  | ChatCompletionToolRunnerParams<any>\n  | ChatCompletionStreamingToolRunnerParams<any>\n  | ChatCompletionStreamParams;\n\nexport type ExtractParsedContentFromParams<Params extends AnyChatCompletionCreateParams> =\n  Params['response_format'] extends AutoParseableResponseFormat<infer P> ? P : null;\n\nexport type AutoParseableResponseFormat<ParsedT> = ResponseFormatJSONSchema & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableResponseFormat<ParsedT>(\n  response_format: ResponseFormatJSONSchema,\n  parser: (content: string) => ParsedT,\n): AutoParseableResponseFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseFormat<ParsedT>;\n}\n\nexport type AutoParseableTextFormat<ParsedT> = ResponseFormatTextJSONSchemaConfig & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableTextFormat<ParsedT>(\n  response_format: ResponseFormatTextJSONSchemaConfig,\n  parser: (content: string) => ParsedT,\n): AutoParseableTextFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTextFormat<ParsedT>;\n}\n\nexport function isAutoParsableResponseFormat<ParsedT>(\n  response_format: any,\n): response_format is AutoParseableResponseFormat<ParsedT> {\n  return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = ChatCompletionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n  __hasFunction: HasFunction; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableTool<OptionsT extends ToolOptions>(\n  tool: ChatCompletionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nexport function maybeParseChatCompletion<\n  Params extends ChatCompletionCreateParams | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...completion,\n      choices: completion.choices.map((choice) => ({\n        ...choice,\n        message: {\n          ...choice.message,\n          parsed: null,\n          ...(choice.message.tool_calls ?\n            {\n              tool_calls: choice.message.tool_calls,\n            }\n          : undefined),\n        },\n      })),\n    };\n  }\n\n  return parseChatCompletion(completion, params);\n}\n\nexport function parseChatCompletion<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  const choices: Array<ParsedChoice<ParsedT>> = completion.choices.map((choice): ParsedChoice<ParsedT> => {\n    if (choice.finish_reason === 'length') {\n      throw new LengthFinishReasonError();\n    }\n\n    if (choice.finish_reason === 'content_filter') {\n      throw new ContentFilterFinishReasonError();\n    }\n\n    return {\n      ...choice,\n      message: {\n        ...choice.message,\n        ...(choice.message.tool_calls ?\n          {\n            tool_calls:\n              choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? undefined,\n          }\n        : undefined),\n        parsed:\n          choice.message.content && !choice.message.refusal ?\n            parseResponseFormat(params, choice.message.content)\n          : null,\n      },\n    };\n  });\n\n  return { ...completion, choices };\n}\n\nfunction parseResponseFormat<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.response_format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if (params.response_format?.type === 'json_schema') {\n    if ('$parseRaw' in params.response_format) {\n      const response_format = params.response_format as AutoParseableResponseFormat<ParsedT>;\n\n      return response_format.$parseRaw(content);\n    }\n\n    return JSON.parse(content);\n  }\n\n  return null;\n}\n\nfunction parseToolCall<Params extends ChatCompletionCreateParams>(\n  params: Params,\n  toolCall: ChatCompletionMessageToolCall,\n): ParsedFunctionToolCall {\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return {\n    ...toolCall,\n    function: {\n      ...toolCall.function,\n      parsed_arguments:\n        isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n        : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n        : null,\n    },\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ChatCompletionCreateParams | null | undefined,\n  toolCall: ChatCompletionMessageToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return isAutoParsableTool(inputTool) || inputTool?.function.strict || false;\n}\n\nexport function hasAutoParseableInput(params: AnyChatCompletionCreateParams): boolean {\n  if (isAutoParsableResponseFormat(params.response_format)) {\n    return true;\n  }\n\n  return (\n    params.tools?.some(\n      (t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true),\n    ) ?? false\n  );\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n", "import * as Core from '../core';\nimport { type CompletionUsage } from '../resources/completions';\nimport {\n  type ChatCompletion,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParams,\n  type ChatCompletionTool,\n} from '../resources/chat/completions';\nimport { OpenAIError } from '../error';\nimport {\n  type RunnableFunction,\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n  RunnableToolFunction,\n} from './RunnableFunction';\nimport { ChatCompletionFunctionRunnerParams, ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingFunctionRunnerParams,\n  ChatCompletionStreamingToolRunnerParams,\n} from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isFunctionMessage, isToolMessage } from './chatCompletionUtils';\nimport { BaseEvents, EventStream } from './EventStream';\nimport { ParsedChatCompletion } from '../resources/beta/chat/completions';\nimport OpenAI from '../index';\nimport { isAutoParsableTool, parseChatCompletion } from '../lib/parser';\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends Core.RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport class AbstractChatCompletionRunner<\n  EventTypes extends AbstractChatCompletionRunnerEvents,\n  ParsedT,\n> extends EventStream<EventTypes> {\n  protected _chatCompletions: ParsedChatCompletion<ParsedT>[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  protected _addChatCompletion(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    chatCompletion: ParsedChatCompletion<ParsedT>,\n  ): ParsedChatCompletion<ParsedT> {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit = true,\n  ) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if ((isFunctionMessage(message) || isToolMessage(message)) && message.content) {\n        // Note, this assumes that {role: 'tool', content: \u2026} is always the result of a call of tool of type=function.\n        this._emit('functionCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.function_call) {\n        this._emit('functionCall', message.function_call);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ParsedChatCompletion<ParsedT>> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        const { function_call, ...rest } = message;\n\n        // TODO: support audio here\n        const ret: Omit<ChatCompletionMessage, 'audio'> = {\n          ...rest,\n          content: (message as ChatCompletionMessage).content ?? null,\n          refusal: (message as ChatCompletionMessage).refusal ?? null,\n        };\n        if (function_call) {\n          ret.function_call = function_call;\n        }\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionCall(): ChatCompletionMessage.FunctionCall | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.function_call) {\n        return message.function_call;\n      }\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionCall(): Promise<ChatCompletionMessage.FunctionCall | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCall();\n  }\n\n  #getFinalFunctionCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isFunctionMessage(message) && message.content != null) {\n        return message.content;\n      }\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        typeof message.content === 'string' &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  protected override _emitFinal(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n  ) {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionCall();\n    if (finalFunctionCall) this._emit('finalFunctionCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await client.chat.completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));\n  }\n\n  protected async _runChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(client, params, options);\n  }\n\n  protected async _runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'function' as const;\n    const { function_call = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of params.functions) {\n      functionsByName[f.name || f.function.name] = f;\n    }\n\n    const functions: ChatCompletionCreateParams.Function[] = params.functions.map(\n      (f): ChatCompletionCreateParams.Function => ({\n        name: f.name || f.function.name,\n        parameters: f.parameters as Record<string, unknown>,\n        description: f.description,\n      }),\n    );\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          function_call,\n          functions,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.function_call) return;\n      const { name, arguments: args } = message.function_call;\n      const fn = functionsByName[name];\n      if (!fn) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\n          .map((f) => JSON.stringify(f.name))\n          .join(', ')}. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(\n          singleFunctionToCall,\n        )} requested. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      }\n\n      let parsed;\n      try {\n        parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n      } catch (error) {\n        this._addMessage({\n          role,\n          name,\n          content: error instanceof Error ? error.message : String(error),\n        });\n        continue;\n      }\n\n      // @ts-expect-error it can't rule out `never` type.\n      const rawContent = await fn.function(parsed, this);\n      const content = this.#stringifyFunctionCallResult(rawContent);\n\n      this._addMessage({ role, name, content });\n\n      if (singleFunctionToCall) return;\n    }\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    // TODO(someday): clean this logic up\n    const inputTools = params.tools.map((tool): RunnableToolFunction<any> => {\n      if (isAutoParsableTool(tool)) {\n        if (!tool.$callback) {\n          throw new OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n        }\n\n        return {\n          type: 'function',\n          function: {\n            function: tool.$callback,\n            name: tool.function.name,\n            description: tool.function.description || '',\n            parameters: tool.function.parameters as any,\n            parse: tool.$parseRaw,\n            strict: true,\n          },\n        };\n      }\n\n      return tool as any as RunnableToolFunction<any>;\n    });\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of inputTools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        inputTools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n                strict: t.function.strict,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls?.length) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(\n            functionsByName,\n          )\n            .map((name) => JSON.stringify(name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\nexport interface AbstractChatCompletionRunnerEvents extends BaseEvents {\n  functionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  functionCallResult: (content: string) => void;\n  finalFunctionCallResult: (content: string) => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n", "import {\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from '../resources/chat/completions';\nimport { type RunnableFunctions, type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionRunner<ParsedT = null> extends AbstractChatCompletionRunner<\n  ChatCompletionRunnerEvents,\n  ParsedT\n> {\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions(\n    client: OpenAI,\n    params: ChatCompletionFunctionRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<null> {\n    const runner = new ChatCompletionRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> {\n    const runner = new ChatCompletionRunner<ParsedT>();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n\n  override _addMessage(\n    this: ChatCompletionRunner<ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit: boolean = true,\n  ) {\n    super._addMessage(message, emit);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n", "const STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\n\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\n\nconst Allow = {\n  STR,\n  NUM,\n  ARR,\n  OBJ,\n  NULL,\n  BOOL,\n  NAN,\n  INFINITY,\n  MINUS_INFINITY,\n  INF,\n  SPECIAL,\n  ATOM,\n  COLLECTION,\n  ALL,\n};\n\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {}\n\nclass MalformedJSON extends Error {}\n\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString: string, allowPartial: number = Allow.ALL): any {\n  if (typeof jsonString !== 'string') {\n    throw new TypeError(`expecting str, got ${typeof jsonString}`);\n  }\n  if (!jsonString.trim()) {\n    throw new Error(`${jsonString} is empty`);\n  }\n  return _parseJSON(jsonString.trim(), allowPartial);\n}\n\nconst _parseJSON = (jsonString: string, allow: number) => {\n  const length = jsonString.length;\n  let index = 0;\n\n  const markPartialJSON = (msg: string) => {\n    throw new PartialJSON(`${msg} at position ${index}`);\n  };\n\n  const throwMalformedError = (msg: string) => {\n    throw new MalformedJSON(`${msg} at position ${index}`);\n  };\n\n  const parseAny: () => any = () => {\n    skipBlank();\n    if (index >= length) markPartialJSON('Unexpected end of input');\n    if (jsonString[index] === '\"') return parseStr();\n    if (jsonString[index] === '{') return parseObj();\n    if (jsonString[index] === '[') return parseArr();\n    if (\n      jsonString.substring(index, index + 4) === 'null' ||\n      (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return null;\n    }\n    if (\n      jsonString.substring(index, index + 4) === 'true' ||\n      (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return true;\n    }\n    if (\n      jsonString.substring(index, index + 5) === 'false' ||\n      (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 5;\n      return false;\n    }\n    if (\n      jsonString.substring(index, index + 8) === 'Infinity' ||\n      (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 8;\n      return Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 9) === '-Infinity' ||\n      (Allow.MINUS_INFINITY & allow &&\n        1 < length - index &&\n        length - index < 9 &&\n        '-Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 9;\n      return -Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 3) === 'NaN' ||\n      (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 3;\n      return NaN;\n    }\n    return parseNum();\n  };\n\n  const parseStr: () => string = () => {\n    const start = index;\n    let escape = false;\n    index++; // skip initial quote\n    while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n      escape = jsonString[index] === '\\\\' ? !escape : false;\n      index++;\n    }\n    if (jsonString.charAt(index) == '\"') {\n      try {\n        return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    } else if (Allow.STR & allow) {\n      try {\n        return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n      } catch (e) {\n        // SyntaxError: Invalid escape sequence\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n      }\n    }\n    markPartialJSON('Unterminated string literal');\n  };\n\n  const parseObj = () => {\n    index++; // skip initial brace\n    skipBlank();\n    const obj: Record<string, any> = {};\n    try {\n      while (jsonString[index] !== '}') {\n        skipBlank();\n        if (index >= length && Allow.OBJ & allow) return obj;\n        const key = parseStr();\n        skipBlank();\n        index++; // skip colon\n        try {\n          const value = parseAny();\n          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n        } catch (e) {\n          if (Allow.OBJ & allow) return obj;\n          else throw e;\n        }\n        skipBlank();\n        if (jsonString[index] === ',') index++; // skip comma\n      }\n    } catch (e) {\n      if (Allow.OBJ & allow) return obj;\n      else markPartialJSON(\"Expected '}' at end of object\");\n    }\n    index++; // skip final brace\n    return obj;\n  };\n\n  const parseArr = () => {\n    index++; // skip initial bracket\n    const arr = [];\n    try {\n      while (jsonString[index] !== ']') {\n        arr.push(parseAny());\n        skipBlank();\n        if (jsonString[index] === ',') {\n          index++; // skip comma\n        }\n      }\n    } catch (e) {\n      if (Allow.ARR & allow) {\n        return arr;\n      }\n      markPartialJSON(\"Expected ']' at end of array\");\n    }\n    index++; // skip final bracket\n    return arr;\n  };\n\n  const parseNum = () => {\n    if (index === 0) {\n      if (jsonString === '-' && Allow.NUM & allow) markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString);\n      } catch (e) {\n        if (Allow.NUM & allow) {\n          try {\n            if ('.' === jsonString[jsonString.length - 1])\n              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n          } catch (e) {}\n        }\n        throwMalformedError(String(e));\n      }\n    }\n\n    const start = index;\n\n    if (jsonString[index] === '-') index++;\n    while (jsonString[index] && !',]}'.includes(jsonString[index]!)) index++;\n\n    if (index == length && !(Allow.NUM & allow)) markPartialJSON('Unterminated number literal');\n\n    try {\n      return JSON.parse(jsonString.substring(start, index));\n    } catch (e) {\n      if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n        markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    }\n  };\n\n  const skipBlank = () => {\n    while (index < length && ' \\n\\r\\t'.includes(jsonString[index]!)) {\n      index++;\n    }\n  };\n\n  return parseAny();\n};\n\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input: string) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\nexport { partialParse, PartialJSON, MalformedJSON };\n", "import * as Core from '../core';\nimport {\n  OpenAIError,\n  APIUserAbortError,\n  LengthFinishReasonError,\n  ContentFilterFinishReasonError,\n} from '../error';\nimport {\n  ChatCompletionTokenLogprob,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionCreateParamsBase,\n  type ChatCompletionRole,\n} from '../resources/chat/completions/completions';\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../_shims/index';\nimport { Stream } from '../streaming';\nimport OpenAI from '../index';\nimport { ParsedChatCompletion } from '../resources/beta/chat/completions';\nimport {\n  AutoParseableResponseFormat,\n  hasAutoParseableInput,\n  isAutoParsableResponseFormat,\n  isAutoParsableTool,\n  maybeParseChatCompletion,\n  shouldParseToolCall,\n} from '../lib/parser';\nimport { partialParse } from '../_vendor/partial-json-parser/parser';\n\nexport interface ContentDeltaEvent {\n  delta: string;\n  snapshot: string;\n  parsed: unknown | null;\n}\n\nexport interface ContentDoneEvent<ParsedT = null> {\n  content: string;\n  parsed: ParsedT | null;\n}\n\nexport interface RefusalDeltaEvent {\n  delta: string;\n  snapshot: string;\n}\n\nexport interface RefusalDoneEvent {\n  refusal: string;\n}\n\nexport interface FunctionToolCallArgumentsDeltaEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n\n  arguments_delta: string;\n}\n\nexport interface FunctionToolCallArgumentsDoneEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n}\n\nexport interface LogProbsContentDeltaEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsContentDoneEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDeltaEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDoneEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface ChatCompletionStreamEvents<ParsedT = null> extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n\n  'content.delta': (props: ContentDeltaEvent) => void;\n  'content.done': (props: ContentDoneEvent<ParsedT>) => void;\n\n  'refusal.delta': (props: RefusalDeltaEvent) => void;\n  'refusal.done': (props: RefusalDoneEvent) => void;\n\n  'tool_calls.function.arguments.delta': (props: FunctionToolCallArgumentsDeltaEvent) => void;\n  'tool_calls.function.arguments.done': (props: FunctionToolCallArgumentsDoneEvent) => void;\n\n  'logprobs.content.delta': (props: LogProbsContentDeltaEvent) => void;\n  'logprobs.content.done': (props: LogProbsContentDoneEvent) => void;\n\n  'logprobs.refusal.delta': (props: LogProbsRefusalDeltaEvent) => void;\n  'logprobs.refusal.done': (props: LogProbsRefusalDoneEvent) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ninterface ChoiceEventState {\n  content_done: boolean;\n  refusal_done: boolean;\n  logprobs_content_done: boolean;\n  logprobs_refusal_done: boolean;\n  current_tool_call_index: number | null;\n  done_tool_calls: Set<number>;\n}\n\nexport class ChatCompletionStream<ParsedT = null>\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents<ParsedT>, ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #params: ChatCompletionCreateParams | null;\n  #choiceEventStates: ChoiceEventState[];\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  constructor(params: ChatCompletionCreateParams | null) {\n    super();\n    this.#params = params;\n    this.#choiceEventStates = [];\n  }\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream<null> {\n    const runner = new ChatCompletionStream(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionStreamParams,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    const runner = new ChatCompletionStream<ParsedT>(params as ChatCompletionCreateParamsStreaming);\n    runner._run(() =>\n      runner._runChatCompletion(\n        client,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n\n  #getChoiceEventState(choice: ChatCompletionSnapshot.Choice): ChoiceEventState {\n    let state = this.#choiceEventStates[choice.index];\n    if (state) {\n      return state;\n    }\n\n    state = {\n      content_done: false,\n      refusal_done: false,\n      logprobs_content_done: false,\n      logprobs_refusal_done: false,\n      done_tool_calls: new Set(),\n      current_tool_call_index: null,\n    };\n    this.#choiceEventStates[choice.index] = state;\n    return state;\n  }\n\n  #addChunk(this: ChatCompletionStream<ParsedT>, chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n\n    for (const choice of chunk.choices) {\n      const choiceSnapshot = completion.choices[choice.index]!;\n\n      if (\n        choice.delta.content != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.content\n      ) {\n        this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n        this._emit('content.delta', {\n          delta: choice.delta.content,\n          snapshot: choiceSnapshot.message.content,\n          parsed: choiceSnapshot.message.parsed,\n        });\n      }\n\n      if (\n        choice.delta.refusal != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.refusal\n      ) {\n        this._emit('refusal.delta', {\n          delta: choice.delta.refusal,\n          snapshot: choiceSnapshot.message.refusal,\n        });\n      }\n\n      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.content.delta', {\n          content: choice.logprobs?.content,\n          snapshot: choiceSnapshot.logprobs?.content ?? [],\n        });\n      }\n\n      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.refusal.delta', {\n          refusal: choice.logprobs?.refusal,\n          snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n        });\n      }\n\n      const state = this.#getChoiceEventState(choiceSnapshot);\n\n      if (choiceSnapshot.finish_reason) {\n        this.#emitContentDoneEvents(choiceSnapshot);\n\n        if (state.current_tool_call_index != null) {\n          this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n        }\n      }\n\n      for (const toolCall of choice.delta.tool_calls ?? []) {\n        if (state.current_tool_call_index !== toolCall.index) {\n          this.#emitContentDoneEvents(choiceSnapshot);\n\n          // new tool call started, the previous one is done\n          if (state.current_tool_call_index != null) {\n            this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n          }\n        }\n\n        state.current_tool_call_index = toolCall.index;\n      }\n\n      for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n        if (!toolCallSnapshot?.type) {\n          continue;\n        }\n\n        if (toolCallSnapshot?.type === 'function') {\n          this._emit('tool_calls.function.arguments.delta', {\n            name: toolCallSnapshot.function?.name,\n            index: toolCallDelta.index,\n            arguments: toolCallSnapshot.function.arguments,\n            parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n            arguments_delta: toolCallDelta.function?.arguments ?? '',\n          });\n        } else {\n          assertNever(toolCallSnapshot?.type);\n        }\n      }\n    }\n  }\n\n  #emitToolCallDoneEvent(choiceSnapshot: ChatCompletionSnapshot.Choice, toolCallIndex: number) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n    if (state.done_tool_calls.has(toolCallIndex)) {\n      // we've already fired the done event\n      return;\n    }\n\n    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n    if (!toolCallSnapshot) {\n      throw new Error('no tool call snapshot');\n    }\n    if (!toolCallSnapshot.type) {\n      throw new Error('tool call snapshot missing `type`');\n    }\n\n    if (toolCallSnapshot.type === 'function') {\n      const inputTool = this.#params?.tools?.find(\n        (tool) => tool.type === 'function' && tool.function.name === toolCallSnapshot.function.name,\n      );\n\n      this._emit('tool_calls.function.arguments.done', {\n        name: toolCallSnapshot.function.name,\n        index: toolCallIndex,\n        arguments: toolCallSnapshot.function.arguments,\n        parsed_arguments:\n          isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n          : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n          : null,\n      });\n    } else {\n      assertNever(toolCallSnapshot.type);\n    }\n  }\n\n  #emitContentDoneEvents(choiceSnapshot: ChatCompletionSnapshot.Choice) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n\n    if (choiceSnapshot.message.content && !state.content_done) {\n      state.content_done = true;\n\n      const responseFormat = this.#getAutoParseableResponseFormat();\n\n      this._emit('content.done', {\n        content: choiceSnapshot.message.content,\n        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : (null as any),\n      });\n    }\n\n    if (choiceSnapshot.message.refusal && !state.refusal_done) {\n      state.refusal_done = true;\n\n      this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n    }\n\n    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n      state.logprobs_content_done = true;\n\n      this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n    }\n\n    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n      state.logprobs_refusal_done = true;\n\n      this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n    }\n  }\n\n  #endRequest(): ParsedChatCompletion<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    this.#choiceEventStates = [];\n    return finalizeChatCompletion(snapshot, this.#params);\n  }\n\n  protected override async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    super._createChatCompletion;\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.chat.completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #getAutoParseableResponseFormat(): AutoParseableResponseFormat<ParsedT> | null {\n    const responseFormat = this.#params?.response_format;\n    if (isAutoParsableResponseFormat<ParsedT>(responseFormat)) {\n      return responseFormat;\n    }\n\n    return null;\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, refusal, ...rest } = logprobs;\n          assertIsEmpty(rest);\n          Object.assign(choice.logprobs, rest);\n\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n\n          if (refusal) {\n            choice.logprobs.refusal ??= [];\n            choice.logprobs.refusal.push(...refusal);\n          }\n        }\n      }\n\n      if (finish_reason) {\n        choice.finish_reason = finish_reason;\n\n        if (this.#params && hasAutoParseableInput(this.#params)) {\n          if (finish_reason === 'length') {\n            throw new LengthFinishReasonError();\n          }\n\n          if (finish_reason === 'content_filter') {\n            throw new ContentFilterFinishReasonError();\n          }\n        }\n      }\n\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n\n      const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n      assertIsEmpty(rest);\n      Object.assign(choice.message, rest);\n\n      if (refusal) {\n        choice.message.refusal = (choice.message.refusal || '') + refusal;\n      }\n\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (content) {\n        choice.message.content = (choice.message.content || '') + content;\n\n        if (!choice.message.refusal && this.#getAutoParseableResponseFormat()) {\n          choice.message.parsed = partialParse(choice.message.content);\n        }\n      }\n\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??=\n            {} as ChatCompletionSnapshot.Choice.Message.ToolCall);\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { name: fn.name ?? '', arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) {\n            tool_call.function!.arguments += fn.arguments;\n\n            if (shouldParseToolCall(this.#params, tool_call)) {\n              tool_call.function!.parsed_arguments = partialParse(tool_call.function!.arguments);\n            }\n          }\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ChatCompletionStream<ParsedT>): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion<ParsedT>(\n  snapshot: ChatCompletionSnapshot,\n  params: ChatCompletionCreateParams | null,\n): ParsedChatCompletion<ParsedT> {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  const completion: ChatCompletion = {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) {\n          throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        }\n\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) {\n          throw new OpenAIError(`missing role for choice ${index}`);\n        }\n\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) {\n            throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          }\n\n          if (!name) {\n            throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          }\n\n          return {\n            ...choiceRest,\n            message: {\n              content,\n              function_call: { arguments: args, name },\n              role,\n              refusal: message.refusal ?? null,\n            },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              refusal: message.refusal ?? null,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                }\n                if (type == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                }\n                if (name == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                }\n                if (args == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n                }\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n\n  return maybeParseChatCompletion(completion, params);\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      refusal?: string | null;\n\n      parsed?: unknown | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: ChatCompletionRole;\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id: string;\n\n        function: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments: string;\n\n          parsed_arguments?: unknown;\n\n          /**\n           * The name of the function to call.\n           */\n          name: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n\ntype AssertIsEmpty<T extends {}> = keyof T extends never ? T : never;\n\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty<T extends {}>(obj: AssertIsEmpty<T>): asserts obj is AssertIsEmpty<T> {\n  return;\n}\n\nfunction assertNever(_x: never) {}\n", "import {\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from '../resources/chat/completions';\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../_shims/index';\nimport { RunnableTools, type BaseFunctionsArgs, type RunnableFunctions } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionStreamingRunner<ParsedT = null>\n  extends ChatCompletionStream<ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions<T extends (string | object)[]>(\n    client: OpenAI,\n    params: ChatCompletionStreamingFunctionRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[], ParsedT = null>(\n    client: OpenAI,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<ParsedT> {\n    const runner = new ChatCompletionStreamingRunner<ParsedT>(\n      // @ts-expect-error TODO these types are incompatible\n      params,\n    );\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nimport { BaseFunctionsArgs } from '../../../lib/RunnableFunction';\nimport { RunnerOptions } from '../../../lib/AbstractChatCompletionRunner';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nimport {\n  ChatCompletion,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionMessage,\n  ChatCompletionMessageToolCall,\n} from '../../chat/completions';\nimport { ExtractParsedContentFromParams, parseChatCompletion, validateInputTools } from '../../../lib/parser';\n\nexport {\n  ChatCompletionStreamingRunner,\n  type ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  type RunnableFunction,\n  type RunnableFunctions,\n  type RunnableFunctionWithParse,\n  type RunnableFunctionWithoutParse,\n  ParsingFunction,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nexport { type ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { type ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nexport {\n  ChatCompletionRunner,\n  type ChatCompletionFunctionRunnerParams,\n} from '../../../lib/ChatCompletionRunner';\n\nexport interface ParsedFunction extends ChatCompletionMessageToolCall.Function {\n  parsed_arguments?: unknown;\n}\n\nexport interface ParsedFunctionToolCall extends ChatCompletionMessageToolCall {\n  function: ParsedFunction;\n}\n\nexport interface ParsedChatCompletionMessage<ParsedT> extends ChatCompletionMessage {\n  parsed: ParsedT | null;\n  tool_calls?: Array<ParsedFunctionToolCall>;\n}\n\nexport interface ParsedChoice<ParsedT> extends ChatCompletion.Choice {\n  message: ParsedChatCompletionMessage<ParsedT>;\n}\n\nexport interface ParsedChatCompletion<ParsedT> extends ChatCompletion {\n  choices: Array<ParsedChoice<ParsedT>>;\n}\n\nexport type ChatCompletionParseParams = ChatCompletionCreateParamsNonStreaming;\n\nexport class Completions extends APIResource {\n  parse<Params extends ChatCompletionParseParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ParsedChatCompletion<ParsedT>> {\n    validateInputTools(body.tools);\n\n    return this._client.chat.completions\n      .create(body, {\n        ...options,\n        headers: {\n          ...options?.headers,\n          'X-Stainless-Helper-Method': 'beta.chat.completions.parse',\n        },\n      })\n      ._thenUnwrap((completion) => parseChatCompletion(completion, body));\n  }\n\n  /**\n   * @deprecated - use `runTools` instead.\n   */\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStreamingRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null> | ChatCompletionStreamingRunner<null> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runFunctions(\n        this._client,\n        body as ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n        options,\n      );\n    }\n    return ChatCompletionRunner.runFunctions(\n      this._client,\n      body as ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n      options,\n    );\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionStreamingRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any> | ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(\n    body: Params,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> | ChatCompletionStreamingRunner<ParsedT> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client,\n        body as ChatCompletionStreamingToolRunnerParams<any>,\n        options,\n      );\n    }\n\n    return ChatCompletionRunner.runTools(this._client, body as ChatCompletionToolRunnerParams<any>, options);\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ChatCompletionStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    return ChatCompletionStream.createChatCompletion(this._client, body, options);\n  }\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport namespace Chat {\n  export import Completions = CompletionsAPI.Completions;\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as Core from '../../../core';\n\nexport class Sessions extends APIResource {\n  /**\n   * Create an ephemeral API token for use in client-side applications with the\n   * Realtime API. Can be configured with the same session parameters as the\n   * `session.update` client event.\n   *\n   * It responds with a session object, plus a `client_secret` key which contains a\n   * usable ephemeral API token that can be used to authenticate browser clients for\n   * the Realtime API.\n   */\n  create(body: SessionCreateParams, options?: Core.RequestOptions): Core.APIPromise<SessionCreateResponse> {\n    return this._client.post('/realtime/sessions', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\n/**\n * Realtime session object configuration.\n */\nexport interface Session {\n  /**\n   * Unique identifier for the session object.\n   */\n  id?: string;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through Whisper and should be treated as rough guidance rather\n   * than the representation understood by the model.\n   */\n  input_audio_transcription?: Session.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<Session.Tool>;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: Session.TurnDetection | null;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n   */\n  voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace Session {\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through Whisper and should be treated as rough guidance rather\n   * than the representation understood by the model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The model to use for transcription, `whisper-1` is the only currently supported\n     * model.\n     */\n    model?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. `true` by default.\n     */\n    create_response?: boolean;\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs. `true` by default.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: 'server_vad';\n  }\n}\n\n/**\n * A new Realtime session configuration, with an ephermeral key. Default TTL for\n * keys is one minute.\n */\nexport interface SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  client_secret: SessionCreateResponse.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  input_audio_format?: string;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through Whisper and should be treated as rough guidance rather\n   * than the representation understood by the model.\n   */\n  input_audio_transcription?: SessionCreateResponse.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: string;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateResponse.Tool>;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: SessionCreateResponse.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n   */\n  voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  export interface ClientSecret {\n    /**\n     * Timestamp for when the token expires. Currently, all tokens expire after one\n     * minute.\n     */\n    expires_at: number;\n\n    /**\n     * Ephemeral key usable in client environments to authenticate connections to the\n     * Realtime API. Use this in client-side environments rather than a standard API\n     * token, which should only be used server-side.\n     */\n    value: string;\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through Whisper and should be treated as rough guidance rather\n   * than the representation understood by the model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The model to use for transcription, `whisper-1` is the only currently supported\n     * model.\n     */\n    model?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport interface SessionCreateParams {\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [OpenAI Whisper transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as rough guidance rather than the representation\n   * understood by the model. The client can optionally set the language and prompt\n   * for transcription, these fields will be passed to the Whisper API.\n   */\n  input_audio_transcription?: SessionCreateParams.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateParams.Tool>;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: SessionCreateParams.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n   */\n  voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateParams {\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [OpenAI Whisper transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as rough guidance rather than the representation\n   * understood by the model. The client can optionally set the language and prompt\n   * for transcription, these fields will be passed to the Whisper API.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, `whisper-1` is the only currently supported\n     * model.\n     */\n    model?: string;\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. The\n     * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n     * should match the audio language.\n     */\n    prompt?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. `true` by default.\n     */\n    create_response?: boolean;\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs. `true` by default.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport declare namespace Sessions {\n  export {\n    type Session as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as RealtimeAPI from './realtime';\nimport * as Shared from '../../shared';\nimport * as SessionsAPI from './sessions';\nimport {\n  Session as SessionsAPISession,\n  SessionCreateParams,\n  SessionCreateResponse,\n  Sessions,\n} from './sessions';\n\nexport class Realtime extends APIResource {\n  sessions: SessionsAPI.Sessions = new SessionsAPI.Sessions(this._client);\n}\n\n/**\n * Returned when a conversation is created. Emitted right after session creation.\n */\nexport interface ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  conversation: ConversationCreatedEvent.Conversation;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `conversation.created`.\n   */\n  type: 'conversation.created';\n}\n\nexport namespace ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id?: string;\n\n    /**\n     * The object type, must be `realtime.conversation`.\n     */\n    object?: 'realtime.conversation';\n  }\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItem {\n  /**\n   * The unique ID of the item, this can be generated by the client to help manage\n   * server-side context, but is not required because the server will generate one if\n   * not provided.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemContent>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`). These have no effect on the\n   * conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output';\n}\n\nexport interface ConversationItemContent {\n  /**\n   * ID of a previous conversation item to reference (for `item_reference` content\n   * types in `response.create` events). These can reference both client and server\n   * created items.\n   */\n  id?: string;\n\n  /**\n   * Base64-encoded audio bytes, used for `input_audio` content type.\n   */\n  audio?: string;\n\n  /**\n   * The text content, used for `input_text` and `text` content types.\n   */\n  text?: string;\n\n  /**\n   * The transcript of the audio, used for `input_audio` content type.\n   */\n  transcript?: string;\n\n  /**\n   * The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n   */\n  type?: 'input_text' | 'input_audio' | 'item_reference' | 'text';\n}\n\n/**\n * Add a new Item to the Conversation's context, including messages, function\n * calls, and function call responses. This event can be used both to populate a\n * \"history\" of the conversation and to add new items mid-stream, but has the\n * current limitation that it cannot populate assistant audio messages.\n *\n * If successful, the server will respond with a `conversation.item.created` event,\n * otherwise an `error` event will be sent.\n */\nexport interface ConversationItemCreateEvent {\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.create`.\n   */\n  type: 'conversation.item.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. If not\n   * set, the new item will be appended to the end of the conversation. If set to\n   * `root`, the new item will be added to the beginning of the conversation. If set\n   * to an existing ID, it allows an item to be inserted mid-conversation. If the ID\n   * cannot be found, an error will be returned and the item will not be added.\n   */\n  previous_item_id?: string;\n}\n\n/**\n * Returned when a conversation item is created. There are several scenarios that\n * produce this event:\n *\n * - The server is generating a Response, which if successful will produce either\n *   one or two Items, which will be of type `message` (role `assistant`) or type\n *   `function_call`.\n * - The input audio buffer has been committed, either by the client or the server\n *   (in `server_vad` mode). The server will take the content of the input audio\n *   buffer and add it to a new user message Item.\n * - The client has sent a `conversation.item.create` event to add a new Item to\n *   the Conversation.\n */\nexport interface ConversationItemCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The ID of the preceding item in the Conversation context, allows the client to\n   * understand the order of the conversation.\n   */\n  previous_item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.created`.\n   */\n  type: 'conversation.item.created';\n}\n\n/**\n * Send this event when you want to remove any item from the conversation history.\n * The server will respond with a `conversation.item.deleted` event, unless the\n * item does not exist in the conversation history, in which case the server will\n * respond with an error.\n */\nexport interface ConversationItemDeleteEvent {\n  /**\n   * The ID of the item to delete.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.delete`.\n   */\n  type: 'conversation.item.delete';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an item in the conversation is deleted by the client with a\n * `conversation.item.delete` event. This event is used to synchronize the server's\n * understanding of the conversation history with the client's view.\n */\nexport interface ConversationItemDeletedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item that was deleted.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.deleted`.\n   */\n  type: 'conversation.item.deleted';\n}\n\n/**\n * This event is the output of audio transcription for user audio written to the\n * user audio buffer. Transcription begins when the input audio buffer is committed\n * by the client or server (in `server_vad` mode). Transcription runs\n * asynchronously with Response creation, so this event may come before or after\n * the Response events.\n *\n * Realtime API models accept audio natively, and thus input transcription is a\n * separate process run on a separate ASR (Automatic Speech Recognition) model,\n * currently always `whisper-1`. Thus the transcript may diverge somewhat from the\n * model's interpretation, and should be treated as a rough guide.\n */\nexport interface ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item containing the audio.\n   */\n  item_id: string;\n\n  /**\n   * The transcribed text.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.completed`.\n   */\n  type: 'conversation.item.input_audio_transcription.completed';\n}\n\n/**\n * Returned when input audio transcription is configured, and a transcription\n * request for a user message failed. These events are separate from other `error`\n * events so that the client can identify the related Item.\n */\nexport interface ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * Details of the transcription error.\n   */\n  error: ConversationItemInputAudioTranscriptionFailedEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.failed`.\n   */\n  type: 'conversation.item.input_audio_transcription.failed';\n}\n\nexport namespace ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * Details of the transcription error.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message?: string;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Send this event to truncate a previous assistant message\u2019s audio. The server\n * will produce audio faster than realtime, so this event is useful when the user\n * interrupts to truncate audio that has already been sent to the client but not\n * yet played. This will synchronize the server's understanding of the audio with\n * the client's playback.\n *\n * Truncating audio will delete the server-side text transcript to ensure there is\n * not text in the context that hasn't been heard by the user.\n *\n * If successful, the server will respond with a `conversation.item.truncated`\n * event.\n */\nexport interface ConversationItemTruncateEvent {\n  /**\n   * Inclusive duration up to which audio is truncated, in milliseconds. If the\n   * audio_end_ms is greater than the actual audio duration, the server will respond\n   * with an error.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part to truncate. Set this to 0.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the assistant message item to truncate. Only assistant message items\n   * can be truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncate`.\n   */\n  type: 'conversation.item.truncate';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an earlier assistant audio message item is truncated by the client\n * with a `conversation.item.truncate` event. This event is used to synchronize the\n * server's understanding of the audio with the client's playback.\n *\n * This action will truncate the audio and remove the server-side text transcript\n * to ensure there is no text in the context that hasn't been heard by the user.\n */\nexport interface ConversationItemTruncatedEvent {\n  /**\n   * The duration up to which the audio was truncated, in milliseconds.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part that was truncated.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the assistant message item that was truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncated`.\n   */\n  type: 'conversation.item.truncated';\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItemWithReference {\n  /**\n   * For an item of type (`message` | `function_call` | `function_call_output`) this\n   * field allows the client to assign the unique ID of the item. It is not required\n   * because the server will generate one if not provided.\n   *\n   * For an item of type `item_reference`, this field is required and is a reference\n   * to any item that has previously existed in the conversation.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemContent>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`). These have no effect on the\n   * conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`,\n   * `item_reference`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output' | 'item_reference';\n}\n\n/**\n * Returned when an error occurs, which could be a client problem or a server\n * problem. Most errors are recoverable and the session will stay open, we\n * recommend to implementors to monitor and log error messages by default.\n */\nexport interface ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  error: ErrorEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `error`.\n   */\n  type: 'error';\n}\n\nexport namespace ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  export interface Error {\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The type of error (e.g., \"invalid_request_error\", \"server_error\").\n     */\n    type: string;\n\n    /**\n     * Error code, if any.\n     */\n    code?: string | null;\n\n    /**\n     * The event_id of the client event that caused the error, if applicable.\n     */\n    event_id?: string | null;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string | null;\n  }\n}\n\n/**\n * Send this event to append audio bytes to the input audio buffer. The audio\n * buffer is temporary storage you can write to and later commit. In Server VAD\n * mode, the audio buffer is used to detect speech and the server will decide when\n * to commit. When Server VAD is disabled, you must commit the audio buffer\n * manually.\n *\n * The client may choose how much audio to place in each event up to a maximum of\n * 15 MiB, for example streaming smaller chunks from the client may allow the VAD\n * to be more responsive. Unlike made other client events, the server will not send\n * a confirmation response to this event.\n */\nexport interface InputAudioBufferAppendEvent {\n  /**\n   * Base64-encoded audio bytes. This must be in the format specified by the\n   * `input_audio_format` field in the session configuration.\n   */\n  audio: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.append`.\n   */\n  type: 'input_audio_buffer.append';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to clear the audio bytes in the buffer. The server will respond\n * with an `input_audio_buffer.cleared` event.\n */\nexport interface InputAudioBufferClearEvent {\n  /**\n   * The event type, must be `input_audio_buffer.clear`.\n   */\n  type: 'input_audio_buffer.clear';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when the input audio buffer is cleared by the client with a\n * `input_audio_buffer.clear` event.\n */\nexport interface InputAudioBufferClearedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.cleared`.\n   */\n  type: 'input_audio_buffer.cleared';\n}\n\n/**\n * Send this event to commit the user input audio buffer, which will create a new\n * user message item in the conversation. This event will produce an error if the\n * input audio buffer is empty. When in Server VAD mode, the client does not need\n * to send this event, the server will commit the audio buffer automatically.\n *\n * Committing the input audio buffer will trigger input audio transcription (if\n * enabled in session configuration), but it will not create a response from the\n * model. The server will respond with an `input_audio_buffer.committed` event.\n */\nexport interface InputAudioBufferCommitEvent {\n  /**\n   * The event type, must be `input_audio_buffer.commit`.\n   */\n  type: 'input_audio_buffer.commit';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an input audio buffer is committed, either by the client or\n * automatically in server VAD mode. The `item_id` property is the ID of the user\n * message item that will be created, thus a `conversation.item.created` event will\n * also be sent to the client.\n */\nexport interface InputAudioBufferCommittedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted.\n   */\n  previous_item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.committed`.\n   */\n  type: 'input_audio_buffer.committed';\n}\n\n/**\n * Sent by the server when in `server_vad` mode to indicate that speech has been\n * detected in the audio buffer. This can happen any time audio is added to the\n * buffer (unless speech is already detected). The client may want to use this\n * event to interrupt audio playback or provide visual feedback to the user.\n *\n * The client should expect to receive a `input_audio_buffer.speech_stopped` event\n * when speech stops. The `item_id` property is the ID of the user message item\n * that will be created when speech stops and will also be included in the\n * `input_audio_buffer.speech_stopped` event (unless the client manually commits\n * the audio buffer during VAD activation).\n */\nexport interface InputAudioBufferSpeechStartedEvent {\n  /**\n   * Milliseconds from the start of all audio written to the buffer during the\n   * session when speech was first detected. This will correspond to the beginning of\n   * audio sent to the model, and thus includes the `prefix_padding_ms` configured in\n   * the Session.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created when speech stops.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_started`.\n   */\n  type: 'input_audio_buffer.speech_started';\n}\n\n/**\n * Returned in `server_vad` mode when the server detects the end of speech in the\n * audio buffer. The server will also send an `conversation.item.created` event\n * with the user message item that is created from the audio buffer.\n */\nexport interface InputAudioBufferSpeechStoppedEvent {\n  /**\n   * Milliseconds since the session started when speech stopped. This will correspond\n   * to the end of audio sent to the model, and thus includes the\n   * `min_silence_duration_ms` configured in the Session.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_stopped`.\n   */\n  type: 'input_audio_buffer.speech_stopped';\n}\n\n/**\n * Emitted at the beginning of a Response to indicate the updated rate limits. When\n * a Response is created some tokens will be \"reserved\" for the output tokens, the\n * rate limits shown here reflect that reservation, which is then adjusted\n * accordingly once the Response is completed.\n */\nexport interface RateLimitsUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * List of rate limit information.\n   */\n  rate_limits: Array<RateLimitsUpdatedEvent.RateLimit>;\n\n  /**\n   * The event type, must be `rate_limits.updated`.\n   */\n  type: 'rate_limits.updated';\n}\n\nexport namespace RateLimitsUpdatedEvent {\n  export interface RateLimit {\n    /**\n     * The maximum allowed value for the rate limit.\n     */\n    limit?: number;\n\n    /**\n     * The name of the rate limit (`requests`, `tokens`).\n     */\n    name?: 'requests' | 'tokens';\n\n    /**\n     * The remaining value before the limit is reached.\n     */\n    remaining?: number;\n\n    /**\n     * Seconds until the rate limit resets.\n     */\n    reset_seconds?: number;\n  }\n}\n\n/**\n * All events that the client can send to the Realtime API\n */\nexport type RealtimeClientEvent =\n  | SessionUpdateEvent\n  | InputAudioBufferAppendEvent\n  | InputAudioBufferCommitEvent\n  | InputAudioBufferClearEvent\n  | ConversationItemCreateEvent\n  | ConversationItemTruncateEvent\n  | ConversationItemDeleteEvent\n  | ResponseCreateEvent\n  | ResponseCancelEvent;\n\n/**\n * The response resource.\n */\nexport interface RealtimeResponse {\n  /**\n   * The unique ID of the response.\n   */\n  id?: string;\n\n  /**\n   * Which conversation the response is added to, determined by the `conversation`\n   * field in the `response.create` event. If `auto`, the response will be added to\n   * the default conversation and the value of `conversation_id` will be an id like\n   * `conv_1234`. If `none`, the response will not be added to any conversation and\n   * the value of `conversation_id` will be `null`. If responses are being triggered\n   * by server VAD, the response will be added to the default conversation, thus the\n   * `conversation_id` will be an id like `conv_1234`.\n   */\n  conversation_id?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls, that was used in this response.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The set of modalities the model used to respond. If there are multiple\n   * modalities, the model will pick one, for example if `modalities` is\n   * `[\"text\", \"audio\"]`, the model could be responding in either text or audio.\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The object type, must be `realtime.response`.\n   */\n  object?: 'realtime.response';\n\n  /**\n   * The list of output items generated by the response.\n   */\n  output?: Array<ConversationItem>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The final status of the response (`completed`, `cancelled`, `failed`, or\n   * `incomplete`).\n   */\n  status?: 'completed' | 'cancelled' | 'failed' | 'incomplete';\n\n  /**\n   * Additional details about the status.\n   */\n  status_details?: RealtimeResponseStatus;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * Usage statistics for the Response, this will correspond to billing. A Realtime\n   * API session will maintain a conversation context and append new Items to the\n   * Conversation, thus output from previous turns (text and audio tokens) will\n   * become the input for later turns.\n   */\n  usage?: RealtimeResponseUsage;\n\n  /**\n   * The voice the model used to respond. Current voice options are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n   */\n  voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\n/**\n * Additional details about the status.\n */\nexport interface RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  error?: RealtimeResponseStatus.Error;\n\n  /**\n   * The reason the Response did not complete. For a `cancelled` Response, one of\n   * `turn_detected` (the server VAD detected a new start of speech) or\n   * `client_cancelled` (the client sent a cancel event). For an `incomplete`\n   * Response, one of `max_output_tokens` or `content_filter` (the server-side safety\n   * filter activated and cut off the response).\n   */\n  reason?: 'turn_detected' | 'client_cancelled' | 'max_output_tokens' | 'content_filter';\n\n  /**\n   * The type of error that caused the response to fail, corresponding with the\n   * `status` field (`completed`, `cancelled`, `incomplete`, `failed`).\n   */\n  type?: 'completed' | 'cancelled' | 'incomplete' | 'failed';\n}\n\nexport namespace RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Usage statistics for the Response, this will correspond to billing. A Realtime\n * API session will maintain a conversation context and append new Items to the\n * Conversation, thus output from previous turns (text and audio tokens) will\n * become the input for later turns.\n */\nexport interface RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  input_token_details?: RealtimeResponseUsage.InputTokenDetails;\n\n  /**\n   * The number of input tokens used in the Response, including text and audio\n   * tokens.\n   */\n  input_tokens?: number;\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  output_token_details?: RealtimeResponseUsage.OutputTokenDetails;\n\n  /**\n   * The number of output tokens sent in the Response, including text and audio\n   * tokens.\n   */\n  output_tokens?: number;\n\n  /**\n   * The total number of tokens in the Response including input and output text and\n   * audio tokens.\n   */\n  total_tokens?: number;\n}\n\nexport namespace RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  export interface InputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of cached tokens used in the Response.\n     */\n    cached_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  export interface OutputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n}\n\n/**\n * All events that the Realtime API can send back\n */\nexport type RealtimeServerEvent =\n  | ErrorEvent\n  | SessionCreatedEvent\n  | SessionUpdatedEvent\n  | ConversationCreatedEvent\n  | InputAudioBufferCommittedEvent\n  | InputAudioBufferClearedEvent\n  | InputAudioBufferSpeechStartedEvent\n  | InputAudioBufferSpeechStoppedEvent\n  | ConversationItemCreatedEvent\n  | ConversationItemInputAudioTranscriptionCompletedEvent\n  | ConversationItemInputAudioTranscriptionFailedEvent\n  | ConversationItemTruncatedEvent\n  | ConversationItemDeletedEvent\n  | ResponseCreatedEvent\n  | ResponseDoneEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | RateLimitsUpdatedEvent;\n\n/**\n * Returned when the model-generated audio is updated.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * Base64-encoded audio data delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Returned when the model-generated audio is done. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is updated.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The transcript delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.delta`.\n   */\n  type: 'response.audio_transcript.delta';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is done\n * streaming. Also emitted when a Response is interrupted, incomplete, or\n * cancelled.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final transcript of the audio.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.done`.\n   */\n  type: 'response.audio_transcript.done';\n}\n\n/**\n * Send this event to cancel an in-progress response. The server will respond with\n * a `response.cancelled` event or an error if there is no response to cancel.\n */\nexport interface ResponseCancelEvent {\n  /**\n   * The event type, must be `response.cancel`.\n   */\n  type: 'response.cancel';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * A specific response ID to cancel - if not provided, will cancel an in-progress\n   * response in the default conversation.\n   */\n  response_id?: string;\n}\n\n/**\n * Returned when a new content part is added to an assistant message item during\n * response generation.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item to which the content part was added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseContentPartAddedEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * The content part that was added.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * Returned when a content part is done streaming in an assistant message item.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseContentPartDoneEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * The content part that is done.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * This event instructs the server to create a Response, which means triggering\n * model inference. When in Server VAD mode, the server will create Responses\n * automatically.\n *\n * A Response will include at least one Item, and may have two, in which case the\n * second will be a function call. These Items will be appended to the conversation\n * history.\n *\n * The server will respond with a `response.created` event, events for Items and\n * content created, and finally a `response.done` event to indicate the Response is\n * complete.\n *\n * The `response.create` event includes inference configuration like\n * `instructions`, and `temperature`. These fields will override the Session's\n * configuration for this Response only.\n */\nexport interface ResponseCreateEvent {\n  /**\n   * The event type, must be `response.create`.\n   */\n  type: 'response.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  response?: ResponseCreateEvent.Response;\n}\n\nexport namespace ResponseCreateEvent {\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  export interface Response {\n    /**\n     * Controls which conversation the response is added to. Currently supports `auto`\n     * and `none`, with `auto` as the default value. The `auto` value means that the\n     * contents of the response will be added to the default conversation. Set this to\n     * `none` to create an out-of-band response which will not add items to default\n     * conversation.\n     */\n    conversation?: (string & {}) | 'auto' | 'none';\n\n    /**\n     * Input items to include in the prompt for the model. Using this field creates a\n     * new context for this Response instead of using the default conversation. An\n     * empty array `[]` will clear the context for this Response. Note that this can\n     * include references to items from the default conversation.\n     */\n    input?: Array<RealtimeAPI.ConversationItemWithReference>;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function, like `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Response.Tool>;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n     */\n    voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Response {\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n  }\n}\n\n/**\n * Returned when a new Response is created. The first event of response creation,\n * where the response is in an initial state of `in_progress`.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * Returned when a Response is done streaming. Always emitted, no matter the final\n * state. The Response object included in the `response.done` event will include\n * all output Items in the Response but will omit the raw audio data.\n */\nexport interface ResponseDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.done`.\n   */\n  type: 'response.done';\n}\n\n/**\n * Returned when the model-generated function call arguments are updated.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The arguments delta as a JSON string.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Returned when the model-generated function call arguments are done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The final arguments as a JSON string.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.done`.\n   */\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * Returned when a new Item is created during Response generation.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Returned when an Item is done streaming. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is updated.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The text delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.text.delta`.\n   */\n  type: 'response.text.delta';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is done streaming. Also\n * emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final text content.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `response.text.done`.\n   */\n  type: 'response.text.done';\n}\n\n/**\n * Returned when a Session is created. Emitted automatically when a new connection\n * is established as the first server event. This event will contain the default\n * Session configuration.\n */\nexport interface SessionCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.created`.\n   */\n  type: 'session.created';\n}\n\n/**\n * Send this event to update the session\u2019s default configuration. The client may\n * send this event at any time to update any field, except for `voice`. However,\n * note that once a session has been initialized with a particular `model`, it\n * can\u2019t be changed to another model using `session.update`.\n *\n * When the server receives a `session.update`, it will respond with a\n * `session.updated` event showing the full, effective configuration. Only the\n * fields that are present are updated. To clear a field like `instructions`, pass\n * an empty string.\n */\nexport interface SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionUpdateEvent.Session;\n\n  /**\n   * The event type, must be `session.update`.\n   */\n  type: 'session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  export interface Session {\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [OpenAI Whisper transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as rough guidance rather than the representation\n     * understood by the model. The client can optionally set the language and prompt\n     * for transcription, these fields will be passed to the Whisper API.\n     */\n    input_audio_transcription?: Session.InputAudioTranscription;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The Realtime model used for this session.\n     */\n    model?:\n      | 'gpt-4o-realtime-preview'\n      | 'gpt-4o-realtime-preview-2024-10-01'\n      | 'gpt-4o-realtime-preview-2024-12-17'\n      | 'gpt-4o-mini-realtime-preview'\n      | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     * For `pcm16`, output audio is sampled at a rate of 24kHz.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Session.Tool>;\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    turn_detection?: Session.TurnDetection;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.\n     */\n    voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Session {\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [OpenAI Whisper transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as rough guidance rather than the representation\n     * understood by the model. The client can optionally set the language and prompt\n     * for transcription, these fields will be passed to the Whisper API.\n     */\n    export interface InputAudioTranscription {\n      /**\n       * The language of the input audio. Supplying the input language in\n       * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n       * format will improve accuracy and latency.\n       */\n      language?: string;\n\n      /**\n       * The model to use for transcription, `whisper-1` is the only currently supported\n       * model.\n       */\n      model?: string;\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio\n       * segment. The\n       * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n       * should match the audio language.\n       */\n      prompt?: string;\n    }\n\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    export interface TurnDetection {\n      /**\n       * Whether or not to automatically generate a response when a VAD stop event\n       * occurs. `true` by default.\n       */\n      create_response?: boolean;\n\n      /**\n       * Whether or not to automatically interrupt any ongoing response with output to\n       * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n       * occurs. `true` by default.\n       */\n      interrupt_response?: boolean;\n\n      /**\n       * Amount of audio to include before the VAD detected speech (in milliseconds).\n       * Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n       * With shorter values the model will respond more quickly, but may jump in on\n       * short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n       * threshold will require louder audio to activate the model, and thus might\n       * perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection, only `server_vad` is currently supported.\n       */\n      type?: string;\n    }\n  }\n}\n\n/**\n * Returned when a session is updated with a `session.update` event, unless there\n * is an error.\n */\nexport interface SessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.updated`.\n   */\n  type: 'session.updated';\n}\n\nRealtime.Sessions = Sessions;\n\nexport declare namespace Realtime {\n  export {\n    Sessions as Sessions,\n    type SessionsAPISession as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n}\n", "import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  MessageDelta,\n  MessageContent,\n} from '../resources/beta/threads/messages';\nimport * as Core from '../core';\nimport { RequestOptions } from '../core';\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from '../resources/beta/threads/runs/runs';\nimport { type ReadableStream } from '../_shims/index';\nimport { Stream } from '../streaming';\nimport { APIUserAbortError, OpenAIError } from '../error';\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from '../resources/beta/assistants';\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from '../resources/beta/threads/runs/steps';\nimport { ThreadCreateAndRunParamsBase, Threads } from '../resources/beta/threads/threads';\nimport { BaseEvents, EventStream } from './EventStream';\n\nexport interface AssistantStreamEvents extends BaseEvents {\n  run: (run: Run) => void;\n\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends EventStream<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(threadId, runId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    threadId: string,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(threadId, runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    params: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(params, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.incomplete':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n      default:\n        assertNever(event);\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(this: AssistantStream, event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(this: AssistantStream, event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(this: AssistantStream, event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (Core.isObj(accValue) && Core.isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n\n        for (const deltaEntry of deltaValue) {\n          if (!Core.isObj(deltaEntry)) {\n            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n          }\n\n          const index = deltaEntry['index'];\n          if (index == null) {\n            console.error(deltaEntry);\n            throw new Error('Expected array delta entry to have an `index` property');\n          }\n\n          if (typeof index !== 'number') {\n            throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n          }\n\n          const accEntry = accValue[index];\n          if (accEntry == null) {\n            accValue.push(deltaEntry);\n          } else {\n            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n          }\n        }\n        continue;\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(this: AssistantStream, event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected async _threadAssistantStream(\n    params: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, params, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, threadId, runId, params, options);\n  }\n}\n\nfunction assertNever(_x: never) {}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   */\n  create(\n    threadId: string,\n    body: MessageCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   */\n  retrieve(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<Message> {\n    return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a message.\n   */\n  update(\n    threadId: string,\n    messageId: string,\n    body: MessageUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   */\n  list(\n    threadId: string,\n    query?: MessageListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<MessagesPage, Message>;\n  list(\n    threadId: string,\n    query: MessageListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/messages`, MessagesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Deletes a message.\n   */\n  del(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<MessageDeleted> {\n    return this._client.delete(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class MessagesPage extends CursorPage<Message> {}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent =\n  | ImageFileContentBlock\n  | ImageURLContentBlock\n  | TextContentBlock\n  | RefusalContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta =\n  | ImageFileDeltaBlock\n  | TextDeltaBlock\n  | RefusalDeltaBlock\n  | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\n/**\n * The refusal content generated by the assistant.\n */\nexport interface RefusalContentBlock {\n  refusal: string;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * The refusal content that is part of a message.\n */\nexport interface RefusalDeltaBlock {\n  /**\n   * The index of the refusal part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n\n  refusal?: string;\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nMessages.MessagesPage = MessagesPage;\n\nexport declare namespace Messages {\n  export {\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type Message as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport * as Core from '../../../../core';\nimport * as StepsAPI from './steps';\nimport * as Shared from '../../../shared';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\n\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   */\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query?: StepRetrieveParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query: StepRetrieveParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep> {\n    if (isRequestOptions(query)) {\n      return this.retrieve(threadId, runId, stepId, {}, query);\n    }\n    return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   */\n  list(\n    threadId: string,\n    runId: string,\n    query?: StepListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    query: StepListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, runId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class RunStepsPage extends CursorPage<RunStep> {}\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: FileSearchToolCall.FileSearch;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport namespace FileSearchToolCall {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  export interface FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n\n    /**\n     * The results of the file search.\n     */\n    results?: Array<FileSearch.Result>;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    export interface RankingOptions {\n      /**\n       * The ranker used for the file search.\n       */\n      ranker: 'default_2024_08_21';\n\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n    }\n\n    /**\n     * A result instance of the file search.\n     */\n    export interface Result {\n      /**\n       * The ID of the file that result was found in.\n       */\n      file_id: string;\n\n      /**\n       * The name of the file that result was found in.\n       */\n      file_name: string;\n\n      /**\n       * The score of the result. All values must be a floating point number between 0\n       * and 1.\n       */\n      score: number;\n\n      /**\n       * The content of the result that was found. The content is only included if\n       * requested via the include query parameter.\n       */\n      content?: Array<Result.Content>;\n    }\n\n    export namespace Result {\n      export interface Content {\n        /**\n         * The text content of the file.\n         */\n        text?: string;\n\n        /**\n         * The type of the content.\n         */\n        type?: 'text';\n      }\n    }\n  }\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\nexport type RunStepInclude = 'step_details.tool_calls[*].file_search.results[*].content';\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepRetrieveParams {\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nSteps.RunStepsPage = RunStepsPage;\n\nexport declare namespace Steps {\n  export {\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport { APIPromise } from '../../../../core';\nimport * as Core from '../../../../core';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../core';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport * as RunsAPI from './runs';\nimport * as Shared from '../../../shared';\nimport * as AssistantsAPI from '../../assistants';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport {\n  CodeInterpreterLogs,\n  CodeInterpreterOutputImage,\n  CodeInterpreterToolCall,\n  CodeInterpreterToolCallDelta,\n  FileSearchToolCall,\n  FileSearchToolCallDelta,\n  FunctionToolCall,\n  FunctionToolCallDelta,\n  MessageCreationStepDetails,\n  RunStep,\n  RunStepDelta,\n  RunStepDeltaEvent,\n  RunStepDeltaMessageDelta,\n  RunStepInclude,\n  RunStepsPage,\n  StepListParams,\n  StepRetrieveParams,\n  Steps,\n  ToolCall,\n  ToolCallDelta,\n  ToolCallDeltaObject,\n  ToolCallsStepDetails,\n} from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\nimport { Stream } from '../../../../streaming';\n\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   */\n  create(\n    threadId: string,\n    params: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  create(\n    threadId: string,\n    params: RunCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadId: string,\n    params: RunCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { include, ...body } = params;\n    return this._client.post(`/threads/${threadId}/runs`, {\n      query: { include },\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   */\n  retrieve(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.get(`/threads/${threadId}/runs/${runId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a run.\n   */\n  update(\n    threadId: string,\n    runId: string,\n    body: RunUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   */\n  list(\n    threadId: string,\n    query?: RunListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<RunsPage, Run>;\n  list(\n    threadId: string,\n    query: RunListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   */\n  cancel(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(threadId, runId, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: Core.RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   */\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(threadId, runId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(\n      threadId,\n      runId,\n      this._client.beta.threads.runs,\n      body,\n      options,\n    );\n  }\n}\n\nexport class RunsPage extends CursorPage<Run> {}\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * Body param: The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<StepsAPI.RunStepInclude>;\n\n  /**\n   * Body param: Appends additional instructions at the end of the instructions for\n   * the run. This is useful for modifying the behavior on a per-run basis without\n   * overriding other instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Body param: Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Body param: Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * Body param: The maximum number of completion tokens that may be used over the\n   * course of the run. The run will make a best effort to use only the number of\n   * completion tokens specified, across multiple turns of the run. If the run\n   * exceeds the number of completion tokens specified, the run will end with status\n   * `incomplete`. See `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * Body param: The maximum number of prompt tokens that may be used over the course\n   * of the run. The run will make a best effort to use only the number of prompt\n   * tokens specified, across multiple turns of the run. If the run exceeds the\n   * number of prompt tokens specified, the run will end with status `incomplete`.\n   * See `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Body param: The ID of the\n   * [Model](https://platform.openai.com/docs/api-reference/models) to be used to\n   * execute this run. If a value is provided here, it will override the model\n   * associated with the assistant. If not, the model associated with the assistant\n   * will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Body param: Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Body param: **o-series models only**\n   *\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `low`, `medium`, and `high`. Reducing reasoning effort can\n   * result in faster responses and fewer tokens used on reasoning in a response.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Body param: Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Body param: What sampling temperature to use, between 0 and 2. Higher values\n   * like 0.8 will make the output more random, while lower values like 0.2 will make\n   * it more focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Body param: Controls which (if any) tool is called by the model. `none` means\n   * the model will not call any tools and instead generates a message. `auto` is the\n   * default value and means the model can pick between generating a message or\n   * calling one or more tools. `required` means the model must call one or more\n   * tools before responding to the user. Specifying a particular tool like\n   * `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Body param: Override the tools the assistant can use for this run. This is\n   * useful for modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * Body param: An alternative to sampling with temperature, called nucleus\n   * sampling, where the model considers the results of the tokens with top_p\n   * probability mass. So 0.1 means only the tokens comprising the top 10%\n   * probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Body param: Controls for how a thread will be truncated prior to the run. Use\n   * this to control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCreateAndPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndPollParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndPollParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndPollParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunCreateAndStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface RunSubmitToolOutputsAndPollParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsAndPollParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsAndPollParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport interface RunSubmitToolOutputsStreamParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsStreamParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsStreamParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nRuns.RunsPage = RunsPage;\nRuns.Steps = Steps;\nRuns.RunStepsPage = RunStepsPage;\n\nexport declare namespace Runs {\n  export {\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Steps as Steps,\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport { APIPromise } from '../../../core';\nimport * as Core from '../../../core';\nimport * as ThreadsAPI from './threads';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport * as MessagesAPI from './messages';\nimport {\n  Annotation,\n  AnnotationDelta,\n  FileCitationAnnotation,\n  FileCitationDeltaAnnotation,\n  FilePathAnnotation,\n  FilePathDeltaAnnotation,\n  ImageFile,\n  ImageFileContentBlock,\n  ImageFileDelta,\n  ImageFileDeltaBlock,\n  ImageURL,\n  ImageURLContentBlock,\n  ImageURLDelta,\n  ImageURLDeltaBlock,\n  Message as MessagesAPIMessage,\n  MessageContent,\n  MessageContentDelta,\n  MessageContentPartParam,\n  MessageCreateParams,\n  MessageDeleted,\n  MessageDelta,\n  MessageDeltaEvent,\n  MessageListParams,\n  MessageUpdateParams,\n  Messages,\n  MessagesPage,\n  RefusalContentBlock,\n  RefusalDeltaBlock,\n  Text,\n  TextContentBlock,\n  TextContentBlockParam,\n  TextDelta,\n  TextDeltaBlock,\n} from './messages';\nimport * as RunsAPI from './runs/runs';\nimport {\n  RequiredActionFunctionToolCall,\n  Run,\n  RunCreateAndPollParams,\n  RunCreateAndStreamParams,\n  RunCreateParams,\n  RunCreateParamsNonStreaming,\n  RunCreateParamsStreaming,\n  RunListParams,\n  RunStatus,\n  RunStreamParams,\n  RunSubmitToolOutputsAndPollParams,\n  RunSubmitToolOutputsParams,\n  RunSubmitToolOutputsParamsNonStreaming,\n  RunSubmitToolOutputsParamsStreaming,\n  RunSubmitToolOutputsStreamParams,\n  RunUpdateParams,\n  Runs,\n  RunsPage,\n} from './runs/runs';\nimport { Stream } from '../../../streaming';\n\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   */\n  create(body?: ThreadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(\n    body: ThreadCreateParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Thread> {\n    if (isRequestOptions(body)) {\n      return this.create({}, body);\n    }\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   */\n  retrieve(threadId: string, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.get(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   */\n  update(threadId: string, body: ThreadUpdateParams, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.post(`/threads/${threadId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a thread.\n   */\n  del(threadId: string, options?: Core.RequestOptions): Core.APIPromise<ThreadDeleted> {\n    return this._client.delete(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   */\n  createAndRun(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.thread_id, run.id, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(\n    body: ThreadCreateAndRunParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n * Outputs which ensures the model will match your supplied JSON schema. Learn more\n * in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption =\n  | 'auto'\n  | Shared.ResponseFormatText\n  | Shared.ResponseFormatJSONObject\n  | Shared.ResponseFormatJSONSchema;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format, and\n       * querying for objects via API or the dashboard.\n       *\n       * Keys are strings with a maximum length of 64 characters. Values are strings with\n       * a maximum length of 512 characters.\n       */\n      metadata?: Shared.Metadata | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy.\n           */\n          chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to an object. This can be useful\n           * for storing additional information about the object in a structured format, and\n           * querying for objects via API or the dashboard.\n           *\n           * Keys are strings with a maximum length of 64 characters. Values are strings with\n           * a maximum length of 512 characters.\n           */\n          metadata?: Shared.Metadata | null;\n        }\n\n        export namespace VectorStore {\n          /**\n           * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n           * `800` and `chunk_overlap_tokens` of `400`.\n           */\n          export interface Auto {\n            /**\n             * Always `auto`.\n             */\n            type: 'auto';\n          }\n\n          export interface Static {\n            static: Static.Static;\n\n            /**\n             * Always `static`.\n             */\n            type: 'static';\n          }\n\n          export namespace Static {\n            export interface Static {\n              /**\n               * The number of tokens that overlap between chunks. The default value is `400`.\n               *\n               * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n               */\n              chunk_overlap_tokens: number;\n\n              /**\n               * The maximum number of tokens in each chunk. The default value is `800`. The\n               * minimum value is `100` and the maximum value is `4096`.\n               */\n              max_chunk_size_tokens: number;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface ThreadCreateAndRunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunStreamParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunStreamParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunStreamParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nThreads.Runs = Runs;\nThreads.RunsPage = RunsPage;\nThreads.Messages = Messages;\nThreads.MessagesPage = MessagesPage;\n\nexport declare namespace Threads {\n  export {\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n\n  export {\n    Runs as Runs,\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Messages as Messages,\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type MessagesAPIMessage as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as AssistantsAPI from './assistants';\nimport * as ChatAPI from './chat/chat';\nimport {\n  Assistant,\n  AssistantCreateParams,\n  AssistantDeleted,\n  AssistantListParams,\n  AssistantStreamEvent,\n  AssistantTool,\n  AssistantUpdateParams,\n  Assistants,\n  AssistantsPage,\n  CodeInterpreterTool,\n  FileSearchTool,\n  FunctionTool,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n  ThreadStreamEvent,\n} from './assistants';\nimport * as RealtimeAPI from './realtime/realtime';\nimport { Realtime } from './realtime/realtime';\nimport * as ThreadsAPI from './threads/threads';\nimport {\n  AssistantResponseFormatOption,\n  AssistantToolChoice,\n  AssistantToolChoiceFunction,\n  AssistantToolChoiceOption,\n  Thread,\n  ThreadCreateAndRunParams,\n  ThreadCreateAndRunParamsNonStreaming,\n  ThreadCreateAndRunParamsStreaming,\n  ThreadCreateAndRunPollParams,\n  ThreadCreateAndRunStreamParams,\n  ThreadCreateParams,\n  ThreadDeleted,\n  ThreadUpdateParams,\n  Threads,\n} from './threads/threads';\nimport { Chat } from './chat/chat';\n\nexport class Beta extends APIResource {\n  realtime: RealtimeAPI.Realtime = new RealtimeAPI.Realtime(this._client);\n  chat: ChatAPI.Chat = new ChatAPI.Chat(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nBeta.Realtime = Realtime;\nBeta.Assistants = Assistants;\nBeta.AssistantsPage = AssistantsPage;\nBeta.Threads = Threads;\n\nexport declare namespace Beta {\n  export { Realtime as Realtime };\n\n  export { Chat };\n\n  export {\n    Assistants as Assistants,\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export {\n    Threads as Threads,\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { APIPromise } from '../core';\nimport * as Core from '../core';\nimport * as CompletionsAPI from './completions';\nimport * as CompletionsCompletionsAPI from './chat/completions/completions';\nimport { Stream } from '../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\n  create(\n    body: CompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<Record<string, number>>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  completion_tokens_details?: CompletionUsage.CompletionTokensDetails;\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  prompt_tokens_details?: CompletionUsage.PromptTokensDetails;\n}\n\nexport namespace CompletionUsage {\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  export interface CompletionTokensDetails {\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that\n     * appeared in the completion.\n     */\n    accepted_prediction_tokens?: number;\n\n    /**\n     * Audio input tokens generated by the model.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Tokens generated by the model for reasoning.\n     */\n    reasoning_tokens?: number;\n\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that did\n     * not appear in the completion. However, like reasoning tokens, these tokens are\n     * still counted in the total completion tokens for purposes of billing, output,\n     * and context window limits.\n     */\n    rejected_prediction_tokens?: number;\n  }\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  export interface PromptTokensDetails {\n    /**\n     * Audio input tokens present in the prompt.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Cached tokens present in the prompt.\n     */\n    cached_tokens?: number;\n  }\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return \u2013 `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: CompletionsCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport declare namespace Completions {\n  export {\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   */\n  create(\n    body: EmbeddingCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<CreateEmbeddingResponse> {\n    return this._client.post('/embeddings', { body, ...options });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens. Some models may also impose a limit on total number of\n   * tokens summed across inputs.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Embeddings {\n  export {\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport { sleep } from '../core';\nimport { APIConnectionTimeoutError } from '../error';\nimport * as Core from '../core';\nimport { CursorPage, type CursorPageParams } from '../pagination';\nimport { type Response } from '../_shims/index';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and the size of all files uploaded by one organization can be up\n   * to 100 GB.\n   *\n   * The Assistants API supports files up to 2 million tokens and of specific file\n   * types. See the\n   * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for\n   * details.\n   *\n   * The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   * required formats for fine-tuning\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * models.\n   *\n   * The Batch API only supports `.jsonl` files up to 200 MB in size. The input also\n   * has a specific required\n   * [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.post('/files', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.get(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns a list of files.\n   */\n  list(query?: FileListParams, options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FileObjectsPage, FileObject> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\n  }\n\n  /**\n   * Delete a file.\n   */\n  del(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileDeleted> {\n    return this._client.delete(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileId: string, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.get(`/files/${fileId}/content`, {\n      ...options,\n      headers: { Accept: 'application/binary', ...options?.headers },\n      __binaryResponse: true,\n    });\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   *\n   * @deprecated The `.content()` method should be used instead\n   */\n  retrieveContent(fileId: string, options?: Core.RequestOptions): Core.APIPromise<string> {\n    return this._client.get(`/files/${fileId}/content`, options);\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\nexport class FileObjectsPage extends CursorPage<FileObject> {}\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\n   * and `vision`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision';\n\n  /**\n   * @deprecated Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * The Unix timestamp (in seconds) for when the file will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * @deprecated Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\n/**\n * The intended purpose of the uploaded file. One of: - `assistants`: Used in the\n * Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for\n * fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`:\n * Flexible file type for any purpose - `evals`: Used for eval data sets\n */\nexport type FilePurpose = 'assistants' | 'batch' | 'fine-tune' | 'vision' | 'user_data' | 'evals';\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file. One of: - `assistants`: Used in the\n   * Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for\n   * fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`:\n   * Flexible file type for any purpose - `evals`: Used for eval data sets\n   */\n  purpose: FilePurpose;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nFiles.FileObjectsPage = FileObjectsPage;\n\nexport declare namespace Files {\n  export {\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   */\n  list(\n    fineTuningJobId: string,\n    query?: CheckpointListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    query: CheckpointListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    if (isRequestOptions(query)) {\n      return this.list(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/fine_tuning/jobs/${fineTuningJobId}/checkpoints`,\n      FineTuningJobCheckpointsPage,\n      { query, ...options },\n    );\n  }\n}\n\nexport class FineTuningJobCheckpointsPage extends CursorPage<FineTuningJobCheckpoint> {}\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nCheckpoints.FineTuningJobCheckpointsPage = FineTuningJobCheckpointsPage;\n\nexport declare namespace Checkpoints {\n  export {\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as CheckpointsAPI from './checkpoints';\nimport {\n  CheckpointListParams,\n  Checkpoints,\n  FineTuningJobCheckpoint,\n  FineTuningJobCheckpointsPage,\n} from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  create(body: JobCreateParams, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  retrieve(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   */\n  list(\n    query?: JobListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(\n    query: JobListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   */\n  cancel(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   */\n  listEvents(\n    fineTuningJobId: string,\n    query?: JobListEventsParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    query: JobListEventsParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    if (isRequestOptions(query)) {\n      return this.listEvents(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\n      query,\n      ...options,\n    });\n  }\n}\n\nexport class FineTuningJobsPage extends CursorPage<FineTuningJob> {}\n\nexport class FineTuningJobEventsPage extends CursorPage<FineTuningJobEvent> {}\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: FineTuningJob.Method;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: Method.Dpo;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: Method.Supervised;\n\n    /**\n     * The type of method. Is either `supervised` or `dpo`.\n     */\n    type?: 'supervised' | 'dpo';\n  }\n\n  export namespace Method {\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    export interface Dpo {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      hyperparameters?: Dpo.Hyperparameters;\n    }\n\n    export namespace Dpo {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      export interface Hyperparameters {\n        /**\n         * Number of examples in each batch. A larger batch size means that model\n         * parameters are updated less frequently, but with lower variance.\n         */\n        batch_size?: 'auto' | number;\n\n        /**\n         * The beta value for the DPO method. A higher beta value will increase the weight\n         * of the penalty between the policy and reference model.\n         */\n        beta?: 'auto' | number;\n\n        /**\n         * Scaling factor for the learning rate. A smaller learning rate may be useful to\n         * avoid overfitting.\n         */\n        learning_rate_multiplier?: 'auto' | number;\n\n        /**\n         * The number of epochs to train the model for. An epoch refers to one full cycle\n         * through the training dataset.\n         */\n        n_epochs?: 'auto' | number;\n      }\n    }\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    export interface Supervised {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      hyperparameters?: Supervised.Hyperparameters;\n    }\n\n    export namespace Supervised {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      export interface Hyperparameters {\n        /**\n         * Number of examples in each batch. A larger batch size means that model\n         * parameters are updated less frequently, but with lower variance.\n         */\n        batch_size?: 'auto' | number;\n\n        /**\n         * Scaling factor for the learning rate. A smaller learning rate may be useful to\n         * avoid overfitting.\n         */\n        learning_rate_multiplier?: 'auto' | number;\n\n        /**\n         * The number of epochs to train the model for. An epoch refers to one full cycle\n         * through the training dataset.\n         */\n        n_epochs?: 'auto' | number;\n      }\n    }\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  /**\n   * The object identifier.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * The log level of the event.\n   */\n  level: 'info' | 'warn' | 'error';\n\n  /**\n   * The message of the event.\n   */\n  message: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.event\".\n   */\n  object: 'fine_tuning.job.event';\n\n  /**\n   * The data associated with the event.\n   */\n  data?: unknown;\n\n  /**\n   * The type of event.\n   */\n  type?: 'message' | 'metrics';\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo' | 'gpt-4o-mini';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input),\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format, or if the fine-tuning method uses the\n   * [preference](https://platform.openai.com/docs/api-reference/fine-tuning/preference-input)\n   * format.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value is now deprecated\n   * in favor of `method`, and should be passed in under the `method` parameter.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: JobCreateParams.Method;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 64 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * @deprecated The hyperparameters used for the fine-tuning job. This value is now\n   * deprecated in favor of `method`, and should be passed in under the `method`\n   * parameter.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: Method.Dpo;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: Method.Supervised;\n\n    /**\n     * The type of method. Is either `supervised` or `dpo`.\n     */\n    type?: 'supervised' | 'dpo';\n  }\n\n  export namespace Method {\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    export interface Dpo {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      hyperparameters?: Dpo.Hyperparameters;\n    }\n\n    export namespace Dpo {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      export interface Hyperparameters {\n        /**\n         * Number of examples in each batch. A larger batch size means that model\n         * parameters are updated less frequently, but with lower variance.\n         */\n        batch_size?: 'auto' | number;\n\n        /**\n         * The beta value for the DPO method. A higher beta value will increase the weight\n         * of the penalty between the policy and reference model.\n         */\n        beta?: 'auto' | number;\n\n        /**\n         * Scaling factor for the learning rate. A smaller learning rate may be useful to\n         * avoid overfitting.\n         */\n        learning_rate_multiplier?: 'auto' | number;\n\n        /**\n         * The number of epochs to train the model for. An epoch refers to one full cycle\n         * through the training dataset.\n         */\n        n_epochs?: 'auto' | number;\n      }\n    }\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    export interface Supervised {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      hyperparameters?: Supervised.Hyperparameters;\n    }\n\n    export namespace Supervised {\n      /**\n       * The hyperparameters used for the fine-tuning job.\n       */\n      export interface Hyperparameters {\n        /**\n         * Number of examples in each batch. A larger batch size means that model\n         * parameters are updated less frequently, but with lower variance.\n         */\n        batch_size?: 'auto' | number;\n\n        /**\n         * Scaling factor for the learning rate. A smaller learning rate may be useful to\n         * avoid overfitting.\n         */\n        learning_rate_multiplier?: 'auto' | number;\n\n        /**\n         * The number of epochs to train the model for. An epoch refers to one full cycle\n         * through the training dataset.\n         */\n        n_epochs?: 'auto' | number;\n      }\n    }\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nJobs.FineTuningJobsPage = FineTuningJobsPage;\nJobs.FineTuningJobEventsPage = FineTuningJobEventsPage;\nJobs.Checkpoints = Checkpoints;\nJobs.FineTuningJobCheckpointsPage = FineTuningJobCheckpointsPage;\n\nexport declare namespace Jobs {\n  export {\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    FineTuningJobsPage as FineTuningJobsPage,\n    FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export {\n    Checkpoints as Checkpoints,\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as JobsAPI from './jobs/jobs';\nimport {\n  FineTuningJob,\n  FineTuningJobEvent,\n  FineTuningJobEventsPage,\n  FineTuningJobIntegration,\n  FineTuningJobWandbIntegration,\n  FineTuningJobWandbIntegrationObject,\n  FineTuningJobsPage,\n  JobCreateParams,\n  JobListEventsParams,\n  JobListParams,\n  Jobs,\n} from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n}\n\nFineTuning.Jobs = Jobs;\nFineTuning.FineTuningJobsPage = FineTuningJobsPage;\nFineTuning.FineTuningJobEventsPage = FineTuningJobEventsPage;\n\nexport declare namespace FineTuning {\n  export {\n    Jobs as Jobs,\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    FineTuningJobsPage as FineTuningJobsPage,\n    FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image.\n   */\n  createVariation(\n    body: ImageCreateVariationParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/variations', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an edited or extended image given an original image and a prompt.\n   */\n  edit(body: ImageEditParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/edits', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an image given a prompt.\n   */\n  generate(body: ImageGenerateParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/generations', { body, ...options });\n  }\n}\n\n/**\n * Represents the url or the content of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image, if `response_format` is\n   * `b64_json`.\n   */\n  b64_json?: string;\n\n  /**\n   * The prompt that was used to generate the image, if there was any revision to the\n   * prompt.\n   */\n  revised_prompt?: string;\n\n  /**\n   * The URL of the generated image, if `response_format` is `url` (default).\n   */\n  url?: string;\n}\n\nexport type ImageModel = 'dall-e-2' | 'dall-e-3';\n\nexport interface ImagesResponse {\n  created: number;\n\n  data: Array<Image>;\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageEditParams {\n  /**\n   * The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask\n   * is not provided, image must have transparency, which will be used as the mask.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters.\n   */\n  prompt: string;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageGenerateParams {\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2` and 4000 characters for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * The model to use for image generation.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `hd` creates images with finer\n   * details and greater consistency across the image. This param is only supported\n   * for `dall-e-3`.\n   */\n  quality?: 'standard' | 'hd';\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or\n   * `1024x1792` for `dall-e-3` models.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792' | null;\n\n  /**\n   * The style of the generated images. Must be one of `vivid` or `natural`. Vivid\n   * causes the model to lean towards generating hyper-real and dramatic images.\n   * Natural causes the model to produce more natural, less hyper-real looking\n   * images. This param is only supported for `dall-e-3`.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Images {\n  export {\n    type Image as Image,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageGenerateParams as ImageGenerateParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport { Page } from '../pagination';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: Core.RequestOptions): Core.APIPromise<Model> {\n    return this._client.get(`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: Core.RequestOptions): Core.PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', ModelsPage, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  del(model: string, options?: Core.RequestOptions): Core.APIPromise<ModelDeleted> {\n    return this._client.delete(`/models/${model}`, options);\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class ModelsPage extends Page<Model> {}\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nModels.ModelsPage = ModelsPage;\n\nexport declare namespace Models {\n  export { type Model as Model, type ModelDeleted as ModelDeleted, ModelsPage as ModelsPage };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text and/or image inputs are potentially harmful. Learn more in\n   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n   */\n  create(\n    body: ModerationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  category_applied_input_types: Moderation.CategoryAppliedInputTypes;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing, or that gives advice or instruction on how to commit\n     * illicit acts. For example, \"how to shoplift\" would fit this category.\n     */\n    illicit: boolean | null;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing that also includes violence, or that gives advice or\n     * instruction on the procurement of any weapon.\n     */\n    'illicit/violent': boolean | null;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  export interface CategoryAppliedInputTypes {\n    /**\n     * The applied input type(s) for the category 'harassment'.\n     */\n    harassment: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate'.\n     */\n    hate: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate/threatening'.\n     */\n    'hate/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit'.\n     */\n    illicit: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit/violent'.\n     */\n    'illicit/violent': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm'.\n     */\n    'self-harm': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual'.\n     */\n    sexual: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual/minors'.\n     */\n    'sexual/minors': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'violence'.\n     */\n    violence: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'violence/graphic'.\n     */\n    'violence/graphic': Array<'text' | 'image'>;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'illicit'.\n     */\n    illicit: number;\n\n    /**\n     * The score for the category 'illicit/violent'.\n     */\n    'illicit/violent': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * An object describing an image to classify.\n */\nexport interface ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  image_url: ModerationImageURLInput.ImageURL;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n}\n\nexport namespace ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n  }\n}\n\nexport type ModerationModel =\n  | 'omni-moderation-latest'\n  | 'omni-moderation-2024-09-26'\n  | 'text-moderation-latest'\n  | 'text-moderation-stable';\n\n/**\n * An object describing an image to classify.\n */\nexport type ModerationMultiModalInput = ModerationImageURLInput | ModerationTextInput;\n\n/**\n * An object describing text to classify.\n */\nexport interface ModerationTextInput {\n  /**\n   * A string of text to classify.\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * Input (or inputs) to classify. Can be a single string, an array of strings, or\n   * an array of multi-modal input objects similar to other models.\n   */\n  input: string | Array<string> | Array<ModerationMultiModalInput>;\n\n  /**\n   * The content moderation model you would like to use. Learn more in\n   * [the moderation guide](https://platform.openai.com/docs/guides/moderation), and\n   * learn about available models\n   * [here](https://platform.openai.com/docs/models#moderation).\n   */\n  model?: (string & {}) | ModerationModel;\n}\n\nexport declare namespace Moderations {\n  export {\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n}\n", "import { OpenAIError } from '../error';\nimport type { ChatCompletionTool } from '../resources/chat/completions';\nimport {\n  type FunctionTool,\n  type ParsedContent,\n  type ParsedResponse,\n  type ParsedResponseFunctionToolCall,\n  type ParsedResponseOutputItem,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsNonStreaming,\n  type ResponseFunctionToolCall,\n  type Tool,\n} from '../resources/responses/responses';\nimport { type AutoParseableTextFormat, isAutoParsableResponseFormat } from '../lib/parser';\n\ntype ParseableToolsParams = Array<Tool> | ChatCompletionTool | null;\n\nexport type ResponseCreateParamsWithTools = ResponseCreateParamsBase & {\n  tools?: ParseableToolsParams;\n};\n\nexport type ExtractParsedContentFromParams<Params extends ResponseCreateParamsWithTools> =\n  NonNullable<Params['text']>['format'] extends AutoParseableTextFormat<infer P> ? P : null;\n\nexport function maybeParseResponse<\n  Params extends ResponseCreateParamsBase | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...response,\n      output_parsed: null,\n      output: response.output.map((item) => {\n        if (item.type === 'function_call') {\n          return {\n            ...item,\n            parsed_arguments: null,\n          };\n        }\n\n        if (item.type === 'message') {\n          return {\n            ...item,\n            content: item.content.map((content) => ({\n              ...content,\n              parsed: null,\n            })),\n          };\n        } else {\n          return item;\n        }\n      }),\n    };\n  }\n\n  return parseResponse(response, params);\n}\n\nexport function parseResponse<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  const output: Array<ParsedResponseOutputItem<ParsedT>> = response.output.map(\n    (item): ParsedResponseOutputItem<ParsedT> => {\n      if (item.type === 'function_call') {\n        return {\n          ...item,\n          parsed_arguments: parseToolCall(params, item),\n        };\n      }\n      if (item.type === 'message') {\n        const content: Array<ParsedContent<ParsedT>> = item.content.map((content) => {\n          if (content.type === 'output_text') {\n            return {\n              ...content,\n              parsed: parseTextFormat(params, content.text),\n            };\n          }\n\n          return content;\n        });\n\n        return {\n          ...item,\n          content,\n        };\n      }\n\n      return item;\n    },\n  );\n\n  const parsed: Omit<ParsedResponse<ParsedT>, 'output_parsed'> = Object.assign({}, response, { output });\n  if (!Object.getOwnPropertyDescriptor(response, 'output_text')) {\n    addOutputText(parsed);\n  }\n\n  Object.defineProperty(parsed, 'output_parsed', {\n    enumerable: true,\n    get() {\n      for (const output of parsed.output) {\n        if (output.type !== 'message') {\n          continue;\n        }\n\n        for (const content of output.content) {\n          if (content.type === 'output_text' && content.parsed !== null) {\n            return content.parsed;\n          }\n        }\n      }\n\n      return null;\n    },\n  });\n\n  return parsed as ParsedResponse<ParsedT>;\n}\n\nfunction parseTextFormat<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.text?.format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if ('$parseRaw' in params.text?.format) {\n    const text_format = params.text?.format as unknown as AutoParseableTextFormat<ParsedT>;\n    return text_format.$parseRaw(content);\n  }\n\n  return JSON.parse(content);\n}\n\nexport function hasAutoParseableInput(params: ResponseCreateParamsWithTools): boolean {\n  if (isAutoParsableResponseFormat(params.text?.format)) {\n    return true;\n  }\n\n  return false;\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableResponseTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = FunctionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableResponseTool<OptionsT extends ToolOptions>(\n  tool: FunctionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableResponseTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableResponseTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nfunction getInputToolByName(input_tools: Array<Tool>, name: string): FunctionTool | undefined {\n  return input_tools.find((tool) => tool.type === 'function' && tool.name === name) as\n    | FunctionTool\n    | undefined;\n}\n\nfunction parseToolCall<Params extends ResponseCreateParamsBase>(\n  params: Params,\n  toolCall: ResponseFunctionToolCall,\n): ParsedResponseFunctionToolCall {\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n\n  return {\n    ...toolCall,\n    ...toolCall,\n    parsed_arguments:\n      isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.arguments)\n      : inputTool?.strict ? JSON.parse(toolCall.arguments)\n      : null,\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ResponseCreateParamsNonStreaming | null | undefined,\n  toolCall: ResponseFunctionToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n  return isAutoParsableTool(inputTool) || inputTool?.strict || false;\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n\nexport function addOutputText(rsp: Response): void {\n  const texts: string[] = [];\n  for (const output of rsp.output) {\n    if (output.type !== 'message') {\n      continue;\n    }\n\n    for (const content of output.content) {\n      if (content.type === 'output_text') {\n        texts.push(content.text);\n      }\n    }\n  }\n\n  rsp.output_text = texts.join('');\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as ResponsesAPI from './responses';\nimport { CursorPage, type CursorPageParams } from '../../pagination';\n\nexport class InputItems extends APIResource {\n  /**\n   * Returns a list of input items for a given response.\n   */\n  list(\n    responseId: string,\n    query?: InputItemListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<\n    ResponseItemListDataPage,\n    | ResponseItemList.Message\n    | ResponsesAPI.ResponseOutputMessage\n    | ResponsesAPI.ResponseFileSearchToolCall\n    | ResponsesAPI.ResponseComputerToolCall\n    | ResponseItemList.ComputerCallOutput\n    | ResponsesAPI.ResponseFunctionWebSearch\n    | ResponsesAPI.ResponseFunctionToolCall\n    | ResponseItemList.FunctionCallOutput\n  >;\n  list(\n    responseId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<\n    ResponseItemListDataPage,\n    | ResponseItemList.Message\n    | ResponsesAPI.ResponseOutputMessage\n    | ResponsesAPI.ResponseFileSearchToolCall\n    | ResponsesAPI.ResponseComputerToolCall\n    | ResponseItemList.ComputerCallOutput\n    | ResponsesAPI.ResponseFunctionWebSearch\n    | ResponsesAPI.ResponseFunctionToolCall\n    | ResponseItemList.FunctionCallOutput\n  >;\n  list(\n    responseId: string,\n    query: InputItemListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<\n    ResponseItemListDataPage,\n    | ResponseItemList.Message\n    | ResponsesAPI.ResponseOutputMessage\n    | ResponsesAPI.ResponseFileSearchToolCall\n    | ResponsesAPI.ResponseComputerToolCall\n    | ResponseItemList.ComputerCallOutput\n    | ResponsesAPI.ResponseFunctionWebSearch\n    | ResponsesAPI.ResponseFunctionToolCall\n    | ResponseItemList.FunctionCallOutput\n  > {\n    if (isRequestOptions(query)) {\n      return this.list(responseId, {}, query);\n    }\n    return this._client.getAPIList(`/responses/${responseId}/input_items`, ResponseItemListDataPage, {\n      query,\n      ...options,\n    });\n  }\n}\n\nexport class ResponseItemListDataPage extends CursorPage<\n  | ResponseItemList.Message\n  | ResponsesAPI.ResponseOutputMessage\n  | ResponsesAPI.ResponseFileSearchToolCall\n  | ResponsesAPI.ResponseComputerToolCall\n  | ResponseItemList.ComputerCallOutput\n  | ResponsesAPI.ResponseFunctionWebSearch\n  | ResponsesAPI.ResponseFunctionToolCall\n  | ResponseItemList.FunctionCallOutput\n> {}\n\n/**\n * A list of Response items.\n */\nexport interface ResponseItemList {\n  /**\n   * A list of items used to generate this response.\n   */\n  data: Array<\n    | ResponseItemList.Message\n    | ResponsesAPI.ResponseOutputMessage\n    | ResponsesAPI.ResponseFileSearchToolCall\n    | ResponsesAPI.ResponseComputerToolCall\n    | ResponseItemList.ComputerCallOutput\n    | ResponsesAPI.ResponseFunctionWebSearch\n    | ResponsesAPI.ResponseFunctionToolCall\n    | ResponseItemList.FunctionCallOutput\n  >;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport namespace ResponseItemList {\n  export interface Message {\n    /**\n     * The unique ID of the message input.\n     */\n    id: string;\n\n    /**\n     * A list of one or many input items to the model, containing different content\n     * types.\n     */\n    content: ResponsesAPI.ResponseInputMessageContentList;\n\n    /**\n     * The role of the message input. One of `user`, `system`, or `developer`.\n     */\n    role: 'user' | 'system' | 'developer';\n\n    /**\n     * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the message input. Always set to `message`.\n     */\n    type?: 'message';\n  }\n\n  export interface ComputerCallOutput {\n    /**\n     * The unique ID of the computer call tool output.\n     */\n    id: string;\n\n    /**\n     * The ID of the computer tool call that produced the output.\n     */\n    call_id: string;\n\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    output: ComputerCallOutput.Output;\n\n    /**\n     * The type of the computer tool call output. Always `computer_call_output`.\n     */\n    type: 'computer_call_output';\n\n    /**\n     * The safety checks reported by the API that have been acknowledged by the\n     * developer.\n     */\n    acknowledged_safety_checks?: Array<ComputerCallOutput.AcknowledgedSafetyCheck>;\n\n    /**\n     * The status of the message input. One of `in_progress`, `completed`, or\n     * `incomplete`. Populated when input items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n  }\n\n  export namespace ComputerCallOutput {\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    export interface Output {\n      /**\n       * Specifies the event type. For a computer screenshot, this property is always set\n       * to `computer_screenshot`.\n       */\n      type: 'computer_screenshot';\n\n      /**\n       * The identifier of an uploaded file that contains the screenshot.\n       */\n      file_id?: string;\n\n      /**\n       * The URL of the screenshot image.\n       */\n      image_url?: string;\n    }\n\n    /**\n     * A pending safety check for the computer call.\n     */\n    export interface AcknowledgedSafetyCheck {\n      /**\n       * The ID of the pending safety check.\n       */\n      id: string;\n\n      /**\n       * The type of the pending safety check.\n       */\n      code: string;\n\n      /**\n       * Details about the pending safety check.\n       */\n      message: string;\n    }\n  }\n\n  export interface FunctionCallOutput {\n    /**\n     * The unique ID of the function call tool output.\n     */\n    id: string;\n\n    /**\n     * The unique ID of the function tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * A JSON string of the output of the function tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the function tool call output. Always `function_call_output`.\n     */\n    type: 'function_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n  }\n}\n\nexport interface InputItemListParams extends CursorPageParams {\n  /**\n   * An item ID to list items before, used in pagination.\n   */\n  before?: string;\n\n  /**\n   * The order to return the input items in. Default is `asc`.\n   *\n   * - `asc`: Return the input items in ascending order.\n   * - `desc`: Return the input items in descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nInputItems.ResponseItemListDataPage = ResponseItemListDataPage;\n\nexport declare namespace InputItems {\n  export {\n    type ResponseItemList as ResponseItemList,\n    ResponseItemListDataPage as ResponseItemListDataPage,\n    type InputItemListParams as InputItemListParams,\n  };\n}\n", "import {\n  type ParsedResponse,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsStreaming,\n  type ResponseStreamEvent,\n} from '../../resources/responses/responses';\nimport * as Core from '../../core';\nimport { APIUserAbortError, OpenAIError } from '../../error';\nimport OpenAI from '../../index';\nimport { type BaseEvents, EventStream } from '../EventStream';\nimport { type ResponseFunctionCallArgumentsDeltaEvent, type ResponseTextDeltaEvent } from './EventTypes';\nimport { maybeParseResponse } from '../ResponsesParser';\n\nexport type ResponseStreamParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ntype ResponseEvents = BaseEvents &\n  Omit<\n    {\n      [K in ResponseStreamEvent['type']]: (event: Extract<ResponseStreamEvent, { type: K }>) => void;\n    },\n    'response.output_text.delta' | 'response.function_call_arguments.delta'\n  > & {\n    event: (event: ResponseStreamEvent) => void;\n    'response.output_text.delta': (event: ResponseTextDeltaEvent) => void;\n    'response.function_call_arguments.delta': (event: ResponseFunctionCallArgumentsDeltaEvent) => void;\n  };\n\nexport type ResponseStreamingParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class ResponseStream<ParsedT = null>\n  extends EventStream<ResponseEvents>\n  implements AsyncIterable<ResponseStreamEvent>\n{\n  #params: ResponseStreamingParams | null;\n  #currentResponseSnapshot: Response | undefined;\n  #finalResponse: ParsedResponse<ParsedT> | undefined;\n\n  constructor(params: ResponseStreamingParams | null) {\n    super();\n    this.#params = params;\n  }\n\n  static createResponse<ParsedT>(\n    client: OpenAI,\n    params: ResponseStreamParams,\n    options?: Core.RequestOptions,\n  ): ResponseStream<ParsedT> {\n    const runner = new ResponseStream<ParsedT>(params as ResponseCreateParamsStreaming);\n    runner._run(() =>\n      runner._createResponse(client, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentResponseSnapshot = undefined;\n  }\n\n  #addEvent(this: ResponseStream<ParsedT>, event: ResponseStreamEvent) {\n    if (this.ended) return;\n\n    const response = this.#accumulateResponse(event);\n    this._emit('event', event);\n\n    switch (event.type) {\n      case 'response.output_text.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n\n          this._emit('response.output_text.delta', {\n            ...event,\n            snapshot: content.text,\n          });\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          this._emit('response.function_call_arguments.delta', {\n            ...event,\n            snapshot: output.arguments,\n          });\n        }\n        break;\n      }\n      default:\n        // @ts-ignore\n        this._emit(event.type, event);\n        break;\n    }\n  }\n\n  #endRequest(): ParsedResponse<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any events`);\n    }\n    this.#currentResponseSnapshot = undefined;\n    const parsedResponse = finalizeResponse<ParsedT>(snapshot, this.#params);\n    this.#finalResponse = parsedResponse;\n\n    return parsedResponse;\n  }\n\n  protected async _createResponse(\n    client: OpenAI,\n    params: ResponseStreamingParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedResponse<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.responses.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this.#endRequest();\n  }\n\n  #accumulateResponse(event: ResponseStreamEvent): Response {\n    let snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      if (event.type !== 'response.created') {\n        throw new OpenAIError(\n          `When snapshot hasn't been set yet, expected 'response.created' event, got ${event.type}`,\n        );\n      }\n      snapshot = this.#currentResponseSnapshot = event.response;\n      return snapshot;\n    }\n\n    switch (event.type) {\n      case 'response.output_item.added': {\n        snapshot.output.push(event.item);\n        break;\n      }\n      case 'response.content_part.added': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          output.content.push(event.part);\n        }\n        break;\n      }\n      case 'response.output_text.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n          content.text += event.delta;\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          output.arguments += event.delta;\n        }\n        break;\n      }\n      case 'response.completed': {\n        this.#currentResponseSnapshot = event.response;\n        break;\n      }\n    }\n\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ResponseStream<ParsedT>): AsyncIterator<ResponseStreamEvent> {\n    const pushQueue: ResponseStreamEvent[] = [];\n    const readQueue: {\n      resolve: (event: ResponseStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ResponseStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ResponseStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((event) => (event ? { value: event, done: false } : { value: undefined, done: true }));\n        }\n        const event = pushQueue.shift()!;\n        return { value: event, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  /**\n   * @returns a promise that resolves with the final Response, or rejects\n   * if an error occurred or the stream ended prematurely without producing a REsponse.\n   */\n  async finalResponse(): Promise<ParsedResponse<ParsedT>> {\n    await this.done();\n    const response = this.#finalResponse;\n    if (!response) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return response;\n  }\n}\n\nfunction finalizeResponse<ParsedT>(\n  snapshot: Response,\n  params: ResponseStreamingParams | null,\n): ParsedResponse<ParsedT> {\n  return maybeParseResponse(snapshot, params);\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport {\n  type ExtractParsedContentFromParams,\n  parseResponse,\n  type ResponseCreateParamsWithTools,\n  addOutputText,\n} from '../../lib/ResponsesParser';\nimport * as Core from '../../core';\nimport { APIPromise, isRequestOptions } from '../../core';\nimport { APIResource } from '../../resource';\nimport { Stream } from '../../streaming';\nimport * as Shared from '../shared';\nimport * as InputItemsAPI from './input-items';\nimport { InputItemListParams, InputItems, ResponseItemList, ResponseItemListDataPage } from './input-items';\nimport * as ResponsesAPI from './responses';\nimport { ResponseStream, ResponseStreamParams } from '../../lib/responses/ResponseStream';\n\nexport interface ParsedResponseOutputText<ParsedT> extends ResponseOutputText {\n  parsed: ParsedT | null;\n}\n\nexport type ParsedContent<ParsedT> = ParsedResponseOutputText<ParsedT> | ResponseOutputRefusal;\n\nexport interface ParsedResponseOutputMessage<ParsedT> extends ResponseOutputMessage {\n  content: ParsedContent<ParsedT>[];\n}\n\nexport interface ParsedResponseFunctionToolCall extends ResponseFunctionToolCall {\n  parsed_arguments: any;\n}\n\nexport type ParsedResponseOutputItem<ParsedT> =\n  | ParsedResponseOutputMessage<ParsedT>\n  | ParsedResponseFunctionToolCall\n  | ResponseFileSearchToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem;\n\nexport interface ParsedResponse<ParsedT> extends Response {\n  output: Array<ParsedResponseOutputItem<ParsedT>>;\n\n  output_parsed: ParsedT | null;\n}\n\nexport type ResponseParseParams = ResponseCreateParamsNonStreaming;\nexport class Responses extends APIResource {\n  inputItems: InputItemsAPI.InputItems = new InputItemsAPI.InputItems(this._client);\n\n  /**\n   * Creates a model response. Provide\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [image](https://platform.openai.com/docs/guides/images) inputs to generate\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have\n   * the model call your own\n   * [custom code](https://platform.openai.com/docs/guides/function-calling) or use\n   * built-in [tools](https://platform.openai.com/docs/guides/tools) like\n   * [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   * [file search](https://platform.openai.com/docs/guides/tools-file-search) to use\n   * your own data as input for the model's response.\n   */\n  create(body: ResponseCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Response>;\n  create(\n    body: ResponseCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent>>;\n  create(\n    body: ResponseCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent> | Response>;\n  create(\n    body: ResponseCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>> {\n    return (\n      this._client.post('/responses', { body, ...options, stream: body.stream ?? false }) as\n        | APIPromise<Response>\n        | APIPromise<Stream<ResponseStreamEvent>>\n    )._thenUnwrap((rsp) => {\n      if ('object' in rsp && rsp.object === 'response') {\n        addOutputText(rsp as Response);\n      }\n\n      return rsp;\n    }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a model response with the given ID.\n   */\n  retrieve(\n    responseId: string,\n    query?: ResponseRetrieveParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Response>;\n  retrieve(responseId: string, options?: Core.RequestOptions): Core.APIPromise<Response>;\n  retrieve(\n    responseId: string,\n    query: ResponseRetrieveParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Response> {\n    if (isRequestOptions(query)) {\n      return this.retrieve(responseId, {}, query);\n    }\n    return this._client.get(`/responses/${responseId}`, { query, ...options });\n  }\n\n  /**\n   * Deletes a model response with the given ID.\n   */\n  del(responseId: string, options?: Core.RequestOptions): Core.APIPromise<void> {\n    return this._client.delete(`/responses/${responseId}`, {\n      ...options,\n      headers: { Accept: '*/*', ...options?.headers },\n    });\n  }\n\n  parse<Params extends ResponseCreateParamsWithTools, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ParsedResponse<ParsedT>> {\n    return this._client.responses\n      .create(body, options)\n      ._thenUnwrap((response) => parseResponse(response as Response, body));\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ResponseStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): ResponseStream<ParsedT> {\n    return ResponseStream.createResponse<ParsedT>(this._client, body, options);\n  }\n}\n\n/**\n * A tool that controls a virtual computer. Learn more about the\n * [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).\n */\nexport interface ComputerTool {\n  /**\n   * The height of the computer display.\n   */\n  display_height: number;\n\n  /**\n   * The width of the computer display.\n   */\n  display_width: number;\n\n  /**\n   * The type of computer environment to control.\n   */\n  environment: 'mac' | 'windows' | 'ubuntu' | 'browser';\n\n  /**\n   * The type of the computer use tool. Always `computer_use_preview`.\n   */\n  type: 'computer-preview';\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport interface EasyInputMessage {\n  /**\n   * Text, image, or audio input to the model, used to generate a response. Can also\n   * contain previous assistant responses.\n   */\n  content: string | ResponseInputMessageContentList;\n\n  /**\n   * The role of the message input. One of `user`, `assistant`, `system`, or\n   * `developer`.\n   */\n  role: 'user' | 'assistant' | 'system' | 'developer';\n\n  /**\n   * The type of the message input. Always `message`.\n   */\n  type?: 'message';\n}\n\n/**\n * A tool that searches for relevant content from uploaded files. Learn more about\n * the\n * [file search tool](https://platform.openai.com/docs/guides/tools-file-search).\n */\nexport interface FileSearchTool {\n  /**\n   * The type of the file search tool. Always `file_search`.\n   */\n  type: 'file_search';\n\n  /**\n   * The IDs of the vector stores to search.\n   */\n  vector_store_ids: Array<string>;\n\n  /**\n   * A filter to apply based on file attributes.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: FileSearchTool.RankingOptions;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    /**\n     * The ranker to use for the file search.\n     */\n    ranker?: 'auto' | 'default-2024-11-15';\n\n    /**\n     * The score threshold for the file search, a number between 0 and 1. Numbers\n     * closer to 1 will attempt to return only the most relevant results, but may\n     * return fewer results.\n     */\n    score_threshold?: number;\n  }\n}\n\n/**\n * Defines a function in your own code the model can choose to call. Learn more\n * about\n * [function calling](https://platform.openai.com/docs/guides/function-calling).\n */\nexport interface FunctionTool {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * A JSON schema object describing the parameters of the function.\n   */\n  parameters: Record<string, unknown>;\n\n  /**\n   * Whether to enforce strict parameter validation. Default `true`.\n   */\n  strict: boolean;\n\n  /**\n   * The type of the function tool. Always `function`.\n   */\n  type: 'function';\n\n  /**\n   * A description of the function. Used by the model to determine whether or not to\n   * call the function.\n   */\n  description?: string | null;\n}\n\nexport interface Response {\n  /**\n   * Unique identifier for this Response.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) of when this Response was created.\n   */\n  created_at: number;\n\n  output_text: string;\n\n  /**\n   * An error object returned when the model fails to generate a Response.\n   */\n  error: ResponseError | null;\n\n  /**\n   * Details about why the response is incomplete.\n   */\n  incomplete_details: Response.IncompleteDetails | null;\n\n  /**\n   * Inserts a system (or developer) message as the first item in the model's\n   * context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will be not be carried over to the next response. This makes it simple\n   * to swap out system (or developer) messages in new responses.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o1`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * The object type of this resource - always set to `response`.\n   */\n  object: 'response';\n\n  /**\n   * An array of content items generated by the model.\n   *\n   * - The length and order of items in the `output` array is dependent on the\n   *   model's response.\n   * - Rather than accessing the first item in the `output` array and assuming it's\n   *   an `assistant` message with the content generated by the model, you might\n   *   consider using the `output_text` property where supported in SDKs.\n   */\n  output: Array<ResponseOutputItem>;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature: number | null;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice: ToolChoiceOptions | ToolChoiceTypes | ToolChoiceFunction;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * The two categories of tools you can provide the model are:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code. Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   */\n  tools: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p: number | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * **o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * The status of the response generation. One of `completed`, `failed`,\n   * `in_progress`, or `incomplete`.\n   */\n  status?: ResponseStatus;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the context of this response and previous ones exceeds the model's\n   *   context window size, the model will truncate the response to fit the context\n   *   window by dropping input items in the middle of the conversation.\n   * - `disabled` (default): If a model response will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * Represents token usage details including input tokens, output tokens, a\n   * breakdown of output tokens, and the total tokens used.\n   */\n  usage?: ResponseUsage;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace Response {\n  /**\n   * Details about why the response is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the response is incomplete.\n     */\n    reason?: 'max_output_tokens' | 'content_filter';\n  }\n}\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * A chunk of Base64 encoded response audio bytes.\n   */\n  delta: string;\n\n  /**\n   * The type of the event. Always `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Emitted when the audio response is complete.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The type of the event. Always `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Emitted when there is a partial transcript of audio.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The partial transcript of the audio response.\n   */\n  delta: string;\n\n  /**\n   * The type of the event. Always `response.audio.transcript.delta`.\n   */\n  type: 'response.audio.transcript.delta';\n}\n\n/**\n * Emitted when the full audio transcript is completed.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The type of the event. Always `response.audio.transcript.done`.\n   */\n  type: 'response.audio.transcript.done';\n}\n\n/**\n * Emitted when a partial code snippet is added by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDeltaEvent {\n  /**\n   * The partial code snippet added by the code interpreter.\n   */\n  delta: string;\n\n  /**\n   * The index of the output item that the code interpreter call is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.code.delta`.\n   */\n  type: 'response.code_interpreter_call.code.delta';\n}\n\n/**\n * Emitted when code snippet output is finalized by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDoneEvent {\n  /**\n   * The final code snippet output by the code interpreter.\n   */\n  code: string;\n\n  /**\n   * The index of the output item that the code interpreter call is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.code.done`.\n   */\n  type: 'response.code_interpreter_call.code.done';\n}\n\n/**\n * Emitted when the code interpreter call is completed.\n */\nexport interface ResponseCodeInterpreterCallCompletedEvent {\n  /**\n   * A tool call to run code.\n   */\n  code_interpreter_call: ResponseCodeInterpreterToolCall;\n\n  /**\n   * The index of the output item that the code interpreter call is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.completed`.\n   */\n  type: 'response.code_interpreter_call.completed';\n}\n\n/**\n * Emitted when a code interpreter call is in progress.\n */\nexport interface ResponseCodeInterpreterCallInProgressEvent {\n  /**\n   * A tool call to run code.\n   */\n  code_interpreter_call: ResponseCodeInterpreterToolCall;\n\n  /**\n   * The index of the output item that the code interpreter call is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.in_progress`.\n   */\n  type: 'response.code_interpreter_call.in_progress';\n}\n\n/**\n * Emitted when the code interpreter is actively interpreting the code snippet.\n */\nexport interface ResponseCodeInterpreterCallInterpretingEvent {\n  /**\n   * A tool call to run code.\n   */\n  code_interpreter_call: ResponseCodeInterpreterToolCall;\n\n  /**\n   * The index of the output item that the code interpreter call is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.interpreting`.\n   */\n  type: 'response.code_interpreter_call.interpreting';\n}\n\n/**\n * A tool call to run code.\n */\nexport interface ResponseCodeInterpreterToolCall {\n  /**\n   * The unique ID of the code interpreter tool call.\n   */\n  id: string;\n\n  /**\n   * The code to run.\n   */\n  code: string;\n\n  /**\n   * The results of the code interpreter tool call.\n   */\n  results: Array<ResponseCodeInterpreterToolCall.Logs | ResponseCodeInterpreterToolCall.Files>;\n\n  /**\n   * The status of the code interpreter tool call.\n   */\n  status: 'in_progress' | 'interpreting' | 'completed';\n\n  /**\n   * The type of the code interpreter tool call. Always `code_interpreter_call`.\n   */\n  type: 'code_interpreter_call';\n}\n\nexport namespace ResponseCodeInterpreterToolCall {\n  /**\n   * The output of a code interpreter tool call that is text.\n   */\n  export interface Logs {\n    /**\n     * The logs of the code interpreter tool call.\n     */\n    logs: string;\n\n    /**\n     * The type of the code interpreter text output. Always `logs`.\n     */\n    type: 'logs';\n  }\n\n  /**\n   * The output of a code interpreter tool call that is a file.\n   */\n  export interface Files {\n    files: Array<Files.File>;\n\n    /**\n     * The type of the code interpreter file output. Always `files`.\n     */\n    type: 'files';\n  }\n\n  export namespace Files {\n    export interface File {\n      /**\n       * The ID of the file.\n       */\n      file_id: string;\n\n      /**\n       * The MIME type of the file.\n       */\n      mime_type: string;\n    }\n  }\n}\n\n/**\n * Emitted when the model response is complete.\n */\nexport interface ResponseCompletedEvent {\n  /**\n   * Properties of the completed response.\n   */\n  response: Response;\n\n  /**\n   * The type of the event. Always `response.completed`.\n   */\n  type: 'response.completed';\n}\n\n/**\n * A tool call to a computer use tool. See the\n * [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use)\n * for more information.\n */\nexport interface ResponseComputerToolCall {\n  /**\n   * The unique ID of the computer call.\n   */\n  id: string;\n\n  /**\n   * A click action.\n   */\n  action:\n    | ResponseComputerToolCall.Click\n    | ResponseComputerToolCall.DoubleClick\n    | ResponseComputerToolCall.Drag\n    | ResponseComputerToolCall.Keypress\n    | ResponseComputerToolCall.Move\n    | ResponseComputerToolCall.Screenshot\n    | ResponseComputerToolCall.Scroll\n    | ResponseComputerToolCall.Type\n    | ResponseComputerToolCall.Wait;\n\n  /**\n   * An identifier used when responding to the tool call with output.\n   */\n  call_id: string;\n\n  /**\n   * The pending safety checks for the computer call.\n   */\n  pending_safety_checks: Array<ResponseComputerToolCall.PendingSafetyCheck>;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the computer call. Always `computer_call`.\n   */\n  type: 'computer_call';\n}\n\nexport namespace ResponseComputerToolCall {\n  /**\n   * A click action.\n   */\n  export interface Click {\n    /**\n     * Indicates which mouse button was pressed during the click. One of `left`,\n     * `right`, `wheel`, `back`, or `forward`.\n     */\n    button: 'left' | 'right' | 'wheel' | 'back' | 'forward';\n\n    /**\n     * Specifies the event type. For a click action, this property is always set to\n     * `click`.\n     */\n    type: 'click';\n\n    /**\n     * The x-coordinate where the click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A double click action.\n   */\n  export interface DoubleClick {\n    /**\n     * Specifies the event type. For a double click action, this property is always set\n     * to `double_click`.\n     */\n    type: 'double_click';\n\n    /**\n     * The x-coordinate where the double click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the double click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A drag action.\n   */\n  export interface Drag {\n    /**\n     * An array of coordinates representing the path of the drag action. Coordinates\n     * will appear as an array of objects, eg\n     *\n     * ```\n     * [\n     *   { x: 100, y: 200 },\n     *   { x: 200, y: 300 }\n     * ]\n     * ```\n     */\n    path: Array<Drag.Path>;\n\n    /**\n     * Specifies the event type. For a drag action, this property is always set to\n     * `drag`.\n     */\n    type: 'drag';\n  }\n\n  export namespace Drag {\n    /**\n     * A series of x/y coordinate pairs in the drag path.\n     */\n    export interface Path {\n      /**\n       * The x-coordinate.\n       */\n      x: number;\n\n      /**\n       * The y-coordinate.\n       */\n      y: number;\n    }\n  }\n\n  /**\n   * A collection of keypresses the model would like to perform.\n   */\n  export interface Keypress {\n    /**\n     * The combination of keys the model is requesting to be pressed. This is an array\n     * of strings, each representing a key.\n     */\n    keys: Array<string>;\n\n    /**\n     * Specifies the event type. For a keypress action, this property is always set to\n     * `keypress`.\n     */\n    type: 'keypress';\n  }\n\n  /**\n   * A mouse move action.\n   */\n  export interface Move {\n    /**\n     * Specifies the event type. For a move action, this property is always set to\n     * `move`.\n     */\n    type: 'move';\n\n    /**\n     * The x-coordinate to move to.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate to move to.\n     */\n    y: number;\n  }\n\n  /**\n   * A screenshot action.\n   */\n  export interface Screenshot {\n    /**\n     * Specifies the event type. For a screenshot action, this property is always set\n     * to `screenshot`.\n     */\n    type: 'screenshot';\n  }\n\n  /**\n   * A scroll action.\n   */\n  export interface Scroll {\n    /**\n     * The horizontal scroll distance.\n     */\n    scroll_x: number;\n\n    /**\n     * The vertical scroll distance.\n     */\n    scroll_y: number;\n\n    /**\n     * Specifies the event type. For a scroll action, this property is always set to\n     * `scroll`.\n     */\n    type: 'scroll';\n\n    /**\n     * The x-coordinate where the scroll occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the scroll occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * An action to type in text.\n   */\n  export interface Type {\n    /**\n     * The text to type.\n     */\n    text: string;\n\n    /**\n     * Specifies the event type. For a type action, this property is always set to\n     * `type`.\n     */\n    type: 'type';\n  }\n\n  /**\n   * A wait action.\n   */\n  export interface Wait {\n    /**\n     * Specifies the event type. For a wait action, this property is always set to\n     * `wait`.\n     */\n    type: 'wait';\n  }\n\n  /**\n   * A pending safety check for the computer call.\n   */\n  export interface PendingSafetyCheck {\n    /**\n     * The ID of the pending safety check.\n     */\n    id: string;\n\n    /**\n     * The type of the pending safety check.\n     */\n    code: string;\n\n    /**\n     * Details about the pending safety check.\n     */\n    message: string;\n  }\n}\n\n/**\n * Multi-modal input and output contents.\n */\nexport type ResponseContent =\n  | ResponseInputText\n  | ResponseInputImage\n  | ResponseInputFile\n  | ResponseOutputText\n  | ResponseOutputRefusal;\n\n/**\n * Emitted when a new content part is added.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part that was added.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal;\n\n  /**\n   * The type of the event. Always `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\n/**\n * Emitted when a content part is done.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part that is done.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal;\n\n  /**\n   * The type of the event. Always `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\n/**\n * An event that is emitted when a response is created.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The response that was created.\n   */\n  response: Response;\n\n  /**\n   * The type of the event. Always `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * An error object returned when the model fails to generate a Response.\n */\nexport interface ResponseError {\n  /**\n   * The error code for the response.\n   */\n  code:\n    | 'server_error'\n    | 'rate_limit_exceeded'\n    | 'invalid_prompt'\n    | 'vector_store_timeout'\n    | 'invalid_image'\n    | 'invalid_image_format'\n    | 'invalid_base64_image'\n    | 'invalid_image_url'\n    | 'image_too_large'\n    | 'image_too_small'\n    | 'image_parse_error'\n    | 'image_content_policy_violation'\n    | 'invalid_image_mode'\n    | 'image_file_too_large'\n    | 'unsupported_image_media_type'\n    | 'empty_image_file'\n    | 'failed_to_download_image'\n    | 'image_file_not_found';\n\n  /**\n   * A human-readable description of the error.\n   */\n  message: string;\n}\n\n/**\n * Emitted when an error occurs.\n */\nexport interface ResponseErrorEvent {\n  /**\n   * The error code.\n   */\n  code: string | null;\n\n  /**\n   * The error message.\n   */\n  message: string;\n\n  /**\n   * The error parameter.\n   */\n  param: string | null;\n\n  /**\n   * The type of the event. Always `error`.\n   */\n  type: 'error';\n}\n\n/**\n * An event that is emitted when a response fails.\n */\nexport interface ResponseFailedEvent {\n  /**\n   * The response that failed.\n   */\n  response: Response;\n\n  /**\n   * The type of the event. Always `response.failed`.\n   */\n  type: 'response.failed';\n}\n\n/**\n * Emitted when a file search call is completed (results found).\n */\nexport interface ResponseFileSearchCallCompletedEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.completed`.\n   */\n  type: 'response.file_search_call.completed';\n}\n\n/**\n * Emitted when a file search call is initiated.\n */\nexport interface ResponseFileSearchCallInProgressEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.in_progress`.\n   */\n  type: 'response.file_search_call.in_progress';\n}\n\n/**\n * Emitted when a file search is currently searching.\n */\nexport interface ResponseFileSearchCallSearchingEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is searching.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.searching`.\n   */\n  type: 'response.file_search_call.searching';\n}\n\n/**\n * The results of a file search tool call. See the\n * [file search guide](https://platform.openai.com/docs/guides/tools-file-search)\n * for more information.\n */\nexport interface ResponseFileSearchToolCall {\n  /**\n   * The unique ID of the file search tool call.\n   */\n  id: string;\n\n  /**\n   * The queries used to search for files.\n   */\n  queries: Array<string>;\n\n  /**\n   * The status of the file search tool call. One of `in_progress`, `searching`,\n   * `incomplete` or `failed`,\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'incomplete' | 'failed';\n\n  /**\n   * The type of the file search tool call. Always `file_search_call`.\n   */\n  type: 'file_search_call';\n\n  /**\n   * The results of the file search tool call.\n   */\n  results?: Array<ResponseFileSearchToolCall.Result> | null;\n}\n\nexport namespace ResponseFileSearchToolCall {\n  export interface Result {\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard. Keys are strings with a maximum\n     * length of 64 characters. Values are strings with a maximum length of 512\n     * characters, booleans, or numbers.\n     */\n    attributes?: Record<string, string | number | boolean> | null;\n\n    /**\n     * The unique ID of the file.\n     */\n    file_id?: string;\n\n    /**\n     * The name of the file.\n     */\n    filename?: string;\n\n    /**\n     * The relevance score of the file - a value between 0 and 1.\n     */\n    score?: number;\n\n    /**\n     * The text that was retrieved from the file.\n     */\n    text?: string;\n  }\n}\n\n/**\n * An object specifying the format that the model must output.\n *\n * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n * ensures the model will match your supplied JSON schema. Learn more in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * The default format is `{ \"type\": \"text\" }` with no additional options.\n *\n * **Not recommended for gpt-4o and newer models:**\n *\n * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n * ensures the message the model generates is valid JSON. Using `json_schema` is\n * preferred for models that support it.\n */\nexport type ResponseFormatTextConfig =\n  | Shared.ResponseFormatText\n  | ResponseFormatTextJSONSchemaConfig\n  | Shared.ResponseFormatJSONObject;\n\n/**\n * JSON Schema response format. Used to generate structured JSON responses. Learn\n * more about\n * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n */\nexport interface ResponseFormatTextJSONSchemaConfig {\n  /**\n   * The schema for the response format, described as a JSON Schema object. Learn how\n   * to build JSON schemas [here](https://json-schema.org/).\n   */\n  schema: Record<string, unknown>;\n\n  /**\n   * The type of response format being defined. Always `json_schema`.\n   */\n  type: 'json_schema';\n\n  /**\n   * A description of what the response format is for, used by the model to determine\n   * how to respond in the format.\n   */\n  description?: string;\n\n  /**\n   * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores\n   * and dashes, with a maximum length of 64.\n   */\n  name?: string;\n\n  /**\n   * Whether to enable strict schema adherence when generating the output. If set to\n   * true, the model will always follow the exact schema defined in the `schema`\n   * field. Only a subset of JSON Schema is supported when `strict` is `true`. To\n   * learn more, read the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   */\n  strict?: boolean | null;\n}\n\n/**\n * Emitted when there is a partial function-call arguments delta.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The function-call arguments delta that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the function-call arguments delta is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the function-call arguments delta is added to.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Emitted when function-call arguments are finalized.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The function-call arguments.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item.\n   */\n  output_index: number;\n\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * A tool call to run a function. See the\n * [function calling guide](https://platform.openai.com/docs/guides/function-calling)\n * for more information.\n */\nexport interface ResponseFunctionToolCall {\n  /**\n   * The unique ID of the function tool call.\n   */\n  id: string;\n\n  /**\n   * A JSON string of the arguments to pass to the function.\n   */\n  arguments: string;\n\n  /**\n   * The unique ID of the function tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The name of the function to run.\n   */\n  name: string;\n\n  /**\n   * The type of the function tool call. Always `function_call`.\n   */\n  type: 'function_call';\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\n/**\n * The results of a web search tool call. See the\n * [web search guide](https://platform.openai.com/docs/guides/tools-web-search) for\n * more information.\n */\nexport interface ResponseFunctionWebSearch {\n  /**\n   * The unique ID of the web search tool call.\n   */\n  id: string;\n\n  /**\n   * The status of the web search tool call.\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'failed';\n\n  /**\n   * The type of the web search tool call. Always `web_search_call`.\n   */\n  type: 'web_search_call';\n}\n\n/**\n * Emitted when the response is in progress.\n */\nexport interface ResponseInProgressEvent {\n  /**\n   * The response that is in progress.\n   */\n  response: Response;\n\n  /**\n   * The type of the event. Always `response.in_progress`.\n   */\n  type: 'response.in_progress';\n}\n\n/**\n * Specify additional output data to include in the model response. Currently\n * supported values are:\n *\n * - `file_search_call.results`: Include the search results of the file search tool\n *   call.\n * - `message.input_image.image_url`: Include image urls from the input message.\n * - `computer_call_output.output.image_url`: Include image urls from the computer\n *   call output.\n */\nexport type ResponseIncludable =\n  | 'file_search_call.results'\n  | 'message.input_image.image_url'\n  | 'computer_call_output.output.image_url';\n\n/**\n * An event that is emitted when a response finishes as incomplete.\n */\nexport interface ResponseIncompleteEvent {\n  /**\n   * The response that was incomplete.\n   */\n  response: Response;\n\n  /**\n   * The type of the event. Always `response.incomplete`.\n   */\n  type: 'response.incomplete';\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInput = Array<ResponseInputItem>;\n\n/**\n * An audio input to the model.\n */\nexport interface ResponseInputAudio {\n  /**\n   * Base64-encoded audio data.\n   */\n  data: string;\n\n  /**\n   * The format of the audio data. Currently supported formats are `mp3` and `wav`.\n   */\n  format: 'mp3' | 'wav';\n\n  /**\n   * The type of the input item. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\n/**\n * A text input to the model.\n */\nexport type ResponseInputContent = ResponseInputText | ResponseInputImage | ResponseInputFile;\n\n/**\n * A file input to the model.\n */\nexport interface ResponseInputFile {\n  /**\n   * The type of the input item. Always `input_file`.\n   */\n  type: 'input_file';\n\n  /**\n   * The content of the file to be sent to the model.\n   */\n  file_data?: string;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string;\n\n  /**\n   * The name of the file to be sent to the model.\n   */\n  filename?: string;\n}\n\n/**\n * An image input to the model. Learn about\n * [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ResponseInputImage {\n  /**\n   * The detail level of the image to be sent to the model. One of `high`, `low`, or\n   * `auto`. Defaults to `auto`.\n   */\n  detail: 'high' | 'low' | 'auto';\n\n  /**\n   * The type of the input item. Always `input_image`.\n   */\n  type: 'input_image';\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the image to be sent to the model. A fully qualified URL or base64\n   * encoded image in a data URL.\n   */\n  image_url?: string | null;\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport type ResponseInputItem =\n  | EasyInputMessage\n  | ResponseInputItem.Message\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseComputerToolCall\n  | ResponseInputItem.ComputerCallOutput\n  | ResponseFunctionWebSearch\n  | ResponseFunctionToolCall\n  | ResponseInputItem.FunctionCallOutput\n  | ResponseReasoningItem\n  | ResponseInputItem.ItemReference;\n\nexport namespace ResponseInputItem {\n  /**\n   * A message input to the model with a role indicating instruction following\n   * hierarchy. Instructions given with the `developer` or `system` role take\n   * precedence over instructions given with the `user` role.\n   */\n  export interface Message {\n    /**\n     * A list of one or many input items to the model, containing different content\n     * types.\n     */\n    content: ResponsesAPI.ResponseInputMessageContentList;\n\n    /**\n     * The role of the message input. One of `user`, `system`, or `developer`.\n     */\n    role: 'user' | 'system' | 'developer';\n\n    /**\n     * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the message input. Always set to `message`.\n     */\n    type?: 'message';\n  }\n\n  /**\n   * The output of a computer tool call.\n   */\n  export interface ComputerCallOutput {\n    /**\n     * The ID of the computer tool call that produced the output.\n     */\n    call_id: string;\n\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    output: ComputerCallOutput.Output;\n\n    /**\n     * The type of the computer tool call output. Always `computer_call_output`.\n     */\n    type: 'computer_call_output';\n\n    /**\n     * The ID of the computer tool call output.\n     */\n    id?: string;\n\n    /**\n     * The safety checks reported by the API that have been acknowledged by the\n     * developer.\n     */\n    acknowledged_safety_checks?: Array<ComputerCallOutput.AcknowledgedSafetyCheck>;\n\n    /**\n     * The status of the message input. One of `in_progress`, `completed`, or\n     * `incomplete`. Populated when input items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n  }\n\n  export namespace ComputerCallOutput {\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    export interface Output {\n      /**\n       * Specifies the event type. For a computer screenshot, this property is always set\n       * to `computer_screenshot`.\n       */\n      type: 'computer_screenshot';\n\n      /**\n       * The identifier of an uploaded file that contains the screenshot.\n       */\n      file_id?: string;\n\n      /**\n       * The URL of the screenshot image.\n       */\n      image_url?: string;\n    }\n\n    /**\n     * A pending safety check for the computer call.\n     */\n    export interface AcknowledgedSafetyCheck {\n      /**\n       * The ID of the pending safety check.\n       */\n      id: string;\n\n      /**\n       * The type of the pending safety check.\n       */\n      code: string;\n\n      /**\n       * Details about the pending safety check.\n       */\n      message: string;\n    }\n  }\n\n  /**\n   * The output of a function tool call.\n   */\n  export interface FunctionCallOutput {\n    /**\n     * The unique ID of the function tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * A JSON string of the output of the function tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the function tool call output. Always `function_call_output`.\n     */\n    type: 'function_call_output';\n\n    /**\n     * The unique ID of the function tool call output. Populated when this item is\n     * returned via API.\n     */\n    id?: string;\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n  }\n\n  /**\n   * An internal identifier for an item to reference.\n   */\n  export interface ItemReference {\n    /**\n     * The ID of the item to reference.\n     */\n    id: string;\n\n    /**\n     * The type of item to reference. Always `item_reference`.\n     */\n    type: 'item_reference';\n  }\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInputMessageContentList = Array<ResponseInputContent>;\n\n/**\n * A text input to the model.\n */\nexport interface ResponseInputText {\n  /**\n   * The text input to the model.\n   */\n  text: string;\n\n  /**\n   * The type of the input item. Always `input_text`.\n   */\n  type: 'input_text';\n}\n\n/**\n * An audio output from the model.\n */\nexport interface ResponseOutputAudio {\n  /**\n   * Base64-encoded audio data from the model.\n   */\n  data: string;\n\n  /**\n   * The transcript of the audio data from the model.\n   */\n  transcript: string;\n\n  /**\n   * The type of the output audio. Always `output_audio`.\n   */\n  type: 'output_audio';\n}\n\n/**\n * An output message from the model.\n */\nexport type ResponseOutputItem =\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseFunctionToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem;\n\n/**\n * Emitted when a new output item is added.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The output item that was added.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was added.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Emitted when an output item is marked done.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The output item that was marked done.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was marked done.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * An output message from the model.\n */\nexport interface ResponseOutputMessage {\n  /**\n   * The unique ID of the output message.\n   */\n  id: string;\n\n  /**\n   * The content of the output message.\n   */\n  content: Array<ResponseOutputText | ResponseOutputRefusal>;\n\n  /**\n   * The role of the output message. Always `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The status of the message input. One of `in_progress`, `completed`, or\n   * `incomplete`. Populated when input items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the output message. Always `message`.\n   */\n  type: 'message';\n}\n\n/**\n * A refusal from the model.\n */\nexport interface ResponseOutputRefusal {\n  /**\n   * The refusal explanationfrom the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the refusal. Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * A text output from the model.\n */\nexport interface ResponseOutputText {\n  /**\n   * The annotations of the text output.\n   */\n  annotations: Array<\n    ResponseOutputText.FileCitation | ResponseOutputText.URLCitation | ResponseOutputText.FilePath\n  >;\n\n  /**\n   * The text output from the model.\n   */\n  text: string;\n\n  /**\n   * The type of the output text. Always `output_text`.\n   */\n  type: 'output_text';\n}\n\nexport namespace ResponseOutputText {\n  /**\n   * A citation to a file.\n   */\n  export interface FileCitation {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file citation. Always `file_citation`.\n     */\n    type: 'file_citation';\n  }\n\n  /**\n   * A citation for a web resource used to generate a model response.\n   */\n  export interface URLCitation {\n    /**\n     * The index of the last character of the URL citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The index of the first character of the URL citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The title of the web resource.\n     */\n    title: string;\n\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * The URL of the web resource.\n     */\n    url: string;\n  }\n\n  /**\n   * A path to a file.\n   */\n  export interface FilePath {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file path. Always `file_path`.\n     */\n    type: 'file_path';\n  }\n}\n\n/**\n * A description of the chain of thought used by a reasoning model while generating\n * a response.\n */\nexport interface ResponseReasoningItem {\n  /**\n   * The unique identifier of the reasoning content.\n   */\n  id: string;\n\n  /**\n   * Reasoning text contents.\n   */\n  summary: Array<ResponseReasoningItem.Summary>;\n\n  /**\n   * The type of the object. Always `reasoning`.\n   */\n  type: 'reasoning';\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\nexport namespace ResponseReasoningItem {\n  export interface Summary {\n    /**\n     * A short summary of the reasoning used by the model when generating the response.\n     */\n    text: string;\n\n    /**\n     * The type of the object. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n}\n\n/**\n * Emitted when there is a partial refusal text.\n */\nexport interface ResponseRefusalDeltaEvent {\n  /**\n   * The index of the content part that the refusal text is added to.\n   */\n  content_index: number;\n\n  /**\n   * The refusal text that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the refusal text is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is added to.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.refusal.delta`.\n   */\n  type: 'response.refusal.delta';\n}\n\n/**\n * Emitted when refusal text is finalized.\n */\nexport interface ResponseRefusalDoneEvent {\n  /**\n   * The index of the content part that the refusal text is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the refusal text is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The refusal text that is finalized.\n   */\n  refusal: string;\n\n  /**\n   * The type of the event. Always `response.refusal.done`.\n   */\n  type: 'response.refusal.done';\n}\n\n/**\n * The status of the response generation. One of `completed`, `failed`,\n * `in_progress`, or `incomplete`.\n */\nexport type ResponseStatus = 'completed' | 'failed' | 'in_progress' | 'incomplete';\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport type ResponseStreamEvent =\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseCodeInterpreterCallCodeDeltaEvent\n  | ResponseCodeInterpreterCallCodeDoneEvent\n  | ResponseCodeInterpreterCallCompletedEvent\n  | ResponseCodeInterpreterCallInProgressEvent\n  | ResponseCodeInterpreterCallInterpretingEvent\n  | ResponseCompletedEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseErrorEvent\n  | ResponseFileSearchCallCompletedEvent\n  | ResponseFileSearchCallInProgressEvent\n  | ResponseFileSearchCallSearchingEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseInProgressEvent\n  | ResponseFailedEvent\n  | ResponseIncompleteEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseRefusalDeltaEvent\n  | ResponseRefusalDoneEvent\n  | ResponseTextAnnotationDeltaEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | ResponseWebSearchCallCompletedEvent\n  | ResponseWebSearchCallInProgressEvent\n  | ResponseWebSearchCallSearchingEvent;\n\n/**\n * Emitted when a text annotation is added.\n */\nexport interface ResponseTextAnnotationDeltaEvent {\n  /**\n   * A citation to a file.\n   */\n  annotation:\n    | ResponseTextAnnotationDeltaEvent.FileCitation\n    | ResponseTextAnnotationDeltaEvent.URLCitation\n    | ResponseTextAnnotationDeltaEvent.FilePath;\n\n  /**\n   * The index of the annotation that was added.\n   */\n  annotation_index: number;\n\n  /**\n   * The index of the content part that the text annotation was added to.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the text annotation was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the text annotation was added to.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.output_text.annotation.added`.\n   */\n  type: 'response.output_text.annotation.added';\n}\n\nexport namespace ResponseTextAnnotationDeltaEvent {\n  /**\n   * A citation to a file.\n   */\n  export interface FileCitation {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file citation. Always `file_citation`.\n     */\n    type: 'file_citation';\n  }\n\n  /**\n   * A citation for a web resource used to generate a model response.\n   */\n  export interface URLCitation {\n    /**\n     * The index of the last character of the URL citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The index of the first character of the URL citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The title of the web resource.\n     */\n    title: string;\n\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * The URL of the web resource.\n     */\n    url: string;\n  }\n\n  /**\n   * A path to a file.\n   */\n  export interface FilePath {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file path. Always `file_path`.\n     */\n    type: 'file_path';\n  }\n}\n\n/**\n * Configuration options for a text response from the model. Can be plain text or\n * structured JSON data. Learn more:\n *\n * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n */\nexport interface ResponseTextConfig {\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n   * ensures the model will match your supplied JSON schema. Learn more in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * The default format is `{ \"type\": \"text\" }` with no additional options.\n   *\n   * **Not recommended for gpt-4o and newer models:**\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  format?: ResponseFormatTextConfig;\n}\n\n/**\n * Emitted when there is an additional text delta.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part that the text delta was added to.\n   */\n  content_index: number;\n\n  /**\n   * The text delta that was added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the text delta was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the text delta was added to.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.output_text.delta`.\n   */\n  type: 'response.output_text.delta';\n}\n\n/**\n * Emitted when text content is finalized.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part that the text content is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the text content is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the text content is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The text content that is finalized.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.output_text.done`.\n   */\n  type: 'response.output_text.done';\n}\n\n/**\n * Represents token usage details including input tokens, output tokens, a\n * breakdown of output tokens, and the total tokens used.\n */\nexport interface ResponseUsage {\n  /**\n   * The number of input tokens.\n   */\n  input_tokens: number;\n\n  /**\n   * The number of output tokens.\n   */\n  output_tokens: number;\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  output_tokens_details: ResponseUsage.OutputTokensDetails;\n\n  /**\n   * The total number of tokens used.\n   */\n  total_tokens: number;\n}\n\nexport namespace ResponseUsage {\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  export interface OutputTokensDetails {\n    /**\n     * The number of reasoning tokens.\n     */\n    reasoning_tokens: number;\n  }\n}\n\n/**\n * Emitted when a web search call is completed.\n */\nexport interface ResponseWebSearchCallCompletedEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.completed`.\n   */\n  type: 'response.web_search_call.completed';\n}\n\n/**\n * Emitted when a web search call is initiated.\n */\nexport interface ResponseWebSearchCallInProgressEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.in_progress`.\n   */\n  type: 'response.web_search_call.in_progress';\n}\n\n/**\n * Emitted when a web search call is executing.\n */\nexport interface ResponseWebSearchCallSearchingEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.searching`.\n   */\n  type: 'response.web_search_call.searching';\n}\n\n/**\n * A tool that searches for relevant content from uploaded files. Learn more about\n * the\n * [file search tool](https://platform.openai.com/docs/guides/tools-file-search).\n */\nexport type Tool = FileSearchTool | FunctionTool | ComputerTool | WebSearchTool;\n\n/**\n * Use this option to force the model to call a specific function.\n */\nexport interface ToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * For function calling, the type is always `function`.\n   */\n  type: 'function';\n}\n\n/**\n * Controls which (if any) tool is called by the model.\n *\n * `none` means the model will not call any tool and instead generates a message.\n *\n * `auto` means the model can pick between generating a message or calling one or\n * more tools.\n *\n * `required` means the model must call one or more tools.\n */\nexport type ToolChoiceOptions = 'none' | 'auto' | 'required';\n\n/**\n * Indicates that the model should use a built-in tool to generate a response.\n * [Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n */\nexport interface ToolChoiceTypes {\n  /**\n   * The type of hosted tool the model should to use. Learn more about\n   * [built-in tools](https://platform.openai.com/docs/guides/tools).\n   *\n   * Allowed values are:\n   *\n   * - `file_search`\n   * - `web_search_preview`\n   * - `computer_use_preview`\n   */\n  type: 'file_search' | 'web_search_preview' | 'computer_use_preview' | 'web_search_preview_2025_03_11';\n}\n\n/**\n * This tool searches the web for relevant results to use in a response. Learn more\n * about the\n * [web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n */\nexport interface WebSearchTool {\n  /**\n   * The type of the web search tool. One of:\n   *\n   * - `web_search_preview`\n   * - `web_search_preview_2025_03_11`\n   */\n  type: 'web_search_preview' | 'web_search_preview_2025_03_11';\n\n  /**\n   * High level guidance for the amount of context window space to use for the\n   * search. One of `low`, `medium`, or `high`. `medium` is the default.\n   */\n  search_context_size?: 'low' | 'medium' | 'high';\n\n  user_location?: WebSearchTool.UserLocation | null;\n}\n\nexport namespace WebSearchTool {\n  export interface UserLocation {\n    /**\n     * The type of location approximation. Always `approximate`.\n     */\n    type: 'approximate';\n\n    /**\n     * Free text input for the city of the user, e.g. `San Francisco`.\n     */\n    city?: string;\n\n    /**\n     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n     * the user, e.g. `US`.\n     */\n    country?: string;\n\n    /**\n     * Free text input for the region of the user, e.g. `California`.\n     */\n    region?: string;\n\n    /**\n     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n     * user, e.g. `America/Los_Angeles`.\n     */\n    timezone?: string;\n  }\n}\n\nexport type ResponseCreateParams = ResponseCreateParamsNonStreaming | ResponseCreateParamsStreaming;\n\nexport interface ResponseCreateParamsBase {\n  /**\n   * Text, image, or file inputs to the model, used to generate a response.\n   *\n   * Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Image inputs](https://platform.openai.com/docs/guides/images)\n   * - [File inputs](https://platform.openai.com/docs/guides/pdf-files)\n   * - [Conversation state](https://platform.openai.com/docs/guides/conversation-state)\n   * - [Function calling](https://platform.openai.com/docs/guides/function-calling)\n   */\n  input: string | ResponseInput;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o1`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * Specify additional output data to include in the model response. Currently\n   * supported values are:\n   *\n   * - `file_search_call.results`: Include the search results of the file search tool\n   *   call.\n   * - `message.input_image.image_url`: Include image urls from the input message.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   */\n  include?: Array<ResponseIncludable> | null;\n\n  /**\n   * Inserts a system (or developer) message as the first item in the model's\n   * context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will be not be carried over to the next response. This makes it simple\n   * to swap out system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls?: boolean | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * **o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * Whether to store the generated model response for later retrieval via API.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice?: ToolChoiceOptions | ToolChoiceTypes | ToolChoiceFunction;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * The two categories of tools you can provide the model are:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code. Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   */\n  tools?: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the context of this response and previous ones exceeds the model's\n   *   context window size, the model will truncate the response to fit the context\n   *   window by dropping input items in the middle of the conversation.\n   * - `disabled` (default): If a model response will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ResponseCreateParams {\n  export type ResponseCreateParamsNonStreaming = ResponsesAPI.ResponseCreateParamsNonStreaming;\n  export type ResponseCreateParamsStreaming = ResponsesAPI.ResponseCreateParamsStreaming;\n}\n\nexport interface ResponseCreateParamsNonStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: false | null;\n}\n\nexport interface ResponseCreateParamsStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport interface ResponseRetrieveParams {\n  /**\n   * Additional fields to include in the response. See the `include` parameter for\n   * Response creation above for more information.\n   */\n  include?: Array<ResponseIncludable>;\n}\n\nResponses.InputItems = InputItems;\nResponses.ResponseItemListDataPage = ResponseItemListDataPage;\n\nexport declare namespace Responses {\n  export {\n    InputItems as InputItems,\n    type ResponseItemList as ResponseItemList,\n    ResponseItemListDataPage as ResponseItemListDataPage,\n    type InputItemListParams as InputItemListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\n\nexport class Parts extends APIResource {\n  /**\n   * Adds a\n   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n   * A Part represents a chunk of bytes from the file you are trying to upload.\n   *\n   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n   * maximum of 8 GB.\n   *\n   * It is possible to add multiple Parts in parallel. You can decide the intended\n   * order of the Parts when you\n   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n   */\n  create(\n    uploadId: string,\n    body: PartCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<UploadPart> {\n    return this._client.post(\n      `/uploads/${uploadId}/parts`,\n      Core.multipartFormRequestOptions({ body, ...options }),\n    );\n  }\n}\n\n/**\n * The upload Part represents a chunk of bytes we can add to an Upload object.\n */\nexport interface UploadPart {\n  /**\n   * The upload Part unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Part was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always `upload.part`.\n   */\n  object: 'upload.part';\n\n  /**\n   * The ID of the Upload object that this Part was added to.\n   */\n  upload_id: string;\n}\n\nexport interface PartCreateParams {\n  /**\n   * The chunk of bytes for this Part.\n   */\n  data: Core.Uploadable;\n}\n\nexport declare namespace Parts {\n  export { type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as FilesAPI from '../files';\nimport * as PartsAPI from './parts';\nimport { PartCreateParams, Parts, UploadPart } from './parts';\n\nexport class Uploads extends APIResource {\n  parts: PartsAPI.Parts = new PartsAPI.Parts(this._client);\n\n  /**\n   * Creates an intermediate\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n   * that you can add\n   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n   * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n   * after you create it.\n   *\n   * Once you complete the Upload, we will create a\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * contains all the parts you uploaded. This File is usable in the rest of our\n   * platform as a regular File object.\n   *\n   * For certain `purpose` values, the correct `mime_type` must be specified. Please\n   * refer to documentation for the\n   * [supported MIME types for your use case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).\n   *\n   * For guidance on the proper filename extensions for each purpose, please follow\n   * the documentation on\n   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n   */\n  create(body: UploadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post('/uploads', { body, ...options });\n  }\n\n  /**\n   * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n   */\n  cancel(uploadId: string, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/cancel`, options);\n  }\n\n  /**\n   * Completes the\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n   *\n   * Within the returned Upload object, there is a nested\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * is ready to use in the rest of the platform.\n   *\n   * You can specify the order of the Parts by passing in an ordered list of the Part\n   * IDs.\n   *\n   * The number of bytes uploaded upon completion must match the number of bytes\n   * initially specified when creating the Upload object. No Parts may be added after\n   * an Upload is completed.\n   */\n  complete(\n    uploadId: string,\n    body: UploadCompleteParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/complete`, { body, ...options });\n  }\n}\n\n/**\n * The Upload object can accept byte chunks in the form of Parts.\n */\nexport interface Upload {\n  /**\n   * The Upload unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The intended number of bytes to be uploaded.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload will expire.\n   */\n  expires_at: number;\n\n  /**\n   * The name of the file to be uploaded.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always \"upload\".\n   */\n  object: 'upload';\n\n  /**\n   * The intended purpose of the file.\n   * [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose)\n   * for acceptable values.\n   */\n  purpose: string;\n\n  /**\n   * The status of the Upload.\n   */\n  status: 'pending' | 'completed' | 'cancelled' | 'expired';\n\n  /**\n   * The `File` object represents a document that has been uploaded to OpenAI.\n   */\n  file?: FilesAPI.FileObject | null;\n}\n\nexport interface UploadCreateParams {\n  /**\n   * The number of bytes in the file you are uploading.\n   */\n  bytes: number;\n\n  /**\n   * The name of the file to upload.\n   */\n  filename: string;\n\n  /**\n   * The MIME type of the file.\n   *\n   * This must fall within the supported MIME types for your file purpose. See the\n   * supported MIME types for assistants and vision.\n   */\n  mime_type: string;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * See the\n   * [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n   */\n  purpose: FilesAPI.FilePurpose;\n}\n\nexport interface UploadCompleteParams {\n  /**\n   * The ordered list of Part IDs.\n   */\n  part_ids: Array<string>;\n\n  /**\n   * The optional md5 checksum for the file contents to verify if the bytes uploaded\n   * matches what you expect.\n   */\n  md5?: string;\n}\n\nUploads.Parts = Parts;\n\nexport declare namespace Uploads {\n  export {\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Parts as Parts, type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n", "/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { sleep, Uploadable, isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as VectorStoresAPI from './vector-stores';\nimport { CursorPage, type CursorPageParams, Page } from '../../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Update attributes on a vector store file.\n   */\n  update(\n    vectorStoreId: string,\n    fileId: string,\n    body: FileUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreId: string,\n    query?: FileListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.list(vectorStoreId, {}, query);\n    }\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  del(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n    while (true) {\n      const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions,\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n\n  /**\n   * Retrieve the parsed contents of a vector store file.\n   */\n  content(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FileContentResponsesPage, FileContentResponse> {\n    return this._client.getAPIList(\n      `/vector_stores/${vectorStoreId}/files/${fileId}/content`,\n      FileContentResponsesPage,\n      { ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } },\n    );\n  }\n}\n\nexport class VectorStoreFilesPage extends CursorPage<VectorStoreFile> {}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class FileContentResponsesPage extends Page<FileContentResponse> {}\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: Record<string, string | number | boolean> | null;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategy;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'unsupported_file' | 'invalid_file';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileContentResponse {\n  /**\n   * The text content\n   */\n  text?: string;\n\n  /**\n   * The content type (currently only `\"text\"`)\n   */\n  type?: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: Record<string, string | number | boolean> | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes: Record<string, string | number | boolean> | null;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nFiles.VectorStoreFilesPage = VectorStoreFilesPage;\nFiles.FileContentResponsesPage = FileContentResponsesPage;\n\nexport declare namespace Files {\n  export {\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    VectorStoreFilesPage as VectorStoreFilesPage,\n    FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport { sleep } from '../../core';\nimport { Uploadable } from '../../core';\nimport { allSettledWithThrow } from '../../lib/Util';\nimport * as Core from '../../core';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { type CursorPageParams } from '../../pagination';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/file_batches/${batchId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query?: FileBatchListFilesParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query: FileBatchListFilesParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.listFiles(vectorStoreId, batchId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/vector_stores/${vectorStoreId}/file_batches/${batchId}/files`,\n      VectorStoreFilesPage,\n      { query, ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(vectorStoreId, batchId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: Core.RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files == null || files.length == 0) {\n      throw new Error(\n        `No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`,\n      );\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n\n    // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    // This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    // Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    // Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: Record<string, string | number | boolean> | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace FileBatches {\n  export {\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n\nexport { VectorStoreFilesPage };\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as Shared from '../shared';\nimport * as FileBatchesAPI from './file-batches';\nimport {\n  FileBatchCreateParams,\n  FileBatchListFilesParams,\n  FileBatches,\n  VectorStoreFileBatch,\n} from './file-batches';\nimport * as FilesAPI from './files';\nimport {\n  FileContentResponse,\n  FileContentResponsesPage,\n  FileCreateParams,\n  FileListParams,\n  FileUpdateParams,\n  Files,\n  VectorStoreFile,\n  VectorStoreFileDeleted,\n  VectorStoreFilesPage,\n} from './files';\nimport { CursorPage, type CursorPageParams, Page } from '../../pagination';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.get(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreId: string,\n    body: VectorStoreUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStore> {\n    return this._client.post(`/vector_stores/${vectorStoreId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query?: VectorStoreListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(options?: Core.RequestOptions): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(\n    query: VectorStoreListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/vector_stores', VectorStoresPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  del(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStoreDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Search a vector store for relevant chunks based on a query and file attributes\n   * filter.\n   */\n  search(\n    vectorStoreId: string,\n    body: VectorStoreSearchParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreSearchResponsesPage, VectorStoreSearchResponse> {\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/search`, VectorStoreSearchResponsesPage, {\n      body,\n      method: 'post',\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class VectorStoresPage extends CursorPage<VectorStore> {}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class VectorStoreSearchResponsesPage extends Page<VectorStoreSearchResponse> {}\n\n/**\n * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n * `800` and `chunk_overlap_tokens` of `400`.\n */\nexport interface AutoFileChunkingStrategyParam {\n  /**\n   * Always `auto`.\n   */\n  type: 'auto';\n}\n\n/**\n * The strategy used to chunk the file.\n */\nexport type FileChunkingStrategy = StaticFileChunkingStrategyObject | OtherFileChunkingStrategyObject;\n\n/**\n * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n * strategy. Only applicable if `file_ids` is non-empty.\n */\nexport type FileChunkingStrategyParam = AutoFileChunkingStrategyParam | StaticFileChunkingStrategyObjectParam;\n\n/**\n * This is returned when the chunking strategy is unknown. Typically, this is\n * because the file was indexed before the `chunking_strategy` concept was\n * introduced in the API.\n */\nexport interface OtherFileChunkingStrategyObject {\n  /**\n   * Always `other`.\n   */\n  type: 'other';\n}\n\nexport interface StaticFileChunkingStrategy {\n  /**\n   * The number of tokens that overlap between chunks. The default value is `400`.\n   *\n   * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n   */\n  chunk_overlap_tokens: number;\n\n  /**\n   * The maximum number of tokens in each chunk. The default value is `800`. The\n   * minimum value is `100` and the maximum value is `4096`.\n   */\n  max_chunk_size_tokens: number;\n}\n\nexport interface StaticFileChunkingStrategyObject {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * Customize your own chunking strategy by setting chunk size and chunk overlap.\n */\nexport interface StaticFileChunkingStrategyObjectParam {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreSearchResponse {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes: Record<string, string | number | boolean> | null;\n\n  /**\n   * Content chunks from the file.\n   */\n  content: Array<VectorStoreSearchResponse.Content>;\n\n  /**\n   * The ID of the vector store file.\n   */\n  file_id: string;\n\n  /**\n   * The name of the vector store file.\n   */\n  filename: string;\n\n  /**\n   * The similarity score for the result.\n   */\n  score: number;\n}\n\nexport namespace VectorStoreSearchResponse {\n  export interface Content {\n    /**\n     * The text content returned from search.\n     */\n    text: string;\n\n    /**\n     * The type of content.\n     */\n    type: 'text';\n  }\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: FileChunkingStrategyParam;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface VectorStoreSearchParams {\n  /**\n   * A query string for a search\n   */\n  query: string | Array<string>;\n\n  /**\n   * A filter to apply based on file attributes.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: VectorStoreSearchParams.RankingOptions;\n\n  /**\n   * Whether to rewrite the natural language query for vector search.\n   */\n  rewrite_query?: boolean;\n}\n\nexport namespace VectorStoreSearchParams {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    ranker?: 'auto' | 'default-2024-11-15';\n\n    score_threshold?: number;\n  }\n}\n\nVectorStores.VectorStoresPage = VectorStoresPage;\nVectorStores.VectorStoreSearchResponsesPage = VectorStoreSearchResponsesPage;\nVectorStores.Files = Files;\nVectorStores.VectorStoreFilesPage = VectorStoreFilesPage;\nVectorStores.FileContentResponsesPage = FileContentResponsesPage;\nVectorStores.FileBatches = FileBatches;\n\nexport declare namespace VectorStores {\n  export {\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    VectorStoresPage as VectorStoresPage,\n    VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export {\n    Files as Files,\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    VectorStoreFilesPage as VectorStoreFilesPage,\n    FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    FileBatches as FileBatches,\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n", "// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { type Agent, type RequestInit } from './_shims/index';\nimport * as qs from './internal/qs';\nimport * as Core from './core';\nimport * as Errors from './error';\nimport * as Pagination from './pagination';\nimport { type CursorPageParams, CursorPageResponse, PageResponse } from './pagination';\nimport * as Uploads from './uploads';\nimport * as API from './resources/index';\nimport {\n  Batch,\n  BatchCreateParams,\n  BatchError,\n  BatchListParams,\n  BatchRequestCounts,\n  Batches,\n  BatchesPage,\n} from './resources/batches';\nimport {\n  Completion,\n  CompletionChoice,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  CompletionUsage,\n  Completions,\n} from './resources/completions';\nimport {\n  CreateEmbeddingResponse,\n  Embedding,\n  EmbeddingCreateParams,\n  EmbeddingModel,\n  Embeddings,\n} from './resources/embeddings';\nimport {\n  FileContent,\n  FileCreateParams,\n  FileDeleted,\n  FileListParams,\n  FileObject,\n  FileObjectsPage,\n  FilePurpose,\n  Files,\n} from './resources/files';\nimport {\n  Image,\n  ImageCreateVariationParams,\n  ImageEditParams,\n  ImageGenerateParams,\n  ImageModel,\n  Images,\n  ImagesResponse,\n} from './resources/images';\nimport { Model, ModelDeleted, Models, ModelsPage } from './resources/models';\nimport {\n  Moderation,\n  ModerationCreateParams,\n  ModerationCreateResponse,\n  ModerationImageURLInput,\n  ModerationModel,\n  ModerationMultiModalInput,\n  ModerationTextInput,\n  Moderations,\n} from './resources/moderations';\nimport { Audio, AudioModel, AudioResponseFormat } from './resources/audio/audio';\nimport { Beta } from './resources/beta/beta';\nimport { Chat } from './resources/chat/chat';\nimport { FineTuning } from './resources/fine-tuning/fine-tuning';\nimport { Responses } from './resources/responses/responses';\nimport {\n  Upload,\n  UploadCompleteParams,\n  UploadCreateParams,\n  Uploads as UploadsAPIUploads,\n} from './resources/uploads/uploads';\nimport {\n  AutoFileChunkingStrategyParam,\n  FileChunkingStrategy,\n  FileChunkingStrategyParam,\n  OtherFileChunkingStrategyObject,\n  StaticFileChunkingStrategy,\n  StaticFileChunkingStrategyObject,\n  StaticFileChunkingStrategyObjectParam,\n  VectorStore,\n  VectorStoreCreateParams,\n  VectorStoreDeleted,\n  VectorStoreListParams,\n  VectorStoreSearchParams,\n  VectorStoreSearchResponse,\n  VectorStoreSearchResponsesPage,\n  VectorStoreUpdateParams,\n  VectorStores,\n  VectorStoresPage,\n} from './resources/vector-stores/vector-stores';\nimport {\n  ChatCompletion,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionPredictionContent,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n} from './resources/chat/completions/completions';\n\nexport interface ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   */\n  timeout?: number | undefined;\n\n  /**\n   * An HTTP agent used to manage HTTP(S) connections.\n   *\n   * If not provided, an agent will be constructed by default in the Node.js environment,\n   * otherwise no agent is used.\n   */\n  httpAgent?: Agent | undefined;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we use `node-fetch` on Node.js and otherwise expect that `fetch` is\n   * defined globally.\n   */\n  fetch?: Core.Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number | undefined;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `undefined` or `null` in request options.\n   */\n  defaultHeaders?: Core.Headers | undefined;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Core.DefaultQuery | undefined;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean | undefined;\n}\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nexport class OpenAI extends Core.APIClient {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n\n  private _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('OPENAI_API_KEY'),\n    organization = Core.readEnv('OPENAI_ORG_ID') ?? null,\n    project = Core.readEnv('OPENAI_PROJECT_ID') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\",\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && Core.isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    super({\n      baseURL: options.baseURL!,\n      timeout: options.timeout ?? 600000 /* 10 minutes */,\n      httpAgent: options.httpAgent,\n      maxRetries: options.maxRetries,\n      fetch: options.fetch,\n    });\n\n    this._options = options;\n\n    this.apiKey = apiKey;\n    this.organization = organization;\n    this.project = project;\n  }\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  vectorStores: API.VectorStores = new API.VectorStores(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n  uploads: API.Uploads = new API.Uploads(this);\n  responses: API.Responses = new API.Responses(this);\n\n  protected override defaultQuery(): Core.DefaultQuery | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected override defaultHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {\n      ...super.defaultHeaders(opts),\n      'OpenAI-Organization': this.organization,\n      'OpenAI-Project': this.project,\n      ...this._options.defaultHeaders,\n    };\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return { Authorization: `Bearer ${this.apiKey}` };\n  }\n\n  protected override stringifyQuery(query: Record<string, unknown>): string {\n    return qs.stringify(query, { arrayFormat: 'brackets' });\n  }\n\n  static OpenAI = this;\n  static DEFAULT_TIMEOUT = 600000; // 10 minutes\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n\n  static toFile = Uploads.toFile;\n  static fileFromPath = Uploads.fileFromPath;\n}\n\nOpenAI.Completions = Completions;\nOpenAI.Chat = Chat;\nOpenAI.ChatCompletionsPage = ChatCompletionsPage;\nOpenAI.Embeddings = Embeddings;\nOpenAI.Files = Files;\nOpenAI.FileObjectsPage = FileObjectsPage;\nOpenAI.Images = Images;\nOpenAI.Audio = Audio;\nOpenAI.Moderations = Moderations;\nOpenAI.Models = Models;\nOpenAI.ModelsPage = ModelsPage;\nOpenAI.FineTuning = FineTuning;\nOpenAI.VectorStores = VectorStores;\nOpenAI.VectorStoresPage = VectorStoresPage;\nOpenAI.VectorStoreSearchResponsesPage = VectorStoreSearchResponsesPage;\nOpenAI.Beta = Beta;\nOpenAI.Batches = Batches;\nOpenAI.BatchesPage = BatchesPage;\nOpenAI.Uploads = UploadsAPIUploads;\nOpenAI.Responses = Responses;\nexport declare namespace OpenAI {\n  export type RequestOptions = Core.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export { type PageResponse as PageResponse };\n\n  export import CursorPage = Pagination.CursorPage;\n  export { type CursorPageParams as CursorPageParams, type CursorPageResponse as CursorPageResponse };\n\n  export {\n    Completions as Completions,\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n\n  export {\n    Chat as Chat,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n\n  export {\n    Embeddings as Embeddings,\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n\n  export {\n    Files as Files,\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    Images as Images,\n    type Image as Image,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageGenerateParams as ImageGenerateParams,\n  };\n\n  export { Audio as Audio, type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Moderations as Moderations,\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n\n  export {\n    Models as Models,\n    type Model as Model,\n    type ModelDeleted as ModelDeleted,\n    ModelsPage as ModelsPage,\n  };\n\n  export { FineTuning as FineTuning };\n\n  export {\n    VectorStores as VectorStores,\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    VectorStoresPage as VectorStoresPage,\n    VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export { Beta as Beta };\n\n  export {\n    Batches as Batches,\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n\n  export {\n    UploadsAPIUploads as Uploads,\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Responses as Responses };\n\n  export type ChatModel = API.ChatModel;\n  export type ComparisonFilter = API.ComparisonFilter;\n  export type CompoundFilter = API.CompoundFilter;\n  export type ErrorObject = API.ErrorObject;\n  export type FunctionDefinition = API.FunctionDefinition;\n  export type FunctionParameters = API.FunctionParameters;\n  export type Metadata = API.Metadata;\n  export type Reasoning = API.Reasoning;\n  export type ReasoningEffort = API.ReasoningEffort;\n  export type ResponseFormatJSONObject = API.ResponseFormatJSONObject;\n  export type ResponseFormatJSONSchema = API.ResponseFormatJSONSchema;\n  export type ResponseFormatText = API.ResponseFormatText;\n}\n\n// ---------------------- Azure ----------------------\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  private _azureADTokenProvider: (() => Promise<string>) | undefined;\n  deploymentName: string | undefined;\n  apiVersion: string = '';\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = Core.readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    // define a sentinel value to avoid any typing issues\n    apiKey ??= API_KEY_SENTINEL;\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this._azureADTokenProvider = azureADTokenProvider;\n    this.apiVersion = apiVersion;\n    this.deploymentName = deployment;\n  }\n\n  override buildRequest(\n    options: Core.FinalRequestOptions<unknown>,\n    props: { retryCount?: number } = {},\n  ): {\n    req: RequestInit;\n    url: string;\n    timeout: number;\n  } {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!Core.isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this.deploymentName || options.body['model'] || options.__metadata?.['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options, props);\n  }\n\n  async _getAzureADToken(): Promise<string | undefined> {\n    if (typeof this._azureADTokenProvider === 'function') {\n      const token = await this._azureADTokenProvider();\n      if (!token || typeof token !== 'string') {\n        throw new Errors.OpenAIError(\n          `Expected 'azureADTokenProvider' argument to return a string but it returned ${token}`,\n        );\n      }\n      return token;\n    }\n    return undefined;\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {};\n  }\n\n  protected override async prepareOptions(opts: Core.FinalRequestOptions<unknown>): Promise<void> {\n    /**\n     * The user should provide a bearer token provider if they want\n     * to use Azure AD authentication. The user shouldn't set the\n     * Authorization header manually because the header is overwritten\n     * with the Azure AD token if a bearer token provider is provided.\n     */\n    if (opts.headers?.['api-key']) {\n      return super.prepareOptions(opts);\n    }\n    const token = await this._getAzureADToken();\n    opts.headers ??= {};\n    if (token) {\n      opts.headers['Authorization'] = `Bearer ${token}`;\n    } else if (this.apiKey !== API_KEY_SENTINEL) {\n      opts.headers['api-key'] = this.apiKey;\n    } else {\n      throw new Errors.OpenAIError('Unable to handle auth');\n    }\n    return super.prepareOptions(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n]);\n\nconst API_KEY_SENTINEL = '<Missing Key>';\n\n// ---------------------- End Azure ----------------------\n\nexport { toFile, fileFromPath } from './uploads';\nexport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n} from './error';\n\nexport default OpenAI;\n", "// @name api-worker\n// @description A Cloudflare Worker script to handle various API endpoints for a blog application.\n// @version 1.0\n// @author Tor Arne H\u00E5ve\n// @license MIT\n\nimport { marked } from 'marked'\nimport { OpenAI } from 'openai'\n\n// Utility functions\nconst corsHeaders = {\n  'Access-Control-Allow-Origin': '*',\n  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS, DELETE',\n  'Access-Control-Allow-Headers':\n    'Content-Type, Authorization, x-user-role, X-API-Token, x-user-email',\n}\n\n// Domain to Zone ID mapping configuration\nconst DOMAIN_ZONE_MAPPING = {\n  'norsegong.com': 'e577205b812b49d012af046535369808',\n  'xyzvibe.com': '602067f0cf860426a35860a8ab179a47',\n  'vegvisr.org': '9178eccd3a7e3d71d8ae09defb09422a', // vegvisr.org zone ID\n  'slowyou.training': '1417691852abd0e8220f60184b7f4eca', // vegvisr.org zone ID\n  'movemetime.com': 'abb39e8d56446afe3ac098abd5c21732', // movemetime.com zone ID\n}\n\n// Protected subdomains configuration - SECURITY CRITICAL\nconst PROTECTED_SUBDOMAINS = {\n  'vegvisr.org': [\n    'api', // API Worker - CRITICAL\n    'www', // Main website\n    'admin', // Admin interface\n    'mail', // Email services\n    'blog', // Blog subdomain\n    'knowledge', // Knowledge worker\n    'auth', // Auth worker\n    'brand', // Brand worker\n    'dash', // Dashboard worker\n    'dev', // Development\n    'test', // Testing\n    'staging', // Staging environment\n    'cdn', // CDN\n    'static', // Static assets\n  ],\n  'norsegong.com': ['www', 'api', 'mail', 'admin', 'blog', 'cdn', 'static'],\n  'xyzvibe.com': ['www', 'api', 'mail', 'admin', 'blog', 'cdn', 'static'],\n  'slowyou.training': ['www', 'api', 'mail', 'admin', 'blog', 'cdn', 'static'],\n  'movemetime.com': ['www', 'api', 'mail', 'admin', 'blog', 'cdn', 'static'],\n}\n\n// Security validation function for protected subdomains\nfunction isProtectedSubdomain(subdomain, rootDomain) {\n  const protectedList = PROTECTED_SUBDOMAINS[rootDomain]\n  return protectedList && protectedList.includes(subdomain.toLowerCase())\n}\n\n// Helper function to determine Zone ID from domain\nfunction getZoneIdForDomain(domain) {\n  // Extract the root domain from subdomains\n  const domainParts = domain.split('.')\n  if (domainParts.length >= 2) {\n    const rootDomain = domainParts.slice(-2).join('.')\n    return DOMAIN_ZONE_MAPPING[rootDomain]\n  }\n  return null\n}\n\nconst createResponse = (body, status = 200, headers = {}) => {\n  return new Response(body, {\n    status,\n    headers: { 'Content-Type': 'application/json', ...corsHeaders, ...headers },\n  })\n}\n\nconst createErrorResponse = (message, status) => {\n  console.error(message)\n  return createResponse(JSON.stringify({ error: message }), status)\n}\n\n// Endpoint handlers\nconst handleCreateKnowledgeGraph = async (request, env) => {\n  const url = new URL(request.url)\n  const subject = url.searchParams.get('subject')\n\n  if (!subject) {\n    return createErrorResponse('Subject is missing in the prompt', 400)\n  }\n\n  const apiKey = env.OPENAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: API key missing', 500)\n  }\n\n  const prompt = `\nGenerate a JSON string representing a knowledge graph compatible with Cytoscape, based on the subject: \"${subject}\". The output must be a valid JSON object with two main keys: \"nodes\" and \"edges\". Follow this structure exactly:\n\n    - \"nodes\": An array of objects, EACH representing a concept related to \"${subject}\", with:\n      - id: A unique string identifier (e.g., \"node1\")\n      - label: A display name for the node relevant to the subject\n      - color: A valid CSS color (e.g., \"red\", \"redorange\", use natural language)\n      - type: Always \"info\"\n      - info: A string with a brief description or null\n      - bibl: An array of strings (can be empty)\n\n    - \"edges\": An array of objects, EACH representing a relationship between concepts related to \"${subject}\", with:\n      - id: A unique UUID string\n      - source: The id of the source node\n      - target: The id of the target node\n      - label: A string describing the relationship or null\n      - type: Always \"info\"\n      - info: A string with relationship details or null\n\n    Ensure the JSON is properly formatted, with no trailing commas, and is ready to be parsed by Cytoscape. Create at least 10 nodes and 5 edges relevant to \"${subject}\". Return only the JSON string, with no additional text or explanations.\n\n`\n\n  const response = await fetch('https://api.openai.com/v1/chat/completions', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      Authorization: `Bearer ${apiKey}`,\n    },\n    body: JSON.stringify({\n      model: 'gpt-4',\n      temperature: 1,\n      max_tokens: 1000,\n      messages: [\n        {\n          role: 'system',\n          content: `You are a precise JSON generator for Cytoscape graphs and an expert in the subject mentioned in \"${subject}\", and keep the creation of the nodes specific to the subject. Return only valid JSON with no additional text.`,\n        },\n        { role: 'user', content: prompt },\n      ],\n    }),\n  })\n\n  if (!response.ok) {\n    const errorText = await response.text()\n    throw new Error(`OpenAI API error: ${response.status} - ${errorText}`)\n  }\n\n  const data = await response.json()\n  const graphData = data.choices[0].message.content.trim()\n\n  // Log the raw JSON response for debugging\n  console.log('Raw JSON response from OpenAI:', graphData)\n\n  try {\n    const parsedData = JSON.parse(graphData)\n    const isValid =\n      parsedData.nodes.every((node) => node.type === 'info') &&\n      parsedData.edges.every((edge) => edge.type === 'info')\n    if (!isValid) {\n      throw new Error('Invalid type field in graph data')\n    }\n    return createResponse(graphData)\n  } catch {\n    console.error('Error parsing JSON or validating graph data:')\n    // Return raw JSON response even if it is not correctly formatted\n    return createResponse(graphData, 200)\n  }\n}\n\n// Handler for generating email templates with AI\nconst handleGenerateEmailTemplate = async (request, env) => {\n  try {\n    const { prompt, emailType, tone } = await request.json()\n\n    if (!prompt) {\n      return createErrorResponse('Prompt is required', 400)\n    }\n\n    const apiKey = env.OPENAI_API_KEY\n    if (!apiKey) {\n      return createErrorResponse('Internal Server Error: API key missing', 500)\n    }\n\n    // Construct a specialized prompt for email templates\n    const systemPrompt = `You are an expert email template generator. Create professional, well-structured email templates based on user requirements.\n\nAlways respond with a valid JSON object in this exact format:\n{\n  \"templateName\": \"Descriptive name for the template\",\n  \"subject\": \"Email subject line with {variableName} placeholders\",\n  \"body\": \"Email body content with {variableName} placeholders\",\n  \"recipients\": \"{recipientEmail}\",\n  \"variables\": {\n    \"variableName1\": \"Default value 1\",\n    \"variableName2\": \"Default value 2\"\n  }\n}\n\nGuidelines:\n- Use {variableName} for placeholders (curly braces)\n- Include appropriate variables for customization\n- Make the tone ${tone || 'professional'}\n- Structure the email properly with greeting, body, and closing\n- Include relevant sections for ${emailType || 'general'} emails\n- Keep it concise but complete`\n\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${apiKey}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        model: 'gpt-4',\n        messages: [\n          { role: 'system', content: systemPrompt },\n          { role: 'user', content: prompt },\n        ],\n        max_tokens: 1500,\n        temperature: 0.7,\n      }),\n    })\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      console.error('OpenAI API error:', response.status, errorText)\n      throw new Error(`OpenAI API error: ${response.status} - ${errorText}`)\n    }\n\n    const data = await response.json()\n    const generatedContent = data.choices[0]?.message?.content\n\n    if (!generatedContent) {\n      throw new Error('No content generated from OpenAI')\n    }\n\n    // Try to parse the JSON response\n    let emailTemplate\n    try {\n      emailTemplate = JSON.parse(generatedContent)\n    } catch (parseError) {\n      console.error('Error parsing OpenAI response as JSON:', parseError)\n      console.log('Raw response:', generatedContent)\n\n      // Fallback: try to extract JSON from the response\n      const jsonMatch = generatedContent.match(/\\{[\\s\\S]*\\}/)\n      if (jsonMatch) {\n        try {\n          emailTemplate = JSON.parse(jsonMatch[0])\n        } catch (e) {\n          throw new Error('Invalid JSON response from AI')\n        }\n      } else {\n        throw new Error('No valid JSON found in AI response')\n      }\n    }\n\n    // Validate the required fields\n    if (!emailTemplate.templateName || !emailTemplate.subject || !emailTemplate.body) {\n      throw new Error('AI response missing required fields')\n    }\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        template: emailTemplate,\n      }),\n    )\n  } catch (error) {\n    console.error('Error generating email template:', error)\n    return createErrorResponse(`Error generating email template: ${error.message}`, 500)\n  }\n}\n\nconst handleSave = async (request, env) => {\n  const { id, markdown, isVisible, email } = await request.json()\n\n  if (!markdown || !email) {\n    return createErrorResponse('Markdown content or email is missing', 400)\n  }\n\n  const newPrefix = isVisible ? 'vis:' : 'hid:'\n  const blogId = id || crypto.randomUUID()\n  const newKey =\n    id && id.includes(`:${email}`) ? `${newPrefix}${id}` : `${newPrefix}${blogId}:${email}`\n\n  if (id) {\n    await Promise.all([env.BINDING_NAME.delete(`vis:${id}`), env.BINDING_NAME.delete(`hid:${id}`)])\n  }\n\n  await env.BINDING_NAME.put(newKey, markdown, { metadata: { encoding: 'utf-8' } })\n  const shareableLink = `https://api.vegvisr.org/view/${blogId}`\n\n  return createResponse(JSON.stringify({ link: shareableLink }))\n}\n\nconst handleView = async (request, env) => {\n  const url = new URL(request.url)\n  const id = url.pathname.split('/').pop()\n  const raw = url.searchParams.get('raw') === 'true'\n\n  const keys = await env.BINDING_NAME.list()\n  const matchingKey = keys.keys.find(\n    (key) => key.name.includes(id) && (key.name.startsWith('vis:') || key.name.startsWith('hid:')),\n  )\n\n  if (!matchingKey) {\n    return createErrorResponse('Not Found', 404)\n  }\n\n  const markdown = await env.BINDING_NAME.get(matchingKey.name)\n  if (!markdown) {\n    return createErrorResponse('Not Found', 404)\n  }\n\n  if (raw) {\n    return createResponse(markdown, 200, { 'Content-Type': 'text/plain' })\n  }\n\n  const fullUrl = `https://api.vegvisr.org/view/${id}`\n  const htmlContent = marked.parse(markdown)\n  const shareButton = `     <div style=\"text-align: center; margin-top: 20px;\">\n      <a href=\"https://www.facebook.com/sharer/sharer.php?u=${encodeURIComponent(fullUrl)}\" target=\"_blank\" class=\"btn btn-primary\">\n\u0E40\u0E27\u0E49\u0E19\u0E27\u0E23\u0E23\u0E04Share on Facebook\n      </a>\n    </div>\n  `\n  const finalHtml = `     <!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n      <meta charset=\"UTF-8\">\n      <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n      <title>View Markdown</title>\n      <style>\n        img { max-width: 100%; height: auto; }\n      </style>\n    </head>\n    <body>\n      ${htmlContent}\n      ${shareButton}\n    </body>\n    </html>\n  `\n\n  return createResponse(finalHtml, 200, { 'Content-Type': 'text/html' })\n}\n\nconst handleBlogPosts = async (request, env, showHidden = false) => {\n  const url = new URL(request.url)\n  const showHiddenParam = url.searchParams.get('hidden') === 'true'\n  const prefix = showHidden || showHiddenParam ? 'hid:' : 'vis:'\n\n  const keys = await env.BINDING_NAME.list()\n  const posts = []\n\n  for (const key of keys.keys) {\n    if (!key.name.startsWith(prefix)) continue\n\n    const markdown = await env.BINDING_NAME.get(key.name)\n    if (markdown) {\n      const lines = markdown.split('\\n')\n      const titleLine = lines.find((line) => line.startsWith('#') && !line.includes('!['))\n      const title = titleLine ? titleLine.replace(/^#\\s*/, '') : 'Untitled'\n\n      const imageMatch = markdown.match(/!\\[.*?\\]\\((.*?)\\)/)\n      const imageUrl = imageMatch ? imageMatch[1] : 'https://via.placeholder.com/150'\n\n      const abstractLine = lines.find(\n        (line) => line.trim() && !line.startsWith('#') && !line.includes('!['),\n      )\n      const abstract = abstractLine ? abstractLine.slice(0, 100) + '...' : ''\n\n      posts.push({\n        id: key.name.replace(/^(vis:|hid:)/, ''),\n        title,\n        snippet: lines.slice(1, 3).join(' '),\n        abstract,\n        image: imageUrl,\n      })\n    }\n  }\n\n  return createResponse(JSON.stringify(posts))\n}\n\nconst handleBlogPostDelete = async (request, env) => {\n  const id = request.url.split('/').pop()\n\n  if (!id) {\n    return createErrorResponse('Blog post ID is required', 400)\n  }\n\n  const keys = await env.BINDING_NAME.list()\n  const matchingKey = keys.keys.find(\n    (key) => key.name.includes(id) && (key.name.startsWith('vis:') || key.name.startsWith('hid:')),\n  )\n\n  if (!matchingKey) {\n    return createErrorResponse('Not Found', 404)\n  }\n\n  await env.BINDING_NAME.delete(matchingKey.name)\n  return createResponse('Blog post deleted successfully')\n}\n\nconst handleSnippetAdd = async (request, env) => {\n  const { id, content } = await request.json()\n\n  if (!id || !content) {\n    return createErrorResponse('ID and content are required', 400)\n  }\n\n  await env.snippets.put(id, content)\n  return createResponse('Snippet added successfully')\n}\n\nconst handleSnippetGet = async (request, env) => {\n  const id = request.url.split('/').pop()\n  const snippet = await env.snippets.get(id)\n\n  if (!snippet) {\n    return createErrorResponse('Snippet not found', 404)\n  }\n\n  return createResponse(JSON.stringify({ id, content: snippet }))\n}\n\nconst handleSnippetDelete = async (request, env) => {\n  const id = request.url.split('/').pop()\n  await env.snippets.delete(id)\n  return createResponse('Snippet deleted successfully')\n}\n\nconst handleSnippetList = async (request, env) => {\n  const keys = await env.snippets.list()\n  return createResponse(JSON.stringify({ keys: keys.keys || [] }))\n}\n\nconst handleUpload = async (request, env) => {\n  const { MY_R2_BUCKET } = env\n  const formData = await request.formData()\n  const file = formData.get('file')\n\n  if (!file) {\n    return createErrorResponse('Missing file', 400)\n  }\n\n  const fileExtension = file.name ? file.name.split('.').pop() : ''\n  if (!fileExtension) {\n    return createErrorResponse('Invalid file name or extension', 400)\n  }\n\n  const fileName = `${Date.now()}.${fileExtension}`\n  const contentType = fileExtension === 'svg' ? 'image/svg+xml' : file.type\n\n  await MY_R2_BUCKET.put(fileName, file.stream(), {\n    httpMetadata: { contentType },\n  })\n\n  const fileUrl = `https://blog.vegvisr.org/${fileName}`\n  return createResponse(JSON.stringify({ url: fileUrl }))\n}\n\nconst handleSearch = async (request, env) => {\n  const query = new URL(request.url).searchParams.get('query')?.toLowerCase()\n\n  if (!query) {\n    return createErrorResponse('Search query is missing', 400)\n  }\n\n  const keys = await env.BINDING_NAME.list()\n  const results = []\n\n  for (const key of keys.keys) {\n    const markdown = await env.BINDING_NAME.get(key.name)\n    if (markdown && markdown.toLowerCase().includes(query)) {\n      const lines = markdown.split('\\n')\n      const titleLine = lines.find((line) => line.startsWith('#') && !line.includes('!['))\n      const title = titleLine ? titleLine.replace(/^#\\s\\*/, '') : 'Untitled'\n\n      const imageMatch = markdown.match(/!\\[.*?\\]\\((.*?)\\)/)\n      const imageUrl = imageMatch ? imageMatch[1] : 'https://via.placeholder.com/150'\n\n      const abstractLine = lines.find(\n        (line) => line.trim() && !line.startsWith('#') && !line.includes('!['),\n      )\n      const abstract = abstractLine ? abstractLine.slice(0, 100) + '...' : ''\n\n      results.push({\n        id: key.name.replace(/^(vis:|hid:)/, ''),\n        title,\n        snippet: lines.slice(1, 3).join(' '),\n        abstract,\n        image: imageUrl,\n      })\n    }\n  }\n\n  return createResponse(JSON.stringify(results))\n}\n\nconst handleToggleVisibility = async (request, env) => {\n  const { id, isVisible } = await request.json()\n\n  if (!id) {\n    return createErrorResponse('Blog post ID is missing', 400)\n  }\n\n  const currentKey = isVisible ? `hid:${id}` : `vis:${id}`\n  const newKey = isVisible ? `vis:${id}` : `hid:${id}`\n\n  const markdown = await env.BINDING_NAME.get(currentKey)\n  if (!markdown) {\n    return createErrorResponse('Blog post not found or already in the desired state', 404)\n  }\n\n  await env.BINDING_NAME.delete(currentKey)\n  await env.BINDING_NAME.put(newKey, markdown, { metadata: { encoding: 'utf-8' } })\n\n  return createResponse('Blog post visibility toggled successfully')\n}\n\nconst handleGetImage = async (request, env) => {\n  const url = new URL(request.url)\n  const imageName = url.searchParams.get('name')\n\n  if (!imageName) {\n    return createErrorResponse('Image name is missing', 400)\n  }\n\n  const image = await env.MY_R2_BUCKET.get(imageName)\n\n  if (!image) {\n    return createErrorResponse('Image not found', 404)\n  }\n\n  const headers = {\n    'Content-Type': image.httpMetadata?.contentType || 'application/octet-stream',\n    ...corsHeaders,\n  }\n\n  return new Response(image.body, { status: 200, headers })\n}\n\nconst handleGetImageFromR2 = async (request, env) => {\n  const url = new URL(request.url)\n  const fileName = url.searchParams.get('name')\n\n  if (!fileName) {\n    return createErrorResponse('Image file name is missing', 400)\n  }\n\n  const image = await env.MY_R2_BUCKET.get(fileName)\n\n  if (!image) {\n    return createErrorResponse('Image not found', 404)\n  }\n\n  const headers = {\n    'Content-Type': image.httpMetadata?.contentType || 'application/octet-stream',\n    'Cache-Control': 'public, max-age=31536000',\n    'Cross-Origin-Resource-Policy': 'cross-origin',\n    'Timing-Allow-Origin': '_',\n    'Access-Control-Allow-Origin': '_',\n    'X-Content-Type-Options': 'nosniff',\n  }\n\n  return new Response(image.body, { status: 200, headers })\n}\n\nconst handleGetImageHeaders = async (request, env) => {\n  const url = new URL(request.url)\n  const fileName = url.searchParams.get('name')\n\n  if (!fileName) {\n    return createErrorResponse('Image file name is missing', 400)\n  }\n\n  const image = await env.MY_R2_BUCKET.get(fileName)\n\n  if (!image) {\n    return createErrorResponse('Image not found', 404)\n  }\n\n  const headers = {\n    'Content-Type': image.httpMetadata?.contentType || 'application/octet-stream',\n    'Cache-Control': 'public, max-age=31536000',\n    'Cross-Origin-Resource-Policy': 'cross-origin',\n    'Timing-Allow-Origin': '_',\n    'Access-Control-Allow-Origin': '_',\n    'X-Content-Type-Options': 'nosniff',\n    'Last-Modified': image.httpMetadata?.lastModified || new Date().toUTCString(),\n    'Content-Length': image.size, // Add content-length\n  }\n\n  return new Response(null, { status: 200, headers }) // No body, only headers\n}\n\nconst handleSummarize = async (request, env) => {\n  const apiKey = env.OPENAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { text } = body\n  if (!text || typeof text !== 'string') {\n    return createErrorResponse('Text input is missing or invalid', 400)\n  }\n\n  const prompt = `     Summarize the following text into a concise paragraph suitable for a fulltext node:\n    ${text}\n  `\n\n  const response = await fetch('https://api.openai.com/v1/chat/completions', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      Authorization: `Bearer ${apiKey}`,\n    },\n    body: JSON.stringify({\n      model: 'gpt-4',\n      temperature: 0.7,\n      max_tokens: 300,\n      messages: [\n        {\n          role: 'system',\n          content: 'You are a summarization assistant. Generate concise summaries.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    }),\n  })\n\n  if (!response.ok) {\n    const errorText = await response.text()\n    return createErrorResponse(`OpenAI API error: ${response.status} - ${errorText}`, 500)\n  }\n\n  const data = await response.json()\n  const summary = data.choices[0].message.content.trim()\n\n  return createResponse(\n    JSON.stringify({\n      id: `fulltext_${Date.now()}`,\n      label: 'Summary',\n      type: 'fulltext',\n      info: summary,\n      color: '#f9f9f9',\n    }),\n    200,\n  )\n}\n\nconst handleGrokTest = async (request, env) => {\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { prompt, returnType = 'fulltext', graphContext } = body\n  if (!prompt || typeof prompt !== 'string') {\n    return createErrorResponse('Prompt input is missing or invalid', 400)\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  try {\n    // Prepare the user message with optional graph context\n    let userMessage = prompt\n    if (graphContext && graphContext.trim()) {\n      userMessage = `Context from knowledge graph:\\n${graphContext}\\n\\nQuestion: ${prompt}`\n    }\n\n    // Generate main content\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 4000,\n      messages: [\n        {\n          role: 'system',\n          content: graphContext\n            ? 'You are a philosophical AI providing deep insights. Use the provided knowledge graph context to inform your response when relevant, but focus on answering the specific question asked.'\n            : 'You are a philosophical AI providing deep insights.',\n        },\n        { role: 'user', content: userMessage },\n      ],\n    })\n\n    const responseText = completion.choices[0].message.content.trim()\n    if (!responseText) {\n      return createErrorResponse('Empty summary response', 500)\n    }\n\n    // Generate bibliographic references in APA format\n    const biblCompletion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 500,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are a scholarly AI. Return only 2-3 bibliographic references in APA format (e.g., \"Author, A. A. (Year). Title of work. Publisher.\"), one per line, with no explanations, headings, or additional text.',\n        },\n        { role: 'user', content: `Generate references for the topic: ${prompt}` },\n      ],\n    })\n\n    const biblText = biblCompletion.choices[0].message.content.trim()\n    // Split references by newline, filter out empty lines\n    const biblReferences = biblText\n      .split('\\n')\n      .filter((ref) => ref.trim())\n      .map((ref) => ref.trim())\n\n    // Handle different return types\n    if (returnType === 'action') {\n      // Return action_test node\n      return new Response(\n        JSON.stringify({\n          id: `action_${Date.now()}`,\n          label: 'https://api.vegvisr.org/groktest',\n          type: 'action_test',\n          info: responseText,\n          color: '#ffe6cc',\n          bibl: biblReferences,\n        }),\n        {\n          status: 200,\n          headers: {\n            ...corsHeaders,\n            'Content-Type': 'application/json',\n          },\n        },\n      )\n    } else if (returnType === 'both') {\n      // Generate follow-up question\n      const followUpCompletion = await client.chat.completions.create({\n        model: 'grok-3-beta',\n        temperature: 0.8,\n        max_tokens: 200,\n        messages: [\n          {\n            role: 'system',\n            content:\n              'You are a philosophical AI. Based on the previous answer, generate ONE thoughtful follow-up question that would lead to deeper insights. Return ONLY the question, no explanations.',\n          },\n          {\n            role: 'user',\n            content: `Previous answer: ${responseText}\\n\\nGenerate a follow-up question:`,\n          },\n        ],\n      })\n\n      const followUpQuestion = followUpCompletion.choices[0].message.content.trim()\n\n      // Return both fulltext and action nodes\n      return new Response(\n        JSON.stringify({\n          type: 'both',\n          fulltext: {\n            id: `fulltext_${Date.now()}`,\n            label: 'Grok Answer',\n            type: 'fulltext',\n            info: responseText,\n            color: '#f9f9f9',\n            bibl: biblReferences,\n          },\n          action: {\n            id: `action_${Date.now() + 1}`,\n            label: 'https://api.vegvisr.org/groktest',\n            type: 'action_test',\n            info: followUpQuestion,\n            color: '#ffe6cc',\n          },\n        }),\n        {\n          status: 200,\n          headers: {\n            ...corsHeaders,\n            'Content-Type': 'application/json',\n          },\n        },\n      )\n    } else {\n      // Default: return fulltext node\n      return new Response(\n        JSON.stringify({\n          id: `fulltext_${Date.now()}`,\n          label: 'Grok Answer',\n          type: 'fulltext',\n          info: responseText,\n          color: '#f9f9f9',\n          bibl: biblReferences,\n        }),\n        {\n          status: 200,\n          headers: {\n            ...corsHeaders,\n            'Content-Type': 'application/json',\n          },\n        },\n      )\n    }\n  } catch (error) {\n    console.error('Grok API error details:', error)\n    return createErrorResponse(`Grok API error: ${error.message || 'Unknown error'}`, 500)\n  }\n}\n\nconst handleGeminiTest = async (request, env) => {\n  const apiKey = env.GOOGLE_GEMINI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: Google Gemini API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { text, prompt, returnType = 'fulltext', graphContext } = body\n  const inputText = text || prompt // Accept both 'text' and 'prompt' for compatibility\n  if (!inputText || typeof inputText !== 'string') {\n    return createErrorResponse('Text or prompt input is missing or invalid', 400)\n  }\n\n  try {\n    // Prepare the input text with optional graph context\n    let finalInputText = inputText\n    if (graphContext && graphContext.trim()) {\n      finalInputText = `Context from knowledge graph:\\n${graphContext}\\n\\nQuestion: ${inputText}`\n    }\n\n    const response = await fetch(\n      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,\n      {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          contents: [\n            {\n              parts: [\n                {\n                  text: finalInputText,\n                },\n              ],\n            },\n          ],\n        }),\n      },\n    )\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      return createErrorResponse(`Gemini API error: ${response.status} - ${errorText}`, 500)\n    }\n\n    const data = await response.json()\n\n    // Extract the generated text from Gemini's response format\n    const generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text || 'No response generated'\n\n    // Handle different return types\n    if (returnType === 'action') {\n      // Return action_test node\n      return createResponse(\n        JSON.stringify({\n          id: `action_${Date.now()}`,\n          label: 'https://api.vegvisr.org/gemini-test',\n          type: 'action_test',\n          info: generatedText,\n          color: '#ffe6cc',\n          model: 'gemini-2.0-flash',\n          prompt: inputText,\n        }),\n      )\n    } else if (returnType === 'both') {\n      // Generate follow-up question\n      const followUpResponse = await fetch(\n        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,\n        {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          body: JSON.stringify({\n            contents: [\n              {\n                parts: [\n                  {\n                    text: `Based on this answer: \"${generatedText}\", generate ONE thoughtful follow-up question that would lead to deeper insights. Return ONLY the question, no explanations.`,\n                  },\n                ],\n              },\n            ],\n          }),\n        },\n      )\n\n      let followUpQuestion = 'What would you like to explore further?'\n      if (followUpResponse.ok) {\n        const followUpData = await followUpResponse.json()\n        followUpQuestion =\n          followUpData.candidates?.[0]?.content?.parts?.[0]?.text || followUpQuestion\n      }\n\n      // Return both fulltext and action nodes\n      return createResponse(\n        JSON.stringify({\n          type: 'both',\n          fulltext: {\n            id: `fulltext_${Date.now()}`,\n            label: 'Gemini Answer',\n            type: 'fulltext',\n            info: generatedText,\n            color: '#e8f4fd',\n            model: 'gemini-2.0-flash',\n            prompt: inputText,\n          },\n          action: {\n            id: `action_${Date.now() + 1}`,\n            label: 'https://api.vegvisr.org/gemini-test',\n            type: 'action_test',\n            info: followUpQuestion,\n            color: '#ffe6cc',\n          },\n        }),\n      )\n    } else {\n      // Default: return fulltext node\n      return createResponse(\n        JSON.stringify({\n          id: `gemini_${Date.now()}`,\n          label: 'Gemini Answer',\n          type: 'fulltext',\n          info: generatedText,\n          color: '#e8f4fd',\n          model: 'gemini-2.0-flash',\n          prompt: inputText,\n        }),\n      )\n    }\n  } catch (error) {\n    return createErrorResponse(`Gemini API error: ${error.message}`, 500)\n  }\n}\n\nconst handleClaudeTest = async (request, env) => {\n  const apiKey = env.ANTHROPIC_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: Anthropic API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { prompt, returnType = 'fulltext', graphContext } = body\n  if (!prompt || typeof prompt !== 'string') {\n    return createErrorResponse('Prompt input is missing or invalid', 400)\n  }\n\n  try {\n    // Prepare the message content with optional graph context\n    let messageContent = prompt\n    if (graphContext && graphContext.trim()) {\n      messageContent = `Context from knowledge graph:\\n${graphContext}\\n\\nQuestion: ${prompt}\\n\\nPlease use the provided context to inform your response when relevant, but focus on answering the specific question asked.`\n    }\n\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'x-api-key': apiKey,\n        'anthropic-version': '2023-06-01',\n      },\n      body: JSON.stringify({\n        model: 'claude-3-5-sonnet-20241022',\n        max_tokens: 2000,\n        messages: [\n          {\n            role: 'user',\n            content: messageContent,\n          },\n        ],\n      }),\n    })\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      return createErrorResponse(`Claude API error: ${response.status} - ${errorText}`, 500)\n    }\n\n    const data = await response.json()\n\n    // Extract the generated text from Claude's response format\n    const generatedText = data.content?.[0]?.text || 'No response generated'\n\n    // Handle different return types\n    if (returnType === 'action') {\n      // Return action_test node\n      return createResponse(\n        JSON.stringify({\n          id: `action_${Date.now()}`,\n          label: 'https://api.vegvisr.org/claude-test',\n          type: 'action_test',\n          info: generatedText,\n          color: '#ffe6cc',\n          model: 'claude-3-5-sonnet',\n          prompt: prompt,\n        }),\n      )\n    } else if (returnType === 'both') {\n      // Generate follow-up question\n      const followUpResponse = await fetch('https://api.anthropic.com/v1/messages', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'x-api-key': apiKey,\n          'anthropic-version': '2023-06-01',\n        },\n        body: JSON.stringify({\n          model: 'claude-3-5-sonnet-20241022',\n          max_tokens: 200,\n          messages: [\n            {\n              role: 'user',\n              content: `Based on this answer: \"${generatedText}\", generate ONE thoughtful follow-up question that would lead to deeper insights. Return ONLY the question, no explanations.`,\n            },\n          ],\n        }),\n      })\n\n      let followUpQuestion = 'What would you like to explore further?'\n      if (followUpResponse.ok) {\n        const followUpData = await followUpResponse.json()\n        followUpQuestion = followUpData.content?.[0]?.text || followUpQuestion\n      }\n\n      // Return both fulltext and action nodes\n      return createResponse(\n        JSON.stringify({\n          type: 'both',\n          fulltext: {\n            id: `fulltext_${Date.now()}`,\n            label: 'Claude Answer',\n            type: 'fulltext',\n            info: generatedText,\n            color: '#f4e5d3',\n            model: 'claude-3-5-sonnet',\n            prompt: prompt,\n          },\n          action: {\n            id: `action_${Date.now() + 1}`,\n            label: 'https://api.vegvisr.org/claude-test',\n            type: 'action_test',\n            info: followUpQuestion,\n            color: '#ffe6cc',\n          },\n        }),\n      )\n    } else {\n      // Default: return fulltext node\n      return createResponse(\n        JSON.stringify({\n          id: `claude_${Date.now()}`,\n          label: 'Claude Answer',\n          type: 'fulltext',\n          info: generatedText,\n          color: '#f4e5d3',\n          model: 'claude-3-5-sonnet',\n          prompt: prompt,\n        }),\n      )\n    }\n  } catch (error) {\n    return createErrorResponse(`Claude API error: ${error.message}`, 500)\n  }\n}\n\n// Updated endpoint for versatile AI action with response format\nconst handleAIAction = async (request, env) => {\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const {\n    prompt,\n    instructions,\n    baseURL,\n    model,\n    temperature,\n    max_tokens,\n    apiProvider,\n    response_format,\n  } = body\n  if (\n    !prompt ||\n    !instructions ||\n    !baseURL ||\n    !model ||\n    !temperature ||\n    !max_tokens ||\n    !apiProvider ||\n    !response_format\n  ) {\n    return createErrorResponse('Missing required parameters', 400)\n  }\n\n  let apiKey\n  switch (apiProvider.toLowerCase()) {\n    case 'xai':\n      apiKey = env.XAI_API_KEY\n      break\n    case 'openai':\n      apiKey = env.OPENAI_API_KEY\n      break\n    case 'google':\n      apiKey = env.GOOGLE_API_KEY\n      break\n    default:\n      return createErrorResponse('Unsupported API provider', 400)\n  }\n\n  if (!apiKey) {\n    return createErrorResponse(`Internal Server Error: ${apiProvider} API key missing`, 500)\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: baseURL,\n  })\n\n  try {\n    const completion = await client.chat.completions.create({\n      model: model,\n      temperature: temperature,\n      max_tokens: max_tokens,\n      messages: [\n        { role: 'system', content: instructions },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const responseText = completion.choices[0].message.content\n    return createResponse(\n      JSON.stringify({\n        id: `node_${Date.now()}`,\n        label: response_format.label || 'Response',\n        type: response_format.type || 'fulltext',\n        info: responseText,\n        color: response_format.color || '#f9f9f9',\n        ...response_format.additional_fields,\n      }),\n      200,\n    )\n  } catch (error) {\n    console.error('AI API error details:', error)\n    return createErrorResponse(`AI API error: ${error.message || 'Unknown error'}`, 500)\n  }\n}\n\nconst handleGetGoogleApiKey = async (request, env) => {\n  const apiKey = env.GOOGLE_API_KEY\n  const url = new URL(request.url)\n  const int_token = url.searchParams.get('key')\n\n  if (!int_token || int_token !== env.INT_TOKEN) {\n    return createErrorResponse({ int_token }, 401)\n  }\n\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: Google API key missing', 500)\n  }\n\n  return createResponse(JSON.stringify({ apiKey }), 200)\n}\n\nconst handleUpdateKml = async (request, env) => {\n  // --- Authorization ---\n  const authHeader = request.headers.get('Authorization') || ''\n  const token = authHeader.replace('Bearer ', '').trim()\n  if (token !== env.INT_TOKEN) {\n    return createErrorResponse('Unauthorized: Invalid token', 401)\n  }\n\n  // --- Parse Request Body ---\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  // --- Extract Fields with Defaults ---\n  const {\n    id,\n    name,\n    description = '',\n    longitude,\n    latitude,\n    altitude = 0,\n    styleUrl,\n    lookAt = {},\n  } = body\n  if (!name || longitude === undefined || latitude === undefined) {\n    return createErrorResponse('Missing required marker fields', 400)\n  }\n\n  // --- Fetch or Initialize KML ---\n  const kmlObject = await env.KLM_BUCKET.get('Vegvisr.org.kml')\n  let kmlText = ''\n  if (kmlObject) {\n    kmlText = await kmlObject.text()\n  } else {\n    kmlText = `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<kml xmlns=\"http://www.opengis.net/kml/2.2\">\\n  <Document>\\n  </Document>\\n</kml>`\n  }\n\n  // --- Build LookAt Block (if provided) ---\n  let lookAtBlock = ''\n  if (Object.keys(lookAt).length > 0) {\n    lookAtBlock = `\\n    <LookAt>\\n      <longitude>${lookAt.longitude ?? longitude}</longitude>\\n      <latitude>${lookAt.latitude ?? latitude}</latitude>\\n      <altitude>${lookAt.altitude ?? altitude}</altitude>\\n      <heading>${lookAt.heading ?? 0}</heading>\\n      <tilt>${lookAt.tilt ?? 0}</tilt>\\n      <gx:fovy>${lookAt.fovy ?? 35}</gx:fovy>\\n      <range>${lookAt.range ?? 1000}</range>\\n      <altitudeMode>${lookAt.altitudeMode ?? 'absolute'}</altitudeMode>\\n    </LookAt>`\n  }\n\n  // --- Build styleUrl Block (if provided) ---\n  let styleUrlBlock = styleUrl ? `\\n    <styleUrl>${styleUrl}</styleUrl>` : ''\n\n  // --- Build id Attribute (if provided) ---\n  let idAttr = id ? ` id=\"${id}\"` : ''\n\n  // --- Build Placemark ---\n  const placemark = `\\n  <Placemark${idAttr}>\\n    <name>${name}</name>\\n    <description>${description}</description>${lookAtBlock}${styleUrlBlock}\\n    <Point>\\n      <coordinates>${longitude},${latitude},${altitude}</coordinates>\\n    </Point>\\n  </Placemark>\\n`\n\n  // --- Insert Placemark Before </Document> ---\n  kmlText = kmlText.replace(/<\\/Document>/, `${placemark}\\n</Document>`)\n\n  // --- Save Updated KML ---\n  await env.KLM_BUCKET.put('Vegvisr.org.kml', kmlText, {\n    httpMetadata: { contentType: 'application/vnd.google-earth.kml+xml' },\n  })\n\n  return createResponse(JSON.stringify({ success: true, message: 'KML updated' }))\n}\n\nconst handleSuggestTitle = async (request, env) => {\n  console.log('Handling title suggestion request')\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    console.error('XAI API key missing')\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n    console.log('Request body:', JSON.stringify(body))\n  } catch {\n    console.error('Invalid JSON body:')\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { nodes, edges } = body\n  if (!Array.isArray(nodes) || !Array.isArray(edges)) {\n    console.error('Invalid graph data:', { nodes, edges })\n    return createErrorResponse('Invalid graph data', 400)\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  try {\n    // Extract content from node.info fields, filtering out empty or null values\n    const nodeContents = nodes\n      .map((n) => n.info)\n      .filter((info) => info && typeof info === 'string' && info.trim().length > 0)\n      .join('\\n')\n\n    const prompt = `Generate a concise, descriptive title (max 10 words) for a knowledge graph based on the following content:\n\n    Content:\n    ${nodeContents}\n\n    The title should reflect the main theme or subject matter of the content, not the structure of the graph.\n    Return only the title, no additional text or explanations.`\n\n    console.log('Sending prompt to Grok:', prompt)\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 50,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are a title generator for knowledge graphs. Focus on the content and main themes, not the graph structure. Return only the title.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const title = completion.choices[0].message.content.trim()\n    console.log('Generated title:', title)\n    return createResponse(JSON.stringify({ title }))\n  } catch {\n    console.error('Grok API error:')\n    return createErrorResponse(`Grok API error:`, 500)\n  }\n}\n\nconst handleSuggestDescription = async (request, env) => {\n  console.log('Handling description suggestion request')\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    console.error('XAI API key missing')\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n    console.log('Request body:', JSON.stringify(body))\n  } catch {\n    console.error('Invalid JSON body:')\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { nodes, edges } = body\n  if (!Array.isArray(nodes) || !Array.isArray(edges)) {\n    console.error('Invalid graph data:', { nodes, edges })\n    return createErrorResponse('Invalid graph data', 400)\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  try {\n    // Extract content from node.info fields, filtering out empty or null values\n    const nodeContents = nodes\n      .map((n) => n.info)\n      .filter((info) => info && typeof info === 'string' && info.trim().length > 0)\n      .join('\\n')\n\n    const prompt = `Generate a concise description (2-3 sentences) for a knowledge graph based on the following content:\n\n    Content:\n    ${nodeContents}\n\n    The description should summarize the main themes, insights, and connections present in the content.\n    Focus on the actual content and its meaning, not the graph structure.\n    Return only the description, no additional text or explanations.`\n\n    console.log('Sending prompt to Grok:', prompt)\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 150,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are a description generator for knowledge graphs. Focus on summarizing the content themes and insights, not the graph structure. Return only the description.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const description = completion.choices[0].message.content.trim()\n    console.log('Generated description:', description)\n    return createResponse(JSON.stringify({ description }))\n  } catch {\n    console.error('Grok API error:')\n    return createErrorResponse(`Grok API error:`, 500)\n  }\n}\n\nconst handleSuggestCategories = async (request, env) => {\n  console.log('Handling categories suggestion request')\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    console.error('XAI API key missing')\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n    console.log('Request body:', JSON.stringify(body))\n  } catch {\n    console.error('Invalid JSON body:')\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { nodes, edges } = body\n  if (!Array.isArray(nodes) || !Array.isArray(edges)) {\n    console.error('Invalid graph data:', { nodes, edges })\n    return createErrorResponse('Invalid graph data', 400)\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  try {\n    // Extract content from node.info fields, filtering out empty or null values\n    const nodeContents = nodes\n      .map((n) => n.info)\n      .filter((info) => info && typeof info === 'string' && info.trim().length > 0)\n      .join('\\n')\n\n    const prompt = `Generate 3-5 relevant categories (as hashtags) for a knowledge graph based on the following content:\n\n    Content:\n    ${nodeContents}\n\n    The categories should reflect the main themes, topics, or subject areas present in the content.\n    Return only the categories as hashtags separated by spaces, no additional text or explanations.\n    Example format: #Category1 #Category2 #Category3`\n\n    console.log('Sending prompt to Grok:', prompt)\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 100,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are a category generator for knowledge graphs. Focus on the content themes and topics, not the graph structure. Return only hashtag categories.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const categories = completion.choices[0].message.content.trim()\n    console.log('Generated categories:', categories)\n    return createResponse(JSON.stringify({ categories }))\n  } catch {\n    console.error('Grok API error:')\n    return createErrorResponse(`Grok API error:`, 500)\n  }\n}\n\nconst handleGrokIssueDescription = async (request, env) => {\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { title, description, body: bodyText, labels, mode } = body\n\n  // Validate mode\n  if (\n    !mode ||\n    !['title_to_description', 'description_to_title', 'expand_description'].includes(mode)\n  ) {\n    return createErrorResponse(\n      'Invalid mode. Must be one of: title_to_description, description_to_title, expand_description',\n      400,\n    )\n  }\n\n  // Use either description or body field\n  const descriptionText = description || bodyText\n\n  // Validate required fields based on mode\n  if (mode === 'title_to_description' && (!title || typeof title !== 'string')) {\n    return createErrorResponse('Title is required for title_to_description mode', 400)\n  }\n  if (\n    (mode === 'description_to_title' || mode === 'expand_description') &&\n    (!descriptionText || typeof descriptionText !== 'string')\n  ) {\n    return createErrorResponse(\n      'Description is required for description_to_title and expand_description modes',\n      400,\n    )\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  try {\n    let labelText = ''\n    if (Array.isArray(labels) && labels.length > 0) {\n      labelText = `Labels: ${labels.join(', ')}.`\n    }\n\n    let prompt, systemContent, maxTokens\n    switch (mode) {\n      case 'title_to_description':\n        prompt = `Generate a concise, clear, and helpful description for a GitHub issue, feature, or enhancement.\\nTitle: ${title}\\n${labelText}\\nThe description should explain the context, the problem or feature, and what a good solution or outcome would look like. Return only the description, no extra text.`\n        systemContent =\n          'You are an expert at writing clear, concise, and actionable GitHub issue descriptions. Return only the description.'\n        maxTokens = 500\n        break\n      case 'description_to_title':\n        prompt = `Generate a clear and concise title for a GitHub issue based on this description:\\n${descriptionText}\\n${labelText}\\nThe title should be specific and descriptive. Return only the title, no extra text.`\n        systemContent =\n          'You are an expert at writing clear and concise GitHub issue titles. Return only the title.'\n        maxTokens = 50\n        break\n      case 'expand_description':\n        prompt = `Expand and enhance this GitHub issue description while maintaining its core message:\\n${descriptionText}\\n${labelText}\\n\\nPlease enhance the description by:\\n1. Adding more technical context and details\\n2. Including relevant background information\\n3. Structuring the content with clear sections\\n4. Adding specific examples or use cases\\n5. Clarifying any ambiguous points\\n6. Suggesting potential solutions or approaches\\n\\nMaintain the original tone and intent while making the description more comprehensive and actionable. Return only the expanded description, no extra text.`\n        systemContent =\n          'You are an expert at expanding and enhancing GitHub issue descriptions. Focus on adding value through technical details, context, and structure while maintaining the original message. Return only the expanded description.'\n        maxTokens = 1000\n        break\n    }\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: maxTokens,\n      messages: [\n        { role: 'system', content: systemContent },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const result = completion.choices[0].message.content.trim()\n    return createResponse(\n      JSON.stringify(mode === 'description_to_title' ? { title: result } : { description: result }),\n    )\n  } catch {\n    return createErrorResponse('Grok API error', 500)\n  }\n}\n\nconst handleGenerateMetaAreas = async (request, env) => {\n  // --- Authorization ---\n  const userRole = request.headers.get('x-user-role') || ''\n  if (userRole !== 'Superadmin') {\n    return createErrorResponse('Forbidden: Superadmin role required', 403)\n  }\n\n  // 1. Fetch all knowledge graphs\n  console.log('Fetching all knowledge graphs...')\n  const response = await fetch('https://knowledge.vegvisr.org/getknowgraphs')\n  console.log('getknowgraphs response status:', response.status)\n  if (!response.ok) {\n    const text = await response.text()\n    console.log('getknowgraphs response body:', text)\n    return createErrorResponse('Failed to fetch graphs', 500)\n  }\n  const data = await response.json()\n  if (!data.results) return createErrorResponse('No graphs found', 404)\n\n  // 2. For each graph, fetch full data and generate a meta area tag if missing\n  for (const graph of data.results) {\n    const graphResponse = await fetch(`https://knowledge.vegvisr.org/getknowgraph?id=${graph.id}`)\n    if (!graphResponse.ok) continue\n    const graphData = await graphResponse.json()\n\n    // Skip if metaArea already exists and is a non-empty string\n    const meta = graphData.metadata?.metaArea\n    if (typeof meta === 'string' && meta.trim().length > 0) {\n      console.log(`Skipping graph ${graph.id} (already has metaArea: '${meta}')`)\n      continue\n    }\n\n    // Compose prompt for GROK AI\n    const prompt = `\\nGiven the following knowledge graph content, generate a single, specific, community-relevant Meta Area tag (all capital letters, no spaces, no special characters) that best summarizes the main theme. \\n- The tag should be a proper noun or a well-known field of study, tradition, technology, or cultural topic (e.g., NORSE MYTHOLOGY, AI GROK TECH, ETYMOLOGY, HERMETICISM, HINDUISM, CLOUD COMPUTING, ASTROLOGY, SYMBOLISM, PSYCHOLOGY, TECHNOLOGY, SHIVA, SHAKTI, NARASIMHA, etc.).\\n- Avoid generic words like FATE, SPIRITUALITY, MINDFULNESS, WISDOM, BREATH, AWAKENING, INTERDISCIPLINARY, TEST, TRANSFORMATION, SACREDNESS, PLAYGROUND, or similar.\\n- Only return the tag, in ALL CAPITAL LETTERS.\\n\\nContent:\\n${graphData.metadata?.title || ''}\\n${graphData.metadata?.description || ''}\\n${graphData.metadata?.category || ''}\\n${graphData.nodes?.map((n) => n.label + ' ' + (n.info || '')).join(' ')}\\n`\n\n    // Call GROK AI\n    let metaArea = ''\n    try {\n      const client = new OpenAI({\n        apiKey: env.XAI_API_KEY,\n        baseURL: 'https://api.x.ai/v1',\n      })\n      const completion = await client.chat.completions.create({\n        model: 'grok-3-beta',\n        temperature: 0.7,\n        max_tokens: 20,\n        messages: [\n          {\n            role: 'system',\n            content:\n              'You are an expert at summarizing knowledge graphs. Return only a single, specific, community-relevant, ALL CAPS, proper-noun tag. Avoid generic words.',\n          },\n          { role: 'user', content: prompt },\n        ],\n      })\n      metaArea = completion.choices[0].message.content.trim().split(/\\s+/)[0].toUpperCase()\n      // Filter out banned tags\n      const bannedTags = [\n        'FATE',\n        'SPIRITUALITY',\n        'MINDFULNESS',\n        'WISDOM',\n        'BREATH',\n        'AWAKENING',\n        'INTERDISCIPLINARY',\n        'TEST',\n        'TRANSFORMATION',\n        'SACREDNESS',\n        'PLAYGROUND',\n      ]\n      if (bannedTags.includes(metaArea)) {\n        console.log(\n          `Banned metaArea '${metaArea}' generated for graph ${graph.id}, skipping update.`,\n        )\n        continue\n      }\n    } catch {\n      continue // Skip on error\n    }\n\n    // 3. Update the graph with the new meta area\n    await fetch('https://knowledge.vegvisr.org/updateknowgraph', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        id: graph.id,\n        graphData: {\n          ...graphData,\n          metadata: {\n            ...graphData.metadata,\n            metaArea,\n          },\n        },\n      }),\n    })\n  }\n\n  return createResponse(JSON.stringify({ success: true }))\n}\n\n// --- GROK Ask Endpoint ---\nconst handleGrokAsk = async (request, env) => {\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  let { context, question } = body\n  if (!context || typeof context !== 'string') {\n    return createErrorResponse('Context is required and must be a string', 400)\n  }\n  if (!question || typeof question !== 'string' || !question.trim()) {\n    return createErrorResponse('Question is required and must be a non-empty string', 400)\n  }\n\n  // Strip markdown/HTML from context using marked\n  let plainContext = ''\n  try {\n    // marked.parse returns HTML, so strip HTML tags\n    const html = marked.parse(context)\n    plainContext = html\n      .replace(/<[^>]+>/g, ' ')\n      .replace(/\\s+/g, ' ')\n      .trim()\n  } catch {\n    plainContext = context\n  }\n\n  const client = new OpenAI({\n    apiKey: apiKey,\n    baseURL: 'https://api.x.ai/v1',\n  })\n\n  const prompt = `Given the following context, answer the user's question in detail.\\n\\nContext:\\n${plainContext}\\n\\nQuestion: ${question}`\n  const systemContent =\n    \"You are an expert assistant. Use the provided context to answer the user's question in detail.\"\n\n  try {\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 800,\n      messages: [\n        { role: 'system', content: systemContent },\n        { role: 'user', content: prompt },\n      ],\n    })\n    const result = completion.choices[0].message.content.trim()\n    return createResponse(JSON.stringify({ result }), 200)\n  } catch {\n    return createErrorResponse('Grok ask error', 500)\n  }\n}\n\n// --- Generate Header Image Endpoint ---\nconst handleGenerateHeaderImage = async (request, env) => {\n  const apiKey = env.OPENAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: OpenAI API key missing', 500)\n  }\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n  let { prompt } = body\n  if (!prompt || typeof prompt !== 'string' || !prompt.trim()) {\n    return createErrorResponse('Prompt is required and must be a non-empty string', 400)\n  }\n  // Add horizontal/landscape hint\n  prompt = prompt + ', horizontal, wide, landscape, header image'\n\n  // 1. Call OpenAI DALL-E 3\n  let imageUrl\n  try {\n    const openaiRes = await fetch('https://api.openai.com/v1/images/generations', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: `Bearer ${apiKey}`,\n      },\n      body: JSON.stringify({\n        model: 'dall-e-3',\n        prompt,\n        n: 1,\n        size: '1792x1024', // Updated to supported size for horizontal images\n        response_format: 'url',\n      }),\n    })\n    if (!openaiRes.ok) {\n      const err = await openaiRes.text()\n      return createErrorResponse('OpenAI error: ' + err, 500)\n    }\n    const openaiData = await openaiRes.json()\n    imageUrl = openaiData.data[0].url\n  } catch {\n    return createErrorResponse('Failed to generate image', 500)\n  }\n\n  // 2. Download the image\n  let imageBuffer\n  try {\n    const imgRes = await fetch(imageUrl)\n    if (!imgRes.ok) throw new Error('Failed to download image')\n    imageBuffer = await imgRes.arrayBuffer()\n  } catch {\n    return createErrorResponse('Failed to download image', 500)\n  }\n\n  // 3. Upload to R2\n  const imageId = Date.now() + '-' + Math.random().toString(36).slice(2, 10)\n  const fileName = `${imageId}.png`\n  try {\n    await env.MY_R2_BUCKET.put(fileName, imageBuffer, {\n      httpMetadata: { contentType: 'image/png' },\n    })\n  } catch {\n    return createErrorResponse('Failed to upload image to R2', 500)\n  }\n\n  // 4. Return the markdown string\n  const publicUrl = `https://vegvisr.imgix.net/${fileName}`\n  const markdown = `![Header|width: 100%; height: 200px; object-fit: cover; object-position: center](${publicUrl})`\n  return createResponse(JSON.stringify({ markdown, url: publicUrl }), 200)\n}\n\n// --- Generate Image Prompt Endpoint ---\nconst handleGenerateImagePrompt = async (request, env) => {\n  const apiKey = env.OPENAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: OpenAI API key missing', 500)\n  }\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n  const { context } = body\n  if (!context || typeof context !== 'string' || !context.trim()) {\n    return createErrorResponse('Context is required and must be a non-empty string', 400)\n  }\n\n  // Compose the system and user prompt\n  const systemPrompt = `You are an expert at creating visually descriptive prompts for AI image generation. Your job is to turn a text context into a concise, creative, and visually rich prompt for DALL-E 3. Always make the image horizontal, wide, and suitable as a website header. Do not mention text, captions, or watermarks. Do not include people unless the context requires it. Focus on landscape, atmosphere, and mood.`\n  const userPrompt = `Context: ${context}\\n\\nGenerate a single, creative, visually descriptive prompt for DALL-E 3 to create a horizontal header image. Do not include any explanations or extra text.`\n\n  try {\n    const openaiRes = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: `Bearer ${apiKey}`,\n      },\n      body: JSON.stringify({\n        model: 'gpt-4',\n        temperature: 0.7,\n        max_tokens: 100,\n        messages: [\n          { role: 'system', content: systemPrompt },\n          { role: 'user', content: userPrompt },\n        ],\n      }),\n    })\n    if (!openaiRes.ok) {\n      const err = await openaiRes.text()\n      return createErrorResponse('OpenAI error: ' + err, 500)\n    }\n    const openaiData = await openaiRes.json()\n    let prompt = openaiData.choices[0].message.content.trim()\n    // Remove any extra text or explanations\n    if (prompt.startsWith('\"') && prompt.endsWith('\"')) prompt = prompt.slice(1, -1)\n    return createResponse(JSON.stringify({ prompt }), 200)\n  } catch {\n    return createErrorResponse('Failed to generate image prompt', 500)\n  }\n}\n\nconst handleListR2Images = async (request, env) => {\n  const list = await env.MY_R2_BUCKET.list()\n  // Only include common image extensions\n  const images = list.objects\n    .filter((obj) => /\\.(png|jpe?g|gif|webp)$/i.test(obj.key))\n    .map((obj) => ({\n      key: obj.key,\n      url: `https://vegvisr.imgix.net/${obj.key}`,\n    }))\n  return createResponse(JSON.stringify({ images }), 200)\n}\n\n// --- YouTube Search Endpoint ---\nconst handleYouTubeSearch = async (request, env) => {\n  const apiKey = env.YOUTUBE_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: YouTube API key missing', 500)\n  }\n\n  const url = new URL(request.url)\n  const query = url.searchParams.get('q')\n\n  if (!query) {\n    return createErrorResponse('Search query parameter \"q\" is required', 400)\n  }\n\n  console.log('\uD83D\uDD0D YouTube Search Request:', { query })\n\n  try {\n    // Build URL with parameters\n    const searchUrl = new URL('https://www.googleapis.com/youtube/v3/search')\n    searchUrl.searchParams.set('part', 'id,snippet')\n    searchUrl.searchParams.set('q', query)\n    searchUrl.searchParams.set('maxResults', '10')\n    searchUrl.searchParams.set('key', apiKey)\n    searchUrl.searchParams.set('type', 'video')\n\n    console.log('\uD83D\uDCE1 Calling YouTube API:', searchUrl.toString())\n\n    const apiResponse = await fetch(searchUrl.toString())\n\n    if (!apiResponse.ok) {\n      const errorText = await apiResponse.text()\n      console.error('\u274C YouTube API Error:', errorText)\n      return createErrorResponse(\n        `YouTube API error: ${apiResponse.status} - ${errorText}`,\n        apiResponse.status,\n      )\n    }\n\n    const data = await apiResponse.json()\n    console.log('\u2705 YouTube Search Results:', { count: data.items?.length || 0 })\n\n    // Get full descriptions for all videoIds\n    const videoIds = data.items.map((item) => item.id.videoId).join(',')\n    const detailsUrl = `https://www.googleapis.com/youtube/v3/videos?part=snippet&id=${videoIds}&key=${apiKey}`\n    const detailsResponse = await fetch(detailsUrl)\n    const detailsData = await detailsResponse.json()\n    const detailsMap = {}\n    if (detailsData.items) {\n      for (const item of detailsData.items) {\n        detailsMap[item.id] = item.snippet?.description || ''\n      }\n    }\n\n    // Transform the data to match our expected format, using the full description if available\n    const results =\n      data.items?.map((item) => ({\n        videoId: item.id.videoId,\n        title: item.snippet.title,\n        description: detailsMap[item.id.videoId] || item.snippet.description,\n        channelTitle: item.snippet.channelTitle,\n        publishedAt: item.snippet.publishedAt,\n        thumbnails: item.snippet.thumbnails,\n      })) || []\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        query: query,\n        results: results,\n        totalResults: results.length,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C YouTube Search Error:', error)\n    return createErrorResponse('Failed to search YouTube videos: ' + error.message, 500)\n  }\n}\n\n// --- YouTube Transcript IO Endpoint ---\nconst handleYouTubeTranscriptIO = async (request, env) => {\n  const url = new URL(request.url)\n  const videoId = url.pathname.split('/').pop()\n\n  if (!videoId) {\n    return createErrorResponse('Video ID is required', 400)\n  }\n\n  const apiToken = env.YOUTUBE_TRANSCRIPT_IO_TOKEN\n  if (!apiToken) {\n    return createErrorResponse(\n      'Internal Server Error: YouTube Transcript IO API token missing',\n      500,\n    )\n  }\n\n  console.log('\uD83D\uDCFA YouTube Transcript IO Request:', { videoId })\n\n  try {\n    // Call the YouTube Transcript IO API exactly as documented\n    const response = await fetch('https://www.youtube-transcript.io/api/transcripts', {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${apiToken}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        ids: [videoId],\n      }),\n    })\n\n    console.log('\uD83D\uDCE1 YouTube Transcript IO API Response Status:', response.status)\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      console.error('\u274C YouTube Transcript IO API Error:', errorText)\n      return createErrorResponse(\n        `YouTube Transcript IO API error: ${response.status} - ${errorText}`,\n        response.status,\n      )\n    }\n\n    const data = await response.json()\n    console.log('\u2705 YouTube Transcript IO Results:', { videoId, hasData: !!data })\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        videoId: videoId,\n        transcript: data,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C YouTube Transcript IO Error:', error)\n    return createErrorResponse('Failed to get YouTube transcript: ' + error.message, 500)\n  }\n}\n\n// --- DOWNSUB URL Transcript Endpoint (for non-YouTube URLs) ---\nconst handleDownsubUrlTranscript = async (request, env) => {\n  const apiToken = env.DOWNDUB_API_TOKEN\n  if (!apiToken) {\n    return createErrorResponse('Internal Server Error: DOWNSUB API token missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { url } = body\n  if (!url) {\n    return createErrorResponse('URL is required', 400)\n  }\n\n  console.log('\uD83D\uDD3D DOWNSUB URL Request:', { url })\n\n  try {\n    // Call the DOWNSUB API with the provided URL\n    const response = await fetch('https://api.downsub.com/download', {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${apiToken}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        url: url,\n      }),\n    })\n\n    console.log('\uD83D\uDCE1 DOWNSUB API Response Status:', response.status)\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      console.error('\u274C DOWNSUB API Error:', errorText)\n      return createErrorResponse(\n        `DOWNSUB API error: ${response.status} - ${errorText}`,\n        response.status,\n      )\n    }\n\n    const data = await response.json()\n    console.log('\u2705 DOWNSUB URL Results:', { url, hasData: !!data })\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        originalUrl: url,\n        transcript: data,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C DOWNSUB URL Error:', error)\n    return createErrorResponse('Failed to get DOWNSUB transcript: ' + error.message, 500)\n  }\n}\n\n// --- DOWNSUB Transcript Endpoint ---\nconst handleDownsubTranscript = async (request, env) => {\n  const url = new URL(request.url)\n  const videoId = url.pathname.split('/').pop()\n\n  if (!videoId) {\n    return createErrorResponse('Video ID is required', 400)\n  }\n\n  const apiToken = env.DOWNDUB_API_TOKEN\n  if (!apiToken) {\n    return createErrorResponse('Internal Server Error: DOWNSUB API token missing', 500)\n  }\n\n  // Construct full YouTube URL from video ID\n  const youtubeUrl = `https://www.youtube.com/watch?v=${videoId}`\n\n  console.log('\uD83D\uDD3D DOWNSUB Request:', { videoId, youtubeUrl })\n\n  try {\n    // Call the DOWNSUB API exactly as documented\n    const response = await fetch('https://api.downsub.com/download', {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${apiToken}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        url: youtubeUrl,\n      }),\n    })\n\n    console.log('\uD83D\uDCE1 DOWNSUB API Response Status:', response.status)\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      console.error('\u274C DOWNSUB API Error:', errorText)\n      return createErrorResponse(\n        `DOWNSUB API error: ${response.status} - ${errorText}`,\n        response.status,\n      )\n    }\n\n    const data = await response.json()\n    console.log('\u2705 DOWNSUB Results:', { videoId, hasData: !!data })\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        videoId: videoId,\n        youtubeUrl: youtubeUrl,\n        transcript: data,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C DOWNSUB Error:', error)\n    return createErrorResponse('Failed to get DOWNSUB transcript: ' + error.message, 500)\n  }\n}\n\n// Add new route handler for Mystmkra.io proxy\nasync function handleMystmkraProxy(request) {\n  const apiToken = request.headers.get('X-API-Token')\n  if (!apiToken) {\n    return new Response(JSON.stringify({ error: 'Missing API token' }), {\n      status: 401,\n      headers: {\n        'Access-Control-Allow-Origin': '*',\n        'Content-Type': 'application/json',\n      },\n    })\n  }\n\n  try {\n    const body = await request.json()\n    const response = await fetch('https://mystmkra.io/dropbox/api/markdown/save', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'X-API-Token': apiToken,\n      },\n      body: JSON.stringify(body),\n    })\n\n    let result\n    const contentType = response.headers.get('content-type') || ''\n    if (contentType.includes('application/json')) {\n      result = await response.json()\n    } else {\n      const text = await response.text()\n      console.log('Mystmkra.io raw response:', text)\n      result = { error: 'Mystmkra.io did not return JSON', status: response.status, raw: text }\n    }\n\n    return new Response(JSON.stringify(result), {\n      status: response.status,\n      headers: {\n        'Access-Control-Allow-Origin': '*',\n        'Content-Type': 'application/json',\n      },\n    })\n  } catch {\n    return new Response(JSON.stringify({ error: 'Failed to proxy request to Mystmkra.io' }), {\n      status: 500,\n      headers: {\n        'Access-Control-Allow-Origin': '*',\n        'Content-Type': 'application/json',\n      },\n    })\n  }\n}\n\n// --- GPT-4 Vision Image Generation Endpoint ---\nconst handleGPT4VisionImage = async (request, env) => {\n  if (!env.OPENAI_API_KEY) {\n    return createErrorResponse('OpenAI API key not configured', 500)\n  }\n\n  try {\n    const body = await request.json()\n    let { prompt, model = 'dall-e-2', size = '1024x1024' } = body\n\n    console.log('=== GPT4 Vision Image Generation Request ===')\n    console.log('Model from request body:', model)\n    console.log('Size from request body:', size)\n    console.log('Prompt length:', prompt?.length || 0)\n    console.log('Prompt preview:', prompt?.substring(0, 100) + '...')\n\n    if (!prompt) {\n      return createErrorResponse('Prompt is required', 400)\n    }\n\n    // Parse model, size, and quality from prompt if provided (overrides request body)\n    let quality = 'auto' // Default quality\n    if (prompt.includes('|')) {\n      const parts = prompt.split('|')\n      const modelPart = parts.find((p) => p.startsWith('model:'))\n      const sizePart = parts.find((p) => p.startsWith('size:'))\n      const qualityPart = parts.find((p) => p.startsWith('quality:'))\n\n      if (modelPart) {\n        const promptModel = modelPart.replace('model:', '').trim()\n        console.log('\uD83D\uDD0D Model found in prompt:', promptModel)\n        model = promptModel\n      }\n\n      if (sizePart) {\n        const promptSize = sizePart.replace('size:', '').trim()\n        console.log('\uD83D\uDD0D Size found in prompt:', promptSize)\n        size = promptSize\n      }\n\n      if (qualityPart) {\n        const promptQuality = qualityPart.replace('quality:', '').trim()\n        console.log('\uD83D\uDD0D Quality found in prompt:', promptQuality)\n        quality = promptQuality\n      }\n    }\n\n    // Set model-specific quality defaults and validate\n    if (quality === 'auto') {\n      if (model === 'gpt-image-1') {\n        quality = 'auto' // gpt-image-1 supports auto\n      } else if (model === 'dall-e-3') {\n        quality = 'standard' // dall-e-3 default\n      } else if (model === 'dall-e-2') {\n        quality = 'standard' // dall-e-2 only supports standard\n      }\n    }\n\n    // Validate quality for each model\n    const qualityValidation = {\n      'gpt-image-1': ['auto', 'high', 'medium', 'low'],\n      'dall-e-3': ['hd', 'standard'],\n      'dall-e-2': ['standard'],\n    }\n\n    if (!qualityValidation[model].includes(quality)) {\n      console.error('\u274C Invalid quality for model:', {\n        model,\n        quality,\n        valid: qualityValidation[model],\n      })\n      return createErrorResponse(\n        `Invalid quality '${quality}' for model '${model}'. Valid options: ${qualityValidation[model].join(', ')}`,\n        400,\n      )\n    }\n\n    console.log('\uD83D\uDCCB Final model to use:', model)\n    console.log('\uD83D\uDCCB Final size to use:', size)\n    console.log('\uD83D\uDCCB Final quality to use:', quality)\n\n    // Validate model\n    const validModels = ['dall-e-2', 'dall-e-3', 'gpt-image-1']\n    if (!validModels.includes(model)) {\n      console.error('\u274C Invalid model requested:', model)\n      return createErrorResponse('Invalid model. Must be one of: ' + validModels.join(', '), 400)\n    }\n\n    console.log('\u2705 Model validation passed for:', model)\n\n    // Validate size based on model\n    const validSizes = {\n      'dall-e-2': ['256x256', '512x512', '1024x1024'],\n      'dall-e-3': ['1024x1024', '1024x1792', '1792x1024'],\n      'gpt-image-1': ['1024x1024', '1024x1536', '1536x1024', 'auto'],\n    }\n\n    if (!validSizes[model].includes(size)) {\n      return createErrorResponse(\n        `Invalid size for model ${model}. Must be one of: ${validSizes[model].join(', ')}`,\n        400,\n      )\n    }\n\n    // Prepare request body based on model\n    const requestBody = {\n      model,\n      prompt,\n      size,\n      n: 1,\n    }\n\n    // Add quality parameter only for models that support it\n    if (model === 'dall-e-3' || model === 'gpt-image-1') {\n      requestBody.quality = quality\n      console.log('\uD83D\uDCCA Including quality parameter:', quality)\n    } else {\n      console.log('\uD83D\uDCCA Omitting quality parameter for', model, '(not supported)')\n    }\n\n    // Add response_format only for DALL-E models\n    if (model.startsWith('dall-e')) {\n      requestBody.response_format = 'url'\n      console.log('\uD83C\uDFA8 Using DALL-E model with URL response format')\n    } else {\n      console.log('\uD83E\uDD16 Using GPT-Image model with base64 response format')\n    }\n\n    console.log('\uD83D\uDCE4 Request body:', JSON.stringify(requestBody, null, 2))\n\n    // Generate image using OpenAI\n    console.log('\uD83D\uDE80 Calling OpenAI Image Generation API...')\n    const response = await fetch('https://api.openai.com/v1/images/generations', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: `Bearer ${env.OPENAI_API_KEY}`,\n      },\n      body: JSON.stringify(requestBody),\n    })\n\n    console.log('\uD83D\uDCE5 OpenAI API Response Status:', response.status, response.statusText)\n\n    if (!response.ok) {\n      const error = await response.json()\n      return createErrorResponse(\n        error.error?.message || 'Failed to generate image',\n        response.status,\n      )\n    }\n\n    const data = await response.json()\n    console.log('\uD83D\uDCCA API Response keys:', Object.keys(data))\n    console.log('\uD83D\uDCCA Data array length:', data.data?.length || 0)\n    if (data.data?.[0]) {\n      console.log('\uD83D\uDCCA First data item keys:', Object.keys(data.data[0]))\n    }\n\n    // Parse additional parameters from prompt if they exist\n    let imageType = 'header'\n    let finalPrompt = prompt\n\n    // Check if prompt contains structured format\n    if (prompt.includes('|')) {\n      const parts = prompt.split('|')\n      const promptPart = parts.find((p) => p.startsWith('prompt:'))\n      const typePart = parts.find((p) => p.startsWith('type:'))\n\n      if (promptPart) {\n        finalPrompt = promptPart.replace('prompt:', '')\n      }\n      if (typePart) {\n        imageType = typePart.replace('type:', '')\n      }\n    }\n\n    // Handle different response formats\n    if (model.startsWith('dall-e')) {\n      console.log('\uD83C\uDFA8 Processing DALL-E response (URL format)')\n      const imageUrl = data.data[0].url\n      console.log('\uD83D\uDD17 Image URL received:', imageUrl?.substring(0, 50) + '...')\n\n      // Return preview data WITHOUT saving to R2\n      return createResponse(\n        JSON.stringify({\n          id: `generated_image_${Date.now()}`,\n          label: `Generated ${imageType.charAt(0).toUpperCase() + imageType.slice(1)} Image`,\n          type: 'fulltext',\n          info: null, // Will be populated after approval\n          color: '#e8f4fd',\n          bibl: [`Generated using ${model} (${quality} quality) with prompt: \"${finalPrompt}\"`],\n          imageWidth: '100%',\n          imageHeight: '100%',\n          metadata: {\n            previewImageUrl: imageUrl, // Original OpenAI URL for preview\n            originalPrompt: finalPrompt,\n            imageType: imageType,\n            model: model,\n            size: size,\n            quality: quality,\n            needsApproval: true, // Flag indicating this image needs approval before saving\n          },\n        }),\n      )\n    } else {\n      console.log('\uD83E\uDD16 Processing GPT-Image response (base64 format)')\n      const base64Data = data.data[0].b64_json\n      console.log('\uD83D\uDCCF Base64 data length:', base64Data?.length || 0)\n\n      if (!base64Data) {\n        console.error('\u274C No base64 image data received from API')\n        return createErrorResponse('No image data received from API', 500)\n      }\n\n      // Convert base64 to data URL for preview\n      const previewDataUrl = `data:image/png;base64,${base64Data}`\n\n      // Return preview data WITHOUT saving to R2\n      return createResponse(\n        JSON.stringify({\n          id: `generated_image_${Date.now()}`,\n          label: `Generated ${imageType.charAt(0).toUpperCase() + imageType.slice(1)} Image`,\n          type: 'fulltext',\n          info: null, // Will be populated after approval\n          color: '#e8f4fd',\n          bibl: [`Generated using ${model} (${quality} quality) with prompt: \"${finalPrompt}\"`],\n          imageWidth: '100%',\n          imageHeight: '100%',\n          metadata: {\n            previewImageUrl: previewDataUrl, // Base64 data URL for preview\n            base64Data: base64Data, // Store base64 data for later upload\n            originalPrompt: finalPrompt,\n            imageType: imageType,\n            model: model,\n            size: size,\n            quality: quality,\n            needsApproval: true, // Flag indicating this image needs approval before saving\n          },\n        }),\n      )\n    }\n  } catch (error) {\n    console.error('Error in handleGPT4VisionImage:', error)\n    return createErrorResponse('Failed to generate image', 500)\n  }\n}\n\n// --- Save Approved AI Image Endpoint ---\nconst handleSaveApprovedImage = async (request, env) => {\n  if (!env.MY_R2_BUCKET) {\n    return createErrorResponse('R2 bucket not configured', 500)\n  }\n\n  try {\n    const body = await request.json()\n    const { imageData } = body\n\n    if (!imageData || !imageData.metadata) {\n      return createErrorResponse('Invalid image data provided', 400)\n    }\n\n    const { previewImageUrl, base64Data, originalPrompt, imageType, model, size, quality } =\n      imageData.metadata\n\n    console.log('=== Saving Approved AI Image ===')\n    console.log('Model:', model)\n    console.log('Image Type:', imageType)\n    console.log('Size:', size)\n\n    let imageBuffer\n    let contentType = 'image/png'\n\n    // Handle different image sources\n    if (base64Data) {\n      // For GPT-Image models with base64 data\n      console.log('\uD83D\uDD04 Processing base64 image data...')\n      const binaryData = atob(base64Data)\n      const bytes = new Uint8Array(binaryData.length)\n      for (let i = 0; i < binaryData.length; i++) {\n        bytes[i] = binaryData.charCodeAt(i)\n      }\n      imageBuffer = bytes\n      console.log('\u2705 Base64 conversion complete, size:', bytes.length, 'bytes')\n    } else if (previewImageUrl && previewImageUrl.startsWith('http')) {\n      // For DALL-E models with URL\n      console.log('\u2B07\uFE0F Downloading image from URL...')\n      const response = await fetch(previewImageUrl)\n      if (!response.ok) {\n        throw new Error('Failed to download image from preview URL')\n      }\n      const arrayBuffer = await response.arrayBuffer()\n      imageBuffer = new Uint8Array(arrayBuffer)\n      console.log('\u2705 Image download complete, size:', imageBuffer.length, 'bytes')\n    } else {\n      throw new Error('No valid image source found')\n    }\n\n    // Generate unique filename\n    const timestamp = Date.now()\n    const filename = `ai-generated/${timestamp}-${Math.random().toString(36).substring(2, 15)}.png`\n    console.log('\uD83D\uDCC1 Generated filename:', filename)\n\n    // Upload to R2\n    console.log('\u2B06\uFE0F Uploading to R2 bucket...')\n    await env.MY_R2_BUCKET.put(filename, imageBuffer, {\n      httpMetadata: {\n        contentType: contentType,\n      },\n    })\n    console.log('\u2705 R2 upload complete')\n\n    // Generate appropriate markdown based on image type\n    const finalImageUrl = `https://vegvisr.imgix.net/${filename}`\n    let imageMarkdown = ''\n\n    switch (imageType.toLowerCase()) {\n      case 'header':\n        imageMarkdown = `![Header|width: 100%; height: 200px; object-fit: 'cover'; object-position: 'center'](${finalImageUrl})`\n        break\n      case 'leftside':\n        imageMarkdown = `![Leftside-1|width: 200px; height: 200px; object-fit: 'cover'; object-position: 'center'](${finalImageUrl})`\n        break\n      case 'rightside':\n        imageMarkdown = `![Rightside-1|width: 200px; height: 200px; object-fit: 'cover'; object-position: 'center'](${finalImageUrl})`\n        break\n      default:\n        imageMarkdown = `![Generated Image|width: 300px; height: auto; object-fit: 'cover'](${finalImageUrl})`\n    }\n\n    console.log('\uD83C\uDF89 Approved image saved successfully!')\n    console.log('\uD83D\uDCC4 Final image URL:', finalImageUrl)\n\n    // Return the final node data\n    return createResponse(\n      JSON.stringify({\n        id: `approved_image_${Date.now()}`,\n        label: `Generated ${imageType.charAt(0).toUpperCase() + imageType.slice(1)} Image`,\n        type: 'fulltext',\n        info: imageMarkdown,\n        color: '#e8f4fd',\n        bibl: [`Generated using ${model} (${quality} quality) with prompt: \"${originalPrompt}\"`],\n        imageWidth: '100%',\n        imageHeight: '100%',\n        metadata: {\n          generatedImageUrl: finalImageUrl,\n          originalPrompt: originalPrompt,\n          imageType: imageType,\n          model: model,\n          size: size,\n          quality: quality,\n          approved: true,\n          savedAt: new Date().toISOString(),\n        },\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleSaveApprovedImage:', error)\n    return createErrorResponse('Failed to save approved image: ' + error.message, 500)\n  }\n}\n\n// --- Process Transcript to Knowledge Graph Endpoint ---\nconst handleProcessTranscript = async (request, env) => {\n  try {\n    console.log('=== handleProcessTranscript called ===')\n\n    const body = await request.json()\n    console.log('Request body keys:', Object.keys(body))\n\n    const { transcript, sourceLanguage, targetLanguage } = body\n\n    if (!transcript) {\n      console.error('Missing transcript text in request')\n      return createErrorResponse('Missing transcript text', 400)\n    }\n\n    console.log('=== Processing Transcript ===')\n    console.log('Transcript length:', transcript.length)\n    console.log('Source language:', sourceLanguage)\n    console.log('Target language:', targetLanguage)\n\n    // Check if Grok API key is available\n    const apiKey = env.XAI_API_KEY\n    if (!apiKey) {\n      console.error('Grok API key not found in environment')\n      return createErrorResponse('Grok API key not configured', 500)\n    }\n    console.log('Grok API key found:', apiKey.substring(0, 10) + '...')\n\n    // Check transcript length and handle accordingly\n    const transcriptWords = transcript.split(/\\s+/).length\n    console.log('Transcript word count:', transcriptWords)\n\n    let prompt\n    let maxTokens = 12000 // Grok has larger context window\n\n    if (targetLanguage === 'original') {\n      // --- PROMPT FOR ORIGINAL LANGUAGE ---\n      console.log('Processing in original language.')\n      maxTokens = 16000\n\n      prompt = `Transform this transcript into a comprehensive knowledge graph in its ORIGINAL language. DO NOT TRANSLATE. Create 8-15 detailed thematic sections as nodes.\n\nSOURCE LANGUAGE: ${sourceLanguage === 'auto' ? 'auto-detect' : sourceLanguage}\nTARGET LANGUAGE: Original (No Translation)\n\nRULES:\n1.  DO NOT TRANSLATE the content. Keep it in the original language.\n2.  Create nodes with structure: {\"id\": \"del_X\", \"label\": \"PART X: [Descriptive Title in Original Language]\", \"color\": \"#f9f9f9\", \"type\": \"fulltext\", \"info\": \"comprehensive content in original language\", \"bibl\": [], \"imageWidth\": \"100%\", \"imageHeight\": \"100%\", \"visible\": true, \"path\": null}\n3.  Split into logical thematic sections. Be thorough.\n4.  Use rich markdown formatting in the \"info\" field with headers, lists, and emphasis.\n5.  Each node should contain substantial content (200-800 words).\n6.  Include key quotes, important details, and context from the original text.\n7.  Create a comprehensive knowledge graph that captures the full essence of the original transcript.\n\nTRANSCRIPT (full content):\n${transcript}\n\nReturn ONLY valid JSON: {\"nodes\": [...], \"edges\": []}`\n    } else {\n      // --- PROMPT FOR NORWEGIAN TRANSLATION (Existing Logic) ---\n      if (transcriptWords > 3000) {\n        // For very long transcripts, use comprehensive processing\n        console.log(\n          'Large transcript detected, using comprehensive processing for Norwegian translation',\n        )\n        maxTokens = 16000 // Use Grok's full capacity for large transcripts\n\n        prompt = `Transform this transcript into a comprehensive Norwegian knowledge graph. Create 8-15 detailed thematic sections as nodes.\n\nSOURCE: ${sourceLanguage === 'auto' ? 'auto-detect' : sourceLanguage}\nTARGET: Norwegian\n\nRULES:\n1. Translate EVERYTHING to Norwegian with high quality\n2. Create nodes with structure: {\"id\": \"del_X\", \"label\": \"DEL X: [Descriptive Title]\", \"color\": \"#f9f9f9\", \"type\": \"fulltext\", \"info\": \"comprehensive content\", \"bibl\": [], \"imageWidth\": \"100%\", \"imageHeight\": \"100%\", \"visible\": true, \"path\": null}\n3. Split into logical thematic sections - be thorough, don't skip content\n4. Use rich markdown formatting in \"info\" field with headers, lists, emphasis\n5. Each node should contain substantial content (200-800 words)\n6. Include key quotes, important details, and context\n7. Create a comprehensive knowledge graph that captures the full essence\n\nTRANSCRIPT (full content):\n${transcript}\n\nReturn JSON: {\"nodes\": [...], \"edges\": []}`\n      } else {\n        // For shorter transcripts, use detailed processing\n        console.log(\n          'Standard transcript length, using detailed processing for Norwegian translation',\n        )\n\n        prompt = `Transform this transcript into a comprehensive Norwegian knowledge graph JSON.\n\nSOURCE: ${sourceLanguage === 'auto' ? 'auto-detect' : sourceLanguage}\nTARGET: Norwegian\n\nCreate nodes with this structure:\n{\"id\": \"del_X\", \"label\": \"DEL X: [Descriptive Title]\", \"color\": \"#f9f9f9\", \"type\": \"fulltext\", \"info\": \"comprehensive Norwegian content\", \"bibl\": [], \"imageWidth\": \"100%\", \"imageHeight\": \"100%\", \"visible\": true, \"path\": null}\n\nRules:\n- Translate ALL content to Norwegian with exceptional quality\n- Split into 6-12 comprehensive thematic sections\n- Use rich markdown formatting in \"info\" field\n- Preserve cultural context and nuanced meaning\n- Each node should be substantial (150-600 words)\n- Include important quotes, examples, and detailed explanations\n- Don't summarize - be comprehensive and detailed\n\nTRANSCRIPT:\n${transcript}\n\nReturn only JSON: {\"nodes\": [...], \"edges\": []}`\n      }\n    }\n\n    console.log('Calling Grok AI API...')\n\n    const client = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: maxTokens,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert Norwegian translator and knowledge graph creator specializing in comprehensive content generation. Transform content into detailed Norwegian knowledge graphs with substantial, well-structured content. Create thorough translations that preserve all important information, cultural context, and nuanced meaning. Always generate multiple detailed nodes with rich markdown formatting. Return only valid JSON in the specified format.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    console.log('Grok AI API response received successfully')\n    const knowledgeGraphData = completion.choices[0].message.content.trim()\n\n    console.log('Generated knowledge graph length:', knowledgeGraphData.length)\n\n    // Parse and validate the JSON\n    try {\n      const parsedGraph = JSON.parse(knowledgeGraphData)\n\n      // Validate structure\n      if (!parsedGraph.nodes || !Array.isArray(parsedGraph.nodes)) {\n        throw new Error('Invalid knowledge graph structure: missing nodes array')\n      }\n\n      // Add timestamps to node IDs if missing\n      parsedGraph.nodes = parsedGraph.nodes.map((node) => ({\n        ...node,\n        id: node.id || `fulltext_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n        visible: true,\n        path: null,\n      }))\n\n      console.log('Successfully generated', parsedGraph.nodes.length, 'nodes')\n\n      return createResponse(\n        JSON.stringify({\n          knowledgeGraph: parsedGraph,\n          stats: {\n            totalNodes: parsedGraph.nodes.length,\n            processingTime: Date.now(),\n            sourceLanguage: sourceLanguage,\n            targetLanguage: targetLanguage,\n            modelUsed: 'grok-3-beta',\n            transcriptWords: transcriptWords,\n          },\n        }),\n      )\n    } catch (parseError) {\n      console.error('Error parsing generated JSON:', parseError)\n      console.log('Raw response:', knowledgeGraphData)\n\n      // Return raw response for debugging\n      return createResponse(\n        JSON.stringify({\n          knowledgeGraph: { nodes: [], edges: [] },\n          error: 'Failed to parse generated JSON',\n          rawResponse: knowledgeGraphData,\n        }),\n        500,\n      )\n    }\n  } catch (error) {\n    console.error('Error in handleProcessTranscript:', error)\n    return createErrorResponse(error.message || 'Internal server error', 500)\n  }\n}\n\n// --- AI Generate Node Endpoint ---\nconst handleAIGenerateNode = async (request, env) => {\n  try {\n    const { userRequest, graphId, username, contextType, contextData } = await request.json()\n\n    console.log('=== AI Generate Node Debug ===')\n    console.log('userRequest:', userRequest)\n    console.log('graphId:', graphId)\n    console.log('username:', username)\n    console.log('contextType:', contextType)\n    console.log('contextData:', JSON.stringify(contextData, null, 2))\n    console.log('contextData type:', typeof contextData)\n    console.log(\n      'contextData length/size:',\n      contextData ? Object.keys(contextData).length : 'null/undefined',\n    )\n    console.log('===============================')\n\n    if (!userRequest) {\n      return createErrorResponse('Missing userRequest parameter', 400)\n    }\n\n    // Get templates from knowledge worker\n    let templates\n    try {\n      console.log('Attempting to fetch templates using KNOWLEDGE binding...')\n      if (!env.KNOWLEDGE) {\n        console.error('KNOWLEDGE binding is not available')\n        throw new Error('KNOWLEDGE binding is not available')\n      }\n\n      const templatesResponse = await env.KNOWLEDGE.fetch(\n        'https://knowledge.vegvisr.org/getAITemplates',\n      )\n      console.log('Templates response status:', templatesResponse.status)\n\n      if (!templatesResponse.ok) {\n        const errorText = await templatesResponse.text()\n        console.error('Templates response error:', errorText)\n        throw new Error(`Failed to fetch templates: ${templatesResponse.status} - ${errorText}`)\n      }\n\n      const templatesData = await templatesResponse.json()\n      if (!templatesData.results || !Array.isArray(templatesData.results)) {\n        throw new Error('Invalid templates data format - missing results array')\n      }\n      templates = templatesData.results\n      console.log('Successfully fetched templates:', templates)\n    } catch (error) {\n      console.error('Detailed error fetching templates:', error)\n      return createErrorResponse(`Failed to fetch templates: ${error.message}`, 500)\n    }\n\n    // Get graph context if available\n    let graphContext = ''\n    if (graphId) {\n      try {\n        const graphResponse = await env.KNOWLEDGE.fetch(\n          `https://knowledge.vegvisr.org/getknowgraph?id=${graphId}`,\n        )\n        if (graphResponse.ok) {\n          const graphData = await graphResponse.json()\n          if (graphData?.nodes) {\n            graphContext = graphData.nodes\n              .filter((node) => node.visible !== false)\n              .map((node) => `Node: ${node.label}\\nType: ${node.type}\\nInfo: ${node.info || ''}`)\n              .join('\\n\\n')\n          }\n        }\n      } catch (error) {\n        console.error('Error fetching graph context:', error)\n      }\n    }\n\n    // Process context based on type\n    let finalContext = ''\n    if (contextType === 'current' && contextData) {\n      finalContext = `Current Node Context:\\n${JSON.stringify(contextData, null, 2)}`\n    } else if (contextType === 'all' && contextData) {\n      finalContext = `All Nodes Context:\\n${graphContext}`\n    }\n\n    // Create the prompt with all context\n    const prompt = `Given the following user request and available templates, generate an appropriate node.\n\nUser Request: ${userRequest}\n${username ? `Username: @${username}` : ''}\n\nAvailable Templates:\n${templates\n  .map(\n    (t) => `Template: ${t.label}\nType: ${t.type}\nExample Node: ${JSON.stringify(t.nodes, null, 2)}\nAI Instructions: ${t.ai_instructions || 'No specific instructions provided.'}`,\n  )\n  .join('\\n')}\n\n${finalContext ? `\\nContext for generation:\\n${finalContext}` : ''}\n\nBased on the user's request, select the most appropriate template and generate content following its structure and instructions.\nThe generated content must strictly follow the AI Instructions of the selected template.\nReturn a JSON object with the following structure:\n{\n\"template\": \"selected_template_id\",\n\"content\": \"generated_content\"\n}`\n\n    // Generate content\n    const client = new OpenAI({\n      apiKey: env.XAI_API_KEY,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 1000,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert at understanding user intent and generating appropriate content for knowledge graphs. You must strictly follow the AI Instructions provided in the template when generating content.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const result = JSON.parse(completion.choices[0].message.content.trim())\n    const selectedTemplate = templates.find((t) => t.id === result.template) || templates[0]\n\n    // Create the node using the selected template's structure\n    const node = {\n      id: crypto.randomUUID(),\n      label: selectedTemplate.nodes.label,\n      color: selectedTemplate.nodes.color,\n      type: selectedTemplate.nodes.type,\n      info: result.content,\n      bibl: selectedTemplate.nodes.bibl || [],\n      imageWidth: selectedTemplate.nodes.imageWidth,\n      imageHeight: selectedTemplate.nodes.imageHeight,\n      visible: true,\n      path: selectedTemplate.nodes.path || '',\n    }\n\n    // If the info field is an object, merge its properties with the node\n    if (typeof node.info === 'object' && node.info !== null) {\n      const infoObj = node.info\n      node.info = infoObj.info || ''\n      node.label = infoObj.label || node.label\n      node.color = infoObj.color || node.color\n      node.type = infoObj.type || node.type\n      node.bibl = infoObj.bibl || node.bibl\n      node.imageWidth = infoObj.imageWidth || node.imageWidth\n      node.imageHeight = infoObj.imageHeight || node.imageHeight\n      node.path = infoObj.path || node.path\n    }\n\n    return createResponse(JSON.stringify({ node }))\n  } catch (error) {\n    console.error('Error in handleAIGenerateNode:', error)\n    return createErrorResponse(error.message || 'Internal server error', 500)\n  }\n}\n\n// --- AI Generate Menu Endpoint ---\nconst handleAIGenerateMenu = async (request, env) => {\n  try {\n    const { graphData, userRequest, currentMenuData } = await request.json()\n\n    console.log('=== AI Generate Menu Debug ===')\n    console.log('userRequest:', userRequest)\n    console.log('graphData nodes:', graphData?.nodes?.length || 0)\n    console.log('graphData metadata:', graphData?.metadata || {})\n    console.log('currentMenuData:', currentMenuData)\n    console.log('===============================')\n\n    if (!graphData || !graphData.nodes || !Array.isArray(graphData.nodes)) {\n      return createErrorResponse('Missing or invalid graphData parameter', 400)\n    }\n\n    // 1. Fetch available node types from graphTemplates table\n    console.log('Fetching available node types from database...')\n    const availableNodeTypes = []\n    try {\n      const templatesQuery = `SELECT id, name, nodes FROM graphTemplates`\n      const templatesResult = await env.vegvisr_org.prepare(templatesQuery).all()\n\n      console.log(`Found ${templatesResult.results?.length || 0} templates in database`)\n\n      for (const template of templatesResult.results || []) {\n        try {\n          const templateNodes = JSON.parse(template.nodes || '[]')\n          console.log(`Template ${template.name} has ${templateNodes.length} nodes`)\n\n          if (templateNodes.length > 0) {\n            const nodeType = templateNodes[0].type\n            console.log(`Template ${template.name} -> nodeType: ${nodeType}`)\n\n            if (nodeType) {\n              availableNodeTypes.push({\n                nodeType: nodeType,\n                name: template.name,\n                id: template.id,\n              })\n            }\n          }\n        } catch (e) {\n          console.warn(`Error parsing template ${template.id}:`, e.message)\n        }\n      }\n    } catch (error) {\n      console.error('Error fetching node types:', error)\n    }\n\n    console.log('Available node types for template-selector:')\n    availableNodeTypes.forEach((t) => {\n      console.log(`  - ${t.nodeType} (${t.name})`)\n    })\n\n    // 2. Query similar graphs by category and metaArea\n    const graphMetadata = graphData.metadata || {}\n    const graphNodes = graphData.nodes || []\n\n    const categories = graphMetadata.category\n      ? graphMetadata.category\n          .split('#')\n          .map((c) => c.trim())\n          .filter((c) => c)\n      : []\n    const metaAreas = graphMetadata.metaArea\n      ? graphMetadata.metaArea\n          .split('#')\n          .map((m) => m.trim())\n          .filter((m) => m)\n      : []\n\n    console.log('Current graph categories:', categories)\n    console.log('Current graph metaAreas:', metaAreas)\n\n    // Find similar graphs\n    const similarGraphs = []\n    if (categories.length > 0 || metaAreas.length > 0) {\n      try {\n        const graphsQuery = `SELECT id, title, data FROM knowledge_graphs LIMIT 100`\n        const graphsResult = await env.vegvisr_org.prepare(graphsQuery).all()\n\n        for (const graph of graphsResult.results || []) {\n          try {\n            const graphData = JSON.parse(graph.data || '{}')\n            const graphMetadata = graphData.metadata || {}\n\n            const graphCategories = graphMetadata.category\n              ? graphMetadata.category\n                  .split('#')\n                  .map((c) => c.trim())\n                  .filter((c) => c)\n              : []\n            const graphMetaAreas = graphMetadata.metaArea\n              ? graphMetadata.metaArea\n                  .split('#')\n                  .map((m) => m.trim())\n                  .filter((m) => m)\n              : []\n\n            // Check for overlap in categories or metaAreas\n            const categoryOverlap = categories.some((cat) =>\n              graphCategories.some((gc) => gc.toLowerCase().includes(cat.toLowerCase())),\n            )\n            const metaAreaOverlap = metaAreas.some((meta) =>\n              graphMetaAreas.some((gm) => gm.toLowerCase().includes(meta.toLowerCase())),\n            )\n\n            if (categoryOverlap || metaAreaOverlap) {\n              similarGraphs.push({\n                id: graph.id,\n                title: graph.title,\n                categories: graphCategories,\n                metaAreas: graphMetaAreas,\n              })\n            }\n          } catch (e) {\n            console.warn(`Error parsing graph ${graph.id}:`, e.message)\n          }\n        }\n      } catch (error) {\n        console.error('Error fetching similar graphs:', error)\n      }\n    }\n\n    console.log('Found similar graphs:', similarGraphs.length)\n    console.log('Similar graphs:', similarGraphs.map((g) => `${g.title} (${g.id})`).join(', '))\n\n    // 3. Extract content themes from current graph\n    const contentThemes = graphNodes\n      .filter((node) => node.visible !== false && node.info)\n      .map((node) => ({\n        label: node.label || 'Untitled',\n        type: node.type || 'default',\n        content: node.info.substring(0, 200) + '...',\n        hasContent: !!node.info,\n      }))\n      .slice(0, 10) // Limit to avoid token limits\n\n    // 4. Define available routes\n    const availableRoutes = [\n      { path: '/', label: 'Home', icon: '\uD83C\uDFE0' },\n      { path: '/graph-editor', label: 'Editor', icon: '\u270F\uFE0F' },\n      { path: '/graph-canvas', label: 'Canvas', icon: '\uD83C\uDFA8' },\n      { path: '/graph-portfolio', label: 'Portfolio', icon: '\uD83D\uDCC1' },\n      { path: '/graph-viewer', label: 'Viewer', icon: '\uD83D\uDC41\uFE0F' },\n      { path: '/search', label: 'Search', icon: '\uD83D\uDD0D' },\n      { path: '/user', label: 'Dashboard', icon: '\uD83D\uDCCA' },\n      { path: '/github-issues', label: 'Roadmap', icon: '\uD83D\uDDFA\uFE0F' },\n      { path: '/gnew-viewer', label: 'GNew Viewer', icon: '\uD83E\uDDEA', requiresRole: ['Superadmin'] },\n      { path: '/sandbox', label: 'Sandbox', icon: '\uD83D\uDD27', requiresRole: ['Superadmin'] },\n    ]\n\n    // Build context-aware prompt with grounded system data\n    const contextPrompt = `Based on the following knowledge graph content, generate a smart, context-aware menu structure that helps users navigate and discover related content.\n\nGRAPH ANALYSIS:\n- Title: ${graphMetadata.title || 'Untitled Graph'}\n- Description: ${graphMetadata.description || 'No description'}\n- Categories: ${categories.join(', ') || 'None'}\n- Meta Areas: ${metaAreas.join(', ') || 'None'}\n- Total Nodes: ${graphNodes.length}\n- Content Themes: ${contentThemes.map((t) => `${t.label} (${t.type})`).join(', ')}\n\nCONTENT SAMPLE:\n${contentThemes.map((theme) => `- ${theme.label}: ${theme.content}`).join('\\n')}\n\nSIMILAR GRAPHS IN THE SYSTEM (${similarGraphs.length} found):\n${similarGraphs\n  .slice(0, 5)\n  .map(\n    (graph, i) =>\n      `${i + 1}. \"${graph.title}\" (ID: ${graph.id}) - Categories: ${graph.categories.join(', ')} - Meta Areas: ${graph.metaAreas.join(', ')}`,\n  )\n  .join('\\n')}\n\nAVAILABLE ROUTES (only use these exact paths):\n${availableRoutes.map((route) => `- ${route.path} (${route.label}) ${route.icon}${route.requiresRole ? ' - Requires: ' + route.requiresRole.join(', ') : ''}`).join('\\n')}\n\nAVAILABLE NODE TYPES FOR TEMPLATE-SELECTOR (only use these exact nodeTypes):\n${availableNodeTypes.map((type) => `- ${type.nodeType} (${type.name})`).join('\\n')}\n\nHOW TEMPLATE-SELECTOR WORKS:\nWhen a user clicks a template-selector menu item, the system:\n1. Fetches templates from the graphTemplates database table\n2. Finds a template where template.nodes[0].type === nodeType\n3. Creates a new node from that template and adds it to the graph\n4. Therefore, the nodeType MUST exactly match a real node type from the list above\n\n${userRequest ? `\\nUSER REQUEST: ${userRequest}` : ''}\n\nCURRENT MENU (if any):\n${currentMenuData ? JSON.stringify(currentMenuData, null, 2) : 'No current menu'}\n\nCRITICAL REQUIREMENTS:\n1. Menu items can ONLY use these types: \"route\", \"graph-link\", \"template-selector\", \"external\"\n2. For \"route\" type: ONLY use paths from the AVAILABLE ROUTES list above\n3. For \"graph-link\" type: ONLY use graph IDs from the SIMILAR GRAPHS list above\n4. For \"template-selector\" type: ONLY use nodeTypes from the AVAILABLE NODE TYPES list above\n5. For \"external\" type: Use valid external URLs\n6. DO NOT invent functionality that doesn't exist\n7. Focus on content themes and actual available similar graphs\n8. Ensure all menu items are grounded in reality\n\nEXACT JSON STRUCTURE FOR MENU ITEMS:\n- route: {\"type\": \"route\", \"path\": \"/exact-path\", \"requiresRole\": null}\n- graph-link: {\"type\": \"graph-link\", \"graphId\": \"exact-graph-id\", \"requiresRole\": null}\n- template-selector: {\"type\": \"template-selector\", \"nodeType\": \"exact-node-type\", \"requiresRole\": [\"Admin\",\"Superadmin\"]}\n- external: {\"type\": \"external\", \"url\": \"https://example.com\", \"requiresRole\": null}\n\nReturn a JSON object with this structure:\n{\n  \"menuSuggestion\": {\n    \"name\": \"Generated Menu Name\",\n    \"description\": \"Brief description of the menu purpose\",\n    \"menuLevel\": \"graph\",\n    \"items\": [\n      {\n        \"id\": \"unique-id\",\n        \"label\": \"Menu Item Label\",\n        \"icon\": \"\uD83C\uDFE0\",\n        \"type\": \"route|graph-link|template-selector|external\",\n        \"path\": \"/exact-path-from-available-routes\",\n        \"graphId\": \"exact-graph-id-from-similar-graphs\",\n        \"nodeType\": \"exact-node-type-from-available-types\",\n        \"url\": \"https://external-url.com\",\n        \"requiresRole\": null,\n        \"description\": \"Why this menu item is relevant\"\n      }\n    ],\n    \"style\": {\n      \"layout\": \"horizontal\",\n      \"theme\": \"default\",\n      \"position\": \"top\",\n      \"buttonStyle\": \"hamburger\"\n    }\n  },\n  \"pageRecommendations\": [\n    {\n      \"title\": \"Suggested Page Title\",\n      \"description\": \"Why this page would be valuable based on similar graphs and content\",\n      \"estimatedContent\": \"Brief description of what this page should contain\",\n      \"targetAudience\": \"Who would benefit from this page\",\n      \"priority\": \"high|medium|low\"\n    }\n  ],\n  \"audienceInsights\": {\n    \"primaryAudience\": \"Identified primary audience based on categories and meta areas\",\n    \"contentComplexity\": \"beginner|intermediate|advanced\",\n    \"suggestedNavigationFlow\": \"How users should navigate through the content\"\n  }\n}`\n\n    console.log('Generated prompt length:', contextPrompt.length)\n\n    // Generate menu using AI\n    const client = new OpenAI({\n      apiKey: env.XAI_API_KEY,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 2000,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert UX designer and information architect specializing in knowledge graphs and user navigation. You excel at creating intuitive menu structures that guide users through complex content and suggest valuable related resources. CRITICAL: You MUST ONLY use the exact paths, graph IDs, and node types provided in the context. DO NOT invent functionality that does not exist. Ground all suggestions in the actual available system capabilities.',\n        },\n        { role: 'user', content: contextPrompt },\n      ],\n    })\n\n    console.log('AI response received, parsing...')\n\n    const result = JSON.parse(completion.choices[0].message.content.trim())\n\n    // Validate the response structure\n    if (!result.menuSuggestion || !result.menuSuggestion.items) {\n      throw new Error('Invalid AI response: missing menuSuggestion or items')\n    }\n\n    // Validate and process each menu item to ensure it uses real functionality\n    const processedItems = result.menuSuggestion.items\n      .map((item, index) => {\n        const processed = {\n          id: item.id || `menu-item-${index + 1}`,\n          label: item.label || `Menu Item ${index + 1}`,\n          icon: item.icon || '\uD83D\uDCC4',\n          type: item.type || 'route',\n          requiresRole: item.requiresRole || null,\n          description: item.description || 'Generated menu item',\n        }\n\n        // Validate based on menu item type\n        switch (item.type) {\n          case 'route':\n            // Validate path is in available routes\n            const validRoute = availableRoutes.find((route) => route.path === item.path)\n            if (validRoute) {\n              processed.path = item.path\n              processed.requiresRole = validRoute.requiresRole || null\n            } else {\n              console.warn(`Invalid route path: ${item.path}, defaulting to /`)\n              processed.path = '/'\n            }\n            break\n\n          case 'graph-link':\n            // Validate graph ID is in similar graphs\n            const validGraph = similarGraphs.find((graph) => graph.id === item.graphId)\n            if (validGraph) {\n              processed.graphId = item.graphId\n            } else {\n              console.warn(`Invalid graph ID: ${item.graphId}, removing item`)\n              return null // Remove invalid items\n            }\n            break\n\n          case 'template-selector':\n            // Validate node type is in available node types\n            const validNodeType = availableNodeTypes.find((type) => type.nodeType === item.nodeType)\n            if (validNodeType) {\n              processed.nodeType = item.nodeType\n              // Ensure requiresRole is properly formatted as array or null\n              if (item.requiresRole && Array.isArray(item.requiresRole)) {\n                processed.requiresRole = item.requiresRole\n              } else if (item.requiresRole && typeof item.requiresRole === 'string') {\n                processed.requiresRole = [item.requiresRole]\n              } else {\n                processed.requiresRole = ['Admin', 'Superadmin'] // Default for template-selector\n              }\n            } else {\n              console.warn(`Invalid node type: ${item.nodeType}, removing item`)\n              return null // Remove invalid items\n            }\n            break\n\n          case 'external':\n            // Validate URL format\n            if (item.url && (item.url.startsWith('http://') || item.url.startsWith('https://'))) {\n              processed.url = item.url\n            } else {\n              console.warn(`Invalid external URL: ${item.url}, removing item`)\n              return null // Remove invalid items\n            }\n            break\n\n          default:\n            console.warn(`Unknown menu item type: ${item.type}, defaulting to route`)\n            processed.type = 'route'\n            processed.path = '/'\n            break\n        }\n\n        return processed\n      })\n      .filter((item) => item !== null) // Remove null items (invalid ones)\n\n    const processedMenu = {\n      ...result.menuSuggestion,\n      items: processedItems,\n    }\n\n    console.log('\u2705 Successfully generated menu:', processedMenu)\n    console.log('\u2705 Validation results:', {\n      originalItems: result.menuSuggestion.items.length,\n      validatedItems: processedItems.length,\n      removedItems: result.menuSuggestion.items.length - processedItems.length,\n    })\n\n    return createResponse(\n      JSON.stringify({\n        menuSuggestion: processedMenu,\n        pageRecommendations: result.pageRecommendations || [],\n        audienceInsights: result.audienceInsights || {},\n        metadata: {\n          sourceNodes: graphNodes.length,\n          analysedCategories: categories,\n          analysedMetaAreas: metaAreas,\n          generatedAt: new Date().toISOString(),\n          model: 'grok-3-beta',\n        },\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleAIGenerateMenu:', error)\n    return createErrorResponse(error.message || 'Internal server error', 500)\n  }\n}\n\n// --- AI Generate Quotes Endpoint ---\nconst handleAIGenerateQuotes = async (request, env) => {\n  try {\n    const { graphContext, userRequest, graphId, username } = await request.json()\n\n    console.log('=== AI Generate Quotes Debug ===')\n    console.log('userRequest:', userRequest)\n    console.log('graphId:', graphId)\n    console.log('username:', username)\n    console.log('graphContext nodes:', graphContext ? graphContext.length : 'null/undefined')\n    console.log('================================')\n\n    if (!graphContext || !Array.isArray(graphContext) || graphContext.length === 0) {\n      return createErrorResponse('Missing or empty graphContext parameter', 400)\n    }\n\n    // Extract meaningful content from graph nodes\n    const contextContent = graphContext\n      .map((node) => {\n        const nodeContent = `Title: ${node.label || 'Untitled'}\\nContent: ${node.info || 'No content'}`\n        return nodeContent\n      })\n      .join('\\n\\n---\\n\\n')\n\n    console.log('Extracted context content length:', contextContent.length)\n\n    // Create the prompt for quote generation\n    const prompt = `Based on the following knowledge graph content, generate 4-5 inspirational and meaningful quotes that capture the essence and wisdom from the material.\n\nKnowledge Graph Content:\n${contextContent}\n\n${userRequest ? `Additional context: ${userRequest}` : ''}\n${username ? `Username: @${username}` : ''}\n\nRequirements:\n- Generate 4-5 unique quotes\n- Each quote should be meaningful and inspirational\n- Quotes should reflect the themes and wisdom from the provided content\n- Include potential attribution/citation when relevant\n- Make quotes suitable for social media sharing\n\nReturn a JSON object with the following structure:\n{\n  \"quotes\": [\n    {\n      \"text\": \"The actual quote text here\",\n      \"citation\": \"Optional author or source attribution\",\n      \"source\": \"Brief description of which part of the content inspired this quote\"\n    }\n  ]\n}`\n\n    console.log('Generated prompt length:', prompt.length)\n\n    // Generate quotes using AI\n    const client = new OpenAI({\n      apiKey: env.XAI_API_KEY,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.8, // Higher temperature for more creative quotes\n      max_tokens: 1500,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert at creating inspirational quotes and extracting wisdom from complex content. You excel at distilling key insights into memorable, shareable quotes that resonate with people.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    console.log('AI response received, parsing...')\n\n    const result = JSON.parse(completion.choices[0].message.content.trim())\n\n    // Validate the response structure\n    if (!result.quotes || !Array.isArray(result.quotes)) {\n      throw new Error('Invalid AI response: missing quotes array')\n    }\n\n    // Ensure each quote has required fields\n    const processedQuotes = result.quotes.map((quote, index) => ({\n      text: quote.text || quote.quote || `Quote ${index + 1}`,\n      citation: quote.citation || quote.author || '',\n      source: quote.source || `Content analysis ${index + 1}`,\n    }))\n\n    console.log('\u2705 Successfully generated quotes:', processedQuotes.length)\n\n    return createResponse(\n      JSON.stringify({\n        quotes: processedQuotes,\n        metadata: {\n          sourceNodes: graphContext.length,\n          generatedAt: new Date().toISOString(),\n          model: 'grok-3-beta',\n        },\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleAIGenerateQuotes:', error)\n    return createErrorResponse(error.message || 'Internal server error', 500)\n  }\n}\n\n// --- Style Templates Handler ---\nconst handleGetStyleTemplates = async (request) => {\n  const url = new URL(request.url)\n  const nodeType = url.searchParams.get('nodeType')\n\n  // Built-in style templates - in a real app, these would come from a database\n  const allTemplates = [\n    {\n      id: 'fulltext_complete_enhancer',\n      name: 'Complete FullText Enhancer',\n      description:\n        'Adds FANCY headers, SECTION blocks, QUOTE citations, WNOTE annotations, and contextual images',\n      nodeTypes: ['fulltext', 'title'],\n      transformationRules: {\n        addFancyHeaders: true,\n        addSections: true,\n        addQuotes: true,\n        addWorkNotes: true,\n        addHeaderImage: true,\n        addSideImages: {\n          leftside: true,\n          rightside: true,\n          contextual: true,\n        },\n      },\n      category: 'comprehensive',\n      isActive: true,\n    },\n    {\n      id: 'visual_content_formatter',\n      name: 'Visual Content Formatter',\n      description:\n        'Focus on image positioning with leftside/rightside placement and WNOTE integration',\n      nodeTypes: ['fulltext', 'worknote'],\n      transformationRules: {\n        addHeaderImage: true,\n        addSideImages: {\n          leftside: true,\n          rightside: true,\n          contextual: true,\n        },\n        addWorkNotes: true,\n        addSections: true,\n      },\n      category: 'visual',\n      isActive: true,\n    },\n    {\n      id: 'work_note_enhancer',\n      name: 'Work Note Enhancer',\n      description:\n        'Specialized WNOTE formatting with contextual rightside images for technical content',\n      nodeTypes: ['fulltext', 'worknote'],\n      transformationRules: {\n        addWorkNotes: true,\n        addSideImages: {\n          rightside: true,\n          contextual: true,\n        },\n        addSections: true,\n      },\n      category: 'technical',\n      isActive: true,\n    },\n    {\n      id: 'header_sections_basic',\n      name: 'Header + Sections Basic',\n      description: 'Basic structure with FANCY headers and SECTION blocks',\n      nodeTypes: ['fulltext', 'title', 'worknote'],\n      transformationRules: {\n        addFancyHeaders: true,\n        addSections: true,\n        addHeaderImage: true,\n      },\n      category: 'structure',\n      isActive: true,\n    },\n    {\n      id: 'text_only_basic',\n      name: 'Text Only Basic',\n      description:\n        'Simple formatting with FANCY headers, SECTION blocks, and QUOTE citations - no images',\n      nodeTypes: ['fulltext', 'title', 'worknote', 'markdown-image'],\n      transformationRules: {\n        addFancyHeaders: true,\n        addSections: true,\n        addQuotes: true,\n      },\n      category: 'basic',\n      isActive: true,\n    },\n  ]\n\n  // Filter by node type if specified\n  const templates = nodeType\n    ? allTemplates.filter((t) => t.nodeTypes.includes(nodeType) && t.isActive)\n    : allTemplates.filter((t) => t.isActive)\n\n  return createResponse(JSON.stringify({ templates }))\n}\n\n// --- Apply Style Template Handler ---\nconst handleApplyStyleTemplate = async (request, env) => {\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    return createErrorResponse('Internal Server Error: XAI API key missing', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const {\n    nodeContent,\n    templateId,\n    nodeType,\n    options = {},\n    colorTheme = null,\n    languageOptions = null,\n  } = body\n\n  if (!nodeContent || !templateId || !nodeType) {\n    return createErrorResponse(\n      'Missing required parameters: nodeContent, templateId, nodeType',\n      400,\n    )\n  }\n\n  console.log('=== Apply Style Template ===')\n  console.log('Template ID:', templateId)\n  console.log('Node Type:', nodeType)\n  console.log('Content length:', nodeContent.length)\n  console.log('Options:', JSON.stringify(options))\n  console.log('Color Theme:', colorTheme ? colorTheme.name : 'Default')\n  console.log('Language Options:', JSON.stringify(languageOptions))\n\n  // Get the template configuration\n  const templates = [\n    {\n      id: 'fulltext_complete_enhancer',\n      aiInstructions: `Transform this content into a rich, well-formatted fulltext node with comprehensive styling:\n\nFORMATTING REQUIREMENTS:\n1. Add a FANCY header at the top with styling: [FANCY | font-size: 3em; color: #2c3e50; background: linear-gradient(45deg, #f0f8ff, #e6f3ff); text-align: center; padding: 20px; border-radius: 10px]Your Title Here[END FANCY]\n\n2. Structure content into SECTION blocks with different colors:\n   [SECTION | background-color: 'lightyellow'; color: 'black'; padding: 15px; border-radius: 8px]\n   Main content here\n   [END SECTION]\n\n3. Add relevant QUOTE blocks with citations:\n   [QUOTE | Cited='Author Name']\n   Relevant quote text\n   [END QUOTE]\n\n4. Include WNOTE annotations for important points:\n   [WNOTE | Cited='Context/Source']\n   Important note or annotation\n   [END WNOTE]\n\n5. Add contextual images (these will be replaced with real images):\n   - Header image: ![Header|height: 200px; object-fit: 'cover'; object-position: 'center'](HEADER_IMAGE_PLACEHOLDER)\n   - Leftside images: ![Leftside-2|width: 200px; height: 200px; object-fit: 'cover'](LEFTSIDE_IMAGE_PLACEHOLDER)\n   - Rightside images: ![Rightside-1|width: 200px; height: 200px; object-fit: 'cover'](RIGHTSIDE_IMAGE_PLACEHOLDER)\n\nMake the content comprehensive, well-structured, and visually appealing. Preserve the original meaning while enhancing presentation.`,\n    },\n    {\n      id: 'visual_content_formatter',\n      aiInstructions: `Transform this content focusing on visual layout with images and work notes:\n\nVISUAL FORMATTING REQUIREMENTS:\n1. Add a contextual header image: ![Header|height: 200px; object-fit: 'cover'; object-position: 'center'](HEADER_IMAGE_PLACEHOLDER)\n2. Structure content with strategic leftside and rightside image placement:\n   ![Leftside-1|width: 200px; height: 200px; object-fit: 'cover'](LEFTSIDE_IMAGE_PLACEHOLDER)\n   ![Rightside-1|width: 200px; height: 200px; object-fit: 'cover'](RIGHTSIDE_IMAGE_PLACEHOLDER)\n3. Include WNOTE blocks for important annotations\n4. Use SECTION blocks to organize content\n5. Balance text and visual elements for optimal readability\n\nFocus on creating a visually engaging layout that enhances comprehension.`,\n    },\n    {\n      id: 'work_note_enhancer',\n      aiInstructions: `Transform this content with focus on technical work notes and rightside documentation:\n\nWORK NOTE FORMATTING:\n1. Add WNOTE blocks for technical annotations and development notes\n2. Include rightside images for diagrams, screenshots, or reference materials:\n   ![Rightside-1|width: 200px; height: 200px; object-fit: 'cover'](RIGHTSIDE_IMAGE_PLACEHOLDER)\n3. Structure content in clear sections\n4. Maintain technical accuracy while improving presentation\n\nPerfect for technical documentation and development notes.`,\n    },\n    {\n      id: 'header_sections_basic',\n      aiInstructions: `Transform this content with basic structural improvements:\n\nBASIC FORMATTING:\n1. Add a FANCY header with attractive styling\n2. Organize content into logical SECTION blocks\n3. Include a relevant header image: ![Header|height: 200px; object-fit: 'cover'; object-position: 'center'](HEADER_IMAGE_PLACEHOLDER)\n4. Maintain clean, professional presentation\n\nFocus on clear structure and readability.`,\n    },\n    {\n      id: 'text_only_basic',\n      aiInstructions: `Transform this content with clean, simple text formatting - NO IMAGES:\n\nTEXT-ONLY FORMATTING REQUIREMENTS:\n1. Add a FANCY header with attractive styling:\n   [FANCY | font-size: 2.5em; color: #2c3e50; background: linear-gradient(45deg, #f8f9fa, #e9ecef); text-align: center; padding: 15px; border-radius: 8px; margin-bottom: 20px]Your Title Here[END FANCY]\n\n2. Structure content into clear SECTION blocks:\n   [SECTION | background-color: '#f8f9fa'; color: '#333'; padding: 15px; border-radius: 6px; margin: 10px 0; border-left: 4px solid #007bff]\n   Main content section here\n   [END SECTION]\n\n3. Add relevant QUOTE blocks with proper citations:\n   [QUOTE | Cited='Author Name or Source']\n   Meaningful quote text that supports the content\n   [END QUOTE]\n\n4. Use different section colors for variety:\n   - Light blue: background-color: '#e3f2fd'\n   - Light green: background-color: '#e8f5e8'\n   - Light yellow: background-color: '#fff8e1'\n   - Light purple: background-color: '#f3e5f5'\n\nIMPORTANT:\n- Do NOT add any images, WNOTE blocks, or visual elements\n- Do NOT add explanatory text, comments, or formatting notes\n- Do NOT include introductory or concluding commentary\n- Focus purely on clean text formatting with headers, sections, and quotes\n- Return ONLY the formatted content, nothing else`,\n    },\n  ]\n\n  const template = templates.find((t) => t.id === templateId)\n  if (!template) {\n    return createErrorResponse('Template not found', 404)\n  }\n\n  try {\n    const client = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    // Build color theme instructions\n    let colorInstructions = ''\n    if (colorTheme) {\n      colorInstructions = `\nCOLOR THEME: \"${colorTheme.name}\"\nUse these specific colors for formatting:\n- Primary Color: ${colorTheme.primary}\n- Secondary Color: ${colorTheme.secondary}\n- Accent Color: ${colorTheme.accent}\n- Background Color: ${colorTheme.background}\n- Section Colors: ${colorTheme.sections.join(', ')}\n\nApply these colors to:\n- FANCY headers: Use primary color and appropriate background\n- SECTION blocks: Use the section colors (${colorTheme.sections.join(', ')}) rotating between them\n- Overall theme: Create a harmonious color scheme using these colors\n`\n    }\n\n    // Build language preservation instructions\n    let languageInstructions = ''\n    if (languageOptions?.mode === 'auto-detect' && languageOptions.detectedLanguage) {\n      if (languageOptions.detectedLanguage !== 'Unknown') {\n        languageInstructions = `\nCRITICAL LANGUAGE REQUIREMENT: The original content is in ${languageOptions.detectedLanguage}.\nYou MUST preserve this language exactly. Do not translate or change the language in any way.\nApply the formatting while keeping all text in ${languageOptions.detectedLanguage}.\nAll headings, sections, and content must remain in ${languageOptions.detectedLanguage}.\n`\n      } else {\n        languageInstructions = `\nCRITICAL LANGUAGE REQUIREMENT: Preserve the exact original language of the content.\nDo not translate, change language, or assume any specific language.\nKeep the original language throughout the formatted content.\n`\n      }\n    } else if (languageOptions?.mode === 'keep-current') {\n      languageInstructions = `\nCRITICAL LANGUAGE REQUIREMENT: Keep the exact same language as the original content.\nDo not translate, change language, or assume any specific language.\nPreserve the original language throughout the formatted content.\n`\n    }\n\n    const prompt = `${template.aiInstructions}\n\n${colorInstructions}\n\n${languageInstructions}\n\nORIGINAL CONTENT TO TRANSFORM:\n${nodeContent}\n\nADDITIONAL OPTIONS: ${JSON.stringify(options)}\n\nCRITICAL OUTPUT REQUIREMENTS:\n- Return ONLY the formatted content with the requested formatting applied\n- Do NOT add any explanatory text, comments, or meta-commentary\n- Do NOT include phrases like \"Below is the transformed content...\" or \"Notes on formatting:\"\n- Do NOT explain your formatting choices or decisions\n- Do NOT add any text that was not in the original content\n- Simply return the clean, formatted version of the original content\n\nUse the placeholder URLs exactly as specified (HEADER_IMAGE_PLACEHOLDER, LEFTSIDE_IMAGE_PLACEHOLDER, RIGHTSIDE_IMAGE_PLACEHOLDER) - these will be replaced with real contextual images. Apply the color theme consistently throughout all formatting elements. Preserve the core meaning while enhancing the presentation with the specified markdown formatting patterns.`\n\n    console.log('=== Language Processing Info ===')\n    if (languageInstructions) {\n      console.log('Language preservation active:', languageOptions.mode)\n      console.log('Detected/Target language:', languageOptions.detectedLanguage || 'N/A')\n    } else {\n      console.log('No language preservation applied')\n    }\n\n    console.log('Sending prompt to Grok:', prompt)\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 3000,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert content formatter specializing in rich markdown formatting for knowledge graphs. Apply the requested formatting patterns precisely while preserving content meaning and enhancing readability. CRITICAL: Return ONLY the formatted content without any explanatory text, comments, introductions, or meta-commentary. Do not explain your formatting choices.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    let formattedContent = completion.choices[0].message.content.trim()\n\n    // Now replace placeholder images with real Pexels images\n    if (env.PEXELS_API_KEY) {\n      console.log('=== Replacing Placeholder Images with Pexels Images ===')\n      formattedContent = await replacePlaceholderImages(formattedContent, nodeContent, env)\n    } else {\n      console.log('Pexels API key not available, using placeholder URLs')\n      // Replace placeholders with vegvisr.imgix.net URLs\n      formattedContent = formattedContent\n        .replace(/HEADER_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/contextual-header.png')\n        .replace(/LEFTSIDE_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/leftside-image.png')\n        .replace(/RIGHTSIDE_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/rightside-image.png')\n    }\n\n    console.log('=== Template Applied Successfully ===')\n    console.log('Formatted content length:', formattedContent.length)\n\n    return createResponse(\n      JSON.stringify({\n        formattedContent,\n        templateUsed: templateId,\n        success: true,\n      }),\n    )\n  } catch (error) {\n    console.error('Error applying style template:', error)\n    return createErrorResponse('Failed to apply style template: ' + error.message, 500)\n  }\n}\n\n// --- Pexels Image Search and Replacement ---\nconst searchPexelsImages = async (query, env, count = 1) => {\n  if (!env.PEXELS_API_KEY) {\n    throw new Error('Pexels API key not configured')\n  }\n\n  try {\n    console.log(`Searching Pexels for: \"${query}\" (${count} images)`)\n\n    const response = await fetch(\n      `https://api.pexels.com/v1/search?query=${encodeURIComponent(query)}&per_page=${count}&orientation=landscape`,\n      {\n        headers: {\n          Authorization: env.PEXELS_API_KEY,\n        },\n      },\n    )\n\n    if (!response.ok) {\n      throw new Error(`Pexels API error: ${response.status}`)\n    }\n\n    const data = await response.json()\n\n    if (data.photos && data.photos.length > 0) {\n      return data.photos.map((photo) => ({\n        url: photo.src.medium, // Use medium size for performance\n        alt: photo.alt || query,\n        photographer: photo.photographer,\n        id: photo.id,\n      }))\n    } else {\n      console.log('No Pexels images found for query:', query)\n      return []\n    }\n  } catch (error) {\n    console.error('Error searching Pexels:', error)\n    return []\n  }\n}\n\nconst generateImageSearchQueries = async (content, env) => {\n  const apiKey = env.XAI_API_KEY\n  if (!apiKey) {\n    return ['nature', 'abstract', 'business'] // Fallback queries\n  }\n\n  try {\n    const client = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.x.ai/v1',\n    })\n\n    const prompt = `Analyze this content and generate 3-5 relevant image search keywords that would make good contextual images. Focus on the main themes, concepts, and visual elements that would enhance understanding.\n\nContent: ${content.substring(0, 500)}...\n\nReturn only the keywords, separated by commas. Examples: \"nature, forest, trees\" or \"technology, computers, digital\" or \"business, meeting, office\"`\n\n    const completion = await client.chat.completions.create({\n      model: 'grok-3-beta',\n      temperature: 0.7,\n      max_tokens: 100,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert at analyzing content and suggesting relevant image search terms. Return only comma-separated keywords, no explanations.',\n        },\n        { role: 'user', content: prompt },\n      ],\n    })\n\n    const keywords = completion.choices[0].message.content.trim()\n    const queries = keywords\n      .split(',')\n      .map((q) => q.trim())\n      .filter((q) => q.length > 0)\n\n    console.log('Generated image search queries:', queries)\n    return queries.length > 0 ? queries : ['abstract', 'concept', 'modern']\n  } catch (error) {\n    console.error('Error generating image queries:', error)\n    return ['nature', 'abstract', 'business'] // Fallback queries\n  }\n}\n\nconst replacePlaceholderImages = async (content, originalContent, env) => {\n  try {\n    // Generate contextual search queries based on content\n    const searchQueries = await generateImageSearchQueries(originalContent, env)\n\n    let updatedContent = content\n\n    // Replace header images\n    if (content.includes('HEADER_IMAGE_PLACEHOLDER')) {\n      console.log('Replacing header image placeholder...')\n      const headerImages = await searchPexelsImages(searchQueries[0] || 'abstract header', env, 1)\n      if (headerImages.length > 0) {\n        updatedContent = updatedContent.replace(/HEADER_IMAGE_PLACEHOLDER/g, headerImages[0].url)\n        console.log('Header image replaced with:', headerImages[0].url)\n      } else {\n        updatedContent = updatedContent.replace(\n          /HEADER_IMAGE_PLACEHOLDER/g,\n          'https://vegvisr.imgix.net/contextual-header.png',\n        )\n      }\n    }\n\n    // Replace leftside images\n    if (content.includes('LEFTSIDE_IMAGE_PLACEHOLDER')) {\n      console.log('Replacing leftside image placeholder...')\n      const leftsideImages = await searchPexelsImages(\n        searchQueries[1] || searchQueries[0] || 'concept',\n        env,\n        1,\n      )\n      if (leftsideImages.length > 0) {\n        updatedContent = updatedContent.replace(\n          /LEFTSIDE_IMAGE_PLACEHOLDER/g,\n          leftsideImages[0].url,\n        )\n        console.log('Leftside image replaced with:', leftsideImages[0].url)\n      } else {\n        updatedContent = updatedContent.replace(\n          /LEFTSIDE_IMAGE_PLACEHOLDER/g,\n          'https://vegvisr.imgix.net/leftside-image.png',\n        )\n      }\n    }\n\n    // Replace rightside images\n    if (content.includes('RIGHTSIDE_IMAGE_PLACEHOLDER')) {\n      console.log('Replacing rightside image placeholder...')\n      const rightsideImages = await searchPexelsImages(\n        searchQueries[2] || searchQueries[0] || 'modern',\n        env,\n        1,\n      )\n      if (rightsideImages.length > 0) {\n        updatedContent = updatedContent.replace(\n          /RIGHTSIDE_IMAGE_PLACEHOLDER/g,\n          rightsideImages[0].url,\n        )\n        console.log('Rightside image replaced with:', rightsideImages[0].url)\n      } else {\n        updatedContent = updatedContent.replace(\n          /RIGHTSIDE_IMAGE_PLACEHOLDER/g,\n          'https://vegvisr.imgix.net/rightside-image.png',\n        )\n      }\n    }\n\n    return updatedContent\n  } catch (error) {\n    console.error('Error replacing placeholder images:', error)\n    // Fallback to vegvisr.imgix.net URLs\n    return content\n      .replace(/HEADER_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/contextual-header.png')\n      .replace(/LEFTSIDE_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/leftside-image.png')\n      .replace(/RIGHTSIDE_IMAGE_PLACEHOLDER/g, 'https://vegvisr.imgix.net/rightside-image.png')\n  }\n}\n\n// --- Pexels Image Search Endpoint ---\nconst handlePexelsImageSearch = async (request, env) => {\n  if (!env.PEXELS_API_KEY) {\n    return createErrorResponse('Pexels API key not configured', 500)\n  }\n\n  let body\n  try {\n    body = await request.json()\n  } catch {\n    return createErrorResponse('Invalid JSON body', 400)\n  }\n\n  const { query, count = 10 } = body\n\n  if (!query || typeof query !== 'string') {\n    return createErrorResponse('Query parameter is required and must be a string', 400)\n  }\n\n  try {\n    const images = await searchPexelsImages(query, env, Math.min(count, 20))\n\n    return createResponse(\n      JSON.stringify({\n        query,\n        total: images.length,\n        images,\n        success: true,\n      }),\n    )\n  } catch (error) {\n    console.error('Error in Pexels search endpoint:', error)\n    return createErrorResponse('Failed to search Pexels images: ' + error.message, 500)\n  }\n}\n\n// --- Google Photos OAuth Handlers ---\nconst handleGoogleOAuthCallback = async () => {\n  console.log('\uD83D\uDD10 handleGoogleOAuthCallback called')\n\n  const callbackHtml = `<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Google Photos Authorization</title>\n    <style>\n      body {\n        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n        color: white;\n        display: flex;\n        align-items: center;\n        justify-content: center;\n        min-height: 100vh;\n        margin: 0;\n        padding: 20px;\n        box-sizing: border-box;\n      }\n      .container {\n        text-align: center;\n        background: rgba(255, 255, 255, 0.1);\n        padding: 30px;\n        border-radius: 16px;\n        backdrop-filter: blur(10px);\n        border: 1px solid rgba(255, 255, 255, 0.2);\n        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n        max-width: 400px;\n        width: 100%;\n      }\n      .icon {\n        font-size: 48px;\n        margin-bottom: 20px;\n        animation: spin 2s linear infinite;\n      }\n      .status {\n        font-size: 18px;\n        margin-bottom: 15px;\n        font-weight: 500;\n      }\n      .message {\n        font-size: 14px;\n        opacity: 0.8;\n        line-height: 1.4;\n      }\n      .error {\n        color: #ff6b6b;\n      }\n      .success {\n        color: #51cf66;\n      }\n      @keyframes spin {\n        0% {\n          transform: rotate(0deg);\n        }\n        100% {\n          transform: rotate(360deg);\n        }\n      }\n      @keyframes fadeIn {\n        0% {\n          opacity: 0;\n          transform: translateY(20px);\n        }\n        100% {\n          opacity: 1;\n          transform: translateY(0);\n        }\n      }\n      .container {\n        animation: fadeIn 0.5s ease-out;\n      }\n    </style>\n  </head>\n  <body>\n    <div class=\"container\">\n      <div class=\"icon\" id=\"statusIcon\">\uD83D\uDD04</div>\n      <div class=\"status\" id=\"statusText\">Processing authorization...</div>\n      <div class=\"message\" id=\"statusMessage\">\n        Please wait while we complete the authentication.\n      </div>\n    </div>\n\n    <script>\n      console.log('\uD83D\uDD10 Google Photos OAuth Callback Page Loaded')\n\n      function updateStatus(icon, text, message, className = '') {\n        document.getElementById('statusIcon').textContent = icon\n        document.getElementById('statusText').textContent = text\n        document.getElementById('statusMessage').textContent = message\n\n        if (className) {\n          document.getElementById('statusText').className = \\`status \\${className}\\`\n          document.getElementById('statusMessage').className = \\`message \\${className}\\`\n        }\n      }\n\n      function handleAuthCallback() {\n        try {\n          // Parse URL parameters\n          const urlParams = new URLSearchParams(window.location.search)\n          const code = urlParams.get('code')\n          const error = urlParams.get('error')\n          const errorDescription = urlParams.get('error_description')\n\n          console.log('\uD83D\uDCCB URL Parameters:', { code: !!code, error, errorDescription })\n\n          if (error) {\n            console.error('\u274C OAuth Error:', error, errorDescription)\n\n            updateStatus(\n              '\u274C',\n              'Authorization Failed',\n              errorDescription || error || 'An error occurred during authorization.',\n              'error',\n            )\n\n            // For redirect-based OAuth, redirect back to the Vue frontend with error\n            const isLocal = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1'\n            const frontendUrl = isLocal\n              ? \\`http://\\${window.location.hostname}:5173/?google_auth_error=\\${encodeURIComponent(errorDescription || error || 'Authorization failed')}\\`\n              : \\`https://www.vegvisr.org/?google_auth_error=\\${encodeURIComponent(errorDescription || error || 'Authorization failed')}\\`\n\n            // Redirect back to the frontend\n            window.location.href = frontendUrl\n            return\n          }\n\n          if (code) {\n            console.log('\u2705 Authorization code received')\n\n            updateStatus(\n              '\u2705',\n              'Authorization Successful!',\n              'Connecting to your Google Photos... This window will close automatically.',\n              'success',\n            )\n\n                        // For redirect-based OAuth, redirect back to the Vue frontend with the code\n            const isLocal = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1'\n            const frontendUrl = isLocal\n              ? \\`http://\\${window.location.hostname}:5173/?google_auth_code=\\${code}&google_auth_success=true\\`\n              : \\`https://www.vegvisr.org/?google_auth_code=\\${code}&google_auth_success=true\\`\n\n            // Redirect back to the frontend\n            window.location.href = frontendUrl\n          } else {\n            console.error('\u274C No authorization code found in URL')\n\n            updateStatus(\n              '\u274C',\n              'No Authorization Code',\n              'The authorization process was incomplete. Please try again.',\n              'error',\n            )\n\n            if (window.opener) {\n              window.opener.postMessage(\n                {\n                  type: 'GOOGLE_AUTH_ERROR',\n                  error: 'No authorization code received',\n                },\n                window.location.origin,\n              )\n            }\n\n            setTimeout(() => {\n              window.close()\n            }, 3000)\n          }\n        } catch (err) {\n          console.error('\u274C Callback processing error:', err)\n\n          updateStatus(\n            '\u274C',\n            'Processing Error',\n            'An error occurred while processing the authorization. Please try again.',\n            'error',\n          )\n\n          if (window.opener) {\n            window.opener.postMessage(\n              {\n                type: 'GOOGLE_AUTH_ERROR',\n                error: 'Callback processing error: ' + err.message,\n              },\n              window.location.origin,\n            )\n          }\n\n          setTimeout(() => {\n            window.close()\n          }, 3000)\n        }\n      }\n\n      // Handle the auth callback when page loads\n      document.addEventListener('DOMContentLoaded', handleAuthCallback)\n\n      // Also handle immediately in case DOMContentLoaded already fired\n      if (document.readyState === 'loading') {\n        // Still loading, wait for DOMContentLoaded\n      } else {\n        // Already loaded\n        handleAuthCallback()\n      }\n\n      console.log('\uD83D\uDE80 Callback page initialized')\n    </script>\n  </body>\n</html>`\n\n  console.log('\u2705 Returning OAuth callback HTML, length:', callbackHtml.length)\n\n  return new Response(callbackHtml, {\n    status: 200,\n    headers: {\n      'Content-Type': 'text/html',\n      ...corsHeaders,\n    },\n  })\n}\n\nconst handleGooglePhotosAuth = async (request, env) => {\n  try {\n    const { code } = await request.json()\n\n    if (!code) {\n      return createErrorResponse('Authorization code is required', 400)\n    }\n\n    console.log('\uD83D\uDD10 Exchanging code for Google Photos access token...')\n\n    // Exchange code for access token\n    const tokenResponse = await fetch('https://oauth2.googleapis.com/token', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        client_id: env.GOOGLE_PHOTOS_CLIENT_ID,\n        client_secret: env.GOOGLE_PHOTOS_CLIENT_SECRET,\n        code: code,\n        grant_type: 'authorization_code',\n        redirect_uri:\n          request.url.includes('localhost') || request.url.includes('127.0.0.1')\n            ? request.url.includes('localhost')\n              ? 'http://localhost:8789/auth/google/callback.html'\n              : 'http://127.0.0.1:8789/auth/google/callback.html'\n            : 'https://api.vegvisr.org/auth/google/callback.html',\n      }),\n    })\n\n    const tokenData = await tokenResponse.json()\n\n    if (!tokenResponse.ok) {\n      console.error('\u274C Token exchange failed:', tokenData)\n      return createErrorResponse(\n        tokenData.error_description || 'Failed to exchange authorization code',\n        400,\n      )\n    }\n\n    if (tokenData.access_token) {\n      console.log('\u2705 Google Photos authentication successful')\n\n      return createResponse(\n        JSON.stringify({\n          success: true,\n          access_token: tokenData.access_token,\n          expires_in: tokenData.expires_in,\n        }),\n      )\n    } else {\n      return createErrorResponse('No access token received', 400)\n    }\n  } catch (error) {\n    console.error('\u274C Google Photos auth error:', error)\n    return createErrorResponse(error.message, 500)\n  }\n}\n\nconst handleGooglePhotosSearch = async (request) => {\n  try {\n    const { access_token, searchParams } = await request.json()\n\n    if (!access_token) {\n      return createErrorResponse('Access token is required', 401)\n    }\n\n    console.log('\uD83D\uDD0D Searching Google Photos...')\n\n    const response = await fetch('https://photoslibrary.googleapis.com/v1/mediaItems:search', {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        pageSize: 20,\n        filters: {\n          mediaTypeFilter: {\n            mediaTypes: ['PHOTO'],\n          },\n          // Add content filter if search term is provided\n          ...(searchParams?.contentCategories && {\n            contentFilter: {\n              includedContentCategories: searchParams.contentCategories,\n            },\n          }),\n        },\n      }),\n    })\n\n    const data = await response.json()\n\n    if (!response.ok) {\n      console.error('\u274C Google Photos search failed:', data)\n      return createErrorResponse(data.error?.message || 'Failed to search Google Photos', 400)\n    }\n\n    console.log(`\u2705 Found ${data.mediaItems?.length || 0} photos`)\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        mediaItems: data.mediaItems || [],\n        nextPageToken: data.nextPageToken,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C Google Photos search error:', error)\n    return createErrorResponse(error.message, 500)\n  }\n}\n\nconst handleGooglePhotosRecent = async (request) => {\n  try {\n    const { access_token } = await request.json()\n\n    if (!access_token) {\n      return createErrorResponse('Access token is required', 401)\n    }\n\n    console.log('\uD83D\uDCF7 Getting recent Google Photos...')\n\n    const response = await fetch('https://photoslibrary.googleapis.com/v1/mediaItems', {\n      method: 'GET',\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n        'Content-Type': 'application/json',\n      },\n    })\n\n    const data = await response.json()\n\n    if (!response.ok) {\n      console.error('\u274C Failed to get recent photos:', data)\n      return createErrorResponse(data.error?.message || 'Failed to get recent photos', 400)\n    }\n\n    console.log(`\u2705 Retrieved ${data.mediaItems?.length || 0} recent photos`)\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        mediaItems: data.mediaItems || [],\n        nextPageToken: data.nextPageToken,\n      }),\n    )\n  } catch (error) {\n    console.error('\u274C Recent photos error:', error)\n    return createErrorResponse(error.message, 500)\n  }\n}\n\n// === Custom Domain Registration Endpoint ===\nasync function handleCreateCustomDomain(request, env) {\n  console.log('\uD83D\uDD27 === Custom Domain Registration Request Started ===')\n  console.log('Request method:', request.method)\n  console.log('Request URL:', request.url)\n\n  if (request.method === 'OPTIONS') {\n    console.log('\u2705 Handling CORS preflight request')\n    return new Response(null, {\n      status: 204,\n      headers: {\n        'Access-Control-Allow-Origin': '*',\n        'Access-Control-Allow-Methods': 'POST, OPTIONS',\n        'Access-Control-Allow-Headers': 'Content-Type',\n        'Access-Control-Max-Age': '86400',\n      },\n    })\n  }\n\n  if (request.method === 'POST') {\n    try {\n      console.log('\uD83D\uDCE5 Processing POST request for custom domain creation')\n\n      const requestBody = await request.json()\n      console.log('\uD83D\uDCCB Request body received:', JSON.stringify(requestBody, null, 2))\n\n      const { subdomain, rootDomain, zoneId } = requestBody\n\n      // Determine the domain to work with\n      let targetDomain\n      let targetZoneId\n\n      console.log('\uD83D\uDD0D Input validation:')\n      console.log('  - subdomain:', subdomain)\n      console.log('  - rootDomain:', rootDomain)\n      console.log('  - zoneId:', zoneId)\n\n      if (!subdomain) {\n        console.log('\u274C Subdomain validation failed - subdomain is required')\n        return new Response(\n          JSON.stringify({\n            error: 'Subdomain is required (e.g., \"torarne\" for torarne.xyzvibe.com)',\n          }),\n          {\n            status: 400,\n            headers: {\n              'Content-Type': 'application/json',\n              'Access-Control-Allow-Origin': '*',\n            },\n          },\n        )\n      }\n\n      // Determine root domain - default to norsegong.com for backward compatibility\n      const targetRootDomain = rootDomain || 'norsegong.com'\n      console.log('\uD83C\uDFAF Target root domain determined:', targetRootDomain)\n\n      // SECURITY: Check if subdomain is protected\n      if (isProtectedSubdomain(subdomain, targetRootDomain)) {\n        console.log(\n          `\uD83D\uDEA8 SECURITY BLOCK: Attempted to create protected subdomain: ${subdomain}.${targetRootDomain}`,\n        )\n        return new Response(\n          JSON.stringify({\n            error: `Subdomain '${subdomain}' is protected and cannot be created. Protected subdomains: ${PROTECTED_SUBDOMAINS[targetRootDomain]?.join(', ') || 'none'}`,\n            protectedSubdomain: true,\n            availableProtectedList: PROTECTED_SUBDOMAINS[targetRootDomain] || [],\n          }),\n          {\n            status: 403,\n            headers: {\n              'Content-Type': 'application/json',\n              'Access-Control-Allow-Origin': '*',\n            },\n          },\n        )\n      }\n\n      // Build the full domain\n      targetDomain = `${subdomain}.${targetRootDomain}`\n      console.log('\uD83C\uDF10 Full target domain:', targetDomain)\n\n      // Get Zone ID for the root domain\n      targetZoneId = zoneId || DOMAIN_ZONE_MAPPING[targetRootDomain]\n      console.log('\uD83D\uDD11 Zone ID lookup:')\n      console.log('  - Available zone mappings:', JSON.stringify(DOMAIN_ZONE_MAPPING, null, 2))\n      console.log('  - Resolved zone ID:', targetZoneId)\n\n      if (!targetZoneId) {\n        console.log('\u274C Zone ID validation failed - no zone ID found for domain')\n        return new Response(\n          JSON.stringify({\n            error: `No Zone ID found for domain: ${targetDomain}. Supported domains: ${Object.keys(DOMAIN_ZONE_MAPPING).join(', ')}`,\n          }),\n          {\n            status: 400,\n            headers: {\n              'Content-Type': 'application/json',\n              'Access-Control-Allow-Origin': '*',\n            },\n          },\n        )\n      }\n\n      console.log(`\u2705 Setting up custom domain: ${targetDomain} with Zone ID: ${targetZoneId}`)\n\n      // Check if CF_API_TOKEN is available\n      if (!env.CF_API_TOKEN) {\n        console.log('\u274C CF_API_TOKEN environment variable is missing')\n        return new Response(\n          JSON.stringify({\n            error: 'CF_API_TOKEN environment variable is not configured',\n            overallSuccess: false,\n          }),\n          {\n            status: 500,\n            headers: {\n              'Content-Type': 'application/json',\n              'Access-Control-Allow-Origin': '*',\n            },\n          },\n        )\n      }\n      console.log('\u2705 CF_API_TOKEN is available')\n\n      // Create DNS record\n      console.log('\uD83D\uDD27 Creating DNS record...')\n      const dnsPayload = {\n        type: 'CNAME',\n        name: targetDomain,\n        content: 'brand-worker.torarnehave.workers.dev',\n        proxied: true,\n      }\n      console.log('\uD83D\uDCE4 DNS payload:', JSON.stringify(dnsPayload, null, 2))\n\n      const dnsResponse = await fetch(\n        `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/dns_records`,\n        {\n          method: 'POST',\n          headers: {\n            Authorization: `Bearer ${env.CF_API_TOKEN}`,\n            'Content-Type': 'application/json',\n          },\n          body: JSON.stringify(dnsPayload),\n        },\n      )\n\n      console.log('\uD83D\uDCE5 DNS response status:', dnsResponse.status, dnsResponse.statusText)\n      const dnsResult = await dnsResponse.json()\n      console.log('\uD83D\uDCCB DNS response body:', JSON.stringify(dnsResult, null, 2))\n\n      const dnsSetup = {\n        success: dnsResult.success,\n        errors: dnsResult.errors,\n        result: dnsResult.result,\n      }\n\n      // Create worker route\n      console.log('\uD83D\uDD27 Creating worker route...')\n      const workerPayload = {\n        pattern: `${targetDomain}/*`,\n        script: 'brand-worker',\n      }\n      console.log('\uD83D\uDCE4 Worker route payload:', JSON.stringify(workerPayload, null, 2))\n\n      const workerResponse = await fetch(\n        `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/workers/routes`,\n        {\n          method: 'POST',\n          headers: {\n            Authorization: `Bearer ${env.CF_API_TOKEN}`,\n            'Content-Type': 'application/json',\n          },\n          body: JSON.stringify(workerPayload),\n        },\n      )\n\n      console.log(\n        '\uD83D\uDCE5 Worker route response status:',\n        workerResponse.status,\n        workerResponse.statusText,\n      )\n      const workerResult = await workerResponse.json()\n      console.log('\uD83D\uDCCB Worker route response body:', JSON.stringify(workerResult, null, 2))\n\n      const workerSetup = {\n        success: workerResult.success,\n        errors: workerResult.errors,\n        result: workerResult.result,\n      }\n\n      const overallSuccess = dnsSetup.success && workerSetup.success\n      console.log('\uD83C\uDFAF Overall success:', overallSuccess)\n      console.log('  - DNS setup success:', dnsSetup.success)\n      console.log('  - Worker setup success:', workerSetup.success)\n\n      const responseData = {\n        overallSuccess,\n        domain: targetDomain,\n        zoneId: targetZoneId,\n        dnsSetup,\n        workerSetup,\n        debug: {\n          requestBody,\n          targetRootDomain,\n          availableDomains: Object.keys(DOMAIN_ZONE_MAPPING),\n        },\n      }\n\n      console.log('\uD83D\uDCE4 Final response:', JSON.stringify(responseData, null, 2))\n\n      return new Response(JSON.stringify(responseData), {\n        status: 200,\n        headers: {\n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*',\n        },\n      })\n    } catch (error) {\n      console.log('\u274C Error in handleCreateCustomDomain:', error)\n      console.log('\u274C Error stack:', error.stack)\n\n      return new Response(\n        JSON.stringify({\n          error: error.message,\n          stack: error.stack,\n          overallSuccess: false,\n        }),\n        {\n          status: 500,\n          headers: {\n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*',\n          },\n        },\n      )\n    }\n  }\n\n  // Method not allowed\n  console.log('\u274C Method not allowed:', request.method)\n  return new Response('Method Not Allowed', { status: 405 })\n}\n\n// === Custom Domain Deletion Endpoint ===\nasync function handleDeleteCustomDomain(request, env) {\n  console.log('\uD83D\uDDD1\uFE0F handleDeleteCustomDomain called')\n\n  if (request.method !== 'POST') {\n    return new Response('Method Not Allowed', { status: 405 })\n  }\n\n  try {\n    const requestBody = await request.json()\n    console.log('\uD83D\uDCE5 Delete request body:', JSON.stringify(requestBody, null, 2))\n\n    const { subdomain, rootDomain } = requestBody\n\n    if (!subdomain || !rootDomain) {\n      return new Response(\n        JSON.stringify({\n          error: 'Missing required fields: subdomain and rootDomain',\n          overallSuccess: false,\n        }),\n        {\n          status: 400,\n          headers: {\n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*',\n          },\n        },\n      )\n    }\n\n    const targetDomain = `${subdomain}.${rootDomain}`\n    console.log('\uD83C\uDFAF Target domain to delete:', targetDomain)\n\n    // SECURITY: Check if subdomain is protected (prevent deletion of critical infrastructure)\n    if (isProtectedSubdomain(subdomain, rootDomain)) {\n      console.log(\n        `\uD83D\uDEA8 SECURITY BLOCK: Attempted to delete protected subdomain: ${subdomain}.${rootDomain}`,\n      )\n      return new Response(\n        JSON.stringify({\n          error: `Subdomain '${subdomain}' is protected and cannot be deleted. Protected subdomains: ${PROTECTED_SUBDOMAINS[rootDomain]?.join(', ') || 'none'}`,\n          protectedSubdomain: true,\n          overallSuccess: false,\n        }),\n        {\n          status: 403,\n          headers: {\n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*',\n          },\n        },\n      )\n    }\n\n    // Get the zone ID for the root domain\n    const targetZoneId = getZoneIdForDomain(rootDomain)\n    if (!targetZoneId) {\n      return new Response(\n        JSON.stringify({\n          error: `Unsupported root domain: ${rootDomain}. Supported domains: ${Object.keys(DOMAIN_ZONE_MAPPING).join(', ')}`,\n          overallSuccess: false,\n        }),\n        {\n          status: 400,\n          headers: {\n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*',\n          },\n        },\n      )\n    }\n\n    console.log('\uD83C\uDFF7\uFE0F Using zone ID:', targetZoneId)\n\n    // Step 1: Find and delete DNS record\n    console.log('\uD83D\uDD0D Finding DNS record for:', targetDomain)\n\n    const dnsListResponse = await fetch(\n      `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/dns_records?name=${targetDomain}`,\n      {\n        method: 'GET',\n        headers: {\n          Authorization: `Bearer ${env.CF_API_TOKEN}`,\n          'Content-Type': 'application/json',\n        },\n      },\n    )\n\n    const dnsListResult = await dnsListResponse.json()\n    console.log('\uD83D\uDCCB DNS list response:', JSON.stringify(dnsListResult, null, 2))\n\n    let dnsSetup = { success: true, errors: [], deleted: false }\n\n    if (dnsListResult.result && dnsListResult.result.length > 0) {\n      const dnsRecord = dnsListResult.result[0] // Get the first matching record\n      console.log('\uD83C\uDFAF Found DNS record to delete:', dnsRecord.id)\n\n      const dnsDeleteResponse = await fetch(\n        `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/dns_records/${dnsRecord.id}`,\n        {\n          method: 'DELETE',\n          headers: {\n            Authorization: `Bearer ${env.CF_API_TOKEN}`,\n            'Content-Type': 'application/json',\n          },\n        },\n      )\n\n      const dnsDeleteResult = await dnsDeleteResponse.json()\n      console.log('\uD83D\uDDD1\uFE0F DNS delete response:', JSON.stringify(dnsDeleteResult, null, 2))\n\n      dnsSetup = {\n        success: dnsDeleteResult.success,\n        errors: dnsDeleteResult.errors || [],\n        deleted: dnsDeleteResult.success,\n        recordId: dnsRecord.id,\n      }\n    } else {\n      console.log('\u2139\uFE0F No DNS record found for domain:', targetDomain)\n      dnsSetup.deleted = false\n      dnsSetup.message = 'No DNS record found'\n    }\n\n    // Step 2: Find and delete worker route\n    console.log('\uD83D\uDD0D Finding worker route for:', `${targetDomain}/*`)\n\n    const routesListResponse = await fetch(\n      `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/workers/routes`,\n      {\n        method: 'GET',\n        headers: {\n          Authorization: `Bearer ${env.CF_API_TOKEN}`,\n          'Content-Type': 'application/json',\n        },\n      },\n    )\n\n    const routesListResult = await routesListResponse.json()\n    console.log('\uD83D\uDCCB Routes list response:', JSON.stringify(routesListResult, null, 2))\n\n    let workerSetup = { success: true, errors: [], deleted: false }\n\n    if (routesListResult.result && routesListResult.result.length > 0) {\n      // Find the route that matches our domain pattern\n      const targetRoute = routesListResult.result.find(\n        (route) => route.pattern === `${targetDomain}/*`,\n      )\n\n      if (targetRoute) {\n        console.log('\uD83C\uDFAF Found worker route to delete:', targetRoute.id)\n\n        const routeDeleteResponse = await fetch(\n          `https://api.cloudflare.com/client/v4/zones/${targetZoneId}/workers/routes/${targetRoute.id}`,\n          {\n            method: 'DELETE',\n            headers: {\n              Authorization: `Bearer ${env.CF_API_TOKEN}`,\n              'Content-Type': 'application/json',\n            },\n          },\n        )\n\n        const routeDeleteResult = await routeDeleteResponse.json()\n        console.log('\uD83D\uDDD1\uFE0F Route delete response:', JSON.stringify(routeDeleteResult, null, 2))\n\n        workerSetup = {\n          success: routeDeleteResult.success,\n          errors: routeDeleteResult.errors || [],\n          deleted: routeDeleteResult.success,\n          routeId: targetRoute.id,\n        }\n      } else {\n        console.log('\u2139\uFE0F No worker route found for pattern:', `${targetDomain}/*`)\n        workerSetup.deleted = false\n        workerSetup.message = 'No worker route found'\n      }\n    } else {\n      console.log('\u2139\uFE0F No worker routes found in zone')\n      workerSetup.deleted = false\n      workerSetup.message = 'No worker routes found'\n    }\n\n    // Step 3: Delete KV store entry\n    console.log('\uD83D\uDDD1\uFE0F Deleting KV store entry for:', `site-config:${targetDomain}`)\n\n    let kvSetup = { success: true, errors: [], deleted: false }\n\n    try {\n      if (!env.SITE_CONFIGS) {\n        throw new Error('SITE_CONFIGS KV namespace not available')\n      }\n\n      await env.SITE_CONFIGS.delete(`site-config:${targetDomain}`)\n      kvSetup.deleted = true\n      kvSetup.message = 'KV entry deleted successfully'\n      console.log('\u2705 KV entry deleted successfully')\n    } catch (kvError) {\n      console.error('\u274C Error deleting KV entry:', kvError)\n      kvSetup.success = false\n      kvSetup.errors.push({ message: kvError.message })\n      kvSetup.message = 'Failed to delete KV entry'\n    }\n\n    const overallSuccess = dnsSetup.success && workerSetup.success && kvSetup.success\n    console.log('\uD83C\uDFAF Overall deletion success:', overallSuccess)\n    console.log('  - DNS deletion success:', dnsSetup.success)\n    console.log('  - Worker deletion success:', workerSetup.success)\n    console.log('  - KV deletion success:', kvSetup.success)\n\n    const responseData = {\n      overallSuccess,\n      domain: targetDomain,\n      zoneId: targetZoneId,\n      dnsSetup,\n      workerSetup,\n      kvSetup,\n      debug: {\n        requestBody,\n        targetRootDomain: rootDomain,\n        availableDomains: Object.keys(DOMAIN_ZONE_MAPPING),\n      },\n    }\n\n    console.log('\uD83D\uDCE4 Final deletion response:', JSON.stringify(responseData, null, 2))\n\n    return new Response(JSON.stringify(responseData), {\n      status: 200,\n      headers: {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*',\n      },\n    })\n  } catch (error) {\n    console.log('\u274C Error in handleDeleteCustomDomain:', error)\n    console.log('\u274C Error stack:', error.stack)\n\n    return new Response(\n      JSON.stringify({\n        error: error.message,\n        stack: error.stack,\n        overallSuccess: false,\n      }),\n      {\n        status: 500,\n        headers: {\n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*',\n        },\n      },\n    )\n  }\n}\n\n// RAG Manager Proxy Handler\nconst handleRAGProxyRequest = async (request, endpoint, env) => {\n  try {\n    const ragManagerUrl = `https://rag-manager-worker.torarnehave.workers.dev${endpoint}`\n\n    console.log(`[API Worker] Proxying to RAG Manager: ${ragManagerUrl}`)\n\n    const response = await fetch(ragManagerUrl, {\n      method: request.method,\n      headers: request.headers,\n      body: request.body,\n    })\n\n    return response\n  } catch (error) {\n    console.error('[API Worker] RAG proxy error:', error)\n    return createErrorResponse(`RAG proxy failed: ${error.message}`, 500)\n  }\n}\n\n// Deploy Sandbox Handler\nconst handleDeploySandbox = async (request, env) => {\n  try {\n    const { userToken, code } = await request.json()\n    if (!userToken || !code) {\n      return createErrorResponse('Missing userToken or code', 400)\n    }\n\n    // Create worker name from user token (sanitized and limited to 54 chars)\n    const sanitizedToken = userToken.replace(/[^a-zA-Z0-9]/g, '').toLowerCase()\n    const workerName = `sandbox-${sanitizedToken}`.substring(0, 54)\n\n    const accountId = env.CF_ACCOUNT_ID\n    const apiToken = env.CF_API_TOKEN_SANDBOX\n    const workersSubdomain = env.CF_WORKERS_SUBDOMAIN\n\n    // Clean and validate the code before deployment\n    console.log(`Deploying persistent sandbox for user: ${workerName}`)\n    console.log('Worker code preview:', code.substring(0, 200) + '...')\n\n    // Enhanced debugging and cleaning\n    console.log('\uD83D\uDD0D Original code analysis:')\n    console.log('- Length:', code.length)\n    console.log('- First 100 chars:', JSON.stringify(code.substring(0, 100)))\n    console.log('- Contains export default:', code.includes('export default'))\n    console.log('- Contains addEventListener:', code.includes('addEventListener'))\n\n    // Clean the code more conservatively\n    let cleanCode = code\n      .replace(/```javascript\\n?/g, '')\n      .replace(/```js\\n?/g, '')\n      .replace(/```\\n?/g, '')\n      .replace(/\\r\\n/g, '\\n') // Normalize line endings\n      .replace(/\\r/g, '\\n') // Convert any remaining \\r to \\n\n      .trim()\n\n    console.log('\uD83E\uDDF9 After cleaning:')\n    console.log('- Length:', cleanCode.length)\n    console.log('- First 100 chars:', JSON.stringify(cleanCode.substring(0, 100)))\n    console.log('- Contains export default:', cleanCode.includes('export default'))\n    console.log('- Contains addEventListener:', cleanCode.includes('addEventListener'))\n\n    // Reject ESM code\n    if (cleanCode.includes('export default')) {\n      return createErrorResponse(\n        \"ESM (export default) syntax is not supported. Please use classic addEventListener('fetch', ...) syntax.\",\n        400,\n      )\n    }\n    // Require classic worker code\n    if (\n      !cleanCode.includes('addEventListener(\"fetch\"') &&\n      !cleanCode.includes(\"addEventListener('fetch'\")\n    ) {\n      return createErrorResponse(\n        'Invalid worker code: must use addEventListener(\"fetch\", ...) syntax.',\n        400,\n      )\n    }\n\n    // Final syntax check: basic braces check\n    const openBraces = (cleanCode.match(/{/g) || []).length\n    const closeBraces = (cleanCode.match(/}/g) || []).length\n    if (openBraces !== closeBraces) {\n      console.log('\u274C Mismatched braces detected:', { openBraces, closeBraces })\n      return createErrorResponse(\n        `Invalid worker code: mismatched braces (${openBraces} open, ${closeBraces} close)`,\n        400,\n      )\n    }\n\n    console.log('\u2705 Code validation passed, deploying...')\n    console.log('\uD83D\uDCE4 Final code to deploy:')\n    console.log('- Length:', cleanCode.length)\n    console.log('- Preview:', JSON.stringify(cleanCode.substring(0, 200) + '...'))\n    console.log('\uD83D\uDD0D Character analysis around position 87:')\n    console.log('- Chars 80-90:', JSON.stringify(cleanCode.substring(80, 90)))\n    console.log('- Char at 87:', JSON.stringify(cleanCode.charAt(87)))\n    console.log('- Char code at 87:', cleanCode.charCodeAt(87))\n\n    // Debug log to confirm deployment URL\n    console.log(\n      'Deploying to:',\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${workerName}`,\n    )\n    const deployRes = await fetch(\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${workerName}`,\n      {\n        method: 'PUT',\n        headers: {\n          Authorization: `Bearer ${apiToken}`,\n          'Content-Type': 'application/javascript',\n        },\n        body: cleanCode,\n      },\n    )\n\n    const deployJson = await deployRes.json()\n    if (!deployJson.success) {\n      return createErrorResponse('Cloudflare API error: ' + JSON.stringify(deployJson.errors), 500)\n    }\n\n    const endpoint = `https://${workerName}.${workersSubdomain}.workers.dev`\n\n    // Save sandbox metadata to KV for user management\n    const sandboxMetadata = {\n      userToken,\n      workerName,\n      endpoint,\n      lastUpdated: new Date().toISOString(),\n      codePreview: cleanCode.substring(0, 500), // Store preview for debugging\n      originalCodeLength: code.length,\n      cleanCodeLength: cleanCode.length,\n    }\n\n    await env.BINDING_NAME.put(`sandbox:${userToken}`, JSON.stringify(sandboxMetadata))\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        endpoint,\n        workerName,\n        message: 'Persistent sandbox updated successfully',\n      }),\n      200,\n    )\n  } catch (e) {\n    return createErrorResponse('Deploy error: ' + e.message, 500)\n  }\n}\n\n// Create Persistent Sandbox Domain Handler\nconst handleCreateSandboxDomain = async (request, env) => {\n  try {\n    const { userToken } = await request.json()\n    if (!userToken) {\n      return createErrorResponse('Missing userToken', 400)\n    }\n\n    // Get sandbox metadata from KV\n    const sandboxData = await env.BINDING_NAME.get(`sandbox:${userToken}`)\n    if (!sandboxData) {\n      return createErrorResponse('Sandbox not found. Please deploy your sandbox first.', 404)\n    }\n\n    const sandbox = JSON.parse(sandboxData)\n    const workerName = sandbox.workerName\n\n    // Create a custom domain based on the worker name\n    const customSubdomain = workerName.replace('sandbox-', '') // Remove 'sandbox-' prefix\n    const domain = `${customSubdomain}.xyzvibe.com`\n    const zoneId = '602067f0cf860426a35860a8ab179a47' // xyzvibe.com zone ID\n    const accountId = env.CF_ACCOUNT_ID\n    const apiToken = env.CF_API_TOKEN // Use main token for domain operations\n    const workersSubdomain = env.CF_WORKERS_SUBDOMAIN\n\n    // 1. Create DNS record\n    const dnsRes = await fetch(`https://api.cloudflare.com/client/v4/zones/${zoneId}/dns_records`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Bearer ${apiToken}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        type: 'CNAME',\n        name: domain,\n        content: `${workerName}.${workersSubdomain}.workers.dev`,\n        proxied: true,\n      }),\n    })\n    const dnsJson = await dnsRes.json()\n    if (!dnsJson.success) {\n      return createErrorResponse('DNS error: ' + JSON.stringify(dnsJson.errors), 500)\n    }\n\n    // 2. Register the custom domain with the worker\n    const domainRes = await fetch(\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/domains`,\n      {\n        method: 'POST',\n        headers: {\n          Authorization: `Bearer ${apiToken}`,\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          hostname: domain,\n          service: workerName,\n        }),\n      },\n    )\n    const domainJson = await domainRes.json()\n    if (!domainJson.success) {\n      return createErrorResponse('Domain error: ' + JSON.stringify(domainJson.errors), 500)\n    }\n\n    // Update sandbox metadata with custom domain\n    sandbox.customDomain = `https://${domain}`\n    sandbox.domainCreated = new Date().toISOString()\n    await env.BINDING_NAME.put(`sandbox:${userToken}`, JSON.stringify(sandbox))\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        url: `https://${domain}`,\n        workerUrl: sandbox.endpoint,\n        message: 'Custom domain created for persistent sandbox',\n      }),\n      200,\n    )\n  } catch (e) {\n    return createErrorResponse('Domain creation error: ' + e.message, 500)\n  }\n}\n\n// Get Sandbox Info Handler\nconst handleGetSandboxInfo = async (request, env) => {\n  try {\n    const url = new URL(request.url)\n    const userToken = url.searchParams.get('userToken')\n\n    if (!userToken) {\n      return createErrorResponse('Missing userToken parameter', 400)\n    }\n\n    const sandboxData = await env.BINDING_NAME.get(`sandbox:${userToken}`)\n    if (!sandboxData) {\n      return createResponse(\n        JSON.stringify({\n          exists: false,\n          message: 'No sandbox found for this user token',\n        }),\n        200,\n      )\n    }\n\n    const sandbox = JSON.parse(sandboxData)\n    return createResponse(\n      JSON.stringify({\n        exists: true,\n        sandbox: {\n          workerName: sandbox.workerName,\n          endpoint: sandbox.endpoint,\n          customDomain: sandbox.customDomain || null,\n          lastUpdated: sandbox.lastUpdated,\n          domainCreated: sandbox.domainCreated || null,\n        },\n      }),\n      200,\n    )\n  } catch (e) {\n    return createErrorResponse('Error retrieving sandbox info: ' + e.message, 500)\n  }\n}\n\n// Get Deployed Sandbox Code Handler\nconst handleGetSandboxCode = async (request, env) => {\n  try {\n    const url = new URL(request.url)\n    const userToken = url.searchParams.get('userToken')\n\n    if (!userToken) {\n      return createErrorResponse('Missing userToken parameter', 400)\n    }\n\n    // Get sandbox metadata from KV\n    const sandboxData = await env.BINDING_NAME.get(`sandbox:${userToken}`)\n    if (!sandboxData) {\n      return createErrorResponse('Sandbox not found. Please deploy your sandbox first.', 404)\n    }\n\n    const sandbox = JSON.parse(sandboxData)\n    const workerName = sandbox.workerName\n\n    const accountId = env.CF_ACCOUNT_ID\n    const apiToken = env.CF_API_TOKEN_SANDBOX\n\n    // Fetch the deployed worker code from Cloudflare API\n    console.log(`Fetching deployed code for worker: ${workerName}`)\n\n    const codeRes = await fetch(\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${workerName}`,\n      {\n        method: 'GET',\n        headers: {\n          Authorization: `Bearer ${apiToken}`,\n          Accept: 'application/javascript',\n        },\n      },\n    )\n\n    if (!codeRes.ok) {\n      const errorText = await codeRes.text()\n      console.error('Failed to fetch deployed code:', errorText)\n      return createErrorResponse(\n        `Failed to fetch deployed code: HTTP ${codeRes.status}`,\n        codeRes.status,\n      )\n    }\n\n    const deployedCode = await codeRes.text()\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        code: deployedCode,\n        workerName: sandbox.workerName,\n        endpoint: sandbox.endpoint,\n        lastUpdated: sandbox.lastUpdated,\n        fetchedAt: new Date().toISOString(),\n      }),\n      200,\n    )\n  } catch (e) {\n    console.error('Error fetching sandbox code:', e)\n    return createErrorResponse('Error fetching deployed code: ' + e.message, 500)\n  }\n}\n\n// AI Worker Generation Handler\nconst handleGenerateWorker = async (request, env) => {\n  try {\n    const body = await request.json()\n    const { prompt, aiModel, selectedExamples, userPrompt } = body\n\n    if (!prompt || !aiModel) {\n      return createErrorResponse('Missing required parameters: prompt and aiModel', 400)\n    }\n\n    // Prepare context from selected examples\n    let exampleContext = ''\n    if (selectedExamples && selectedExamples.length > 0) {\n      exampleContext = `\\n\\nSelected Code Examples:\\n${selectedExamples\n        .map((ex) => `// ${ex.title} (${ex.language})\\n// ${ex.description}\\n${ex.code}`)\n        .join('\\n\\n// ---\\n\\n')}`\n    }\n\n    const finalPrompt = `Generate a complete, production-ready Cloudflare Worker script based on the following requirements:\n\nUser Request: ${userPrompt || 'Create a basic worker'}\n\nContext: This worker will be deployed to a RAG-enabled sandbox environment for knowledge graph operations.\n\nRequirements:\n- Must be a complete, working Cloudflare Worker\n- Should handle HTTP requests appropriately\n- Include proper error handling and CORS headers\n- Add helpful comments explaining the functionality\n- Make it production-ready and efficient\n- Return valid JavaScript code only\n\n${exampleContext}\n\nPlease generate only the JavaScript code for the worker, without any markdown formatting, explanations, or additional text.`\n\n    let apiKey, baseURL, model, result\n\n    // Call the appropriate AI model\n    switch (aiModel) {\n      case 'grok':\n        apiKey = env.XAI_API_KEY\n        if (!apiKey) {\n          return createErrorResponse('XAI API key not configured', 500)\n        }\n\n        const grokClient = new OpenAI({\n          apiKey: apiKey,\n          baseURL: 'https://api.x.ai/v1',\n        })\n\n        const grokCompletion = await grokClient.chat.completions.create({\n          model: 'grok-3-beta',\n          temperature: 0.7,\n          max_tokens: 3000,\n          messages: [\n            {\n              role: 'system',\n              content:\n                'You are an expert Cloudflare Worker developer. Generate clean, production-ready JavaScript code without any markdown formatting or explanations.',\n            },\n            { role: 'user', content: finalPrompt },\n          ],\n        })\n\n        result = grokCompletion.choices[0].message.content.trim()\n        break\n\n      case 'openai':\n        apiKey = env.OPENAI_API_KEY\n        if (!apiKey) {\n          return createErrorResponse('OpenAI API key not configured', 500)\n        }\n\n        const openaiClient = new OpenAI({\n          apiKey: apiKey,\n          baseURL: 'https://api.openai.com/v1',\n        })\n\n        const openaiCompletion = await openaiClient.chat.completions.create({\n          model: 'gpt-4',\n          temperature: 0.7,\n          max_tokens: 3000,\n          messages: [\n            {\n              role: 'system',\n              content:\n                'You are an expert Cloudflare Worker developer. Generate clean, production-ready JavaScript code without any markdown formatting or explanations.',\n            },\n            { role: 'user', content: finalPrompt },\n          ],\n        })\n\n        result = openaiCompletion.choices[0].message.content.trim()\n        break\n\n      case 'gemini':\n        apiKey = env.GOOGLE_GEMINI_API_KEY\n        if (!apiKey) {\n          return createErrorResponse('Google Gemini API key not configured', 500)\n        }\n\n        const geminiResponse = await fetch(\n          `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,\n          {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({\n              contents: [{ parts: [{ text: finalPrompt }] }],\n              generationConfig: {\n                temperature: 0.7,\n                maxOutputTokens: 3000,\n              },\n            }),\n          },\n        )\n\n        if (!geminiResponse.ok) {\n          throw new Error(`Gemini API error: ${geminiResponse.status}`)\n        }\n\n        const geminiData = await geminiResponse.json()\n        result = geminiData.candidates?.[0]?.content?.parts?.[0]?.text || 'No code generated'\n        break\n\n      default:\n        return createErrorResponse('Invalid AI model specified', 400)\n    }\n\n    // Clean up the generated code\n    let cleanCode = result\n      .replace(/```javascript\\n?/g, '')\n      .replace(/```js\\n?/g, '')\n      .replace(/```\\n?/g, '')\n      .trim()\n\n    // Ensure it starts with proper worker code\n    if (!cleanCode.includes('addEventListener') && !cleanCode.includes('export default')) {\n      cleanCode = `// Generated Cloudflare Worker\\n${cleanCode}`\n    }\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        code: cleanCode,\n        model: aiModel,\n        timestamp: new Date().toISOString(),\n      }),\n    )\n  } catch (error) {\n    console.error('Worker generation error:', error)\n    return createErrorResponse(`Worker generation failed: ${error.message}`, 500)\n  }\n}\n\n// --- YouTube Script Generation Handler ---\nconst handleGenerateYouTubeScript = async (request, env) => {\n  try {\n    const body = await request.json()\n    const {\n      markdown,\n      youtubeUrl,\n      aiProvider,\n      language,\n      scriptStyle,\n      targetDuration,\n      includeTimestamps,\n      includeEngagement,\n    } = body\n\n    if (!markdown) {\n      return createErrorResponse('Missing required parameter: markdown', 400)\n    }\n\n    // Extract YouTube video ID from URL\n    let videoId = ''\n    if (youtubeUrl) {\n      const urlMatch = youtubeUrl.match(\n        /(?:youtube\\.com\\/watch\\?v=|youtu\\.be\\/|youtube\\.com\\/embed\\/)([a-zA-Z0-9_-]{11})/,\n      )\n      videoId = urlMatch ? urlMatch[1] : ''\n    }\n\n    // Create language-specific prompt\n    const isNorwegian = language === 'norwegian'\n    const finalPrompt = isNorwegian\n      ? `Du er en profesjonell YouTube-skaper og manusforfatter. Generer et omfattende, engasjerende YouTube-manus basert p\u00E5 f\u00F8lgende dokumentasjon:\n\nDOKUMENTASJON:\n${markdown}\n\nVIDEOSTIL: ${scriptStyle || 'tutorial'}\nM\u00C5LVARIGHET: ${targetDuration || '5-10 minutter'}\nYOUTUBE URL: ${youtubeUrl || 'Ikke oppgitt'}\n\nKRAV:\n1. **Huk (F\u00F8rste 15 sekunder)** - Fang oppmerksomhet umiddelbart\n2. **Verdil\u00F8fte** - Fortell seerne hva de vil l\u00E6re\n3. **Strukturerte seksjoner** med klare overganger\n4. **Engasjementselementer** - Abonner-p\u00E5minnelser, kommentarer, liker\n5. **Handling-til-handling** - Veilede seere til neste steg\n6. **YouTube beste praksis** - Retensjonsfokusert skriving\n\n${includeTimestamps ? 'INKLUDER TIDSSTEMPLER: Legg til [0:00], [1:30], etc. for YouTube-kapitler' : ''}\n${includeEngagement ? 'INKLUDER ENGASJEMENT: Legg til abonner-oppfordringer, like-p\u00E5minnelser, kommentarsp\u00F8rsm\u00E5l' : ''}\n\nFORMAT:\n- Profesjonell, samtaleaktig tone\n- Klare seksjonsoverskrifter\n- Handlingsrettet innhold\n- Seer-fokusert spr\u00E5k (\"du vil l\u00E6re\", \"la meg vise deg\")\n- Naturlige overganger mellom seksjoner\n\nGenerer et komplett, klart-til-bruk YouTube-manus som ville fungere godt for pedagogisk innhold om den dokumenterte funksjonen eller systemet. Skriv HELE manuset p\u00E5 norsk.`\n      : `You are a professional YouTube creator and scriptwriter. Generate a comprehensive, engaging YouTube script based on the following documentation:\n\nDOCUMENTATION:\n${markdown}\n\nVIDEO STYLE: ${scriptStyle || 'tutorial'}\nTARGET DURATION: ${targetDuration || '5-10 minutes'}\nYOUTUBE URL: ${youtubeUrl || 'Not provided'}\n\nREQUIREMENTS:\n1. **Hook (First 15 seconds)** - Grab attention immediately\n2. **Value Promise** - Tell viewers what they'll learn\n3. **Structured Sections** with clear transitions\n4. **Engagement Elements** - Subscribe reminders, comments, likes\n5. **Call-to-Actions** - Guide viewers to next steps\n6. **YouTube Best Practices** - Retention-focused writing\n\n${includeTimestamps ? 'INCLUDE TIMESTAMPS: Add [0:00], [1:30], etc. for YouTube chapters' : ''}\n${includeEngagement ? 'INCLUDE ENGAGEMENT: Add subscribe prompts, like reminders, comment questions' : ''}\n\nFORMAT:\n- Professional, conversational tone\n- Clear section headings\n- Actionable content\n- Viewer-focused language (\"you'll learn\", \"let me show you\")\n- Natural transitions between sections\n\nGenerate a complete, ready-to-use YouTube script that would work well for educational content about the documented feature or system.`\n\n    let apiKey, result\n\n    // Determine AI provider (default to grok if not specified)\n    // Handle both 'api-worker' and 'dev-worker' as valid provider names\n    let provider = aiProvider\n    if (aiProvider === 'dev-worker' || aiProvider === 'api-worker') {\n      provider = 'grok' // Default to grok for both worker types\n    } else if (!aiProvider) {\n      provider = 'grok' // Default fallback\n    }\n\n    console.log('[Worker] YouTube script generation - AI provider mapping:', {\n      originalProvider: aiProvider,\n      mappedProvider: provider,\n      language: language || 'english',\n    })\n\n    // Call the appropriate AI model\n    switch (provider) {\n      case 'grok':\n        apiKey = env.XAI_API_KEY\n        if (!apiKey) {\n          return createErrorResponse('XAI API key not configured', 500)\n        }\n\n        const grokClient = new OpenAI({\n          apiKey: apiKey,\n          baseURL: 'https://api.x.ai/v1',\n        })\n\n        const grokCompletion = await grokClient.chat.completions.create({\n          model: 'grok-3-beta',\n          temperature: 0.7,\n          max_tokens: 2000,\n          messages: [\n            {\n              role: 'system',\n              content: isNorwegian\n                ? 'Du er en profesjonell YouTube-skaper og manusforfatter. Lag engasjerende, pedagogiske manus som holder seere interesserte og l\u00E6rer dem noe.'\n                : 'You are a professional YouTube creator and scriptwriter. Create engaging, educational scripts that keep viewers watching and learning.',\n            },\n            { role: 'user', content: finalPrompt },\n          ],\n        })\n\n        result = grokCompletion.choices[0].message.content.trim()\n        break\n\n      case 'openai':\n        apiKey = env.OPENAI_API_KEY\n        if (!apiKey) {\n          return createErrorResponse('OpenAI API key not configured', 500)\n        }\n\n        const openaiClient = new OpenAI({\n          apiKey: apiKey,\n          baseURL: 'https://api.openai.com/v1',\n        })\n\n        const openaiCompletion = await openaiClient.chat.completions.create({\n          model: 'gpt-4',\n          temperature: 0.7,\n          max_tokens: 2000,\n          messages: [\n            {\n              role: 'system',\n              content: isNorwegian\n                ? 'Du er en profesjonell YouTube-skaper og manusforfatter. Lag engasjerende, pedagogiske manus som holder seere interesserte og l\u00E6rer dem noe.'\n                : 'You are a professional YouTube creator and scriptwriter. Create engaging, educational scripts that keep viewers watching and learning.',\n            },\n            { role: 'user', content: finalPrompt },\n          ],\n        })\n\n        result = openaiCompletion.choices[0].message.content.trim()\n        break\n\n      default:\n        return createErrorResponse('Invalid AI provider specified', 400)\n    }\n\n    // Clean up the generated script\n    const cleanScript = result.trim()\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        script: cleanScript,\n        videoId: videoId,\n        provider: provider,\n        language: language || 'english',\n        timestamp: new Date().toISOString(),\n      }),\n    )\n  } catch (error) {\n    console.error('YouTube script generation error:', error)\n    return createErrorResponse(`YouTube script generation failed: ${error.message}`, 500)\n  }\n}\n\n// Removed handleCreateSandboxBrandDomain - using direct API calls instead\n\n// --- Update Sandman Worker Endpoint ---\nconst handleUpdateSandman = async (request, env) => {\n  try {\n    const accountId = env.CF_ACCOUNT_ID\n    const apiToken = env.SANDMAN_API_TOKEN\n    const workerName = 'sandman'\n    const newCode = `addEventListener('fetch', event => { event.respondWith(new Response('Hello I am the Sandman')) })`\n\n    // Debug log\n    console.log(\n      'Updating sandman worker at:',\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${workerName}`,\n    )\n\n    const deployRes = await fetch(\n      `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${workerName}`,\n      {\n        method: 'PUT',\n        headers: {\n          Authorization: `Bearer ${apiToken}`,\n          'Content-Type': 'application/javascript',\n        },\n        body: newCode,\n      },\n    )\n    const deployJson = await deployRes.json()\n    if (!deployJson.success) {\n      return createErrorResponse('Cloudflare API error: ' + JSON.stringify(deployJson.errors), 500)\n    }\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        message: 'Sandman worker updated successfully',\n        workerName,\n      }),\n      200,\n    )\n  } catch (e) {\n    return createErrorResponse('Update sandman error: ' + e.message, 500)\n  }\n}\n\n// ============================================\n// SUPERADMIN DOMAIN MANAGEMENT ENDPOINTS\n// ============================================\n\n// Helper function to validate Superadmin role\nconst validateSuperadminRole = async (request, email, env) => {\n  try {\n    // Get role from header (sent from userStore)\n    const userRole = request.headers.get('x-user-role')\n\n    if (!userRole || userRole !== 'Superadmin') {\n      return { valid: false, error: 'Access denied: Superadmin role required' }\n    }\n\n    // Optional: Verify role matches database for extra security\n    // This could be cached or done periodically rather than every request\n    const db = env.vegvisr_org\n    const query = `SELECT role FROM config WHERE email = ?`\n    const row = await db.prepare(query).bind(email).first()\n\n    if (!row || row.role !== 'Superadmin') {\n      return { valid: false, error: 'Role verification failed' }\n    }\n\n    return { valid: true }\n  } catch (error) {\n    console.error('Error validating Superadmin role:', error)\n    return { valid: false, error: 'Role validation failed' }\n  }\n}\n\n// GET /admin/domains - List all domains with ownership info\nconst handleAdminDomains = async (request, env) => {\n  try {\n    const url = new URL(request.url)\n    const email = url.searchParams.get('email')\n\n    if (!email) {\n      return createErrorResponse('Missing email parameter', 400)\n    }\n\n    // Validate Superadmin role\n    const roleCheck = await validateSuperadminRole(request, email, env)\n    if (!roleCheck.valid) {\n      return createErrorResponse(roleCheck.error, 403)\n    }\n\n    // Get all domains from KV store\n    const keys = await env.BINDING_NAME.list({ prefix: 'site-config:' })\n    const domains = []\n\n    for (const key of keys.keys) {\n      const domain = key.name.replace('site-config:', '')\n      const config = await env.BINDING_NAME.get(key.name)\n\n      if (config) {\n        const parsedConfig = JSON.parse(config)\n        domains.push({\n          domain,\n          owner: parsedConfig.owner || 'Unknown',\n          createdAt: parsedConfig.createdAt || null,\n          lastModified: parsedConfig.lastModified || null,\n          hasLogo: !!parsedConfig.logo,\n          hasContentFilters: !!parsedConfig.contentFilters,\n          graphId: parsedConfig.graphId || null,\n        })\n      }\n    }\n\n    // Sort domains by owner and domain name\n    domains.sort((a, b) => {\n      if (a.owner !== b.owner) {\n        return a.owner.localeCompare(b.owner)\n      }\n      return a.domain.localeCompare(b.domain)\n    })\n\n    return createResponse(JSON.stringify({ domains }))\n  } catch (error) {\n    console.error('Error in handleAdminDomains:', error)\n    return createErrorResponse('Internal server error', 500)\n  }\n}\n\n// POST /admin/transfer-domain - Transfer domain between users\nconst handleTransferDomain = async (request, env) => {\n  try {\n    const { email, domain, newOwner } = await request.json()\n\n    if (!email || !domain || !newOwner) {\n      return createErrorResponse('Missing required fields: email, domain, newOwner', 400)\n    }\n\n    // Validate Superadmin role\n    const roleCheck = await validateSuperadminRole(request, email, env)\n    if (!roleCheck.valid) {\n      return createErrorResponse(roleCheck.error, 403)\n    }\n\n    // Get current domain config from KV store\n    const kvKey = `site-config:${domain}`\n    const currentConfig = await env.BINDING_NAME.get(kvKey)\n\n    if (!currentConfig) {\n      return createErrorResponse('Domain not found', 404)\n    }\n\n    const parsedConfig = JSON.parse(currentConfig)\n    const oldOwner = parsedConfig.owner\n\n    // Update domain config in KV store\n    parsedConfig.owner = newOwner\n    parsedConfig.lastModified = new Date().toISOString()\n    parsedConfig.transferHistory = parsedConfig.transferHistory || []\n    parsedConfig.transferHistory.push({\n      from: oldOwner,\n      to: newOwner,\n      transferredBy: email,\n      timestamp: new Date().toISOString(),\n    })\n\n    await env.BINDING_NAME.put(kvKey, JSON.stringify(parsedConfig))\n\n    // Update old owner's SQL profile - remove domain from domainConfigs\n    if (oldOwner) {\n      const oldOwnerData = await env.vegvisr_org\n        .prepare('SELECT data FROM config WHERE email = ?')\n        .bind(oldOwner)\n        .first()\n      if (oldOwnerData && oldOwnerData.data) {\n        const userData = JSON.parse(oldOwnerData.data)\n        if (userData.domainConfigs) {\n          userData.domainConfigs = userData.domainConfigs.filter((d) => d.domain !== domain)\n          await env.vegvisr_org\n            .prepare('UPDATE config SET data = ? WHERE email = ?')\n            .bind(JSON.stringify(userData), oldOwner)\n            .run()\n        }\n      }\n    }\n\n    // Update new owner's SQL profile - add domain to domainConfigs\n    const newOwnerData = await env.vegvisr_org\n      .prepare('SELECT data FROM config WHERE email = ?')\n      .bind(newOwner)\n      .first()\n    let userData = { domainConfigs: [] }\n\n    if (newOwnerData && newOwnerData.data) {\n      userData = JSON.parse(newOwnerData.data)\n      if (!userData.domainConfigs) {\n        userData.domainConfigs = []\n      }\n    }\n\n    // Add domain to new owner's profile if not already present\n    if (!userData.domainConfigs.find((d) => d.domain === domain)) {\n      userData.domainConfigs.push({\n        domain,\n        owner: newOwner,\n        createdAt: parsedConfig.createdAt || new Date().toISOString(),\n        lastModified: parsedConfig.lastModified,\n      })\n    }\n\n    await env.vegvisr_org\n      .prepare(\n        `\n      INSERT INTO config (email, data)\n      VALUES (?, ?)\n      ON CONFLICT(email) DO UPDATE SET data = ?\n    `,\n      )\n      .bind(newOwner, JSON.stringify(userData), JSON.stringify(userData))\n      .run()\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        message: `Domain ${domain} transferred from ${oldOwner} to ${newOwner}`,\n        domain,\n        oldOwner,\n        newOwner,\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleTransferDomain:', error)\n    return createErrorResponse('Internal server error', 500)\n  }\n}\n\n// POST /admin/share-template - Share domain template\nconst handleShareTemplate = async (request, env) => {\n  try {\n    const { email, sourceDomain, targetDomain, targetOwner, includeContent } = await request.json()\n\n    if (!email || !sourceDomain || !targetDomain || !targetOwner) {\n      return createErrorResponse(\n        'Missing required fields: email, sourceDomain, targetDomain, targetOwner',\n        400,\n      )\n    }\n\n    // Validate Superadmin role\n    const roleCheck = await validateSuperadminRole(request, email, env)\n    if (!roleCheck.valid) {\n      return createErrorResponse(roleCheck.error, 403)\n    }\n\n    // Get source domain config\n    const sourceConfig = await env.BINDING_NAME.get(`site-config:${sourceDomain}`)\n    if (!sourceConfig) {\n      return createErrorResponse('Source domain not found', 404)\n    }\n\n    const parsedSourceConfig = JSON.parse(sourceConfig)\n\n    // Create template config for target domain\n    const templateConfig = {\n      domain: targetDomain,\n      owner: targetOwner,\n      createdAt: new Date().toISOString(),\n      lastModified: new Date().toISOString(),\n      templateSource: sourceDomain,\n      templateCreatedBy: email,\n      logo: parsedSourceConfig.logo || null,\n      contentFilters: parsedSourceConfig.contentFilters || null,\n      graphId: includeContent ? parsedSourceConfig.graphId : null,\n      templateHistory: [\n        {\n          sourceTemplate: sourceDomain,\n          createdBy: email,\n          timestamp: new Date().toISOString(),\n          includeContent: !!includeContent,\n        },\n      ],\n    }\n\n    // Save template to KV store\n    await env.BINDING_NAME.put(`site-config:${targetDomain}`, JSON.stringify(templateConfig))\n\n    // Update target owner's SQL profile\n    const targetOwnerData = await env.vegvisr_org\n      .prepare('SELECT data FROM config WHERE email = ?')\n      .bind(targetOwner)\n      .first()\n    let userData = { domainConfigs: [] }\n\n    if (targetOwnerData && targetOwnerData.data) {\n      userData = JSON.parse(targetOwnerData.data)\n      if (!userData.domainConfigs) {\n        userData.domainConfigs = []\n      }\n    }\n\n    // Add domain to target owner's profile if not already present\n    if (!userData.domainConfigs.find((d) => d.domain === targetDomain)) {\n      userData.domainConfigs.push({\n        domain: targetDomain,\n        owner: targetOwner,\n        createdAt: templateConfig.createdAt,\n        lastModified: templateConfig.lastModified,\n        templateSource: sourceDomain,\n      })\n    }\n\n    await env.vegvisr_org\n      .prepare(\n        `\n      INSERT INTO config (email, data)\n      VALUES (?, ?)\n      ON CONFLICT(email) DO UPDATE SET data = ?\n    `,\n      )\n      .bind(targetOwner, JSON.stringify(userData), JSON.stringify(userData))\n      .run()\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        message: `Template shared from ${sourceDomain} to ${targetDomain} for ${targetOwner}`,\n        sourceDomain,\n        targetDomain,\n        targetOwner,\n        includeContent: !!includeContent,\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleShareTemplate:', error)\n    return createErrorResponse('Internal server error', 500)\n  }\n}\n\n// DELETE /admin/remove-domain - Remove domain from system\nconst handleRemoveDomain = async (request, env) => {\n  try {\n    const url = new URL(request.url)\n    const email = url.searchParams.get('email')\n    const domain = url.searchParams.get('domain')\n\n    if (!email || !domain) {\n      return createErrorResponse('Missing required parameters: email, domain', 400)\n    }\n\n    // Validate Superadmin role\n    const roleCheck = await validateSuperadminRole(request, email, env)\n    if (!roleCheck.valid) {\n      return createErrorResponse(roleCheck.error, 403)\n    }\n\n    // Get domain config to identify owner\n    const kvKey = `site-config:${domain}`\n    const currentConfig = await env.BINDING_NAME.get(kvKey)\n\n    if (!currentConfig) {\n      return createErrorResponse('Domain not found', 404)\n    }\n\n    const parsedConfig = JSON.parse(currentConfig)\n    const owner = parsedConfig.owner\n\n    // Remove domain from KV store\n    await env.BINDING_NAME.delete(kvKey)\n\n    // Update owner's SQL profile - remove domain from domainConfigs\n    if (owner) {\n      const ownerData = await env.vegvisr_org\n        .prepare('SELECT data FROM config WHERE email = ?')\n        .bind(owner)\n        .first()\n      if (ownerData && ownerData.data) {\n        const userData = JSON.parse(ownerData.data)\n        if (userData.domainConfigs) {\n          userData.domainConfigs = userData.domainConfigs.filter((d) => d.domain !== domain)\n          await env.vegvisr_org\n            .prepare('UPDATE config SET data = ? WHERE email = ?')\n            .bind(JSON.stringify(userData), owner)\n            .run()\n        }\n      }\n    }\n\n    return createResponse(\n      JSON.stringify({\n        success: true,\n        message: `Domain ${domain} removed from system`,\n        domain,\n        owner,\n        removedBy: email,\n      }),\n    )\n  } catch (error) {\n    console.error('Error in handleRemoveDomain:', error)\n    return createErrorResponse('Internal server error', 500)\n  }\n}\n\nexport default {\n  async fetch(request, env) {\n    const url = new URL(request.url)\n    const pathname = url.pathname\n\n    // Log all incoming requests for debugging\n    console.log('\uD83D\uDD0D API Worker Request:', {\n      method: request.method,\n      pathname: pathname,\n      fullUrl: request.url,\n      origin: request.headers.get('Origin'),\n      userAgent: request.headers.get('User-Agent'),\n      timestamp: new Date().toISOString(),\n    })\n\n    // Handle CORS preflight requests\n    if (request.method === 'OPTIONS') {\n      return new Response(null, {\n        status: 204,\n        headers: {\n          ...corsHeaders,\n          'Access-Control-Max-Age': '86400',\n        },\n      })\n    }\n\n    if (pathname === '/createknowledgegraph' && request.method === 'GET') {\n      return await handleCreateKnowledgeGraph(request, env)\n    }\n\n    if (pathname === '/generateEmailTemplate' && request.method === 'POST') {\n      return await handleGenerateEmailTemplate(request, env)\n    }\n    if (pathname === '/save' && request.method === 'POST') {\n      return await handleSave(request, env)\n    }\n    if (pathname.startsWith('/view/') && request.method === 'GET') {\n      return await handleView(request, env)\n    }\n    if (pathname === '/blog-posts' && request.method === 'GET') {\n      return await handleBlogPosts(request, env)\n    }\n    if (pathname === '/hidden-blog-posts' && request.method === 'GET') {\n      return await handleBlogPosts(request, env, true)\n    }\n    if (pathname.startsWith('/blogpostdelete/') && request.method === 'DELETE') {\n      return await handleBlogPostDelete(request, env)\n    }\n    if (pathname === '/snippetadd' && request.method === 'POST') {\n      return await handleSnippetAdd(request, env)\n    }\n    if (pathname.startsWith('/snippets/') && request.method === 'GET') {\n      return await handleSnippetGet(request, env)\n    }\n    if (pathname === '/snippetlist' && request.method === 'GET') {\n      return await handleSnippetList(request, env)\n    }\n    if (pathname.startsWith('/snippetdelete') && request.method === 'DELETE') {\n      return await handleSnippetDelete(request, env)\n    }\n    if (pathname === '/upload' && request.method === 'POST') {\n      return await handleUpload(request, env)\n    }\n    if (pathname === '/search' && request.method === 'GET') {\n      return await handleSearch(request, env)\n    }\n    if (pathname === '/hid_vis' && request.method === 'POST') {\n      return await handleToggleVisibility(request, env)\n    }\n    if (pathname === '/getimage' && request.method === 'GET') {\n      return await handleGetImage(request, env)\n    }\n    if (pathname === '/getcorsimage' && request.method === 'GET') {\n      return await handleGetImageFromR2(request, env)\n    }\n    if (pathname === '/getcorsimage' && request.method === 'HEAD') {\n      return await handleGetImageHeaders(request, env)\n    }\n    if (pathname === '/summarize' && request.method === 'POST') {\n      return await handleSummarize(request, env)\n    }\n    if (pathname === '/groktest' && request.method === 'POST') {\n      return await handleGrokTest(request, env)\n    }\n    if (pathname === '/gemini-test' && request.method === 'POST') {\n      return await handleGeminiTest(request, env)\n    }\n    if (pathname === '/claude-test' && request.method === 'POST') {\n      return await handleClaudeTest(request, env)\n    }\n    if (pathname === '/aiaction' && request.method === 'POST') {\n      return await handleAIAction(request, env)\n    }\n    if (pathname === '/getGoogleApiKey' && request.method === 'GET') {\n      return await handleGetGoogleApiKey(request, env)\n    }\n    if (pathname === '/updatekml' && request.method === 'POST') {\n      return await handleUpdateKml(request, env)\n    }\n    if (pathname === '/suggest-title' && request.method === 'POST') {\n      return await handleSuggestTitle(request, env)\n    }\n    if (pathname === '/suggest-description' && request.method === 'POST') {\n      return await handleSuggestDescription(request, env)\n    }\n    if (pathname === '/suggest-categories' && request.method === 'POST') {\n      return await handleSuggestCategories(request, env)\n    }\n    if (pathname === '/grok-issue-description' && request.method === 'POST') {\n      return await handleGrokIssueDescription(request, env)\n    }\n    if (pathname === '/generate-meta-areas' && request.method === 'POST') {\n      return await handleGenerateMetaAreas(request, env)\n    }\n    if (pathname === '/grok-ask' && request.method === 'POST') {\n      return await handleGrokAsk(request, env)\n    }\n    if (pathname === '/generate-header-image' && request.method === 'POST') {\n      return await handleGenerateHeaderImage(request, env)\n    }\n    if (pathname === '/generate-image-prompt' && request.method === 'POST') {\n      return await handleGenerateImagePrompt(request, env)\n    }\n    if (pathname === '/list-r2-images' && request.method === 'GET') {\n      return await handleListR2Images(request, env)\n    }\n\n    if (pathname === '/youtube-search' && request.method === 'GET') {\n      return await handleYouTubeSearch(request, env)\n    }\n\n    if (pathname.startsWith('/youtube-transcript-io/') && request.method === 'GET') {\n      return await handleYouTubeTranscriptIO(request, env)\n    }\n\n    if (pathname.startsWith('/downsub-transcript/') && request.method === 'GET') {\n      return await handleDownsubTranscript(request, env)\n    }\n\n    if (pathname === '/downsub-url-transcript' && request.method === 'POST') {\n      return await handleDownsubUrlTranscript(request, env)\n    }\n\n    if (pathname === '/mystmkrasave' && request.method === 'POST') {\n      return handleMystmkraProxy(request)\n    }\n\n    if (pathname === '/gpt4-vision-image' && request.method === 'POST') {\n      return await handleGPT4VisionImage(request, env)\n    }\n\n    if (pathname === '/save-approved-image' && request.method === 'POST') {\n      return await handleSaveApprovedImage(request, env)\n    }\n\n    if (pathname === '/ai-generate-node' && request.method === 'POST') {\n      return await handleAIGenerateNode(request, env)\n    }\n    if (pathname === '/ai-generate-menu' && request.method === 'POST') {\n      return await handleAIGenerateMenu(request, env)\n    }\n\n    if (pathname === '/ai-generate-quotes' && request.method === 'POST') {\n      return await handleAIGenerateQuotes(request, env)\n    }\n\n    if (pathname === '/process-transcript' && request.method === 'POST') {\n      return await handleProcessTranscript(request, env)\n    }\n\n    if (pathname === '/apply-style-template' && request.method === 'POST') {\n      return await handleApplyStyleTemplate(request, env)\n    }\n\n    if (pathname === '/style-templates' && request.method === 'GET') {\n      return await handleGetStyleTemplates(request, env)\n    }\n\n    if (pathname === '/pexels-search' && request.method === 'POST') {\n      return await handlePexelsImageSearch(request, env)\n    }\n\n    if (pathname === '/google-photos-auth' && request.method === 'POST') {\n      return await handleGooglePhotosAuth(request, env)\n    }\n\n    if (pathname === '/google-photos-search' && request.method === 'POST') {\n      return await handleGooglePhotosSearch(request)\n    }\n\n    if (pathname === '/google-photos-recent' && request.method === 'POST') {\n      return await handleGooglePhotosRecent(request)\n    }\n\n    if (pathname === '/auth/google/callback.html' && request.method === 'GET') {\n      console.log('\u2705 OAuth Callback Route Matched!', {\n        pathname: pathname,\n        method: request.method,\n        queryParams: url.searchParams.toString(),\n      })\n      return await handleGoogleOAuthCallback()\n    }\n\n    // Placeholder endpoints to prevent 404 errors\n    if (pathname === '/user-preferences') {\n      return createResponse(\n        JSON.stringify({\n          message: 'User preferences endpoint not yet implemented',\n          preferences: {},\n        }),\n        200,\n      )\n    }\n\n    if (pathname === '/ai-node-history') {\n      return createResponse(\n        JSON.stringify({\n          message: 'AI node history endpoint not yet implemented',\n          history: [],\n        }),\n        200,\n      )\n    }\n\n    if (url.pathname === '/create-custom-domain') {\n      return await handleCreateCustomDomain(request, env)\n    }\n\n    if (url.pathname === '/delete-custom-domain') {\n      return await handleDeleteCustomDomain(request, env)\n    }\n\n    // RAG Manager Proxy Endpoints\n    if (pathname === '/rag/analyze-graph' && request.method === 'POST') {\n      return await handleRAGProxyRequest(request, '/analyze-graph', env)\n    }\n    if (pathname === '/rag/create-index' && request.method === 'POST') {\n      return await handleRAGProxyRequest(request, '/create-rag-index', env)\n    }\n    if (pathname === '/rag/create-sandbox' && request.method === 'POST') {\n      return await handleRAGProxyRequest(request, '/create-rag-sandbox', env)\n    }\n    if (pathname === '/rag/list-sandboxes' && request.method === 'GET') {\n      return await handleRAGProxyRequest(request, '/list-sandboxes', env)\n    }\n\n    if (pathname === '/deploy-sandbox' && request.method === 'POST') {\n      return await handleDeploySandbox(request, env)\n    }\n\n    if (pathname === '/create-sandbox-domain' && request.method === 'POST') {\n      return await handleCreateSandboxDomain(request, env)\n    }\n\n    if (pathname === '/get-sandbox-info' && request.method === 'GET') {\n      return await handleGetSandboxInfo(request, env)\n    }\n\n    if (pathname === '/get-sandbox-code' && request.method === 'GET') {\n      return await handleGetSandboxCode(request, env)\n    }\n\n    if (pathname === '/generate-worker' && request.method === 'POST') {\n      return await handleGenerateWorker(request, env)\n    }\n\n    if (pathname === '/generate-youtube-script' && request.method === 'POST') {\n      return await handleGenerateYouTubeScript(request, env)\n    }\n\n    if (pathname === '/update-sandman' && request.method === 'POST') {\n      return await handleUpdateSandman(request, env)\n    }\n\n    // Add new admin endpoints before the fallback\n    if (pathname === '/admin/domains' && request.method === 'GET') {\n      return await handleAdminDomains(request, env)\n    }\n\n    if (pathname === '/admin/transfer-domain' && request.method === 'POST') {\n      return await handleTransferDomain(request, env)\n    }\n\n    if (pathname === '/admin/share-template' && request.method === 'POST') {\n      return await handleShareTemplate(request, env)\n    }\n\n    if (pathname === '/admin/remove-domain' && request.method === 'DELETE') {\n      return await handleRemoveDomain(request, env)\n    }\n\n    // Fallback - log unmatched routes\n    console.log('\u274C No route matched, returning 404:', {\n      pathname: pathname,\n      method: request.method,\n      availableRoutes: [\n        '/auth/google/callback.html',\n        '/google-photos-auth',\n        '/google-photos-search',\n        '/google-photos-recent',\n        '/rag/analyze-graph',\n        '/rag/create-index',\n        '/rag/create-sandbox',\n        '/rag/list-sandboxes',\n        '/deploy-sandbox',\n        '/create-sandbox-domain',\n        '/get-sandbox-info',\n        // ... other routes\n      ],\n    })\n    return createErrorResponse('Not Found', 404)\n  },\n}\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\api-worker\\\\index.js\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\node_modules\\\\wrangler\\\\templates\\\\middleware\\\\middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\node_modules\\\\wrangler\\\\templates\\\\middleware\\\\middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\api-worker\\\\index.js\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\api-worker\\\\.wrangler\\\\tmp\\\\bundle-ie53cl\\\\middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\node_modules\\\\wrangler\\\\templates\\\\middleware\\\\common.ts\";\nimport type { WorkerEntrypointConstructor } from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\api-worker\\\\.wrangler\\\\tmp\\\\bundle-ie53cl\\\\middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"C:\\\\Users\\\\torar\\\\MyApps\\\\vegvisr-frontend\\\\api-worker\\\\.wrangler\\\\tmp\\\\bundle-ie53cl\\\\middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;AAGO,SAAS,eAAe;AAC3B,SAAO;IACH,OAAO;IACP,QAAQ;IACR,YAAY;IACZ,KAAK;IACL,OAAO;IACP,UAAU;IACV,UAAU;IACV,QAAQ;IACR,WAAW;IACX,YAAY;EACpB;AACA;AAbgB;AAcN,IAAC,YAAY,aAAY;AAC5B,SAAS,eAAe,aAAa;AACxC,cAAY;AAChB;AAFgB;AClBhB,IAAM,WAAW,EAAE,MAAM,6BAAM,MAAN,QAAU;AACnC,SAAS,KAAK,OAAO,MAAM,IAAI;AAC3B,MAAI,SAAS,OAAO,UAAU,WAAW,QAAQ,MAAM;AACvD,QAAM,MAAM;IACR,SAAS,wBAAC,MAAM,QAAQ;AACpB,UAAI,YAAY,OAAO,QAAQ,WAAW,MAAM,IAAI;AACpD,kBAAY,UAAU,QAAQ,MAAM,OAAO,IAAI;AAC/C,eAAS,OAAO,QAAQ,MAAM,SAAS;AACvC,aAAO;IACnB,GALiB;IAMT,UAAU,6BAAM;AACZ,aAAO,IAAI,OAAO,QAAQ,GAAG;IACzC,GAFkB;EAGlB;AACI,SAAO;AACX;AAdS;AAeF,IAAM,QAAQ;EACjB,kBAAkB;EAClB,mBAAmB;EACnB,wBAAwB;EACxB,gBAAgB;EAChB,YAAY;EACZ,mBAAmB;EACnB,iBAAiB;EACjB,cAAc;EACd,mBAAmB;EACnB,eAAe;EACf,qBAAqB;EACrB,WAAW;EACX,iBAAiB;EACjB,iBAAiB;EACjB,yBAAyB;EACzB,0BAA0B;EAC1B,iBAAiB;EACjB,oBAAoB;EACpB,YAAY;EACZ,iBAAiB;EACjB,SAAS;EACT,cAAc;EACd,gBAAgB;EAChB,iBAAiB;EACjB,mBAAmB;EACnB,iBAAiB;EACjB,kBAAkB;EAClB,gBAAgB;EAChB,WAAW;EACX,SAAS;EACT,mBAAmB;EACnB,iBAAiB;EACjB,mBAAmB;EACnB,iBAAiB;EACjB,mBAAmB;EACnB,qBAAqB;EACrB,YAAY;EACZ,eAAe;EACf,oBAAoB;EACpB,uBAAuB;EACvB,cAAc;EACd,OAAO;EACP,eAAe;EACf,UAAU;EACV,WAAW;EACX,WAAW;EACX,gBAAgB;EAChB,WAAW;EACX,eAAe;EACf,eAAe;EACf,eAAe,wBAAC,SAAS,IAAI,OAAO,WAAW,IAAI,8BAA+B,GAAnE;EACf,iBAAiB,wBAAC,WAAW,IAAI,OAAO,QAAQ,KAAK,IAAI,GAAG,SAAS,CAAC,CAAC,oDAAqD,GAA3G;EACjB,SAAS,wBAAC,WAAW,IAAI,OAAO,QAAQ,KAAK,IAAI,GAAG,SAAS,CAAC,CAAC,oDAAoD,GAA1G;EACT,kBAAkB,wBAAC,WAAW,IAAI,OAAO,QAAQ,KAAK,IAAI,GAAG,SAAS,CAAC,CAAC,iBAAiB,GAAvE;EAClB,mBAAmB,wBAAC,WAAW,IAAI,OAAO,QAAQ,KAAK,IAAI,GAAG,SAAS,CAAC,CAAC,IAAI,GAA1D;EACnB,gBAAgB,wBAAC,WAAW,IAAI,OAAO,QAAQ,KAAK,IAAI,GAAG,SAAS,CAAC,CAAC,sBAAsB,GAAG,GAA/E;AACpB;AAIA,IAAM,UAAU;AAChB,IAAM,YAAY;AAClB,IAAM,SAAS;AACf,IAAM,KAAK;AACX,IAAM,UAAU;AAChB,IAAM,SAAS;AACf,IAAM,eAAe;AACrB,IAAM,WAAW,KAAK,YAAY,EAC7B,QAAQ,SAAS,MAAM,EACvB,QAAQ,cAAc,mBAAmB,EACzC,QAAQ,WAAW,uBAAuB,EAC1C,QAAQ,eAAe,SAAS,EAChC,QAAQ,YAAY,cAAc,EAClC,QAAQ,SAAS,mBAAmB,EACpC,QAAQ,YAAY,EAAE,EACtB,SAAQ;AACb,IAAM,cAAc,KAAK,YAAY,EAChC,QAAQ,SAAS,MAAM,EACvB,QAAQ,cAAc,mBAAmB,EACzC,QAAQ,WAAW,uBAAuB,EAC1C,QAAQ,eAAe,SAAS,EAChC,QAAQ,YAAY,cAAc,EAClC,QAAQ,SAAS,mBAAmB,EACpC,QAAQ,UAAU,mCAAmC,EACrD,SAAQ;AACb,IAAM,aAAa;AACnB,IAAM,YAAY;AAClB,IAAM,cAAc;AACpB,IAAM,MAAM,KAAK,6GAA6G,EACzH,QAAQ,SAAS,WAAW,EAC5B,QAAQ,SAAS,8DAA8D,EAC/E,SAAQ;AACb,IAAM,OAAO,KAAK,sCAAsC,EACnD,QAAQ,SAAS,MAAM,EACvB,SAAQ;AACb,IAAM,OAAO;AAMb,IAAM,WAAW;AACjB,IAAM,OAAO,KAAK,6dASP,GAAG,EACT,QAAQ,WAAW,QAAQ,EAC3B,QAAQ,OAAO,IAAI,EACnB,QAAQ,aAAa,0EAA0E,EAC/F,SAAQ;AACb,IAAM,YAAY,KAAK,UAAU,EAC5B,QAAQ,MAAM,EAAE,EAChB,QAAQ,WAAW,uBAAuB,EAC1C,QAAQ,aAAa,EAAE,EACvB,QAAQ,UAAU,EAAE,EACpB,QAAQ,cAAc,SAAS,EAC/B,QAAQ,UAAU,gDAAgD,EAClE,QAAQ,QAAQ,wBAAwB,EACxC,QAAQ,QAAQ,6DAA6D,EAC7E,QAAQ,OAAO,IAAI,EACnB,SAAQ;AACb,IAAM,aAAa,KAAK,yCAAyC,EAC5D,QAAQ,aAAa,SAAS,EAC9B,SAAQ;AAIb,IAAM,cAAc;EAChB;EACA,MAAM;EACN;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,OAAO;EACP,MAAM;AACV;AAIA,IAAM,WAAW,KAAK,6JAEsE,EACvF,QAAQ,MAAM,EAAE,EAChB,QAAQ,WAAW,uBAAuB,EAC1C,QAAQ,cAAc,SAAS,EAC/B,QAAQ,QAAQ,wBAAyB,EACzC,QAAQ,UAAU,gDAAgD,EAClE,QAAQ,QAAQ,wBAAwB,EACxC,QAAQ,QAAQ,6DAA6D,EAC7E,QAAQ,OAAO,IAAI,EACnB,SAAQ;AACb,IAAM,WAAW;EACb,GAAG;EACH,UAAU;EACV,OAAO;EACP,WAAW,KAAK,UAAU,EACrB,QAAQ,MAAM,EAAE,EAChB,QAAQ,WAAW,uBAAuB,EAC1C,QAAQ,aAAa,EAAE,EACvB,QAAQ,SAAS,QAAQ,EACzB,QAAQ,cAAc,SAAS,EAC/B,QAAQ,UAAU,gDAAgD,EAClE,QAAQ,QAAQ,wBAAwB,EACxC,QAAQ,QAAQ,6DAA6D,EAC7E,QAAQ,OAAO,IAAI,EACnB,SAAQ;AACjB;AAIA,IAAM,gBAAgB;EAClB,GAAG;EACH,MAAM,KAAK,wIAEiE,EACvE,QAAQ,WAAW,QAAQ,EAC3B,QAAQ,QAAQ,mKAGgB,EAChC,SAAQ;EACb,KAAK;EACL,SAAS;EACT,QAAQ;;EACR,UAAU;EACV,WAAW,KAAK,UAAU,EACrB,QAAQ,MAAM,EAAE,EAChB,QAAQ,WAAW,iBAAiB,EACpC,QAAQ,YAAY,QAAQ,EAC5B,QAAQ,UAAU,EAAE,EACpB,QAAQ,cAAc,SAAS,EAC/B,QAAQ,WAAW,EAAE,EACrB,QAAQ,SAAS,EAAE,EACnB,QAAQ,SAAS,EAAE,EACnB,QAAQ,QAAQ,EAAE,EAClB,SAAQ;AACjB;AAIA,IAAMA,WAAS;AACf,IAAM,aAAa;AACnB,IAAM,KAAK;AACX,IAAM,aAAa;AAEnB,IAAM,eAAe;AACrB,IAAM,sBAAsB;AAC5B,IAAM,yBAAyB;AAC/B,IAAM,cAAc,KAAK,yBAAyB,GAAG,EAChD,QAAQ,eAAe,mBAAmB,EAAE,SAAQ;AAEzD,IAAM,0BAA0B;AAChC,IAAM,iCAAiC;AACvC,IAAM,oCAAoC;AAE1C,IAAM,YAAY;AAClB,IAAM,qBAAqB;AAC3B,IAAM,iBAAiB,KAAK,oBAAoB,GAAG,EAC9C,QAAQ,UAAU,YAAY,EAC9B,SAAQ;AACb,IAAM,oBAAoB,KAAK,oBAAoB,GAAG,EACjD,QAAQ,UAAU,uBAAuB,EACzC,SAAQ;AACb,IAAM,wBAAwB;AAQ9B,IAAM,oBAAoB,KAAK,uBAAuB,IAAI,EACrD,QAAQ,kBAAkB,sBAAsB,EAChD,QAAQ,eAAe,mBAAmB,EAC1C,QAAQ,UAAU,YAAY,EAC9B,SAAQ;AACb,IAAM,uBAAuB,KAAK,uBAAuB,IAAI,EACxD,QAAQ,kBAAkB,iCAAiC,EAC3D,QAAQ,eAAe,8BAA8B,EACrD,QAAQ,UAAU,uBAAuB,EACzC,SAAQ;AAEb,IAAM,oBAAoB,KAAK,oNAMQ,IAAI,EACtC,QAAQ,kBAAkB,sBAAsB,EAChD,QAAQ,eAAe,mBAAmB,EAC1C,QAAQ,UAAU,YAAY,EAC9B,SAAQ;AACb,IAAM,iBAAiB,KAAK,aAAa,IAAI,EACxC,QAAQ,UAAU,YAAY,EAC9B,SAAQ;AACb,IAAM,WAAW,KAAK,qCAAqC,EACtD,QAAQ,UAAU,8BAA8B,EAChD,QAAQ,SAAS,8IAA8I,EAC/J,SAAQ;AACb,IAAM,iBAAiB,KAAK,QAAQ,EAAE,QAAQ,aAAa,KAAK,EAAE,SAAQ;AAC1E,IAAM,MAAM,KAAK,0JAKuB,EACnC,QAAQ,WAAW,cAAc,EACjC,QAAQ,aAAa,6EAA6E,EAClG,SAAQ;AACb,IAAM,eAAe;AACrB,IAAM,OAAO,KAAK,+CAA+C,EAC5D,QAAQ,SAAS,YAAY,EAC7B,QAAQ,QAAQ,sCAAsC,EACtD,QAAQ,SAAS,6DAA6D,EAC9E,SAAQ;AACb,IAAM,UAAU,KAAK,yBAAyB,EACzC,QAAQ,SAAS,YAAY,EAC7B,QAAQ,OAAO,WAAW,EAC1B,SAAQ;AACb,IAAM,SAAS,KAAK,uBAAuB,EACtC,QAAQ,OAAO,WAAW,EAC1B,SAAQ;AACb,IAAM,gBAAgB,KAAK,yBAAyB,GAAG,EAClD,QAAQ,WAAW,OAAO,EAC1B,QAAQ,UAAU,MAAM,EACxB,SAAQ;AAIb,IAAM,eAAe;EACjB,YAAY;;EACZ;EACA;EACA;EACA;EACA,MAAM;EACN,KAAK;EACL;EACA;EACA;EACJ,QAAIA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM;EACN,KAAK;AACT;AAIA,IAAM,iBAAiB;EACnB,GAAG;EACH,MAAM,KAAK,yBAAyB,EAC/B,QAAQ,SAAS,YAAY,EAC7B,SAAQ;EACb,SAAS,KAAK,+BAA+B,EACxC,QAAQ,SAAS,YAAY,EAC7B,SAAQ;AACjB;AAIA,IAAM,YAAY;EACd,GAAG;EACH,mBAAmB;EACnB,gBAAgB;EAChB,KAAK,KAAK,oEAAoE,GAAG,EAC5E,QAAQ,SAAS,2EAA2E,EAC5F,SAAQ;EACb,YAAY;EACZ,KAAK;EACL,MAAM;AACV;AAIA,IAAM,eAAe;EACjB,GAAG;EACH,IAAI,KAAK,EAAE,EAAE,QAAQ,QAAQ,GAAG,EAAE,SAAQ;EAC1C,MAAM,KAAK,UAAU,IAAI,EACpB,QAAQ,QAAQ,eAAe,EAC/B,QAAQ,WAAW,GAAG,EACtB,SAAQ;AACjB;AAIO,IAAM,QAAQ;EACjB,QAAQ;EACR,KAAK;EACL,UAAU;AACd;AACO,IAAM,SAAS;EAClB,QAAQ;EACR,KAAK;EACL,QAAQ;EACR,UAAU;AACd;AClYA,IAAM,qBAAqB;EACvB,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;AACT;AACA,IAAM,uBAAuB,wBAAC,OAAO,mBAAmB,EAAE,GAA7B;AACtB,SAASA,QAAOC,OAAMC,SAAQ;AACjC,MAAIA,SAAQ;AACR,QAAI,MAAM,WAAW,KAAKD,KAAI,GAAG;AAC7B,aAAOA,MAAK,QAAQ,MAAM,eAAe,oBAAoB;IACzE;EACA,OACS;AACD,QAAI,MAAM,mBAAmB,KAAKA,KAAI,GAAG;AACrC,aAAOA,MAAK,QAAQ,MAAM,uBAAuB,oBAAoB;IACjF;EACA;AACI,SAAOA;AACX;AAZgB,OAAAD,SAAA;AA2BT,SAAS,SAAS,MAAM;AAC3B,MAAI;AACA,WAAO,UAAU,IAAI,EAAE,QAAQ,MAAM,eAAe,GAAG;EAC/D,QACU;AACF,WAAO;EACf;AACI,SAAO;AACX;AARgB;AAST,SAAS,WAAW,UAAU,OAAO;AAGxC,QAAM,MAAM,SAAS,QAAQ,MAAM,UAAU,CAAC,OAAO,QAAQG,SAAQ;AACjE,QAAI,UAAU;AACd,QAAI,OAAO;AACX,WAAO,EAAE,QAAQ,KAAKA,KAAI,IAAI,MAAM;AAChC,gBAAU,CAAC;AACf,QAAI,SAAS;AAGT,aAAO;IACnB,OACa;AAED,aAAO;IACnB;EACA,CAAK,GAAG,QAAQ,IAAI,MAAM,MAAM,SAAS;AACrC,MAAI,IAAI;AAER,MAAI,CAAC,MAAM,CAAC,EAAE,KAAI,GAAI;AAClB,UAAM,MAAK;EACnB;AACI,MAAI,MAAM,SAAS,KAAK,CAAC,MAAM,GAAG,EAAE,GAAG,KAAI,GAAI;AAC3C,UAAM,IAAG;EACjB;AACI,MAAI,OAAO;AACP,QAAI,MAAM,SAAS,OAAO;AACtB,YAAM,OAAO,KAAK;IAC9B,OACa;AACD,aAAO,MAAM,SAAS;AAClB,cAAM,KAAK,EAAE;IAC7B;EACA;AACI,SAAO,IAAI,MAAM,QAAQ,KAAK;AAE1B,UAAM,CAAC,IAAI,MAAM,CAAC,EAAE,KAAI,EAAG,QAAQ,MAAM,WAAW,GAAG;EAC/D;AACI,SAAO;AACX;AAxCgB;AAiDT,SAAS,MAAMA,MAAK,GAAG,QAAQ;AAClC,QAAM,IAAIA,KAAI;AACd,MAAI,MAAM,GAAG;AACT,WAAO;EACf;AAEI,MAAI,UAAU;AAEd,SAAO,UAAU,GAAG;AAChB,UAAM,WAAWA,KAAI,OAAO,IAAI,UAAU,CAAC;AAC3C,QAAI,aAAa,KAAK,MAAS;AAC3B;IACZ,OAIa;AACD;IACZ;EACA;AACI,SAAOA,KAAI,MAAM,GAAG,IAAI,OAAO;AACnC;AArBgB;AAsBT,SAAS,mBAAmBA,MAAK,GAAG;AACvC,MAAIA,KAAI,QAAQ,EAAE,CAAC,CAAC,MAAM,IAAI;AAC1B,WAAO;EACf;AACI,MAAI,QAAQ;AACZ,WAAS,IAAI,GAAG,IAAIA,KAAI,QAAQ,KAAK;AACjC,QAAIA,KAAI,CAAC,MAAM,MAAM;AACjB;IACZ,WACiBA,KAAI,CAAC,MAAM,EAAE,CAAC,GAAG;AACtB;IACZ,WACiBA,KAAI,CAAC,MAAM,EAAE,CAAC,GAAG;AACtB;AACA,UAAI,QAAQ,GAAG;AACX,eAAO;MACvB;IACA;EACA;AACI,SAAO;AACX;AApBgB;ACrHhB,SAAS,WAAW,KAAKC,OAAM,KAAKC,QAAO,OAAO;AAC9C,QAAM,OAAOD,MAAK;AAClB,QAAM,QAAQA,MAAK,SAAS;AAC5B,QAAM,OAAO,IAAI,CAAC,EAAE,QAAQ,MAAM,MAAM,mBAAmB,IAAI;AAC/D,MAAI,IAAI,CAAC,EAAE,OAAO,CAAC,MAAM,KAAK;AAC1B,IAAAC,OAAM,MAAM,SAAS;AACrB,UAAM,QAAQ;MACV,MAAM;MACN;MACA;MACA;MACA;MACA,QAAQA,OAAM,aAAa,IAAI;IAC3C;AACQ,IAAAA,OAAM,MAAM,SAAS;AACrB,WAAO;EACf;AACI,SAAO;IACH,MAAM;IACN;IACA;IACA;IACA;EACR;AACA;AAxBS;AAyBT,SAAS,uBAAuB,KAAK,MAAM,OAAO;AAC9C,QAAM,oBAAoB,IAAI,MAAM,MAAM,MAAM,sBAAsB;AACtE,MAAI,sBAAsB,MAAM;AAC5B,WAAO;EACf;AACI,QAAM,eAAe,kBAAkB,CAAC;AACxC,SAAO,KACF,MAAM,IAAI,EACV,IAAI,UAAQ;AACb,UAAM,oBAAoB,KAAK,MAAM,MAAM,MAAM,cAAc;AAC/D,QAAI,sBAAsB,MAAM;AAC5B,aAAO;IACnB;AACQ,UAAM,CAAC,YAAY,IAAI;AACvB,QAAI,aAAa,UAAU,aAAa,QAAQ;AAC5C,aAAO,KAAK,MAAM,aAAa,MAAM;IACjD;AACQ,WAAO;EACf,CAAK,EACI,KAAK,IAAI;AAClB;AApBS;AAwBF,IAAM,aAAN,MAAiB;SAAA;;;EACpB;EACA;;EACA;;EACA,YAAYC,UAAS;AACjB,SAAK,UAAUA,YAAW;EAClC;EACI,MAAM,KAAK;AACP,UAAM,MAAM,KAAK,MAAM,MAAM,QAAQ,KAAK,GAAG;AAC7C,QAAI,OAAO,IAAI,CAAC,EAAE,SAAS,GAAG;AAC1B,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;MAC1B;IACA;EACA;EACI,KAAK,KAAK;AACN,UAAM,MAAM,KAAK,MAAM,MAAM,KAAK,KAAK,GAAG;AAC1C,QAAI,KAAK;AACL,YAAM,OAAO,IAAI,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,kBAAkB,EAAE;AACjE,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,gBAAgB;QAChB,MAAM,CAAC,KAAK,QAAQ,WACd,MAAM,MAAM,IAAI,IAChB;MACtB;IACA;EACA;EACI,OAAO,KAAK;AACR,UAAM,MAAM,KAAK,MAAM,MAAM,OAAO,KAAK,GAAG;AAC5C,QAAI,KAAK;AACL,YAAM,MAAM,IAAI,CAAC;AACjB,YAAM,OAAO,uBAAuB,KAAK,IAAI,CAAC,KAAK,IAAI,KAAK,KAAK;AACjE,aAAO;QACH,MAAM;QACN;QACA,MAAM,IAAI,CAAC,IAAI,IAAI,CAAC,EAAE,KAAI,EAAG,QAAQ,KAAK,MAAM,OAAO,gBAAgB,IAAI,IAAI,IAAI,CAAC;QACpF;MAChB;IACA;EACA;EACI,QAAQ,KAAK;AACT,UAAM,MAAM,KAAK,MAAM,MAAM,QAAQ,KAAK,GAAG;AAC7C,QAAI,KAAK;AACL,UAAI,OAAO,IAAI,CAAC,EAAE,KAAI;AAEtB,UAAI,KAAK,MAAM,MAAM,WAAW,KAAK,IAAI,GAAG;AACxC,cAAM,UAAU,MAAM,MAAM,GAAG;AAC/B,YAAI,KAAK,QAAQ,UAAU;AACvB,iBAAO,QAAQ,KAAI;QACvC,WACyB,CAAC,WAAW,KAAK,MAAM,MAAM,gBAAgB,KAAK,OAAO,GAAG;AAEjE,iBAAO,QAAQ,KAAI;QACvC;MACA;AACY,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,OAAO,IAAI,CAAC,EAAE;QACd;QACA,QAAQ,KAAK,MAAM,OAAO,IAAI;MAC9C;IACA;EACA;EACI,GAAG,KAAK;AACJ,UAAM,MAAM,KAAK,MAAM,MAAM,GAAG,KAAK,GAAG;AACxC,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,MAAM,IAAI,CAAC,GAAG,IAAI;MACvC;IACA;EACA;EACI,WAAW,KAAK;AACZ,UAAM,MAAM,KAAK,MAAM,MAAM,WAAW,KAAK,GAAG;AAChD,QAAI,KAAK;AACL,UAAI,QAAQ,MAAM,IAAI,CAAC,GAAG,IAAI,EAAE,MAAM,IAAI;AAC1C,UAAI,MAAM;AACV,UAAI,OAAO;AACX,YAAM,SAAS,CAAA;AACf,aAAO,MAAM,SAAS,GAAG;AACrB,YAAI,eAAe;AACnB,cAAM,eAAe,CAAA;AACrB,YAAI;AACJ,aAAK,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AAE/B,cAAI,KAAK,MAAM,MAAM,gBAAgB,KAAK,MAAM,CAAC,CAAC,GAAG;AACjD,yBAAa,KAAK,MAAM,CAAC,CAAC;AAC1B,2BAAe;UACvC,WAC6B,CAAC,cAAc;AACpB,yBAAa,KAAK,MAAM,CAAC,CAAC;UAClD,OACyB;AACD;UACxB;QACA;AACgB,gBAAQ,MAAM,MAAM,CAAC;AACrB,cAAM,aAAa,aAAa,KAAK,IAAI;AACzC,cAAM,cAAc,WAEf,QAAQ,KAAK,MAAM,MAAM,yBAAyB,UAAU,EAC5D,QAAQ,KAAK,MAAM,MAAM,0BAA0B,EAAE;AAC1D,cAAM,MAAM,GAAG,GAAG;EAAK,UAAU,KAAK;AACtC,eAAO,OAAO,GAAG,IAAI;EAAK,WAAW,KAAK;AAG1C,cAAM,MAAM,KAAK,MAAM,MAAM;AAC7B,aAAK,MAAM,MAAM,MAAM;AACvB,aAAK,MAAM,YAAY,aAAa,QAAQ,IAAI;AAChD,aAAK,MAAM,MAAM,MAAM;AAEvB,YAAI,MAAM,WAAW,GAAG;AACpB;QACpB;AACgB,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,WAAW,SAAS,QAAQ;AAE5B;QACpB,WACyB,WAAW,SAAS,cAAc;AAEvC,gBAAM,WAAW;AACjB,gBAAM,UAAU,SAAS,MAAM,OAAO,MAAM,KAAK,IAAI;AACrD,gBAAM,WAAW,KAAK,WAAW,OAAO;AACxC,iBAAO,OAAO,SAAS,CAAC,IAAI;AAC5B,gBAAM,IAAI,UAAU,GAAG,IAAI,SAAS,SAAS,IAAI,MAAM,IAAI,SAAS;AACpE,iBAAO,KAAK,UAAU,GAAG,KAAK,SAAS,SAAS,KAAK,MAAM,IAAI,SAAS;AACxE;QACpB,WACyB,WAAW,SAAS,QAAQ;AAEjC,gBAAM,WAAW;AACjB,gBAAM,UAAU,SAAS,MAAM,OAAO,MAAM,KAAK,IAAI;AACrD,gBAAM,WAAW,KAAK,KAAK,OAAO;AAClC,iBAAO,OAAO,SAAS,CAAC,IAAI;AAC5B,gBAAM,IAAI,UAAU,GAAG,IAAI,SAAS,UAAU,IAAI,MAAM,IAAI,SAAS;AACrE,iBAAO,KAAK,UAAU,GAAG,KAAK,SAAS,SAAS,IAAI,MAAM,IAAI,SAAS;AACvE,kBAAQ,QAAQ,UAAU,OAAO,GAAG,EAAE,EAAE,IAAI,MAAM,EAAE,MAAM,IAAI;AAC9D;QACpB;MACA;AACY,aAAO;QACH,MAAM;QACN;QACA;QACA;MAChB;IACA;EACA;EACI,KAAK,KAAK;AACN,QAAI,MAAM,KAAK,MAAM,MAAM,KAAK,KAAK,GAAG;AACxC,QAAI,KAAK;AACL,UAAI,OAAO,IAAI,CAAC,EAAE,KAAI;AACtB,YAAM,YAAY,KAAK,SAAS;AAChC,YAAMC,QAAO;QACT,MAAM;QACN,KAAK;QACL,SAAS;QACT,OAAO,YAAY,CAAC,KAAK,MAAM,GAAG,EAAE,IAAI;QACxC,OAAO;QACP,OAAO,CAAA;MACvB;AACY,aAAO,YAAY,aAAa,KAAK,MAAM,EAAE,CAAC,KAAK,KAAK,IAAI;AAC5D,UAAI,KAAK,QAAQ,UAAU;AACvB,eAAO,YAAY,OAAO;MAC1C;AAEY,YAAM,YAAY,KAAK,MAAM,MAAM,cAAc,IAAI;AACrD,UAAI,oBAAoB;AAExB,aAAO,KAAK;AACR,YAAI,WAAW;AACf,YAAI,MAAM;AACV,YAAI,eAAe;AACnB,YAAI,EAAE,MAAM,UAAU,KAAK,GAAG,IAAI;AAC9B;QACpB;AACgB,YAAI,KAAK,MAAM,MAAM,GAAG,KAAK,GAAG,GAAG;AAC/B;QACpB;AACgB,cAAM,IAAI,CAAC;AACX,cAAM,IAAI,UAAU,IAAI,MAAM;AAC9B,YAAI,OAAO,IAAI,CAAC,EAAE,MAAM,MAAM,CAAC,EAAE,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,iBAAiB,CAAC,MAAM,IAAI,OAAO,IAAI,EAAE,MAAM,CAAC;AAC7G,YAAI,WAAW,IAAI,MAAM,MAAM,CAAC,EAAE,CAAC;AACnC,YAAI,YAAY,CAAC,KAAK,KAAI;AAC1B,YAAI,SAAS;AACb,YAAI,KAAK,QAAQ,UAAU;AACvB,mBAAS;AACT,yBAAe,KAAK,UAAS;QACjD,WACyB,WAAW;AAChB,mBAAS,IAAI,CAAC,EAAE,SAAS;QAC7C,OACqB;AACD,mBAAS,IAAI,CAAC,EAAE,OAAO,KAAK,MAAM,MAAM,YAAY;AACpD,mBAAS,SAAS,IAAI,IAAI;AAC1B,yBAAe,KAAK,MAAM,MAAM;AAChC,oBAAU,IAAI,CAAC,EAAE;QACrC;AACgB,YAAI,aAAa,KAAK,MAAM,MAAM,UAAU,KAAK,QAAQ,GAAG;AACxD,iBAAO,WAAW;AAClB,gBAAM,IAAI,UAAU,SAAS,SAAS,CAAC;AACvC,qBAAW;QAC/B;AACgB,YAAI,CAAC,UAAU;AACX,gBAAM,kBAAkB,KAAK,MAAM,MAAM,gBAAgB,MAAM;AAC/D,gBAAM,UAAU,KAAK,MAAM,MAAM,QAAQ,MAAM;AAC/C,gBAAM,mBAAmB,KAAK,MAAM,MAAM,iBAAiB,MAAM;AACjE,gBAAM,oBAAoB,KAAK,MAAM,MAAM,kBAAkB,MAAM;AACnE,gBAAM,iBAAiB,KAAK,MAAM,MAAM,eAAe,MAAM;AAE7D,iBAAO,KAAK;AACR,kBAAM,UAAU,IAAI,MAAM,MAAM,CAAC,EAAE,CAAC;AACpC,gBAAI;AACJ,uBAAW;AAEX,gBAAI,KAAK,QAAQ,UAAU;AACvB,yBAAW,SAAS,QAAQ,KAAK,MAAM,MAAM,oBAAoB,IAAI;AACrE,oCAAsB;YAClD,OAC6B;AACD,oCAAsB,SAAS,QAAQ,KAAK,MAAM,MAAM,eAAe,MAAM;YACzG;AAEwB,gBAAI,iBAAiB,KAAK,QAAQ,GAAG;AACjC;YAC5B;AAEwB,gBAAI,kBAAkB,KAAK,QAAQ,GAAG;AAClC;YAC5B;AAEwB,gBAAI,eAAe,KAAK,QAAQ,GAAG;AAC/B;YAC5B;AAEwB,gBAAI,gBAAgB,KAAK,QAAQ,GAAG;AAChC;YAC5B;AAEwB,gBAAI,QAAQ,KAAK,QAAQ,GAAG;AACxB;YAC5B;AACwB,gBAAI,oBAAoB,OAAO,KAAK,MAAM,MAAM,YAAY,KAAK,UAAU,CAAC,SAAS,KAAI,GAAI;AACzF,8BAAgB,OAAO,oBAAoB,MAAM,MAAM;YACnF,OAC6B;AAED,kBAAI,WAAW;AACX;cAChC;AAE4B,kBAAI,KAAK,QAAQ,KAAK,MAAM,MAAM,eAAe,MAAM,EAAE,OAAO,KAAK,MAAM,MAAM,YAAY,KAAK,GAAG;AACjG;cAChC;AAC4B,kBAAI,iBAAiB,KAAK,IAAI,GAAG;AAC7B;cAChC;AAC4B,kBAAI,kBAAkB,KAAK,IAAI,GAAG;AAC9B;cAChC;AAC4B,kBAAI,QAAQ,KAAK,IAAI,GAAG;AACpB;cAChC;AAC4B,8BAAgB,OAAO;YACnD;AACwB,gBAAI,CAAC,aAAa,CAAC,SAAS,KAAI,GAAI;AAChC,0BAAY;YACxC;AACwB,mBAAO,UAAU;AACjB,kBAAM,IAAI,UAAU,QAAQ,SAAS,CAAC;AACtC,mBAAO,oBAAoB,MAAM,MAAM;UAC/D;QACA;AACgB,YAAI,CAACA,MAAK,OAAO;AAEb,cAAI,mBAAmB;AACnB,YAAAA,MAAK,QAAQ;UACrC,WAC6B,KAAK,MAAM,MAAM,gBAAgB,KAAK,GAAG,GAAG;AACjD,gCAAoB;UAC5C;QACA;AACgB,YAAI,SAAS;AACb,YAAI;AAEJ,YAAI,KAAK,QAAQ,KAAK;AAClB,mBAAS,KAAK,MAAM,MAAM,WAAW,KAAK,YAAY;AACtD,cAAI,QAAQ;AACR,wBAAY,OAAO,CAAC,MAAM;AAC1B,2BAAe,aAAa,QAAQ,KAAK,MAAM,MAAM,iBAAiB,EAAE;UAChG;QACA;AACgB,QAAAA,MAAK,MAAM,KAAK;UACZ,MAAM;UACN;UACA,MAAM,CAAC,CAAC;UACR,SAAS;UACT,OAAO;UACP,MAAM;UACN,QAAQ,CAAA;QAC5B,CAAiB;AACD,QAAAA,MAAK,OAAO;MAC5B;AAEY,YAAM,WAAWA,MAAK,MAAM,GAAG,EAAE;AACjC,UAAI,UAAU;AACV,iBAAS,MAAM,SAAS,IAAI,QAAO;AACnC,iBAAS,OAAO,SAAS,KAAK,QAAO;MACrD,OACiB;AAED;MAChB;AACY,MAAAA,MAAK,MAAMA,MAAK,IAAI,QAAO;AAE3B,eAAS,IAAI,GAAG,IAAIA,MAAK,MAAM,QAAQ,KAAK;AACxC,aAAK,MAAM,MAAM,MAAM;AACvB,QAAAA,MAAK,MAAM,CAAC,EAAE,SAAS,KAAK,MAAM,YAAYA,MAAK,MAAM,CAAC,EAAE,MAAM,CAAA,CAAE;AACpE,YAAI,CAACA,MAAK,OAAO;AAEb,gBAAM,UAAUA,MAAK,MAAM,CAAC,EAAE,OAAO,OAAO,OAAK,EAAE,SAAS,OAAO;AACnE,gBAAM,wBAAwB,QAAQ,SAAS,KAAK,QAAQ,KAAK,OAAK,KAAK,MAAM,MAAM,QAAQ,KAAK,EAAE,GAAG,CAAC;AAC1G,UAAAA,MAAK,QAAQ;QACjC;MACA;AAEY,UAAIA,MAAK,OAAO;AACZ,iBAAS,IAAI,GAAG,IAAIA,MAAK,MAAM,QAAQ,KAAK;AACxC,UAAAA,MAAK,MAAM,CAAC,EAAE,QAAQ;QAC1C;MACA;AACY,aAAOA;IACnB;EACA;EACI,KAAK,KAAK;AACN,UAAM,MAAM,KAAK,MAAM,MAAM,KAAK,KAAK,GAAG;AAC1C,QAAI,KAAK;AACL,YAAM,QAAQ;QACV,MAAM;QACN,OAAO;QACP,KAAK,IAAI,CAAC;QACV,KAAK,IAAI,CAAC,MAAM,SAAS,IAAI,CAAC,MAAM,YAAY,IAAI,CAAC,MAAM;QAC3D,MAAM,IAAI,CAAC;MAC3B;AACY,aAAO;IACnB;EACA;EACI,IAAI,KAAK;AACL,UAAM,MAAM,KAAK,MAAM,MAAM,IAAI,KAAK,GAAG;AACzC,QAAI,KAAK;AACL,YAAMC,OAAM,IAAI,CAAC,EAAE,YAAW,EAAG,QAAQ,KAAK,MAAM,MAAM,qBAAqB,GAAG;AAClF,YAAM,OAAO,IAAI,CAAC,IAAI,IAAI,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,cAAc,IAAI,EAAE,QAAQ,KAAK,MAAM,OAAO,gBAAgB,IAAI,IAAI;AAC5H,YAAM,QAAQ,IAAI,CAAC,IAAI,IAAI,CAAC,EAAE,UAAU,GAAG,IAAI,CAAC,EAAE,SAAS,CAAC,EAAE,QAAQ,KAAK,MAAM,OAAO,gBAAgB,IAAI,IAAI,IAAI,CAAC;AACrH,aAAO;QACH,MAAM;QACN,KAAAA;QACA,KAAK,IAAI,CAAC;QACV;QACA;MAChB;IACA;EACA;EACI,MAAM,KAAK;AACP,UAAM,MAAM,KAAK,MAAM,MAAM,MAAM,KAAK,GAAG;AAC3C,QAAI,CAAC,KAAK;AACN;IACZ;AACQ,QAAI,CAAC,KAAK,MAAM,MAAM,eAAe,KAAK,IAAI,CAAC,CAAC,GAAG;AAE/C;IACZ;AACQ,UAAM,UAAU,WAAW,IAAI,CAAC,CAAC;AACjC,UAAM,SAAS,IAAI,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,iBAAiB,EAAE,EAAE,MAAM,GAAG;AAC7E,UAAM,OAAO,IAAI,CAAC,GAAG,KAAI,IAAK,IAAI,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,mBAAmB,EAAE,EAAE,MAAM,IAAI,IAAI,CAAA;AACnG,UAAM,OAAO;MACT,MAAM;MACN,KAAK,IAAI,CAAC;MACV,QAAQ,CAAA;MACR,OAAO,CAAA;MACP,MAAM,CAAA;IAClB;AACQ,QAAI,QAAQ,WAAW,OAAO,QAAQ;AAElC;IACZ;AACQ,eAAW,SAAS,QAAQ;AACxB,UAAI,KAAK,MAAM,MAAM,gBAAgB,KAAK,KAAK,GAAG;AAC9C,aAAK,MAAM,KAAK,OAAO;MACvC,WACqB,KAAK,MAAM,MAAM,iBAAiB,KAAK,KAAK,GAAG;AACpD,aAAK,MAAM,KAAK,QAAQ;MACxC,WACqB,KAAK,MAAM,MAAM,eAAe,KAAK,KAAK,GAAG;AAClD,aAAK,MAAM,KAAK,MAAM;MACtC,OACiB;AACD,aAAK,MAAM,KAAK,IAAI;MACpC;IACA;AACQ,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACrC,WAAK,OAAO,KAAK;QACb,MAAM,QAAQ,CAAC;QACf,QAAQ,KAAK,MAAM,OAAO,QAAQ,CAAC,CAAC;QACpC,QAAQ;QACR,OAAO,KAAK,MAAM,CAAC;MACnC,CAAa;IACb;AACQ,eAAW,OAAO,MAAM;AACpB,WAAK,KAAK,KAAK,WAAW,KAAK,KAAK,OAAO,MAAM,EAAE,IAAI,CAAC,MAAM,MAAM;AAChE,eAAO;UACH,MAAM;UACN,QAAQ,KAAK,MAAM,OAAO,IAAI;UAC9B,QAAQ;UACR,OAAO,KAAK,MAAM,CAAC;QACvC;MACA,CAAa,CAAC;IACd;AACQ,WAAO;EACf;EACI,SAAS,KAAK;AACV,UAAM,MAAM,KAAK,MAAM,MAAM,SAAS,KAAK,GAAG;AAC9C,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,OAAO,IAAI,CAAC,EAAE,OAAO,CAAC,MAAM,MAAM,IAAI;QACtC,MAAM,IAAI,CAAC;QACX,QAAQ,KAAK,MAAM,OAAO,IAAI,CAAC,CAAC;MAChD;IACA;EACA;EACI,UAAU,KAAK;AACX,UAAM,MAAM,KAAK,MAAM,MAAM,UAAU,KAAK,GAAG;AAC/C,QAAI,KAAK;AACL,YAAM,OAAO,IAAI,CAAC,EAAE,OAAO,IAAI,CAAC,EAAE,SAAS,CAAC,MAAM,OAC5C,IAAI,CAAC,EAAE,MAAM,GAAG,EAAE,IAClB,IAAI,CAAC;AACX,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV;QACA,QAAQ,KAAK,MAAM,OAAO,IAAI;MAC9C;IACA;EACA;EACI,KAAK,KAAK;AACN,UAAM,MAAM,KAAK,MAAM,MAAM,KAAK,KAAK,GAAG;AAC1C,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,MAAM,IAAI,CAAC;QACX,QAAQ,KAAK,MAAM,OAAO,IAAI,CAAC,CAAC;MAChD;IACA;EACA;EACI,OAAO,KAAK;AACR,UAAM,MAAM,KAAK,MAAM,OAAO,OAAO,KAAK,GAAG;AAC7C,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,MAAM,IAAI,CAAC;MAC3B;IACA;EACA;EACI,IAAI,KAAK;AACL,UAAM,MAAM,KAAK,MAAM,OAAO,IAAI,KAAK,GAAG;AAC1C,QAAI,KAAK;AACL,UAAI,CAAC,KAAK,MAAM,MAAM,UAAU,KAAK,MAAM,MAAM,UAAU,KAAK,IAAI,CAAC,CAAC,GAAG;AACrE,aAAK,MAAM,MAAM,SAAS;MAC1C,WACqB,KAAK,MAAM,MAAM,UAAU,KAAK,MAAM,MAAM,QAAQ,KAAK,IAAI,CAAC,CAAC,GAAG;AACvE,aAAK,MAAM,MAAM,SAAS;MAC1C;AACY,UAAI,CAAC,KAAK,MAAM,MAAM,cAAc,KAAK,MAAM,MAAM,kBAAkB,KAAK,IAAI,CAAC,CAAC,GAAG;AACjF,aAAK,MAAM,MAAM,aAAa;MAC9C,WACqB,KAAK,MAAM,MAAM,cAAc,KAAK,MAAM,MAAM,gBAAgB,KAAK,IAAI,CAAC,CAAC,GAAG;AACnF,aAAK,MAAM,MAAM,aAAa;MAC9C;AACY,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,QAAQ,KAAK,MAAM,MAAM;QACzB,YAAY,KAAK,MAAM,MAAM;QAC7B,OAAO;QACP,MAAM,IAAI,CAAC;MAC3B;IACA;EACA;EACI,KAAK,KAAK;AACN,UAAM,MAAM,KAAK,MAAM,OAAO,KAAK,KAAK,GAAG;AAC3C,QAAI,KAAK;AACL,YAAM,aAAa,IAAI,CAAC,EAAE,KAAI;AAC9B,UAAI,CAAC,KAAK,QAAQ,YAAY,KAAK,MAAM,MAAM,kBAAkB,KAAK,UAAU,GAAG;AAE/E,YAAI,CAAE,KAAK,MAAM,MAAM,gBAAgB,KAAK,UAAU,GAAI;AACtD;QACpB;AAEgB,cAAM,aAAa,MAAM,WAAW,MAAM,GAAG,EAAE,GAAG,IAAI;AACtD,aAAK,WAAW,SAAS,WAAW,UAAU,MAAM,GAAG;AACnD;QACpB;MACA,OACiB;AAED,cAAM,iBAAiB,mBAAmB,IAAI,CAAC,GAAG,IAAI;AACtD,YAAI,iBAAiB,IAAI;AACrB,gBAAM,QAAQ,IAAI,CAAC,EAAE,QAAQ,GAAG,MAAM,IAAI,IAAI;AAC9C,gBAAM,UAAU,QAAQ,IAAI,CAAC,EAAE,SAAS;AACxC,cAAI,CAAC,IAAI,IAAI,CAAC,EAAE,UAAU,GAAG,cAAc;AAC3C,cAAI,CAAC,IAAI,IAAI,CAAC,EAAE,UAAU,GAAG,OAAO,EAAE,KAAI;AAC1C,cAAI,CAAC,IAAI;QAC7B;MACA;AACY,UAAI,OAAO,IAAI,CAAC;AAChB,UAAI,QAAQ;AACZ,UAAI,KAAK,QAAQ,UAAU;AAEvB,cAAMJ,QAAO,KAAK,MAAM,MAAM,kBAAkB,KAAK,IAAI;AACzD,YAAIA,OAAM;AACN,iBAAOA,MAAK,CAAC;AACb,kBAAQA,MAAK,CAAC;QAClC;MACA,OACiB;AACD,gBAAQ,IAAI,CAAC,IAAI,IAAI,CAAC,EAAE,MAAM,GAAG,EAAE,IAAI;MACvD;AACY,aAAO,KAAK,KAAI;AAChB,UAAI,KAAK,MAAM,MAAM,kBAAkB,KAAK,IAAI,GAAG;AAC/C,YAAI,KAAK,QAAQ,YAAY,CAAE,KAAK,MAAM,MAAM,gBAAgB,KAAK,UAAU,GAAI;AAE/E,iBAAO,KAAK,MAAM,CAAC;QACvC,OACqB;AACD,iBAAO,KAAK,MAAM,GAAG,EAAE;QAC3C;MACA;AACY,aAAO,WAAW,KAAK;QACnB,MAAM,OAAO,KAAK,QAAQ,KAAK,MAAM,OAAO,gBAAgB,IAAI,IAAI;QACpE,OAAO,QAAQ,MAAM,QAAQ,KAAK,MAAM,OAAO,gBAAgB,IAAI,IAAI;MACvF,GAAe,IAAI,CAAC,GAAG,KAAK,OAAO,KAAK,KAAK;IAC7C;EACA;EACI,QAAQ,KAAK,OAAO;AAChB,QAAI;AACJ,SAAK,MAAM,KAAK,MAAM,OAAO,QAAQ,KAAK,GAAG,OACrC,MAAM,KAAK,MAAM,OAAO,OAAO,KAAK,GAAG,IAAI;AAC/C,YAAM,cAAc,IAAI,CAAC,KAAK,IAAI,CAAC,GAAG,QAAQ,KAAK,MAAM,MAAM,qBAAqB,GAAG;AACvF,YAAMA,QAAO,MAAM,WAAW,YAAW,CAAE;AAC3C,UAAI,CAACA,OAAM;AACP,cAAM,OAAO,IAAI,CAAC,EAAE,OAAO,CAAC;AAC5B,eAAO;UACH,MAAM;UACN,KAAK;UACL;QACpB;MACA;AACY,aAAO,WAAW,KAAKA,OAAM,IAAI,CAAC,GAAG,KAAK,OAAO,KAAK,KAAK;IACvE;EACA;EACI,SAAS,KAAK,WAAW,WAAW,IAAI;AACpC,QAAI,QAAQ,KAAK,MAAM,OAAO,eAAe,KAAK,GAAG;AACrD,QAAI,CAAC;AACD;AAEJ,QAAI,MAAM,CAAC,KAAK,SAAS,MAAM,KAAK,MAAM,MAAM,mBAAmB;AAC/D;AACJ,UAAM,WAAW,MAAM,CAAC,KAAK,MAAM,CAAC,KAAK;AACzC,QAAI,CAAC,YAAY,CAAC,YAAY,KAAK,MAAM,OAAO,YAAY,KAAK,QAAQ,GAAG;AAExE,YAAM,UAAU,CAAC,GAAG,MAAM,CAAC,CAAC,EAAE,SAAS;AACvC,UAAI,QAAQ,SAAS,aAAa,SAAS,gBAAgB;AAC3D,YAAM,SAAS,MAAM,CAAC,EAAE,CAAC,MAAM,MAAM,KAAK,MAAM,OAAO,oBAAoB,KAAK,MAAM,OAAO;AAC7F,aAAO,YAAY;AAEnB,kBAAY,UAAU,MAAM,KAAK,IAAI,SAAS,OAAO;AACrD,cAAQ,QAAQ,OAAO,KAAK,SAAS,MAAM,MAAM;AAC7C,iBAAS,MAAM,CAAC,KAAK,MAAM,CAAC,KAAK,MAAM,CAAC,KAAK,MAAM,CAAC,KAAK,MAAM,CAAC,KAAK,MAAM,CAAC;AAC5E,YAAI,CAAC;AACD;AACJ,kBAAU,CAAC,GAAG,MAAM,EAAE;AACtB,YAAI,MAAM,CAAC,KAAK,MAAM,CAAC,GAAG;AACtB,wBAAc;AACd;QACpB,WACyB,MAAM,CAAC,KAAK,MAAM,CAAC,GAAG;AAC3B,cAAI,UAAU,KAAK,GAAG,UAAU,WAAW,IAAI;AAC3C,6BAAiB;AACjB;UACxB;QACA;AACgB,sBAAc;AACd,YAAI,aAAa;AACb;AAEJ,kBAAU,KAAK,IAAI,SAAS,UAAU,aAAa,aAAa;AAEhE,cAAM,iBAAiB,CAAC,GAAG,MAAM,CAAC,CAAC,EAAE,CAAC,EAAE;AACxC,cAAM,MAAM,IAAI,MAAM,GAAG,UAAU,MAAM,QAAQ,iBAAiB,OAAO;AAEzE,YAAI,KAAK,IAAI,SAAS,OAAO,IAAI,GAAG;AAChC,gBAAMK,QAAO,IAAI,MAAM,GAAG,EAAE;AAC5B,iBAAO;YACH,MAAM;YACN;YACA,MAAAA;YACA,QAAQ,KAAK,MAAM,aAAaA,KAAI;UAC5D;QACA;AAEgB,cAAM,OAAO,IAAI,MAAM,GAAG,EAAE;AAC5B,eAAO;UACH,MAAM;UACN;UACA;UACA,QAAQ,KAAK,MAAM,aAAa,IAAI;QACxD;MACA;IACA;EACA;EACI,SAAS,KAAK;AACV,UAAM,MAAM,KAAK,MAAM,OAAO,KAAK,KAAK,GAAG;AAC3C,QAAI,KAAK;AACL,UAAI,OAAO,IAAI,CAAC,EAAE,QAAQ,KAAK,MAAM,MAAM,mBAAmB,GAAG;AACjE,YAAM,mBAAmB,KAAK,MAAM,MAAM,aAAa,KAAK,IAAI;AAChE,YAAM,0BAA0B,KAAK,MAAM,MAAM,kBAAkB,KAAK,IAAI,KAAK,KAAK,MAAM,MAAM,gBAAgB,KAAK,IAAI;AAC3H,UAAI,oBAAoB,yBAAyB;AAC7C,eAAO,KAAK,UAAU,GAAG,KAAK,SAAS,CAAC;MACxD;AACY,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV;MAChB;IACA;EACA;EACI,GAAG,KAAK;AACJ,UAAM,MAAM,KAAK,MAAM,OAAO,GAAG,KAAK,GAAG;AACzC,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;MAC1B;IACA;EACA;EACI,IAAI,KAAK;AACL,UAAM,MAAM,KAAK,MAAM,OAAO,IAAI,KAAK,GAAG;AAC1C,QAAI,KAAK;AACL,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,MAAM,IAAI,CAAC;QACX,QAAQ,KAAK,MAAM,aAAa,IAAI,CAAC,CAAC;MACtD;IACA;EACA;EACI,SAAS,KAAK;AACV,UAAM,MAAM,KAAK,MAAM,OAAO,SAAS,KAAK,GAAG;AAC/C,QAAI,KAAK;AACL,UAAI,MAAM;AACV,UAAI,IAAI,CAAC,MAAM,KAAK;AAChB,eAAO,IAAI,CAAC;AACZ,eAAO,YAAY;MACnC,OACiB;AACD,eAAO,IAAI,CAAC;AACZ,eAAO;MACvB;AACY,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV;QACA;QACA,QAAQ;UACJ;YACI,MAAM;YACN,KAAK;YACL;UACxB;QACA;MACA;IACA;EACA;EACI,IAAI,KAAK;AACL,QAAI;AACJ,QAAI,MAAM,KAAK,MAAM,OAAO,IAAI,KAAK,GAAG,GAAG;AACvC,UAAI,MAAM;AACV,UAAI,IAAI,CAAC,MAAM,KAAK;AAChB,eAAO,IAAI,CAAC;AACZ,eAAO,YAAY;MACnC,OACiB;AAED,YAAI;AACJ,WAAG;AACC,wBAAc,IAAI,CAAC;AACnB,cAAI,CAAC,IAAI,KAAK,MAAM,OAAO,WAAW,KAAK,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK;QAC/E,SAAyB,gBAAgB,IAAI,CAAC;AAC9B,eAAO,IAAI,CAAC;AACZ,YAAI,IAAI,CAAC,MAAM,QAAQ;AACnB,iBAAO,YAAY,IAAI,CAAC;QAC5C,OACqB;AACD,iBAAO,IAAI,CAAC;QAChC;MACA;AACY,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV;QACA;QACA,QAAQ;UACJ;YACI,MAAM;YACN,KAAK;YACL;UACxB;QACA;MACA;IACA;EACA;EACI,WAAW,KAAK;AACZ,UAAM,MAAM,KAAK,MAAM,OAAO,KAAK,KAAK,GAAG;AAC3C,QAAI,KAAK;AACL,YAAM,UAAU,KAAK,MAAM,MAAM;AACjC,aAAO;QACH,MAAM;QACN,KAAK,IAAI,CAAC;QACV,MAAM,IAAI,CAAC;QACX;MAChB;IACA;EACA;AACA;AClxBO,IAAM,SAAN,MAAM,QAAO;SAAA;;;EAChB;EACA;EACA;EACA;EACA;EACA,YAAYH,UAAS;AAEjB,SAAK,SAAS,CAAA;AACd,SAAK,OAAO,QAAQ,uBAAO,OAAO,IAAI;AACtC,SAAK,UAAUA,YAAW;AAC1B,SAAK,QAAQ,YAAY,KAAK,QAAQ,aAAa,IAAI,WAAU;AACjE,SAAK,YAAY,KAAK,QAAQ;AAC9B,SAAK,UAAU,UAAU,KAAK;AAC9B,SAAK,UAAU,QAAQ;AACvB,SAAK,cAAc,CAAA;AACnB,SAAK,QAAQ;MACT,QAAQ;MACR,YAAY;MACZ,KAAK;IACjB;AACQ,UAAM,QAAQ;MACV;MACA,OAAO,MAAM;MACb,QAAQ,OAAO;IAC3B;AACQ,QAAI,KAAK,QAAQ,UAAU;AACvB,YAAM,QAAQ,MAAM;AACpB,YAAM,SAAS,OAAO;IAClC,WACiB,KAAK,QAAQ,KAAK;AACvB,YAAM,QAAQ,MAAM;AACpB,UAAI,KAAK,QAAQ,QAAQ;AACrB,cAAM,SAAS,OAAO;MACtC,OACiB;AACD,cAAM,SAAS,OAAO;MACtC;IACA;AACQ,SAAK,UAAU,QAAQ;EAC/B;;;;EAII,WAAW,QAAQ;AACf,WAAO;MACH;MACA;IACZ;EACA;;;;EAII,OAAO,IAAI,KAAKA,UAAS;AACrB,UAAMD,SAAQ,IAAI,QAAOC,QAAO;AAChC,WAAOD,OAAM,IAAI,GAAG;EAC5B;;;;EAII,OAAO,UAAU,KAAKC,UAAS;AAC3B,UAAMD,SAAQ,IAAI,QAAOC,QAAO;AAChC,WAAOD,OAAM,aAAa,GAAG;EACrC;;;;EAII,IAAI,KAAK;AACL,UAAM,IAAI,QAAQ,MAAM,gBAAgB,IAAI;AAC5C,SAAK,YAAY,KAAK,KAAK,MAAM;AACjC,aAAS,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,KAAK;AAC9C,YAAM,OAAO,KAAK,YAAY,CAAC;AAC/B,WAAK,aAAa,KAAK,KAAK,KAAK,MAAM;IACnD;AACQ,SAAK,cAAc,CAAA;AACnB,WAAO,KAAK;EACpB;EACI,YAAY,KAAK,SAAS,CAAA,GAAI,uBAAuB,OAAO;AACxD,QAAI,KAAK,QAAQ,UAAU;AACvB,YAAM,IAAI,QAAQ,MAAM,eAAe,MAAM,EAAE,QAAQ,MAAM,WAAW,EAAE;IACtF;AACQ,WAAO,KAAK;AACR,UAAI;AACJ,UAAI,KAAK,QAAQ,YAAY,OAAO,KAAK,CAAC,iBAAiB;AACvD,YAAI,QAAQ,aAAa,KAAK,EAAE,OAAO,KAAI,GAAI,KAAK,MAAM,GAAG;AACzD,gBAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,iBAAO,KAAK,KAAK;AACjB,iBAAO;QAC3B;AACgB,eAAO;MACvB,CAAa,GAAG;AACA;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,MAAM,GAAG,GAAG;AACnC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,MAAM,IAAI,WAAW,KAAK,cAAc,QAAW;AAGnD,oBAAU,OAAO;QACrC,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,KAAK,GAAG,GAAG;AAClC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,cAAM,YAAY,OAAO,GAAG,EAAE;AAE9B,YAAI,WAAW,SAAS,eAAe,WAAW,SAAS,QAAQ;AAC/D,oBAAU,OAAO,OAAO,MAAM;AAC9B,oBAAU,QAAQ,OAAO,MAAM;AAC/B,eAAK,YAAY,GAAG,EAAE,EAAE,MAAM,UAAU;QAC5D,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,OAAO,GAAG,GAAG;AACpC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,QAAQ,GAAG,GAAG;AACrC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,GAAG,GAAG,GAAG;AAChC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,WAAW,GAAG,GAAG;AACxC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,KAAK,GAAG,GAAG;AAClC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,KAAK,GAAG,GAAG;AAClC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,IAAI,GAAG,GAAG;AACjC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,WAAW,SAAS,eAAe,WAAW,SAAS,QAAQ;AAC/D,oBAAU,OAAO,OAAO,MAAM;AAC9B,oBAAU,QAAQ,OAAO,MAAM;AAC/B,eAAK,YAAY,GAAG,EAAE,EAAE,MAAM,UAAU;QAC5D,WACyB,CAAC,KAAK,OAAO,MAAM,MAAM,GAAG,GAAG;AACpC,eAAK,OAAO,MAAM,MAAM,GAAG,IAAI;YAC3B,MAAM,MAAM;YACZ,OAAO,MAAM;UACrC;QACA;AACgB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,MAAM,GAAG,GAAG;AACnC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,SAAS,GAAG,GAAG;AACtC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAGY,UAAI,SAAS;AACb,UAAI,KAAK,QAAQ,YAAY,YAAY;AACrC,YAAI,aAAa;AACjB,cAAM,UAAU,IAAI,MAAM,CAAC;AAC3B,YAAI;AACJ,aAAK,QAAQ,WAAW,WAAW,QAAQ,CAAC,kBAAkB;AAC1D,sBAAY,cAAc,KAAK,EAAE,OAAO,KAAI,GAAI,OAAO;AACvD,cAAI,OAAO,cAAc,YAAY,aAAa,GAAG;AACjD,yBAAa,KAAK,IAAI,YAAY,SAAS;UACnE;QACA,CAAiB;AACD,YAAI,aAAa,YAAY,cAAc,GAAG;AAC1C,mBAAS,IAAI,UAAU,GAAG,aAAa,CAAC;QAC5D;MACA;AACY,UAAI,KAAK,MAAM,QAAQ,QAAQ,KAAK,UAAU,UAAU,MAAM,IAAI;AAC9D,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,wBAAwB,WAAW,SAAS,aAAa;AACzD,oBAAU,OAAO,OAAO,MAAM;AAC9B,oBAAU,QAAQ,OAAO,MAAM;AAC/B,eAAK,YAAY,IAAG;AACpB,eAAK,YAAY,GAAG,EAAE,EAAE,MAAM,UAAU;QAC5D,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB,+BAAuB,OAAO,WAAW,IAAI;AAC7C,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,KAAK,GAAG,GAAG;AAClC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,WAAW,SAAS,QAAQ;AAC5B,oBAAU,OAAO,OAAO,MAAM;AAC9B,oBAAU,QAAQ,OAAO,MAAM;AAC/B,eAAK,YAAY,IAAG;AACpB,eAAK,YAAY,GAAG,EAAE,EAAE,MAAM,UAAU;QAC5D,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB;MAChB;AACY,UAAI,KAAK;AACL,cAAM,SAAS,4BAA4B,IAAI,WAAW,CAAC;AAC3D,YAAI,KAAK,QAAQ,QAAQ;AACrB,kBAAQ,MAAM,MAAM;AACpB;QACpB,OACqB;AACD,gBAAM,IAAI,MAAM,MAAM;QAC1C;MACA;IACA;AACQ,SAAK,MAAM,MAAM;AACjB,WAAO;EACf;EACI,OAAO,KAAK,SAAS,CAAA,GAAI;AACrB,SAAK,YAAY,KAAK,EAAE,KAAK,OAAM,CAAE;AACrC,WAAO;EACf;;;;EAII,aAAa,KAAK,SAAS,CAAA,GAAI;AAE3B,QAAI,YAAY;AAChB,QAAI,QAAQ;AAEZ,QAAI,KAAK,OAAO,OAAO;AACnB,YAAM,QAAQ,OAAO,KAAK,KAAK,OAAO,KAAK;AAC3C,UAAI,MAAM,SAAS,GAAG;AAClB,gBAAQ,QAAQ,KAAK,UAAU,MAAM,OAAO,cAAc,KAAK,SAAS,MAAM,MAAM;AAChF,cAAI,MAAM,SAAS,MAAM,CAAC,EAAE,MAAM,MAAM,CAAC,EAAE,YAAY,GAAG,IAAI,GAAG,EAAE,CAAC,GAAG;AACnE,wBAAY,UAAU,MAAM,GAAG,MAAM,KAAK,IACpC,MAAM,IAAI,OAAO,MAAM,CAAC,EAAE,SAAS,CAAC,IAAI,MACxC,UAAU,MAAM,KAAK,UAAU,MAAM,OAAO,cAAc,SAAS;UACjG;QACA;MACA;IACA;AAEQ,YAAQ,QAAQ,KAAK,UAAU,MAAM,OAAO,UAAU,KAAK,SAAS,MAAM,MAAM;AAC5E,kBAAY,UAAU,MAAM,GAAG,MAAM,KAAK,IAAI,MAAM,IAAI,OAAO,MAAM,CAAC,EAAE,SAAS,CAAC,IAAI,MAAM,UAAU,MAAM,KAAK,UAAU,MAAM,OAAO,UAAU,SAAS;IACvK;AAEQ,YAAQ,QAAQ,KAAK,UAAU,MAAM,OAAO,eAAe,KAAK,SAAS,MAAM,MAAM;AACjF,kBAAY,UAAU,MAAM,GAAG,MAAM,KAAK,IAAI,OAAO,UAAU,MAAM,KAAK,UAAU,MAAM,OAAO,eAAe,SAAS;IACrI;AACQ,QAAI,eAAe;AACnB,QAAI,WAAW;AACf,WAAO,KAAK;AACR,UAAI,CAAC,cAAc;AACf,mBAAW;MAC3B;AACY,qBAAe;AACf,UAAI;AAEJ,UAAI,KAAK,QAAQ,YAAY,QAAQ,KAAK,CAAC,iBAAiB;AACxD,YAAI,QAAQ,aAAa,KAAK,EAAE,OAAO,KAAI,GAAI,KAAK,MAAM,GAAG;AACzD,gBAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,iBAAO,KAAK,KAAK;AACjB,iBAAO;QAC3B;AACgB,eAAO;MACvB,CAAa,GAAG;AACA;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,OAAO,GAAG,GAAG;AACpC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,IAAI,GAAG,GAAG;AACjC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,KAAK,GAAG,GAAG;AAClC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,QAAQ,KAAK,KAAK,OAAO,KAAK,GAAG;AACxD,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,MAAM,SAAS,UAAU,WAAW,SAAS,QAAQ;AACrD,oBAAU,OAAO,MAAM;AACvB,oBAAU,QAAQ,MAAM;QAC5C,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,SAAS,KAAK,WAAW,QAAQ,GAAG;AAC3D,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,SAAS,GAAG,GAAG;AACtC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,GAAG,GAAG,GAAG;AAChC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,IAAI,GAAG,GAAG;AACjC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,QAAQ,KAAK,UAAU,SAAS,GAAG,GAAG;AACtC,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAEY,UAAI,CAAC,KAAK,MAAM,WAAW,QAAQ,KAAK,UAAU,IAAI,GAAG,IAAI;AACzD,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,eAAO,KAAK,KAAK;AACjB;MAChB;AAGY,UAAI,SAAS;AACb,UAAI,KAAK,QAAQ,YAAY,aAAa;AACtC,YAAI,aAAa;AACjB,cAAM,UAAU,IAAI,MAAM,CAAC;AAC3B,YAAI;AACJ,aAAK,QAAQ,WAAW,YAAY,QAAQ,CAAC,kBAAkB;AAC3D,sBAAY,cAAc,KAAK,EAAE,OAAO,KAAI,GAAI,OAAO;AACvD,cAAI,OAAO,cAAc,YAAY,aAAa,GAAG;AACjD,yBAAa,KAAK,IAAI,YAAY,SAAS;UACnE;QACA,CAAiB;AACD,YAAI,aAAa,YAAY,cAAc,GAAG;AAC1C,mBAAS,IAAI,UAAU,GAAG,aAAa,CAAC;QAC5D;MACA;AACY,UAAI,QAAQ,KAAK,UAAU,WAAW,MAAM,GAAG;AAC3C,cAAM,IAAI,UAAU,MAAM,IAAI,MAAM;AACpC,YAAI,MAAM,IAAI,MAAM,EAAE,MAAM,KAAK;AAC7B,qBAAW,MAAM,IAAI,MAAM,EAAE;QACjD;AACgB,uBAAe;AACf,cAAM,YAAY,OAAO,GAAG,EAAE;AAC9B,YAAI,WAAW,SAAS,QAAQ;AAC5B,oBAAU,OAAO,MAAM;AACvB,oBAAU,QAAQ,MAAM;QAC5C,OACqB;AACD,iBAAO,KAAK,KAAK;QACrC;AACgB;MAChB;AACY,UAAI,KAAK;AACL,cAAM,SAAS,4BAA4B,IAAI,WAAW,CAAC;AAC3D,YAAI,KAAK,QAAQ,QAAQ;AACrB,kBAAQ,MAAM,MAAM;AACpB;QACpB,OACqB;AACD,gBAAM,IAAI,MAAM,MAAM;QAC1C;MACA;IACA;AACQ,WAAO;EACf;AACA;AC5ZO,IAAM,YAAN,MAAgB;SAAA;;;EACnB;EACA;;EACA,YAAYC,UAAS;AACjB,SAAK,UAAUA,YAAW;EAClC;EACI,MAAM,OAAO;AACT,WAAO;EACf;EACI,KAAK,EAAE,MAAM,MAAM,QAAO,GAAI;AAC1B,UAAM,cAAc,QAAQ,IAAI,MAAM,MAAM,aAAa,IAAI,CAAC;AAC9D,UAAM,OAAO,KAAK,QAAQ,MAAM,eAAe,EAAE,IAAI;AACrD,QAAI,CAAC,YAAY;AACb,aAAO,iBACA,UAAU,OAAON,QAAO,MAAM,IAAI,KACnC;IAClB;AACQ,WAAO,gCACDA,QAAO,UAAU,IACjB,QACC,UAAU,OAAOA,QAAO,MAAM,IAAI,KACnC;EACd;EACI,WAAW,EAAE,OAAM,GAAI;AACnB,UAAM,OAAO,KAAK,OAAO,MAAM,MAAM;AACrC,WAAO;EAAiB,IAAI;;EACpC;EACI,KAAK,EAAE,KAAI,GAAI;AACX,WAAO;EACf;EACI,QAAQ,EAAE,QAAQ,MAAK,GAAI;AACvB,WAAO,KAAK,KAAK,IAAI,KAAK,OAAO,YAAY,MAAM,CAAC,MAAM,KAAK;;EACvE;EACI,GAAG,OAAO;AACN,WAAO;EACf;EACI,KAAK,OAAO;AACR,UAAM,UAAU,MAAM;AACtB,UAAM,QAAQ,MAAM;AACpB,QAAI,OAAO;AACX,aAAS,IAAI,GAAG,IAAI,MAAM,MAAM,QAAQ,KAAK;AACzC,YAAM,OAAO,MAAM,MAAM,CAAC;AAC1B,cAAQ,KAAK,SAAS,IAAI;IACtC;AACQ,UAAM,OAAO,UAAU,OAAO;AAC9B,UAAM,YAAa,WAAW,UAAU,IAAM,aAAa,QAAQ,MAAO;AAC1E,WAAO,MAAM,OAAO,YAAY,QAAQ,OAAO,OAAO,OAAO;EACrE;EACI,SAAS,MAAM;AACX,QAAI,WAAW;AACf,QAAI,KAAK,MAAM;AACX,YAAM,WAAW,KAAK,SAAS,EAAE,SAAS,CAAC,CAAC,KAAK,QAAO,CAAE;AAC1D,UAAI,KAAK,OAAO;AACZ,YAAI,KAAK,OAAO,CAAC,GAAG,SAAS,aAAa;AACtC,eAAK,OAAO,CAAC,EAAE,OAAO,WAAW,MAAM,KAAK,OAAO,CAAC,EAAE;AACtD,cAAI,KAAK,OAAO,CAAC,EAAE,UAAU,KAAK,OAAO,CAAC,EAAE,OAAO,SAAS,KAAK,KAAK,OAAO,CAAC,EAAE,OAAO,CAAC,EAAE,SAAS,QAAQ;AACvG,iBAAK,OAAO,CAAC,EAAE,OAAO,CAAC,EAAE,OAAO,WAAW,MAAMA,QAAO,KAAK,OAAO,CAAC,EAAE,OAAO,CAAC,EAAE,IAAI;AACrF,iBAAK,OAAO,CAAC,EAAE,OAAO,CAAC,EAAE,UAAU;UAC3D;QACA,OACqB;AACD,eAAK,OAAO,QAAQ;YAChB,MAAM;YACN,KAAK,WAAW;YAChB,MAAM,WAAW;YACjB,SAAS;UACjC,CAAqB;QACrB;MACA,OACiB;AACD,oBAAY,WAAW;MACvC;IACA;AACQ,gBAAY,KAAK,OAAO,MAAM,KAAK,QAAQ,CAAC,CAAC,KAAK,KAAK;AACvD,WAAO,OAAO,QAAQ;;EAC9B;EACI,SAAS,EAAE,QAAO,GAAI;AAClB,WAAO,aACA,UAAU,gBAAgB,MAC3B;EACd;EACI,UAAU,EAAE,OAAM,GAAI;AAClB,WAAO,MAAM,KAAK,OAAO,YAAY,MAAM,CAAC;;EACpD;EACI,MAAM,OAAO;AACT,QAAI,SAAS;AAEb,QAAI,OAAO;AACX,aAAS,IAAI,GAAG,IAAI,MAAM,OAAO,QAAQ,KAAK;AAC1C,cAAQ,KAAK,UAAU,MAAM,OAAO,CAAC,CAAC;IAClD;AACQ,cAAU,KAAK,SAAS,EAAE,MAAM,KAAI,CAAE;AACtC,QAAI,OAAO;AACX,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK,QAAQ,KAAK;AACxC,YAAM,MAAM,MAAM,KAAK,CAAC;AACxB,aAAO;AACP,eAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACjC,gBAAQ,KAAK,UAAU,IAAI,CAAC,CAAC;MAC7C;AACY,cAAQ,KAAK,SAAS,EAAE,MAAM,KAAI,CAAE;IAChD;AACQ,QAAI;AACA,aAAO,UAAU,IAAI;AACzB,WAAO,uBAED,SACA,eACA,OACA;EACd;EACI,SAAS,EAAE,KAAI,GAAI;AACf,WAAO;EAAS,IAAI;;EAC5B;EACI,UAAU,OAAO;AACb,UAAM,UAAU,KAAK,OAAO,YAAY,MAAM,MAAM;AACpD,UAAM,OAAO,MAAM,SAAS,OAAO;AACnC,UAAMQ,OAAM,MAAM,QACZ,IAAI,IAAI,WAAW,MAAM,KAAK,OAC9B,IAAI,IAAI;AACd,WAAOA,OAAM,UAAU,KAAK,IAAI;;EACxC;;;;EAII,OAAO,EAAE,OAAM,GAAI;AACf,WAAO,WAAW,KAAK,OAAO,YAAY,MAAM,CAAC;EACzD;EACI,GAAG,EAAE,OAAM,GAAI;AACX,WAAO,OAAO,KAAK,OAAO,YAAY,MAAM,CAAC;EACrD;EACI,SAAS,EAAE,KAAI,GAAI;AACf,WAAO,SAASR,QAAO,MAAM,IAAI,CAAC;EAC1C;EACI,GAAG,OAAO;AACN,WAAO;EACf;EACI,IAAI,EAAE,OAAM,GAAI;AACZ,WAAO,QAAQ,KAAK,OAAO,YAAY,MAAM,CAAC;EACtD;EACI,KAAK,EAAE,MAAM,OAAO,OAAM,GAAI;AAC1B,UAAM,OAAO,KAAK,OAAO,YAAY,MAAM;AAC3C,UAAM,YAAY,SAAS,IAAI;AAC/B,QAAI,cAAc,MAAM;AACpB,aAAO;IACnB;AACQ,WAAO;AACP,QAAI,MAAM,cAAc,OAAO;AAC/B,QAAI,OAAO;AACP,aAAO,aAAcA,QAAO,KAAK,IAAK;IAClD;AACQ,WAAO,MAAM,OAAO;AACpB,WAAO;EACf;EACI,MAAM,EAAE,MAAM,OAAO,KAAI,GAAI;AACzB,UAAM,YAAY,SAAS,IAAI;AAC/B,QAAI,cAAc,MAAM;AACpB,aAAOA,QAAO,IAAI;IAC9B;AACQ,WAAO;AACP,QAAI,MAAM,aAAa,IAAI,UAAU,IAAI;AACzC,QAAI,OAAO;AACP,aAAO,WAAWA,QAAO,KAAK,CAAC;IAC3C;AACQ,WAAO;AACP,WAAO;EACf;EACI,KAAK,OAAO;AACR,WAAO,YAAY,SAAS,MAAM,SAC5B,KAAK,OAAO,YAAY,MAAM,MAAM,IACnC,aAAa,SAAS,MAAM,UAAU,MAAM,OAAOA,QAAO,MAAM,IAAI;EACnF;AACA;AC7KO,IAAM,gBAAN,MAAoB;SAAA;;;;EAEvB,OAAO,EAAE,KAAI,GAAI;AACb,WAAO;EACf;EACI,GAAG,EAAE,KAAI,GAAI;AACT,WAAO;EACf;EACI,SAAS,EAAE,KAAI,GAAI;AACf,WAAO;EACf;EACI,IAAI,EAAE,KAAI,GAAI;AACV,WAAO;EACf;EACI,KAAK,EAAE,KAAI,GAAI;AACX,WAAO;EACf;EACI,KAAK,EAAE,KAAI,GAAI;AACX,WAAO;EACf;EACI,KAAK,EAAE,KAAI,GAAI;AACX,WAAO,KAAK;EACpB;EACI,MAAM,EAAE,KAAI,GAAI;AACZ,WAAO,KAAK;EACpB;EACI,KAAK;AACD,WAAO;EACf;AACA;AC3BO,IAAM,UAAN,MAAM,SAAQ;SAAA;;;EACjB;EACA;EACA;EACA,YAAYM,UAAS;AACjB,SAAK,UAAUA,YAAW;AAC1B,SAAK,QAAQ,WAAW,KAAK,QAAQ,YAAY,IAAI,UAAS;AAC9D,SAAK,WAAW,KAAK,QAAQ;AAC7B,SAAK,SAAS,UAAU,KAAK;AAC7B,SAAK,SAAS,SAAS;AACvB,SAAK,eAAe,IAAI,cAAa;EAC7C;;;;EAII,OAAO,MAAM,QAAQA,UAAS;AAC1B,UAAMI,UAAS,IAAI,SAAQJ,QAAO;AAClC,WAAOI,QAAO,MAAM,MAAM;EAClC;;;;EAII,OAAO,YAAY,QAAQJ,UAAS;AAChC,UAAMI,UAAS,IAAI,SAAQJ,QAAO;AAClC,WAAOI,QAAO,YAAY,MAAM;EACxC;;;;EAII,MAAM,QAAQ,MAAM,MAAM;AACtB,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACpC,YAAM,WAAW,OAAO,CAAC;AAEzB,UAAI,KAAK,QAAQ,YAAY,YAAY,SAAS,IAAI,GAAG;AACrD,cAAM,eAAe;AACrB,cAAM,MAAM,KAAK,QAAQ,WAAW,UAAU,aAAa,IAAI,EAAE,KAAK,EAAE,QAAQ,KAAI,GAAI,YAAY;AACpG,YAAI,QAAQ,SAAS,CAAC,CAAC,SAAS,MAAM,WAAW,QAAQ,SAAS,cAAc,QAAQ,QAAQ,aAAa,MAAM,EAAE,SAAS,aAAa,IAAI,GAAG;AAC9I,iBAAO,OAAO;AACd;QACpB;MACA;AACY,YAAM,QAAQ;AACd,cAAQ,MAAM,MAAI;QACd,KAAK,SAAS;AACV,iBAAO,KAAK,SAAS,MAAM,KAAK;AAChC;QACpB;QACgB,KAAK,MAAM;AACP,iBAAO,KAAK,SAAS,GAAG,KAAK;AAC7B;QACpB;QACgB,KAAK,WAAW;AACZ,iBAAO,KAAK,SAAS,QAAQ,KAAK;AAClC;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,KAAK,SAAS,KAAK,KAAK;AAC/B;QACpB;QACgB,KAAK,SAAS;AACV,iBAAO,KAAK,SAAS,MAAM,KAAK;AAChC;QACpB;QACgB,KAAK,cAAc;AACf,iBAAO,KAAK,SAAS,WAAW,KAAK;AACrC;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,KAAK,SAAS,KAAK,KAAK;AAC/B;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,KAAK,SAAS,KAAK,KAAK;AAC/B;QACpB;QACgB,KAAK,aAAa;AACd,iBAAO,KAAK,SAAS,UAAU,KAAK;AACpC;QACpB;QACgB,KAAK,QAAQ;AACT,cAAI,YAAY;AAChB,cAAI,OAAO,KAAK,SAAS,KAAK,SAAS;AACvC,iBAAO,IAAI,IAAI,OAAO,UAAU,OAAO,IAAI,CAAC,EAAE,SAAS,QAAQ;AAC3D,wBAAY,OAAO,EAAE,CAAC;AACtB,oBAAQ,OAAO,KAAK,SAAS,KAAK,SAAS;UACnE;AACoB,cAAI,KAAK;AACL,mBAAO,KAAK,SAAS,UAAU;cAC3B,MAAM;cACN,KAAK;cACL,MAAM;cACN,QAAQ,CAAC,EAAE,MAAM,QAAQ,KAAK,MAAM,MAAM,MAAM,SAAS,KAAI,CAAE;YAC3F,CAAyB;UACzB,OACyB;AACD,mBAAO;UAC/B;AACoB;QACpB;QACgB,SAAS;AACL,gBAAM,SAAS,iBAAiB,MAAM,OAAO;AAC7C,cAAI,KAAK,QAAQ,QAAQ;AACrB,oBAAQ,MAAM,MAAM;AACpB,mBAAO;UAC/B,OACyB;AACD,kBAAM,IAAI,MAAM,MAAM;UAC9C;QACA;MACA;IACA;AACQ,WAAO;EACf;;;;EAII,YAAY,QAAQ,WAAW,KAAK,UAAU;AAC1C,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACpC,YAAM,WAAW,OAAO,CAAC;AAEzB,UAAI,KAAK,QAAQ,YAAY,YAAY,SAAS,IAAI,GAAG;AACrD,cAAM,MAAM,KAAK,QAAQ,WAAW,UAAU,SAAS,IAAI,EAAE,KAAK,EAAE,QAAQ,KAAI,GAAI,QAAQ;AAC5F,YAAI,QAAQ,SAAS,CAAC,CAAC,UAAU,QAAQ,QAAQ,SAAS,UAAU,MAAM,YAAY,MAAM,OAAO,MAAM,EAAE,SAAS,SAAS,IAAI,GAAG;AAChI,iBAAO,OAAO;AACd;QACpB;MACA;AACY,YAAM,QAAQ;AACd,cAAQ,MAAM,MAAI;QACd,KAAK,UAAU;AACX,iBAAO,SAAS,KAAK,KAAK;AAC1B;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,SAAS,KAAK,KAAK;AAC1B;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,SAAS,KAAK,KAAK;AAC1B;QACpB;QACgB,KAAK,SAAS;AACV,iBAAO,SAAS,MAAM,KAAK;AAC3B;QACpB;QACgB,KAAK,UAAU;AACX,iBAAO,SAAS,OAAO,KAAK;AAC5B;QACpB;QACgB,KAAK,MAAM;AACP,iBAAO,SAAS,GAAG,KAAK;AACxB;QACpB;QACgB,KAAK,YAAY;AACb,iBAAO,SAAS,SAAS,KAAK;AAC9B;QACpB;QACgB,KAAK,MAAM;AACP,iBAAO,SAAS,GAAG,KAAK;AACxB;QACpB;QACgB,KAAK,OAAO;AACR,iBAAO,SAAS,IAAI,KAAK;AACzB;QACpB;QACgB,KAAK,QAAQ;AACT,iBAAO,SAAS,KAAK,KAAK;AAC1B;QACpB;QACgB,SAAS;AACL,gBAAM,SAAS,iBAAiB,MAAM,OAAO;AAC7C,cAAI,KAAK,QAAQ,QAAQ;AACrB,oBAAQ,MAAM,MAAM;AACpB,mBAAO;UAC/B,OACyB;AACD,kBAAM,IAAI,MAAM,MAAM;UAC9C;QACA;MACA;IACA;AACQ,WAAO;EACf;AACA;AC5LO,IAAM,SAAN,MAAa;SAAA;;;EAChB;EACA;EACA,YAAYJ,UAAS;AACjB,SAAK,UAAUA,YAAW;EAClC;EACI,OAAO,mBAAmB,oBAAI,IAAI;IAC9B;IACA;IACA;EACR,CAAK;;;;EAID,WAAW,UAAU;AACjB,WAAO;EACf;;;;EAII,YAAYL,OAAM;AACd,WAAOA;EACf;;;;EAII,iBAAiB,QAAQ;AACrB,WAAO;EACf;;;;EAII,eAAe;AACX,WAAO,KAAK,QAAQ,OAAO,MAAM,OAAO;EAChD;;;;EAII,gBAAgB;AACZ,WAAO,KAAK,QAAQ,QAAQ,QAAQ,QAAQ;EACpD;AACA;ACpCO,IAAM,SAAN,MAAa;SAAA;;;EAChB,WAAW,aAAY;EACvB,UAAU,KAAK;EACf,QAAQ,KAAK,cAAc,IAAI;EAC/B,cAAc,KAAK,cAAc,KAAK;EACtC,SAAS;EACT,WAAW;EACX,eAAe;EACf,QAAQ;EACR,YAAY;EACZ,QAAQ;EACR,eAAe,MAAM;AACjB,SAAK,IAAI,GAAG,IAAI;EACxB;;;;EAII,WAAW,QAAQ,UAAU;AACzB,QAAI,SAAS,CAAA;AACb,eAAW,SAAS,QAAQ;AACxB,eAAS,OAAO,OAAO,SAAS,KAAK,MAAM,KAAK,CAAC;AACjD,cAAQ,MAAM,MAAI;QACd,KAAK,SAAS;AACV,gBAAM,aAAa;AACnB,qBAAW,QAAQ,WAAW,QAAQ;AAClC,qBAAS,OAAO,OAAO,KAAK,WAAW,KAAK,QAAQ,QAAQ,CAAC;UACrF;AACoB,qBAAW,OAAO,WAAW,MAAM;AAC/B,uBAAW,QAAQ,KAAK;AACpB,uBAAS,OAAO,OAAO,KAAK,WAAW,KAAK,QAAQ,QAAQ,CAAC;YACzF;UACA;AACoB;QACpB;QACgB,KAAK,QAAQ;AACT,gBAAM,YAAY;AAClB,mBAAS,OAAO,OAAO,KAAK,WAAW,UAAU,OAAO,QAAQ,CAAC;AACjE;QACpB;QACgB,SAAS;AACL,gBAAM,eAAe;AACrB,cAAI,KAAK,SAAS,YAAY,cAAc,aAAa,IAAI,GAAG;AAC5D,iBAAK,SAAS,WAAW,YAAY,aAAa,IAAI,EAAE,QAAQ,CAAC,gBAAgB;AAC7E,oBAAMU,UAAS,aAAa,WAAW,EAAE,KAAK,QAAQ;AACtD,uBAAS,OAAO,OAAO,KAAK,WAAWA,SAAQ,QAAQ,CAAC;YACpF,CAAyB;UACzB,WAC6B,aAAa,QAAQ;AAC1B,qBAAS,OAAO,OAAO,KAAK,WAAW,aAAa,QAAQ,QAAQ,CAAC;UAC7F;QACA;MACA;IACA;AACQ,WAAO;EACf;EACI,OAAO,MAAM;AACT,UAAM,aAAa,KAAK,SAAS,cAAc,EAAE,WAAW,CAAA,GAAI,aAAa,CAAA,EAAE;AAC/E,SAAK,QAAQ,CAAC,SAAS;AAEnB,YAAM,OAAO,EAAE,GAAG,KAAI;AAEtB,WAAK,QAAQ,KAAK,SAAS,SAAS,KAAK,SAAS;AAElD,UAAI,KAAK,YAAY;AACjB,aAAK,WAAW,QAAQ,CAAC,QAAQ;AAC7B,cAAI,CAAC,IAAI,MAAM;AACX,kBAAM,IAAI,MAAM,yBAAyB;UACjE;AACoB,cAAI,cAAc,KAAK;AACnB,kBAAM,eAAe,WAAW,UAAU,IAAI,IAAI;AAClD,gBAAI,cAAc;AAEd,yBAAW,UAAU,IAAI,IAAI,IAAI,YAAaC,OAAM;AAChD,oBAAI,MAAM,IAAI,SAAS,MAAM,MAAMA,KAAI;AACvC,oBAAI,QAAQ,OAAO;AACf,wBAAM,aAAa,MAAM,MAAMA,KAAI;gBACvE;AACgC,uBAAO;cACvC;YACA,OAC6B;AACD,yBAAW,UAAU,IAAI,IAAI,IAAI,IAAI;YACjE;UACA;AACoB,cAAI,eAAe,KAAK;AACpB,gBAAI,CAAC,IAAI,SAAU,IAAI,UAAU,WAAW,IAAI,UAAU,UAAW;AACjE,oBAAM,IAAI,MAAM,6CAA6C;YACzF;AACwB,kBAAM,WAAW,WAAW,IAAI,KAAK;AACrC,gBAAI,UAAU;AACV,uBAAS,QAAQ,IAAI,SAAS;YAC1D,OAC6B;AACD,yBAAW,IAAI,KAAK,IAAI,CAAC,IAAI,SAAS;YAClE;AACwB,gBAAI,IAAI,OAAO;AACX,kBAAI,IAAI,UAAU,SAAS;AACvB,oBAAI,WAAW,YAAY;AACvB,6BAAW,WAAW,KAAK,IAAI,KAAK;gBACxE,OACqC;AACD,6BAAW,aAAa,CAAC,IAAI,KAAK;gBACtE;cACA,WACqC,IAAI,UAAU,UAAU;AAC7B,oBAAI,WAAW,aAAa;AACxB,6BAAW,YAAY,KAAK,IAAI,KAAK;gBACzE,OACqC;AACD,6BAAW,cAAc,CAAC,IAAI,KAAK;gBACvE;cACA;YACA;UACA;AACoB,cAAI,iBAAiB,OAAO,IAAI,aAAa;AACzC,uBAAW,YAAY,IAAI,IAAI,IAAI,IAAI;UAC/D;QACA,CAAiB;AACD,aAAK,aAAa;MAClC;AAEY,UAAI,KAAK,UAAU;AACf,cAAM,WAAW,KAAK,SAAS,YAAY,IAAI,UAAU,KAAK,QAAQ;AACtE,mBAAW,QAAQ,KAAK,UAAU;AAC9B,cAAI,EAAE,QAAQ,WAAW;AACrB,kBAAM,IAAI,MAAM,aAAa,IAAI,kBAAkB;UAC3E;AACoB,cAAI,CAAC,WAAW,QAAQ,EAAE,SAAS,IAAI,GAAG;AAEtC;UACxB;AACoB,gBAAM,eAAe;AACrB,gBAAM,eAAe,KAAK,SAAS,YAAY;AAC/C,gBAAM,eAAe,SAAS,YAAY;AAE1C,mBAAS,YAAY,IAAI,IAAIA,UAAS;AAClC,gBAAI,MAAM,aAAa,MAAM,UAAUA,KAAI;AAC3C,gBAAI,QAAQ,OAAO;AACf,oBAAM,aAAa,MAAM,UAAUA,KAAI;YACnE;AACwB,mBAAO,OAAO;UACtC;QACA;AACgB,aAAK,WAAW;MAChC;AACY,UAAI,KAAK,WAAW;AAChB,cAAM,YAAY,KAAK,SAAS,aAAa,IAAI,WAAW,KAAK,QAAQ;AACzE,mBAAW,QAAQ,KAAK,WAAW;AAC/B,cAAI,EAAE,QAAQ,YAAY;AACtB,kBAAM,IAAI,MAAM,cAAc,IAAI,kBAAkB;UAC5E;AACoB,cAAI,CAAC,WAAW,SAAS,OAAO,EAAE,SAAS,IAAI,GAAG;AAE9C;UACxB;AACoB,gBAAM,gBAAgB;AACtB,gBAAM,gBAAgB,KAAK,UAAU,aAAa;AAClD,gBAAM,gBAAgB,UAAU,aAAa;AAG7C,oBAAU,aAAa,IAAI,IAAIA,UAAS;AACpC,gBAAI,MAAM,cAAc,MAAM,WAAWA,KAAI;AAC7C,gBAAI,QAAQ,OAAO;AACf,oBAAM,cAAc,MAAM,WAAWA,KAAI;YACrE;AACwB,mBAAO;UAC/B;QACA;AACgB,aAAK,YAAY;MACjC;AAEY,UAAI,KAAK,OAAO;AACZ,cAAM,QAAQ,KAAK,SAAS,SAAS,IAAI,OAAM;AAC/C,mBAAW,QAAQ,KAAK,OAAO;AAC3B,cAAI,EAAE,QAAQ,QAAQ;AAClB,kBAAM,IAAI,MAAM,SAAS,IAAI,kBAAkB;UACvE;AACoB,cAAI,CAAC,WAAW,OAAO,EAAE,SAAS,IAAI,GAAG;AAErC;UACxB;AACoB,gBAAM,YAAY;AAClB,gBAAM,YAAY,KAAK,MAAM,SAAS;AACtC,gBAAM,WAAW,MAAM,SAAS;AAChC,cAAI,OAAO,iBAAiB,IAAI,IAAI,GAAG;AAEnC,kBAAM,SAAS,IAAI,CAAC,QAAQ;AACxB,kBAAI,KAAK,SAAS,OAAO;AACrB,uBAAO,QAAQ,QAAQ,UAAU,KAAK,OAAO,GAAG,CAAC,EAAE,KAAK,CAAAC,SAAO;AAC3D,yBAAO,SAAS,KAAK,OAAOA,IAAG;gBACnE,CAAiC;cACjC;AAC4B,oBAAM,MAAM,UAAU,KAAK,OAAO,GAAG;AACrC,qBAAO,SAAS,KAAK,OAAO,GAAG;YAC3D;UACA,OACyB;AAED,kBAAM,SAAS,IAAI,IAAID,UAAS;AAC5B,kBAAI,MAAM,UAAU,MAAM,OAAOA,KAAI;AACrC,kBAAI,QAAQ,OAAO;AACf,sBAAM,SAAS,MAAM,OAAOA,KAAI;cAChE;AAC4B,qBAAO;YACnC;UACA;QACA;AACgB,aAAK,QAAQ;MAC7B;AAEY,UAAI,KAAK,YAAY;AACjB,cAAME,cAAa,KAAK,SAAS;AACjC,cAAM,iBAAiB,KAAK;AAC5B,aAAK,aAAa,SAAU,OAAO;AAC/B,cAAI,SAAS,CAAA;AACb,iBAAO,KAAK,eAAe,KAAK,MAAM,KAAK,CAAC;AAC5C,cAAIA,aAAY;AACZ,qBAAS,OAAO,OAAOA,YAAW,KAAK,MAAM,KAAK,CAAC;UAC3E;AACoB,iBAAO;QAC3B;MACA;AACY,WAAK,WAAW,EAAE,GAAG,KAAK,UAAU,GAAG,KAAI;IACvD,CAAS;AACD,WAAO;EACf;EACI,WAAW,KAAK;AACZ,SAAK,WAAW,EAAE,GAAG,KAAK,UAAU,GAAG,IAAG;AAC1C,WAAO;EACf;EACI,MAAM,KAAKR,UAAS;AAChB,WAAO,OAAO,IAAI,KAAKA,YAAW,KAAK,QAAQ;EACvD;EACI,OAAO,QAAQA,UAAS;AACpB,WAAO,QAAQ,MAAM,QAAQA,YAAW,KAAK,QAAQ;EAC7D;EACI,cAAc,WAAW;AAErB,UAAM,QAAQ,wBAAC,KAAKA,aAAY;AAC5B,YAAM,UAAU,EAAE,GAAGA,SAAO;AAC5B,YAAM,MAAM,EAAE,GAAG,KAAK,UAAU,GAAG,QAAO;AAC1C,YAAM,aAAa,KAAK,QAAQ,CAAC,CAAC,IAAI,QAAQ,CAAC,CAAC,IAAI,KAAK;AAEzD,UAAI,KAAK,SAAS,UAAU,QAAQ,QAAQ,UAAU,OAAO;AACzD,eAAO,WAAW,IAAI,MAAM,oIAAoI,CAAC;MACjL;AAEY,UAAI,OAAO,QAAQ,eAAe,QAAQ,MAAM;AAC5C,eAAO,WAAW,IAAI,MAAM,gDAAgD,CAAC;MAC7F;AACY,UAAI,OAAO,QAAQ,UAAU;AACzB,eAAO,WAAW,IAAI,MAAM,0CACtB,OAAO,UAAU,SAAS,KAAK,GAAG,IAAI,mBAAmB,CAAC;MAChF;AACY,UAAI,IAAI,OAAO;AACX,YAAI,MAAM,UAAU;AACpB,YAAI,MAAM,QAAQ;MAClC;AACY,YAAMD,SAAQ,IAAI,QAAQ,IAAI,MAAM,aAAY,IAAM,YAAY,OAAO,MAAM,OAAO;AACtF,YAAMK,UAAS,IAAI,QAAQ,IAAI,MAAM,cAAa,IAAM,YAAY,QAAQ,QAAQ,QAAQ;AAC5F,UAAI,IAAI,OAAO;AACX,eAAO,QAAQ,QAAQ,IAAI,QAAQ,IAAI,MAAM,WAAW,GAAG,IAAI,GAAG,EAC7D,KAAK,CAAAK,SAAOV,OAAMU,MAAK,GAAG,CAAC,EAC3B,KAAK,YAAU,IAAI,QAAQ,IAAI,MAAM,iBAAiB,MAAM,IAAI,MAAM,EACtE,KAAK,YAAU,IAAI,aAAa,QAAQ,IAAI,KAAK,WAAW,QAAQ,IAAI,UAAU,CAAC,EAAE,KAAK,MAAM,MAAM,IAAI,MAAM,EAChH,KAAK,YAAUL,QAAO,QAAQ,GAAG,CAAC,EAClC,KAAK,CAAAT,UAAQ,IAAI,QAAQ,IAAI,MAAM,YAAYA,KAAI,IAAIA,KAAI,EAC3D,MAAM,UAAU;MACrC;AACY,UAAI;AACA,YAAI,IAAI,OAAO;AACX,gBAAM,IAAI,MAAM,WAAW,GAAG;QAClD;AACgB,YAAI,SAASI,OAAM,KAAK,GAAG;AAC3B,YAAI,IAAI,OAAO;AACX,mBAAS,IAAI,MAAM,iBAAiB,MAAM;QAC9D;AACgB,YAAI,IAAI,YAAY;AAChB,eAAK,WAAW,QAAQ,IAAI,UAAU;QAC1D;AACgB,YAAIJ,QAAOS,QAAO,QAAQ,GAAG;AAC7B,YAAI,IAAI,OAAO;AACX,UAAAT,QAAO,IAAI,MAAM,YAAYA,KAAI;QACrD;AACgB,eAAOA;MACvB,SACmB,GAAG;AACN,eAAO,WAAW,CAAC;MACnC;IACA,GAnDsB;AAoDd,WAAO;EACf;EACI,QAAQ,QAAQ,OAAO;AACnB,WAAO,CAAC,MAAM;AACV,QAAE,WAAW;AACb,UAAI,QAAQ;AACR,cAAM,MAAM,mCACND,QAAO,EAAE,UAAU,IAAI,IAAI,IAC3B;AACN,YAAI,OAAO;AACP,iBAAO,QAAQ,QAAQ,GAAG;QAC9C;AACgB,eAAO;MACvB;AACY,UAAI,OAAO;AACP,eAAO,QAAQ,OAAO,CAAC;MACvC;AACY,YAAM;IAClB;EACA;AACA;ACtTA,IAAM,iBAAiB,IAAI,OAAM;AAC1B,SAAS,OAAO,KAAK,KAAK;AAC7B,SAAO,eAAe,MAAM,KAAK,GAAG;AACxC;AAFgB;AAQhB,OAAO,UACH,OAAO,aAAa,SAAUM,UAAS;AACnC,iBAAe,WAAWA,QAAO;AACjC,SAAO,WAAW,eAAe;AACjC,iBAAe,OAAO,QAAQ;AAC9B,SAAO;AACf;AAIA,OAAO,cAAc;AACrB,OAAO,WAAW;AAIlB,OAAO,MAAM,YAAa,MAAM;AAC5B,iBAAe,IAAI,GAAG,IAAI;AAC1B,SAAO,WAAW,eAAe;AACjC,iBAAe,OAAO,QAAQ;AAC9B,SAAO;AACX;AAIA,OAAO,aAAa,SAAU,QAAQ,UAAU;AAC5C,SAAO,eAAe,WAAW,QAAQ,QAAQ;AACrD;AAQA,OAAO,cAAc,eAAe;AAIpC,OAAO,SAAS;AAChB,OAAO,SAAS,QAAQ;AACxB,OAAO,WAAW;AAClB,OAAO,eAAe;AACtB,OAAO,QAAQ;AACf,OAAO,QAAQ,OAAO;AACtB,OAAO,YAAY;AACnB,OAAO,QAAQ;AACf,OAAO,QAAQ;AACH,IAAC,UAAU,OAAO;AAClB,IAAC,aAAa,OAAO;AACrB,IAAC,MAAM,OAAO;AACd,IAAC,aAAa,OAAO;AACrB,IAAC,cAAc,OAAO;AAEtB,IAAC,SAAS,QAAQ;AAClB,IAAC,QAAQ,OAAO;;;ACrErB,IAAM,iBAAyB;AAC/B,IAAM,aAA2D;EACtE,SAAS,wBAAC,MAAmB,OAAO,CAAC,EAAE,QAAQ,QAAQ,GAAG,GAAjD;EACT,SAAS,wBAAC,MAAmB,OAAO,CAAC,GAA5B;;AAEJ,IAAM,UAAU;;;ACHvB,IAAM,WAAW,MAAM;AAEvB,IAAM,aAAa,MAAK;AACtB,QAAM,QAAQ,CAAA;AACd,WAAS,IAAI,GAAG,IAAI,KAAK,EAAE,GAAG;AAC5B,UAAM,KAAK,QAAQ,IAAI,KAAK,MAAM,MAAM,EAAE,SAAS,EAAE,GAAG,YAAW,CAAE;;AAGvE,SAAO;AACT,GAAE;AAwHF,IAAM,QAAQ;AAEP,IAAM,SAMC,wBAACU,MAAK,iBAAiB,SAAS,OAAO,WAAkB;AAGrE,MAAIA,KAAI,WAAW,GAAG;AACpB,WAAOA;;AAGT,MAAI,SAASA;AACb,MAAI,OAAOA,SAAQ,UAAU;AAC3B,aAAS,OAAO,UAAU,SAAS,KAAKA,IAAG;aAClC,OAAOA,SAAQ,UAAU;AAClC,aAAS,OAAOA,IAAG;;AAGrB,MAAI,YAAY,cAAc;AAC5B,WAAO,OAAO,MAAM,EAAE,QAAQ,mBAAmB,SAAU,IAAE;AAC3D,aAAO,WAAW,SAAS,GAAG,MAAM,CAAC,GAAG,EAAE,IAAI;IAChD,CAAC;;AAGH,MAAI,MAAM;AACV,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK,OAAO;AAC7C,UAAM,UAAU,OAAO,UAAU,QAAQ,OAAO,MAAM,GAAG,IAAI,KAAK,IAAI;AACtE,UAAM,MAAM,CAAA;AAEZ,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,EAAE,GAAG;AACvC,UAAI,IAAI,QAAQ,WAAW,CAAC;AAC5B,UACE,MAAM;MACN,MAAM;MACN,MAAM;MACN,MAAM;MACL,KAAK,MAAQ,KAAK;MAClB,KAAK,MAAQ,KAAK;MAClB,KAAK,MAAQ,KAAK;MAClB,WAAW,YAAY,MAAM,MAAQ,MAAM,KAC5C;AACA,YAAI,IAAI,MAAM,IAAI,QAAQ,OAAO,CAAC;AAClC;;AAGF,UAAI,IAAI,KAAM;AACZ,YAAI,IAAI,MAAM,IAAI,UAAU,CAAC;AAC7B;;AAGF,UAAI,IAAI,MAAO;AACb,YAAI,IAAI,MAAM,IAAI,UAAU,MAAQ,KAAK,CAAE,IAAK,UAAU,MAAQ,IAAI,EAAK;AAC3E;;AAGF,UAAI,IAAI,SAAU,KAAK,OAAQ;AAC7B,YAAI,IAAI,MAAM,IACZ,UAAU,MAAQ,KAAK,EAAG,IAAK,UAAU,MAAS,KAAK,IAAK,EAAK,IAAI,UAAU,MAAQ,IAAI,EAAK;AAClG;;AAGF,WAAK;AACL,UAAI,UAAa,IAAI,SAAU,KAAO,QAAQ,WAAW,CAAC,IAAI;AAE9D,UAAI,IAAI,MAAM,IACZ,UAAU,MAAQ,KAAK,EAAG,IAC1B,UAAU,MAAS,KAAK,KAAM,EAAK,IACnC,UAAU,MAAS,KAAK,IAAK,EAAK,IAClC,UAAU,MAAQ,IAAI,EAAK;;AAG/B,WAAO,IAAI,KAAK,EAAE;;AAGpB,SAAO;AACT,GAvEc;AAsGR,SAAU,UAAU,KAAQ;AAChC,MAAI,CAAC,OAAO,OAAO,QAAQ,UAAU;AACnC,WAAO;;AAGT,SAAO,CAAC,EAAE,IAAI,eAAe,IAAI,YAAY,YAAY,IAAI,YAAY,SAAS,GAAG;AACvF;AANgB;AAYV,SAAU,UAAa,KAAU,IAAe;AACpD,MAAI,SAAS,GAAG,GAAG;AACjB,UAAM,SAAS,CAAA;AACf,aAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK,GAAG;AACtC,aAAO,KAAK,GAAG,IAAI,CAAC,CAAE,CAAC;;AAEzB,WAAO;;AAET,SAAO,GAAG,GAAG;AACf;AATgB;;;AC3PhB,IAAM,MAAM,OAAO,UAAU;AAE7B,IAAM,0BAA0B;EAC9B,SAAS,QAAmB;AAC1B,WAAO,OAAO,MAAM,IAAI;EAC1B;EACA,OAAO;EACP,QAAQ,QAAqB,KAAW;AACtC,WAAO,OAAO,MAAM,IAAI,MAAM,MAAM;EACtC;EACA,OAAO,QAAmB;AACxB,WAAO,OAAO,MAAM;EACtB;;AAGF,IAAMC,YAAW,MAAM;AACvB,IAAM,OAAO,MAAM,UAAU;AAC7B,IAAM,gBAAgB,gCAAU,KAAY,gBAAmB;AAC7D,OAAK,MAAM,KAAKA,UAAS,cAAc,IAAI,iBAAiB,CAAC,cAAc,CAAC;AAC9E,GAFsB;AAItB,IAAM,SAAS,KAAK,UAAU;AAE9B,IAAM,WAAW;EACf,gBAAgB;EAChB,WAAW;EACX,kBAAkB;EAClB,aAAa;EACb,SAAS;EACT,iBAAiB;EACjB,WAAW;EACX,QAAQ;EACR,iBAAiB;EACjB,SAAS;EACT,kBAAkB;EAClB,QAAQ;EACR,WAAW,WAAW,cAAc;;EAEpC,SAAS;EACT,cAAc,MAAI;AAChB,WAAO,OAAO,KAAK,IAAI;EACzB;EACA,WAAW;EACX,oBAAoB;;AAGtB,SAAS,yBAAyB,GAAU;AAC1C,SACE,OAAO,MAAM,YACb,OAAO,MAAM,YACb,OAAO,MAAM,aACb,OAAO,MAAM,YACb,OAAO,MAAM;AAEjB;AARS;AAUT,IAAM,WAAW,CAAA;AAEjB,SAAS,gBACP,QACA,QACA,qBACA,gBACA,kBACA,oBACA,WACA,iBACA,SACA,QACA,MACA,WACA,eACA,QACA,WACA,kBACA,SACA,aAA8B;AAE9B,MAAI,MAAM;AAEV,MAAI,SAAS;AACb,MAAI,OAAO;AACX,MAAI,YAAY;AAChB,UAAQ,SAAS,OAAO,IAAI,QAAQ,OAAO,UAAkB,CAAC,WAAW;AAEvE,UAAM,MAAM,OAAO,IAAI,MAAM;AAC7B,YAAQ;AACR,QAAI,OAAO,QAAQ,aAAa;AAC9B,UAAI,QAAQ,MAAM;AAChB,cAAM,IAAI,WAAW,qBAAqB;aACrC;AACL,oBAAY;;;AAGhB,QAAI,OAAO,OAAO,IAAI,QAAQ,MAAM,aAAa;AAC/C,aAAO;;;AAIX,MAAI,OAAO,WAAW,YAAY;AAChC,UAAM,OAAO,QAAQ,GAAG;aACf,eAAe,MAAM;AAC9B,UAAM,gBAAgB,GAAG;aAChB,wBAAwB,WAAWA,UAAS,GAAG,GAAG;AAC3D,UAAM,UAAU,KAAK,SAAU,OAAK;AAClC,UAAI,iBAAiB,MAAM;AACzB,eAAO,gBAAgB,KAAK;;AAE9B,aAAO;IACT,CAAC;;AAGH,MAAI,QAAQ,MAAM;AAChB,QAAI,oBAAoB;AACtB,aAAO,WAAW,CAAC;;QAEf,QAAQ,QAAQ,SAAS,SAAS,SAAS,OAAO,MAAM;UACxD;;AAGN,UAAM;;AAGR,MAAI,yBAAyB,GAAG,KAAK,UAAU,GAAG,GAAG;AACnD,QAAI,SAAS;AACX,YAAM,YACJ,mBAAmB,SAEjB,QAAQ,QAAQ,SAAS,SAAS,SAAS,OAAO,MAAM;AAC5D,aAAO;QACL,YAAY,SAAS,IACnB;QAEA,YAAY,QAAQ,KAAK,SAAS,SAAS,SAAS,SAAS,MAAM,CAAC;;;AAG1E,WAAO,CAAC,YAAY,MAAM,IAAI,MAAM,YAAY,OAAO,GAAG,CAAC,CAAC;;AAG9D,QAAM,SAAmB,CAAA;AAEzB,MAAI,OAAO,QAAQ,aAAa;AAC9B,WAAO;;AAGT,MAAI;AACJ,MAAI,wBAAwB,WAAWA,UAAS,GAAG,GAAG;AAEpD,QAAI,oBAAoB,SAAS;AAE/B,YAAM,UAAU,KAAK,OAAO;;AAE9B,eAAW,CAAC,EAAE,OAAO,IAAI,SAAS,IAAI,IAAI,KAAK,GAAG,KAAK,OAAO,OAAc,CAAE;aACrEA,UAAS,MAAM,GAAG;AAC3B,eAAW;SACN;AACL,UAAM,OAAO,OAAO,KAAK,GAAG;AAC5B,eAAW,OAAO,KAAK,KAAK,IAAI,IAAI;;AAGtC,QAAM,iBAAiB,kBAAkB,OAAO,MAAM,EAAE,QAAQ,OAAO,KAAK,IAAI,OAAO,MAAM;AAE7F,QAAM,kBACJ,kBAAkBA,UAAS,GAAG,KAAK,IAAI,WAAW,IAAI,iBAAiB,OAAO;AAEhF,MAAI,oBAAoBA,UAAS,GAAG,KAAK,IAAI,WAAW,GAAG;AACzD,WAAO,kBAAkB;;AAG3B,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE,GAAG;AACxC,UAAM,MAAM,SAAS,CAAC;AACtB,UAAM;;MAEJ,OAAO,QAAQ,YAAY,OAAO,IAAI,UAAU,cAAc,IAAI,QAAQ,IAAI,GAAU;;AAE1F,QAAI,aAAa,UAAU,MAAM;AAC/B;;AAIF,UAAM,cAAc,aAAa,kBAAmB,IAAY,QAAQ,OAAO,KAAK,IAAI;AACxF,UAAM,aACJA,UAAS,GAAG,IACV,OAAO,wBAAwB,aAC7B,oBAAoB,iBAAiB,WAAW,IAChD,kBACF,mBAAmB,YAAY,MAAM,cAAc,MAAM,cAAc;AAE3E,gBAAY,IAAI,QAAQ,IAAI;AAC5B,UAAM,mBAAmB,oBAAI,QAAO;AACpC,qBAAiB,IAAI,UAAU,WAAW;AAC1C,kBACE,QACA;MACE;MACA;MACA;MACA;MACA;MACA;MACA;MACA;;MAEA,wBAAwB,WAAW,oBAAoBA,UAAS,GAAG,IAAI,OAAO;MAC9E;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;IAAgB,CACjB;;AAIL,SAAO;AACT;AAhKS;AAkKT,SAAS,4BACP,OAAyB,UAAQ;AAEjC,MAAI,OAAO,KAAK,qBAAqB,eAAe,OAAO,KAAK,qBAAqB,WAAW;AAC9F,UAAM,IAAI,UAAU,wEAAwE;;AAG9F,MAAI,OAAO,KAAK,oBAAoB,eAAe,OAAO,KAAK,oBAAoB,WAAW;AAC5F,UAAM,IAAI,UAAU,uEAAuE;;AAG7F,MAAI,KAAK,YAAY,QAAQ,OAAO,KAAK,YAAY,eAAe,OAAO,KAAK,YAAY,YAAY;AACtG,UAAM,IAAI,UAAU,+BAA+B;;AAGrD,QAAM,UAAU,KAAK,WAAW,SAAS;AACzC,MAAI,OAAO,KAAK,YAAY,eAAe,KAAK,YAAY,WAAW,KAAK,YAAY,cAAc;AACpG,UAAM,IAAI,UAAU,mEAAmE;;AAGzF,MAAI,SAAS;AACb,MAAI,OAAO,KAAK,WAAW,aAAa;AACtC,QAAI,CAAC,IAAI,KAAK,YAAY,KAAK,MAAM,GAAG;AACtC,YAAM,IAAI,UAAU,iCAAiC;;AAEvD,aAAS,KAAK;;AAEhB,QAAM,YAAY,WAAW,MAAM;AAEnC,MAAI,SAAS,SAAS;AACtB,MAAI,OAAO,KAAK,WAAW,cAAcA,UAAS,KAAK,MAAM,GAAG;AAC9D,aAAS,KAAK;;AAGhB,MAAI;AACJ,MAAI,KAAK,eAAe,KAAK,eAAe,yBAAyB;AACnE,kBAAc,KAAK;aACV,aAAa,MAAM;AAC5B,kBAAc,KAAK,UAAU,YAAY;SACpC;AACL,kBAAc,SAAS;;AAGzB,MAAI,oBAAoB,QAAQ,OAAO,KAAK,mBAAmB,WAAW;AACxE,UAAM,IAAI,UAAU,+CAA+C;;AAGrE,QAAM,YACJ,OAAO,KAAK,cAAc,cACxB,CAAC,CAAC,KAAK,oBAAoB,OACzB,OACA,SAAS,YACX,CAAC,CAAC,KAAK;AAEX,SAAO;IACL,gBAAgB,OAAO,KAAK,mBAAmB,YAAY,KAAK,iBAAiB,SAAS;;IAE1F;IACA,kBACE,OAAO,KAAK,qBAAqB,YAAY,CAAC,CAAC,KAAK,mBAAmB,SAAS;IAClF;IACA;IACA,iBACE,OAAO,KAAK,oBAAoB,YAAY,KAAK,kBAAkB,SAAS;IAC9E,gBAAgB,CAAC,CAAC,KAAK;IACvB,WAAW,OAAO,KAAK,cAAc,cAAc,SAAS,YAAY,KAAK;IAC7E,QAAQ,OAAO,KAAK,WAAW,YAAY,KAAK,SAAS,SAAS;IAClE,iBACE,OAAO,KAAK,oBAAoB,YAAY,KAAK,kBAAkB,SAAS;IAC9E,SAAS,OAAO,KAAK,YAAY,aAAa,KAAK,UAAU,SAAS;IACtE,kBACE,OAAO,KAAK,qBAAqB,YAAY,KAAK,mBAAmB,SAAS;IAChF;IACA;IACA;IACA,eAAe,OAAO,KAAK,kBAAkB,aAAa,KAAK,gBAAgB,SAAS;IACxF,WAAW,OAAO,KAAK,cAAc,YAAY,KAAK,YAAY,SAAS;;IAE3E,MAAM,OAAO,KAAK,SAAS,aAAa,KAAK,OAAO;IACpD,oBACE,OAAO,KAAK,uBAAuB,YAAY,KAAK,qBAAqB,SAAS;;AAExF;AAlFS;AAoFH,SAAU,UAAU,QAAa,OAAyB,CAAA,GAAE;AAChE,MAAI,MAAM;AACV,QAAMC,WAAU,4BAA4B,IAAI;AAEhD,MAAI;AACJ,MAAI;AAEJ,MAAI,OAAOA,SAAQ,WAAW,YAAY;AACxC,aAASA,SAAQ;AACjB,UAAM,OAAO,IAAI,GAAG;aACXD,UAASC,SAAQ,MAAM,GAAG;AACnC,aAASA,SAAQ;AACjB,eAAW;;AAGb,QAAM,OAAiB,CAAA;AAEvB,MAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AAC3C,WAAO;;AAGT,QAAM,sBAAsB,wBAAwBA,SAAQ,WAAW;AACvE,QAAM,iBAAiB,wBAAwB,WAAWA,SAAQ;AAElE,MAAI,CAAC,UAAU;AACb,eAAW,OAAO,KAAK,GAAG;;AAG5B,MAAIA,SAAQ,MAAM;AAChB,aAAS,KAAKA,SAAQ,IAAI;;AAG5B,QAAM,cAAc,oBAAI,QAAO;AAC/B,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE,GAAG;AACxC,UAAM,MAAM,SAAS,CAAC;AAEtB,QAAIA,SAAQ,aAAa,IAAI,GAAG,MAAM,MAAM;AAC1C;;AAEF,kBACE,MACA;MACE,IAAI,GAAG;MACP;;MAEA;MACA;MACAA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ,SAASA,SAAQ,UAAU;MACnCA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACRA,SAAQ;MACR;IAAW,CACZ;;AAIL,QAAM,SAAS,KAAK,KAAKA,SAAQ,SAAS;AAC1C,MAAI,SAASA,SAAQ,mBAAmB,OAAO,MAAM;AAErD,MAAIA,SAAQ,iBAAiB;AAC3B,QAAIA,SAAQ,YAAY,cAAc;AAEpC,gBAAU;WACL;AAEL,gBAAU;;;AAId,SAAO,OAAO,SAAS,IAAI,SAAS,SAAS;AAC/C;AA/EgB;;;ACpTT,IAAM,UAAU;;;AC0BhB,IAAI,OAAO;AACX,IAAI,OAAkC;AACtC,IAAIC,SAAoC;AACxC,IAAIC,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,QAAkC;AACtC,IAAIC,QAAkC;AACtC,IAAIC,kBAAsD;AAC1D,IAAI,6BAA8E;AAClF,IAAI,kBAAwD;AAC5D,IAAI,eAAkD;AACtD,IAAI,iBAAsD;AAE3D,SAAU,SAAS,OAAcC,WAA6B,EAAE,MAAM,MAAK,GAAE;AACjF,MAAI,MAAM;AACR,UAAM,IAAI,MACR,mCAAmC,MAAM,IAAI,gDAAgD;;AAGjG,MAAI,MAAM;AACR,UAAM,IAAI,MAAM,gCAAgC,MAAM,IAAI,oCAAoC,IAAI,KAAK;;AAEzG,SAAOA,SAAQ;AACf,SAAO,MAAM;AACb,EAAAR,SAAQ,MAAM;AACd,EAAAC,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,QAAO,MAAM;AACb,EAAAC,QAAO,MAAM;AACb,EAAAC,kBAAiB,MAAM;AACvB,+BAA6B,MAAM;AACnC,oBAAkB,MAAM;AACxB,iBAAe,MAAM;AACrB,mBAAiB,MAAM;AACzB;AAvBgB;;;ACtCV,IAAO,gBAAP,MAAoB;EAH1B,OAG0B;;;EACxB,YAAmB,MAAS;AAAT,SAAA,OAAA;EAAY;EAC/B,KAAK,OAAO,WAAW,IAAC;AACtB,WAAO;EACT;;;;ACAI,SAAU,WAAW,EAAE,iBAAgB,IAAqC,CAAA,GAAE;AAClF,QAAM,iBACJ,mBACE,kCACA;;;;AAKJ,MAAI,QAAQ,UAAU,WAAW;AACjC,MAAI;AAEF,aAAS;AAET,eAAW;AAEX,gBAAY;AAEZ,eAAW;WACJ,OAAO;AACd,UAAM,IAAI,MACR,iEACG,MAAc,OACjB,KAAK,cAAc,EAAE;;AAIzB,SAAO;IACL,MAAM;IACN,OAAO;IACP,SAAS;IACT,UAAU;IACV,SAAS;IACT;;MAEE,OAAO,aAAa,cAAc,WAChC,MAAM,SAAQ;eAAA;;;;QAEZ,cAAA;AACE,gBAAM,IAAI,MACR,qFAAqF,cAAc,EAAE;QAEzG;;;IAGN,MACE,OAAO,SAAS,cAAc,OAC5B,MAAM,KAAI;aAAA;;;MACR,cAAA;AACE,cAAM,IAAI,MACR,iFAAiF,cAAc,EAAE;MAErG;;IAGN;;MAEE,OAAO,SAAS,cAAc,OAC5B,MAAM,KAAI;eAAA;;;;QAER,cAAA;AACE,gBAAM,IAAI,MACR,iFAAiF,cAAc,EAAE;QAErG;;;IAGN;;MAEE,OAAO,mBAAmB,cAAc,iBACtC,MAAM,eAAc;eAAA;;;;QAElB,cAAA;AACE,gBAAM,IAAI,MACR,uFAAuF,cAAc,EAAE;QAE3G;;;IAGN,4BAA4B,8BAE1B,MACA,UACgC;MAChC,GAAG;MACH,MAAM,IAAI,cAAc,IAAI;QANF;IAQ5B,iBAAiB,wBAAC,QAAgB,QAAjB;IACjB,cAAc,6BAAK;AACjB,YAAM,IAAI,MACR,gJAAgJ;IAEpJ,GAJc;IAKd,gBAAgB,wBAAC,UAAe,OAAhB;;AAEpB;AA/FgB;;;ACFhB,IAAI,CAAO,KAAM,CAAM,SAAc,WAAW,GAAG,EAAE,MAAM,KAAK,CAAC;;;ACD3D,IAAO,cAAP,cAA2B,MAAK;EAJtC,OAIsC;;;;AAEhC,IAAO,WAAP,MAAO,kBAIH,YAAW;EAVrB,OAUqB;;;EAcnB,YAAY,QAAiB,OAAe,SAA6B,SAAiB;AACxF,UAAM,GAAG,UAAS,YAAY,QAAQ,OAAO,OAAO,CAAC,EAAE;AACvD,SAAK,SAAS;AACd,SAAK,UAAU;AACf,SAAK,aAAa,UAAU,cAAc;AAC1C,SAAK,QAAQ;AAEb,UAAM,OAAO;AACb,SAAK,OAAO,OAAO,MAAM;AACzB,SAAK,QAAQ,OAAO,OAAO;AAC3B,SAAK,OAAO,OAAO,MAAM;EAC3B;EAEQ,OAAO,YAAY,QAA4B,OAAY,SAA2B;AAC5F,UAAM,MACJ,OAAO,UACL,OAAO,MAAM,YAAY,WACvB,MAAM,UACN,KAAK,UAAU,MAAM,OAAO,IAC9B,QAAQ,KAAK,UAAU,KAAK,IAC5B;AAEJ,QAAI,UAAU,KAAK;AACjB,aAAO,GAAG,MAAM,IAAI,GAAG;;AAEzB,QAAI,QAAQ;AACV,aAAO,GAAG,MAAM;;AAElB,QAAI,KAAK;AACP,aAAO;;AAET,WAAO;EACT;EAEA,OAAO,SACL,QACA,eACA,SACA,SAA4B;AAE5B,QAAI,CAAC,UAAU,CAAC,SAAS;AACvB,aAAO,IAAI,mBAAmB,EAAE,SAAS,OAAO,YAAY,aAAa,EAAC,CAAE;;AAG9E,UAAM,QAAS,gBAAwC,OAAO;AAE9D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,gBAAgB,QAAQ,OAAO,SAAS,OAAO;;AAG5D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,sBAAsB,QAAQ,OAAO,SAAS,OAAO;;AAGlE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,yBAAyB,QAAQ,OAAO,SAAS,OAAO;;AAGrE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,eAAe,QAAQ,OAAO,SAAS,OAAO;;AAG3D,QAAI,UAAU,KAAK;AACjB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,WAAO,IAAI,UAAS,QAAQ,OAAO,SAAS,OAAO;EACrD;;AAGI,IAAO,oBAAP,cAAiC,SAAyC;EA1GhF,OA0GgF;;;EAC9E,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,QAAW,QAAW,WAAW,wBAAwB,MAAS;EAC1E;;AAGI,IAAO,qBAAP,cAAkC,SAAyC;EAhHjF,OAgHiF;;;EAC/E,YAAY,EAAE,SAAS,MAAK,GAA+D;AACzF,UAAM,QAAW,QAAW,WAAW,qBAAqB,MAAS;AAGrE,QAAI;AAAO,WAAK,QAAQ;EAC1B;;AAGI,IAAO,4BAAP,cAAyC,mBAAkB;EAzHjE,OAyHiE;;;EAC/D,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,EAAE,SAAS,WAAW,qBAAoB,CAAE;EACpD;;AAGI,IAAO,kBAAP,cAA+B,SAAsB;EA/H3D,OA+H2D;;;;AAErD,IAAO,sBAAP,cAAmC,SAAsB;EAjI/D,OAiI+D;;;;AAEzD,IAAO,wBAAP,cAAqC,SAAsB;EAnIjE,OAmIiE;;;;AAE3D,IAAO,gBAAP,cAA6B,SAAsB;EArIzD,OAqIyD;;;;AAEnD,IAAO,gBAAP,cAA6B,SAAsB;EAvIzD,OAuIyD;;;;AAEnD,IAAO,2BAAP,cAAwC,SAAsB;EAzIpE,OAyIoE;;;;AAE9D,IAAO,iBAAP,cAA8B,SAAsB;EA3I1D,OA2I0D;;;;AAEpD,IAAO,sBAAP,cAAmC,SAAyB;EA7IlE,OA6IkE;;;;AAE5D,IAAO,0BAAP,cAAuC,YAAW;EA/IxD,OA+IwD;;;EACtD,cAAA;AACE,UAAM,kEAAkE;EAC1E;;AAGI,IAAO,iCAAP,cAA8C,YAAW;EArJ/D,OAqJ+D;;;EAC7D,cAAA;AACE,UAAM,oFAAoF;EAC5F;;;;;;;;;;;;;;;;AC9II,IAAO,cAAP,MAAkB;SAAA;;;EAStB,cAAA;AAHA,qCAAA,IAAA,MAAA,MAAA;AAIE,SAAK,SAAS,IAAI,WAAU;AAC5B,2BAAA,MAAI,kCAAwB,MAAI,GAAA;EAClC;EAEA,OAAO,OAAY;AACjB,QAAI,SAAS,MAAM;AACjB,aAAO,CAAA;;AAGT,UAAM,cACJ,iBAAiB,cAAc,IAAI,WAAW,KAAK,IACjD,OAAO,UAAU,WAAW,IAAI,YAAW,EAAG,OAAO,KAAK,IAC1D;AAEJ,QAAI,UAAU,IAAI,WAAW,KAAK,OAAO,SAAS,YAAY,MAAM;AACpE,YAAQ,IAAI,KAAK,MAAM;AACvB,YAAQ,IAAI,aAAa,KAAK,OAAO,MAAM;AAC3C,SAAK,SAAS;AAEd,UAAM,QAAkB,CAAA;AACxB,QAAI;AACJ,YAAQ,eAAe,iBAAiB,KAAK,QAAQ,uBAAA,MAAI,kCAAA,GAAA,CAAqB,MAAM,MAAM;AACxF,UAAI,aAAa,YAAY,uBAAA,MAAI,kCAAA,GAAA,KAAyB,MAAM;AAE9D,+BAAA,MAAI,kCAAwB,aAAa,OAAK,GAAA;AAC9C;;AAIF,UACE,uBAAA,MAAI,kCAAA,GAAA,KAAyB,SAC5B,aAAa,UAAU,uBAAA,MAAI,kCAAA,GAAA,IAAwB,KAAK,aAAa,WACtE;AACA,cAAM,KAAK,KAAK,WAAW,KAAK,OAAO,MAAM,GAAG,uBAAA,MAAI,kCAAA,GAAA,IAAwB,CAAC,CAAC,CAAC;AAC/E,aAAK,SAAS,KAAK,OAAO,MAAM,uBAAA,MAAI,kCAAA,GAAA,CAAqB;AACzD,+BAAA,MAAI,kCAAwB,MAAI,GAAA;AAChC;;AAGF,YAAM,WACJ,uBAAA,MAAI,kCAAA,GAAA,MAA0B,OAAO,aAAa,YAAY,IAAI,aAAa;AAEjF,YAAM,OAAO,KAAK,WAAW,KAAK,OAAO,MAAM,GAAG,QAAQ,CAAC;AAC3D,YAAM,KAAK,IAAI;AAEf,WAAK,SAAS,KAAK,OAAO,MAAM,aAAa,KAAK;AAClD,6BAAA,MAAI,kCAAwB,MAAI,GAAA;;AAGlC,WAAO;EACT;EAEA,WAAW,OAAY;AACrB,QAAI,SAAS;AAAM,aAAO;AAC1B,QAAI,OAAO,UAAU;AAAU,aAAO;AAGtC,QAAI,OAAO,WAAW,aAAa;AACjC,UAAI,iBAAiB,QAAQ;AAC3B,eAAO,MAAM,SAAQ;;AAEvB,UAAI,iBAAiB,YAAY;AAC/B,eAAO,OAAO,KAAK,KAAK,EAAE,SAAQ;;AAGpC,YAAM,IAAI,YACR,wCAAwC,MAAM,YAAY,IAAI,mIAAmI;;AAKrM,QAAI,OAAO,gBAAgB,aAAa;AACtC,UAAI,iBAAiB,cAAc,iBAAiB,aAAa;AAC/D,aAAK,gBAAL,KAAK,cAAgB,IAAI,YAAY,MAAM;AAC3C,eAAO,KAAK,YAAY,OAAO,KAAK;;AAGtC,YAAM,IAAI,YACR,oDACG,MAAc,YAAY,IAC7B,gDAAgD;;AAIpD,UAAM,IAAI,YACR,gGAAgG;EAEpG;EAEA,QAAK;AACH,QAAI,CAAC,KAAK,OAAO,QAAQ;AACvB,aAAO,CAAA;;AAET,WAAO,KAAK,OAAO,IAAI;EACzB;;;AAtGO,YAAA,gBAAgB,oBAAI,IAAI,CAAC,MAAM,IAAI,CAAC;AACpC,YAAA,iBAAiB;AAiH1B,SAAS,iBACP,QACA,YAAyB;AAEzB,QAAME,WAAU;AAChB,QAAM,WAAW;AAEjB,WAAS,IAAI,cAAc,GAAG,IAAI,OAAO,QAAQ,KAAK;AACpD,QAAI,OAAO,CAAC,MAAMA,UAAS;AACzB,aAAO,EAAE,WAAW,GAAG,OAAO,IAAI,GAAG,UAAU,MAAK;;AAGtD,QAAI,OAAO,CAAC,MAAM,UAAU;AAC1B,aAAO,EAAE,WAAW,GAAG,OAAO,IAAI,GAAG,UAAU,KAAI;;;AAIvD,SAAO;AACT;AAlBS;AAoBH,SAAU,uBAAuB,QAAkB;AAIvD,QAAMA,WAAU;AAChB,QAAM,WAAW;AAEjB,WAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAC1C,QAAI,OAAO,CAAC,MAAMA,YAAW,OAAO,IAAI,CAAC,MAAMA,UAAS;AAEtD,aAAO,IAAI;;AAEb,QAAI,OAAO,CAAC,MAAM,YAAY,OAAO,IAAI,CAAC,MAAM,UAAU;AAExD,aAAO,IAAI;;AAEb,QACE,OAAO,CAAC,MAAM,YACd,OAAO,IAAI,CAAC,MAAMA,YAClB,IAAI,IAAI,OAAO,UACf,OAAO,IAAI,CAAC,MAAM,YAClB,OAAO,IAAI,CAAC,MAAMA,UAClB;AAEA,aAAO,IAAI;;;AAIf,SAAO;AACT;AA7BgB;;;AC5IV,SAAU,8BAAiC,QAAW;AAC1D,MAAI,OAAO,OAAO,aAAa;AAAG,WAAO;AAEzC,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO;IACL,MAAM,OAAI;AACR,UAAI;AACF,cAAM,SAAS,MAAM,OAAO,KAAI;AAChC,YAAI,QAAQ;AAAM,iBAAO,YAAW;AACpC,eAAO;eACA,GAAG;AACV,eAAO,YAAW;AAClB,cAAM;;IAEV;IACA,MAAM,SAAM;AACV,YAAM,gBAAgB,OAAO,OAAM;AACnC,aAAO,YAAW;AAClB,YAAM;AACN,aAAO,EAAE,MAAM,MAAM,OAAO,OAAS;IACvC;IACA,CAAC,OAAO,aAAa,IAAC;AACpB,aAAO;IACT;;AAEJ;AAzBgB;;;ACSV,IAAO,SAAP,MAAO,QAAM;SAAA;;;EAGjB,YACU,UACR,YAA2B;AADnB,SAAA,WAAA;AAGR,SAAK,aAAa;EACpB;EAEA,OAAO,gBAAsB,UAAoB,YAA2B;AAC1E,QAAI,WAAW;AAEf,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,OAAO,iBAAiB,UAAU,UAAU,GAAG;AAC9D,cAAI;AAAM;AAEV,cAAI,IAAI,KAAK,WAAW,QAAQ,GAAG;AACjC,mBAAO;AACP;;AAGF,cAAI,IAAI,UAAU,QAAQ,IAAI,MAAM,WAAW,WAAW,GAAG;AAC3D,gBAAI;AAEJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,QAAQ,KAAK,OAAO;AACtB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,QAAW,MAAS;;AAGhE,kBAAM;iBACD;AACL,gBAAI;AACJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,IAAI,SAAS,SAAS;AACxB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,KAAK,SAAS,MAAS;;AAEnE,kBAAM,EAAE,OAAO,IAAI,OAAO,KAAU;;;AAGxC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAxDgB;AA0DhB,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;;;;;EAMA,OAAO,mBAAyB,gBAAgC,YAA2B;AACzF,QAAI,WAAW;AAEf,oBAAgB,YAAS;AACvB,YAAM,cAAc,IAAI,YAAW;AAEnC,YAAM,OAAO,8BAAqC,cAAc;AAChE,uBAAiB,SAAS,MAAM;AAC9B,mBAAW,QAAQ,YAAY,OAAO,KAAK,GAAG;AAC5C,gBAAM;;;AAIV,iBAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,cAAM;;IAEV;AAbgB;AAehB,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,QAAQ,UAAS,GAAI;AACpC,cAAI;AAAM;AACV,cAAI;AAAM,kBAAM,KAAK,MAAM,IAAI;;AAEjC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AApBgB;AAsBhB,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;EAEA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,SAAQ;EACtB;;;;;EAMA,MAAG;AACD,UAAM,OAA6C,CAAA;AACnD,UAAM,QAA8C,CAAA;AACpD,UAAM,WAAW,KAAK,SAAQ;AAE9B,UAAM,cAAc,wBAAC,UAAoE;AACvF,aAAO;QACL,MAAM,6BAAK;AACT,cAAI,MAAM,WAAW,GAAG;AACtB,kBAAM,SAAS,SAAS,KAAI;AAC5B,iBAAK,KAAK,MAAM;AAChB,kBAAM,KAAK,MAAM;;AAEnB,iBAAO,MAAM,MAAK;QACpB,GAPM;;IASV,GAXoB;AAapB,WAAO;MACL,IAAI,QAAO,MAAM,YAAY,IAAI,GAAG,KAAK,UAAU;MACnD,IAAI,QAAO,MAAM,YAAY,KAAK,GAAG,KAAK,UAAU;;EAExD;;;;;;EAOA,mBAAgB;AACd,UAAM,OAAO;AACb,QAAI;AACJ,UAAM,UAAU,IAAI,YAAW;AAE/B,WAAO,IAAIC,gBAAe;MACxB,MAAM,QAAK;AACT,eAAO,KAAK,OAAO,aAAa,EAAC;MACnC;MACA,MAAM,KAAK,MAAS;AAClB,YAAI;AACF,gBAAM,EAAE,OAAO,KAAI,IAAK,MAAM,KAAK,KAAI;AACvC,cAAI;AAAM,mBAAO,KAAK,MAAK;AAE3B,gBAAM,QAAQ,QAAQ,OAAO,KAAK,UAAU,KAAK,IAAI,IAAI;AAEzD,eAAK,QAAQ,KAAK;iBACX,KAAK;AACZ,eAAK,MAAM,GAAG;;MAElB;MACA,MAAM,SAAM;AACV,cAAM,KAAK,SAAQ;MACrB;KACD;EACH;;AAGF,gBAAuB,iBACrB,UACA,YAA2B;AAE3B,MAAI,CAAC,SAAS,MAAM;AAClB,eAAW,MAAK;AAChB,UAAM,IAAI,YAAY,mDAAmD;;AAG3E,QAAM,aAAa,IAAI,WAAU;AACjC,QAAM,cAAc,IAAI,YAAW;AAEnC,QAAM,OAAO,8BAAqC,SAAS,IAAI;AAC/D,mBAAiB,YAAY,cAAc,IAAI,GAAG;AAChD,eAAW,QAAQ,YAAY,OAAO,QAAQ,GAAG;AAC/C,YAAM,MAAM,WAAW,OAAO,IAAI;AAClC,UAAI;AAAK,cAAM;;;AAInB,aAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,UAAM,MAAM,WAAW,OAAO,IAAI;AAClC,QAAI;AAAK,YAAM;;AAEnB;AAxBuB;AA8BvB,gBAAgB,cAAc,UAAsC;AAClE,MAAI,OAAO,IAAI,WAAU;AAEzB,mBAAiB,SAAS,UAAU;AAClC,QAAI,SAAS,MAAM;AACjB;;AAGF,UAAM,cACJ,iBAAiB,cAAc,IAAI,WAAW,KAAK,IACjD,OAAO,UAAU,WAAW,IAAI,YAAW,EAAG,OAAO,KAAK,IAC1D;AAEJ,QAAI,UAAU,IAAI,WAAW,KAAK,SAAS,YAAY,MAAM;AAC7D,YAAQ,IAAI,IAAI;AAChB,YAAQ,IAAI,aAAa,KAAK,MAAM;AACpC,WAAO;AAEP,QAAI;AACJ,YAAQ,eAAe,uBAAuB,IAAI,OAAO,IAAI;AAC3D,YAAM,KAAK,MAAM,GAAG,YAAY;AAChC,aAAO,KAAK,MAAM,YAAY;;;AAIlC,MAAI,KAAK,SAAS,GAAG;AACnB,UAAM;;AAEV;AA5BgB;AA8BhB,IAAM,aAAN,MAAgB;SAAA;;;EAKd,cAAA;AACE,SAAK,QAAQ;AACb,SAAK,OAAO,CAAA;AACZ,SAAK,SAAS,CAAA;EAChB;EAEA,OAAO,MAAY;AACjB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,aAAO,KAAK,UAAU,GAAG,KAAK,SAAS,CAAC;;AAG1C,QAAI,CAAC,MAAM;AAET,UAAI,CAAC,KAAK,SAAS,CAAC,KAAK,KAAK;AAAQ,eAAO;AAE7C,YAAM,MAAuB;QAC3B,OAAO,KAAK;QACZ,MAAM,KAAK,KAAK,KAAK,IAAI;QACzB,KAAK,KAAK;;AAGZ,WAAK,QAAQ;AACb,WAAK,OAAO,CAAA;AACZ,WAAK,SAAS,CAAA;AAEd,aAAO;;AAGT,SAAK,OAAO,KAAK,IAAI;AAErB,QAAI,KAAK,WAAW,GAAG,GAAG;AACxB,aAAO;;AAGT,QAAI,CAAC,WAAW,GAAG,KAAK,IAAI,UAAU,MAAM,GAAG;AAE/C,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,cAAQ,MAAM,UAAU,CAAC;;AAG3B,QAAI,cAAc,SAAS;AACzB,WAAK,QAAQ;eACJ,cAAc,QAAQ;AAC/B,WAAK,KAAK,KAAK,KAAK;;AAGtB,WAAO;EACT;;AAGF,SAAS,UAAUC,MAAa,WAAiB;AAC/C,QAAM,QAAQA,KAAI,QAAQ,SAAS;AACnC,MAAI,UAAU,IAAI;AAChB,WAAO,CAACA,KAAI,UAAU,GAAG,KAAK,GAAG,WAAWA,KAAI,UAAU,QAAQ,UAAU,MAAM,CAAC;;AAGrF,SAAO,CAACA,MAAK,IAAI,EAAE;AACrB;AAPS;;;AChQF,IAAM,iBAAiB,wBAAC,UAC7B,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,QAAQ,YACrB,OAAO,MAAM,SAAS,YAJM;AAMvB,IAAM,aAAa,wBAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,iBAAiB,YAC9B,WAAW,KAAK,GALQ;AAWnB,IAAM,aAAa,wBAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,cACtB,OAAO,MAAM,UAAU,cACvB,OAAO,MAAM,gBAAgB,YAPL;AASnB,IAAM,eAAe,wBAAC,UAAmC;AAC9D,SAAO,WAAW,KAAK,KAAK,eAAe,KAAK,KAAK,eAAe,KAAK;AAC3E,GAF4B;AAe5B,eAAsB,OACpB,OACA,MACAC,UAAqC;AAGrC,UAAQ,MAAM;AAGd,MAAI,WAAW,KAAK,GAAG;AACrB,WAAO;;AAGT,MAAI,eAAe,KAAK,GAAG;AACzB,UAAM,OAAO,MAAM,MAAM,KAAI;AAC7B,aAAA,OAAS,IAAI,IAAI,MAAM,GAAG,EAAE,SAAS,MAAM,OAAO,EAAE,IAAG,KAAM;AAK7D,UAAM,OAAO,WAAW,IAAI,IAAI,CAAE,MAAM,KAAK,YAAW,CAAU,IAAI,CAAC,IAAI;AAE3E,WAAO,IAAIC,MAAK,MAAM,MAAMD,QAAO;;AAGrC,QAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,WAAA,OAAS,QAAQ,KAAK,KAAK;AAE3B,MAAI,CAACA,UAAS,MAAM;AAClB,UAAM,OAAQ,KAAK,CAAC,GAAW;AAC/B,QAAI,OAAO,SAAS,UAAU;AAC5B,MAAAA,WAAU,EAAE,GAAGA,UAAS,KAAI;;;AAIhC,SAAO,IAAIC,MAAK,MAAM,MAAMD,QAAO;AACrC;AArCsB;AAuCtB,eAAe,SAAS,OAAkB;AACxC,MAAI,QAAyB,CAAA;AAC7B,MACE,OAAO,UAAU,YACjB,YAAY,OAAO,KAAK;EACxB,iBAAiB,aACjB;AACA,UAAM,KAAK,KAAK;aACP,WAAW,KAAK,GAAG;AAC5B,UAAM,KAAK,MAAM,MAAM,YAAW,CAAE;aAEpC,wBAAwB,KAAK,GAC7B;AACA,qBAAiB,SAAS,OAAO;AAC/B,YAAM,KAAK,KAAiB;;SAEzB;AACL,UAAM,IAAI,MACR,yBAAyB,OAAO,KAAK,kBAAkB,OAAO,aAC1D,IAAI,YAAY,cAAc,KAAK,CAAC,EAAE;;AAI9C,SAAO;AACT;AAxBe;AA0Bf,SAAS,cAAc,OAAU;AAC/B,QAAM,QAAQ,OAAO,oBAAoB,KAAK;AAC9C,SAAO,IAAI,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,IAAI,CAAC;AAClD;AAHS;AAKT,SAAS,QAAQ,OAAU;AACzB,SACE,yBAAyB,MAAM,IAAI,KACnC,yBAAyB,MAAM,QAAQ;EAEvC,yBAAyB,MAAM,IAAI,GAAG,MAAM,OAAO,EAAE,IAAG;AAE5D;AAPS;AAST,IAAM,2BAA2B,wBAAC,MAAoD;AACpF,MAAI,OAAO,MAAM;AAAU,WAAO;AAClC,MAAI,OAAO,WAAW,eAAe,aAAa;AAAQ,WAAO,OAAO,CAAC;AACzE,SAAO;AACT,GAJiC;AAMjC,IAAM,0BAA0B,wBAAC,UAC/B,SAAS,QAAQ,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,aAAa,MAAM,YADvD;AAGzB,IAAM,kBAAkB,wBAAC,SAC9B,QAAQ,OAAO,SAAS,YAAY,KAAK,QAAQ,KAAK,OAAO,WAAW,MAAM,iBADjD;AAgBxB,IAAM,8BAA8B,8BACzC,SAC8C;AAC9C,QAAM,OAAO,MAAM,WAAW,KAAK,IAAI;AACvC,SAAO,2BAA2B,MAAM,IAAI;AAC9C,GAL2C;AAOpC,IAAM,aAAa,8BAAoC,SAA0C;AACtG,QAAM,OAAO,IAAIE,UAAQ;AACzB,QAAM,QAAQ,IAAI,OAAO,QAAQ,QAAQ,CAAA,CAAE,EAAE,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,aAAa,MAAM,KAAK,KAAK,CAAC,CAAC;AAClG,SAAO;AACT,GAJ0B;AAiB1B,IAAM,eAAe,8BAAO,MAAgB,KAAa,UAAiC;AACxF,MAAI,UAAU;AAAW;AACzB,MAAI,SAAS,MAAM;AACjB,UAAM,IAAI,UACR,sBAAsB,GAAG,6DAA6D;;AAK1F,MAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,SAAK,OAAO,KAAK,OAAO,KAAK,CAAC;aACrB,aAAa,KAAK,GAAG;AAC9B,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,SAAK,OAAO,KAAK,IAAY;aACpB,MAAM,QAAQ,KAAK,GAAG;AAC/B,UAAM,QAAQ,IAAI,MAAM,IAAI,CAAC,UAAU,aAAa,MAAM,MAAM,MAAM,KAAK,CAAC,CAAC;aACpE,OAAO,UAAU,UAAU;AACpC,UAAM,QAAQ,IACZ,OAAO,QAAQ,KAAK,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM,aAAa,MAAM,GAAG,GAAG,IAAI,IAAI,KAAK,IAAI,CAAC,CAAC;SAErF;AACL,UAAM,IAAI,UACR,wGAAwG,KAAK,UAAU;;AAG7H,GAzBqB;;;;;;;;;;;;;;;AC9LrB,eAAe,qBAAwB,OAAuB;AAC5D,QAAM,EAAE,SAAQ,IAAK;AACrB,MAAI,MAAM,QAAQ,QAAQ;AACxB,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,SAAS,IAAI;AAKhF,QAAI,MAAM,QAAQ,eAAe;AAC/B,aAAO,MAAM,QAAQ,cAAc,gBAAgB,UAAU,MAAM,UAAU;;AAG/E,WAAO,OAAO,gBAAgB,UAAU,MAAM,UAAU;;AAI1D,MAAI,SAAS,WAAW,KAAK;AAC3B,WAAO;;AAGT,MAAI,MAAM,QAAQ,kBAAkB;AAClC,WAAO;;AAGT,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,QAAM,YAAY,aAAa,MAAM,GAAG,EAAE,CAAC,GAAG,KAAI;AAClD,QAAM,SAAS,WAAW,SAAS,kBAAkB,KAAK,WAAW,SAAS,OAAO;AACrF,MAAI,QAAQ;AACV,UAAM,OAAO,MAAM,SAAS,KAAI;AAEhC,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAEvE,WAAO,cAAc,MAAM,QAAQ;;AAGrC,QAAM,OAAO,MAAM,SAAS,KAAI;AAChC,QAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAGvE,SAAO;AACT;AAxCe;AA+Cf,SAAS,cAAiB,OAAU,UAAkB;AACpD,MAAI,CAAC,SAAS,OAAO,UAAU,YAAY,MAAM,QAAQ,KAAK,GAAG;AAC/D,WAAO;;AAGT,SAAO,OAAO,eAAe,OAAO,eAAe;IACjD,OAAO,SAAS,QAAQ,IAAI,cAAc;IAC1C,YAAY;GACb;AACH;AATS;AAeH,IAAO,aAAP,MAAO,oBAAsB,QAAyB;SAAA;;;EAG1D,YACU,iBACAC,iBAEgC,sBAAoB;AAE5D,UAAM,CAAC,YAAW;AAIhB,cAAQ,IAAW;IACrB,CAAC;AAVO,SAAA,kBAAA;AACA,SAAA,gBAAAA;EAUV;EAEA,YAAe,WAAkD;AAC/D,WAAO,IAAI,YAAW,KAAK,iBAAiB,OAAO,UACjD,cAAc,UAAU,MAAM,KAAK,cAAc,KAAK,GAAG,KAAK,GAAG,MAAM,QAAQ,CAAC;EAEpF;;;;;;;;;;;;;;EAeA,aAAU;AACR,WAAO,KAAK,gBAAgB,KAAK,CAAC,MAAM,EAAE,QAAQ;EACpD;;;;;;;;;;;;;;;;EAiBA,MAAM,eAAY;AAChB,UAAM,CAAC,MAAM,QAAQ,IAAI,MAAM,QAAQ,IAAI,CAAC,KAAK,MAAK,GAAI,KAAK,WAAU,CAAE,CAAC;AAC5E,WAAO,EAAE,MAAM,UAAU,YAAY,SAAS,QAAQ,IAAI,cAAc,EAAC;EAC3E;EAEQ,QAAK;AACX,QAAI,CAAC,KAAK,eAAe;AACvB,WAAK,gBAAgB,KAAK,gBAAgB,KAAK,KAAK,aAAa;;AAEnE,WAAO,KAAK;EACd;EAES,KACP,aACA,YAAmF;AAEnF,WAAO,KAAK,MAAK,EAAG,KAAK,aAAa,UAAU;EAClD;EAES,MACP,YAAiF;AAEjF,WAAO,KAAK,MAAK,EAAG,MAAM,UAAU;EACtC;EAES,QAAQ,WAA2C;AAC1D,WAAO,KAAK,MAAK,EAAG,QAAQ,SAAS;EACvC;;AAGI,IAAgB,YAAhB,MAAyB;SAAA;;;EAS7B,YAAY;IACV;IACA,aAAa;IACb,UAAU;;IACV;IACA,OAAO;EAAe,GAOvB;AACC,SAAK,UAAU;AACf,SAAK,aAAa,wBAAwB,cAAc,UAAU;AAClE,SAAK,UAAU,wBAAwB,WAAW,OAAO;AACzD,SAAK,YAAY;AAEjB,SAAK,QAAQ,mBAAmBC;EAClC;EAEU,YAAY,MAAyB;AAC7C,WAAO,CAAA;EACT;;;;;;;;;EAUU,eAAe,MAAyB;AAChD,WAAO;MACL,QAAQ;MACR,gBAAgB;MAChB,cAAc,KAAK,aAAY;MAC/B,GAAG,mBAAkB;MACrB,GAAG,KAAK,YAAY,IAAI;;EAE5B;;;;EAOU,gBAAgB,SAAkB,eAAsB;EAAG;EAE3D,wBAAqB;AAC7B,WAAO,wBAAwB,MAAK,CAAE;EACxC;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,KAAe,MAAc,MAA0C;AACrE,WAAO,KAAK,cAAc,QAAQ,MAAM,IAAI;EAC9C;EAEA,MAAgB,MAAc,MAA0C;AACtE,WAAO,KAAK,cAAc,SAAS,MAAM,IAAI;EAC/C;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,OAAiB,MAAc,MAA0C;AACvE,WAAO,KAAK,cAAc,UAAU,MAAM,IAAI;EAChD;EAEQ,cACN,QACA,MACA,MAA0C;AAE1C,WAAO,KAAK,QACV,QAAQ,QAAQ,IAAI,EAAE,KAAK,OAAOC,UAAQ;AACxC,YAAM,OACJA,SAAQ,WAAWA,OAAM,IAAI,IAAI,IAAI,SAAS,MAAMA,MAAK,KAAK,YAAW,CAAE,IACzEA,OAAM,gBAAgB,WAAWA,MAAK,OACtCA,OAAM,gBAAgB,cAAc,IAAI,SAASA,MAAK,IAAI,IAC1DA,SAAQ,YAAY,OAAOA,OAAM,IAAI,IAAI,IAAI,SAASA,MAAK,KAAK,MAAM,IACtEA,OAAM;AACV,aAAO,EAAE,QAAQ,MAAM,GAAGA,OAAM,KAAI;IACtC,CAAC,CAAC;EAEN;EAEA,WACE,MACAC,OACA,MAA0B;AAE1B,WAAO,KAAK,eAAeA,OAAM,EAAE,QAAQ,OAAO,MAAM,GAAG,KAAI,CAAE;EACnE;EAEQ,uBAAuB,MAAa;AAC1C,QAAI,OAAO,SAAS,UAAU;AAC5B,UAAI,OAAO,WAAW,aAAa;AACjC,eAAO,OAAO,WAAW,MAAM,MAAM,EAAE,SAAQ;;AAGjD,UAAI,OAAO,gBAAgB,aAAa;AACtC,cAAM,UAAU,IAAI,YAAW;AAC/B,cAAM,UAAU,QAAQ,OAAO,IAAI;AACnC,eAAO,QAAQ,OAAO,SAAQ;;eAEvB,YAAY,OAAO,IAAI,GAAG;AACnC,aAAO,KAAK,WAAW,SAAQ;;AAGjC,WAAO;EACT;EAEA,aACEC,UACA,EAAE,aAAa,EAAC,IAA8B,CAAA,GAAE;AAEhD,IAAAA,WAAU,EAAE,GAAGA,SAAO;AACtB,UAAM,EAAE,QAAQ,MAAM,OAAO,UAAmB,CAAA,EAAE,IAAKA;AAEvD,UAAM,OACJ,YAAY,OAAOA,SAAQ,IAAI,KAAMA,SAAQ,mBAAmB,OAAOA,SAAQ,SAAS,WACtFA,SAAQ,OACR,gBAAgBA,SAAQ,IAAI,IAAIA,SAAQ,KAAK,OAC7CA,SAAQ,OAAO,KAAK,UAAUA,SAAQ,MAAM,MAAM,CAAC,IACnD;AACJ,UAAM,gBAAgB,KAAK,uBAAuB,IAAI;AAEtD,UAAM,MAAM,KAAK,SAAS,MAAO,KAAK;AACtC,QAAI,aAAaA;AAAS,8BAAwB,WAAWA,SAAQ,OAAO;AAC5E,IAAAA,SAAQ,UAAUA,SAAQ,WAAW,KAAK;AAC1C,UAAM,YAAYA,SAAQ,aAAa,KAAK,aAAa,gBAAgB,GAAG;AAC5E,UAAM,kBAAkBA,SAAQ,UAAU;AAC1C,QACE,OAAQ,WAAmB,SAAS,YAAY,YAChD,mBAAoB,UAAkB,QAAQ,WAAW,IACzD;AAKC,gBAAkB,QAAQ,UAAU;;AAGvC,QAAI,KAAK,qBAAqB,WAAW,OAAO;AAC9C,UAAI,CAACA,SAAQ;AAAgB,QAAAA,SAAQ,iBAAiB,KAAK,sBAAqB;AAChF,cAAQ,KAAK,iBAAiB,IAAIA,SAAQ;;AAG5C,UAAM,aAAa,KAAK,aAAa,EAAE,SAAAA,UAAS,SAAS,eAAe,WAAU,CAAE;AAEpF,UAAM,MAAmB;MACvB;MACA,GAAI,QAAQ,EAAE,KAAiB;MAC/B,SAAS;MACT,GAAI,aAAa,EAAE,OAAO,UAAS;;;MAGnC,QAAQA,SAAQ,UAAU;;AAG5B,WAAO,EAAE,KAAK,KAAK,SAASA,SAAQ,QAAO;EAC7C;EAEQ,aAAa,EACnB,SAAAA,UACA,SACA,eACA,WAAU,GAMX;AACC,UAAM,aAAqC,CAAA;AAC3C,QAAI,eAAe;AACjB,iBAAW,gBAAgB,IAAI;;AAGjC,UAAM,iBAAiB,KAAK,eAAeA,QAAO;AAClD,oBAAgB,YAAY,cAAc;AAC1C,oBAAgB,YAAY,OAAO;AAGnC,QAAI,gBAAgBA,SAAQ,IAAI,KAAK,SAAc,QAAQ;AACzD,aAAO,WAAW,cAAc;;AAMlC,QACE,UAAU,gBAAgB,yBAAyB,MAAM,UACzD,UAAU,SAAS,yBAAyB,MAAM,QAClD;AACA,iBAAW,yBAAyB,IAAI,OAAO,UAAU;;AAE3D,QACE,UAAU,gBAAgB,qBAAqB,MAAM,UACrD,UAAU,SAAS,qBAAqB,MAAM,UAC9CA,SAAQ,SACR;AACA,iBAAW,qBAAqB,IAAI,OAAOA,SAAQ,OAAO;;AAG5D,SAAK,gBAAgB,YAAY,OAAO;AAExC,WAAO;EACT;;;;EAKU,MAAM,eAAeA,UAA4B;EAAkB;;;;;;;EAQnE,MAAM,eACd,SACA,EAAE,KAAK,SAAAA,SAAO,GAAiD;EAC/C;EAER,aAAa,SAAuC;AAC5D,WACE,CAAC,UAAU,CAAA,IACT,OAAO,YAAY,UACnB,OAAO,YAAY,MAAM,KAAK,OAA6B,EAAE,IAAI,CAAC,WAAW,CAAC,GAAG,MAAM,CAAC,CAAC,IACzF,EAAE,GAAG,QAAO;EAElB;EAEU,gBACR,QACA,OACA,SACA,SAA4B;AAE5B,WAAO,SAAS,SAAS,QAAQ,OAAO,SAAS,OAAO;EAC1D;EAEA,QACEA,UACA,mBAAkC,MAAI;AAEtC,WAAO,IAAI,WAAW,KAAK,YAAYA,UAAS,gBAAgB,CAAC;EACnE;EAEQ,MAAM,YACZ,cACA,kBAA+B;AAE/B,UAAMA,WAAU,MAAM;AACtB,UAAM,aAAaA,SAAQ,cAAc,KAAK;AAC9C,QAAI,oBAAoB,MAAM;AAC5B,yBAAmB;;AAGrB,UAAM,KAAK,eAAeA,QAAO;AAEjC,UAAM,EAAE,KAAK,KAAK,QAAO,IAAK,KAAK,aAAaA,UAAS,EAAE,YAAY,aAAa,iBAAgB,CAAE;AAEtG,UAAM,KAAK,eAAe,KAAK,EAAE,KAAK,SAAAA,SAAO,CAAE;AAE/C,UAAM,WAAW,KAAKA,UAAS,IAAI,OAAO;AAE1C,QAAIA,SAAQ,QAAQ,SAAS;AAC3B,YAAM,IAAI,kBAAiB;;AAG7B,UAAM,aAAa,IAAI,gBAAe;AACtC,UAAM,WAAW,MAAM,KAAK,iBAAiB,KAAK,KAAK,SAAS,UAAU,EAAE,MAAM,WAAW;AAE7F,QAAI,oBAAoB,OAAO;AAC7B,UAAIA,SAAQ,QAAQ,SAAS;AAC3B,cAAM,IAAI,kBAAiB;;AAE7B,UAAI,kBAAkB;AACpB,eAAO,KAAK,aAAaA,UAAS,gBAAgB;;AAEpD,UAAI,SAAS,SAAS,cAAc;AAClC,cAAM,IAAI,0BAAyB;;AAErC,YAAM,IAAI,mBAAmB,EAAE,OAAO,SAAQ,CAAE;;AAGlD,UAAM,kBAAkB,sBAAsB,SAAS,OAAO;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,oBAAoB,KAAK,YAAY,QAAQ,GAAG;AAClD,cAAMC,gBAAe,aAAa,gBAAgB;AAClD,cAAM,oBAAoBA,aAAY,KAAK,SAAS,QAAQ,KAAK,eAAe;AAChF,eAAO,KAAK,aAAaD,UAAS,kBAAkB,eAAe;;AAGrE,YAAM,UAAU,MAAM,SAAS,KAAI,EAAG,MAAM,CAAC,MAAM,YAAY,CAAC,EAAE,OAAO;AACzE,YAAM,UAAU,SAAS,OAAO;AAChC,YAAM,aAAa,UAAU,SAAY;AACzC,YAAM,eAAe,mBAAmB,kCAAkC;AAE1E,YAAM,oBAAoB,YAAY,KAAK,SAAS,QAAQ,KAAK,iBAAiB,UAAU;AAE5F,YAAM,MAAM,KAAK,gBAAgB,SAAS,QAAQ,SAAS,YAAY,eAAe;AACtF,YAAM;;AAGR,WAAO,EAAE,UAAU,SAAAA,UAAS,WAAU;EACxC;EAEA,eACED,OACAC,UAA4B;AAE5B,UAAM,UAAU,KAAK,YAAYA,UAAS,IAAI;AAC9C,WAAO,IAAI,YAA6B,MAAM,SAASD,KAAI;EAC7D;EAEA,SAAc,MAAc,OAA6B;AACvD,UAAM,MACJ,cAAc,IAAI,IAChB,IAAI,IAAI,IAAI,IACZ,IAAI,IAAI,KAAK,WAAW,KAAK,QAAQ,SAAS,GAAG,KAAK,KAAK,WAAW,GAAG,IAAI,KAAK,MAAM,CAAC,IAAI,KAAK;AAEtG,UAAM,eAAe,KAAK,aAAY;AACtC,QAAI,CAAC,WAAW,YAAY,GAAG;AAC7B,cAAQ,EAAE,GAAG,cAAc,GAAG,MAAK;;AAGrC,QAAI,OAAO,UAAU,YAAY,SAAS,CAAC,MAAM,QAAQ,KAAK,GAAG;AAC/D,UAAI,SAAS,KAAK,eAAe,KAAgC;;AAGnE,WAAO,IAAI,SAAQ;EACrB;EAEU,eAAe,OAA8B;AACrD,WAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,OAAO,UAAU,WAAW,EACnD,IAAI,CAAC,CAAC,KAAK,KAAK,MAAK;AACpB,UAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,eAAO,GAAG,mBAAmB,GAAG,CAAC,IAAI,mBAAmB,KAAK,CAAC;;AAEhE,UAAI,UAAU,MAAM;AAClB,eAAO,GAAG,mBAAmB,GAAG,CAAC;;AAEnC,YAAM,IAAI,YACR,yBAAyB,OAAO,KAAK,mQAAmQ;IAE5S,CAAC,EACA,KAAK,GAAG;EACb;EAEA,MAAM,iBACJ,KACA,MACA,IACA,YAA2B;AAE3B,UAAM,EAAE,QAAQ,GAAGC,SAAO,IAAK,QAAQ,CAAA;AACvC,QAAI;AAAQ,aAAO,iBAAiB,SAAS,MAAM,WAAW,MAAK,CAAE;AAErE,UAAM,UAAU,WAAW,MAAM,WAAW,MAAK,GAAI,EAAE;AAEvD,UAAM,eAAe;MACnB,QAAQ,WAAW;MACnB,GAAGA;;AAEL,QAAI,aAAa,QAAQ;AAGvB,mBAAa,SAAS,aAAa,OAAO,YAAW;;AAGvD;;MAEE,KAAK,MAAM,KAAK,QAAW,KAAK,YAAY,EAAE,QAAQ,MAAK;AACzD,qBAAa,OAAO;MACtB,CAAC;;EAEL;EAEQ,YAAY,UAAkB;AAEpC,UAAM,oBAAoB,SAAS,QAAQ,IAAI,gBAAgB;AAG/D,QAAI,sBAAsB;AAAQ,aAAO;AACzC,QAAI,sBAAsB;AAAS,aAAO;AAG1C,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,UAAU;AAAK,aAAO;AAEnC,WAAO;EACT;EAEQ,MAAM,aACZA,UACA,kBACA,iBAAqC;AAErC,QAAI;AAGJ,UAAM,yBAAyB,kBAAkB,gBAAgB;AACjE,QAAI,wBAAwB;AAC1B,YAAM,YAAY,WAAW,sBAAsB;AACnD,UAAI,CAAC,OAAO,MAAM,SAAS,GAAG;AAC5B,wBAAgB;;;AAKpB,UAAM,mBAAmB,kBAAkB,aAAa;AACxD,QAAI,oBAAoB,CAAC,eAAe;AACtC,YAAM,iBAAiB,WAAW,gBAAgB;AAClD,UAAI,CAAC,OAAO,MAAM,cAAc,GAAG;AACjC,wBAAgB,iBAAiB;aAC5B;AACL,wBAAgB,KAAK,MAAM,gBAAgB,IAAI,KAAK,IAAG;;;AAM3D,QAAI,EAAE,iBAAiB,KAAK,iBAAiB,gBAAgB,KAAK,MAAO;AACvE,YAAM,aAAaA,SAAQ,cAAc,KAAK;AAC9C,sBAAgB,KAAK,mCAAmC,kBAAkB,UAAU;;AAEtF,UAAM,MAAM,aAAa;AAEzB,WAAO,KAAK,YAAYA,UAAS,mBAAmB,CAAC;EACvD;EAEQ,mCAAmC,kBAA0B,YAAkB;AACrF,UAAM,oBAAoB;AAC1B,UAAM,gBAAgB;AAEtB,UAAM,aAAa,aAAa;AAGhC,UAAM,eAAe,KAAK,IAAI,oBAAoB,KAAK,IAAI,GAAG,UAAU,GAAG,aAAa;AAGxF,UAAM,SAAS,IAAI,KAAK,OAAM,IAAK;AAEnC,WAAO,eAAe,SAAS;EACjC;EAEQ,eAAY;AAClB,WAAO,GAAG,KAAK,YAAY,IAAI,OAAO,OAAO;EAC/C;;AAKI,IAAgB,eAAhB,MAA4B;SAAA;;;EAOhC,YAAY,QAAmB,UAAoB,MAAeA,UAA4B;AAN9F,yBAAA,IAAA,MAAA,MAAA;AAOE,IAAAE,wBAAA,MAAI,sBAAW,QAAM,GAAA;AACrB,SAAK,UAAUF;AACf,SAAK,WAAW;AAChB,SAAK,OAAO;EACd;EAUA,cAAW;AACT,UAAM,QAAQ,KAAK,kBAAiB;AACpC,QAAI,CAAC,MAAM;AAAQ,aAAO;AAC1B,WAAO,KAAK,aAAY,KAAM;EAChC;EAEA,MAAM,cAAW;AACf,UAAM,WAAW,KAAK,aAAY;AAClC,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YACR,uFAAuF;;AAG3F,UAAM,cAAc,EAAE,GAAG,KAAK,QAAO;AACrC,QAAI,YAAY,YAAY,OAAO,YAAY,UAAU,UAAU;AACjE,kBAAY,QAAQ,EAAE,GAAG,YAAY,OAAO,GAAG,SAAS,OAAM;eACrD,SAAS,UAAU;AAC5B,YAAM,SAAS,CAAC,GAAG,OAAO,QAAQ,YAAY,SAAS,CAAA,CAAE,GAAG,GAAG,SAAS,IAAI,aAAa,QAAO,CAAE;AAClG,iBAAW,CAAC,KAAK,KAAK,KAAK,QAAQ;AACjC,iBAAS,IAAI,aAAa,IAAI,KAAK,KAAY;;AAEjD,kBAAY,QAAQ;AACpB,kBAAY,OAAO,SAAS,IAAI,SAAQ;;AAE1C,WAAO,MAAMG,wBAAA,MAAI,sBAAA,GAAA,EAAS,eAAe,KAAK,aAAoB,WAAW;EAC/E;EAEA,OAAO,YAAS;AAEd,QAAI,OAAa;AACjB,UAAM;AACN,WAAO,KAAK,YAAW,GAAI;AACzB,aAAO,MAAM,KAAK,YAAW;AAC7B,YAAM;;EAEV;EAEA,SAAO,uBAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AAC3B,qBAAiB,QAAQ,KAAK,UAAS,GAAI;AACzC,iBAAW,QAAQ,KAAK,kBAAiB,GAAI;AAC3C,cAAM;;;EAGZ;;AAYI,IAAO,cAAP,cAII,WAAqB;SAAA;;;EAG7B,YACE,QACA,SACAJ,OAA4E;AAE5E,UACE,SACA,OAAO,UACL,IAAIA,MACF,QACA,MAAM,UACN,MAAM,qBAAqB,KAAK,GAChC,MAAM,OAAO,CACc;EAEnC;;;;;;;;EASA,QAAQ,OAAO,aAAa,IAAC;AAC3B,UAAM,OAAO,MAAM;AACnB,qBAAiB,QAAQ,MAAM;AAC7B,YAAM;;EAEV;;AAGK,IAAM,wBAAwB,wBACnC,YAC0B;AAC1B,SAAO,IAAI,MACT,OAAO;;IAEL,QAAQ,QAAO;EAAE,GAEnB;IACE,IAAI,QAAQ,MAAI;AACd,YAAM,MAAM,KAAK,SAAQ;AACzB,aAAO,OAAO,IAAI,YAAW,CAAE,KAAK,OAAO,GAAG;IAChD;GACD;AAEL,GAfqC;AAiDrC,IAAM,qBAA+C;EACnD,QAAQ;EACR,MAAM;EACN,OAAO;EACP,MAAM;EACN,SAAS;EAET,YAAY;EACZ,QAAQ;EACR,SAAS;EACT,WAAW;EACX,QAAQ;EACR,gBAAgB;EAEhB,YAAY;EACZ,iBAAiB;EACjB,kBAAkB;EAClB,eAAe;;AAGV,IAAM,mBAAmB,wBAAC,QAAuC;AACtE,SACE,OAAO,QAAQ,YACf,QAAQ,QACR,CAAC,WAAW,GAAG,KACf,OAAO,KAAK,GAAG,EAAE,MAAM,CAAC,MAAM,OAAO,oBAAoB,CAAC,CAAC;AAE/D,GAPgC;AAqChC,IAAM,wBAAwB,6BAAyB;AACrD,MAAI,OAAO,SAAS,eAAe,KAAK,SAAS,MAAM;AACrD,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,KAAK,MAAM,EAAE;MACjD,oBAAoB,cAAc,KAAK,MAAM,IAAI;MACjD,uBAAuB;MACvB,+BACE,OAAO,KAAK,YAAY,WAAW,KAAK,UAAU,KAAK,SAAS,QAAQ;;;AAG9E,MAAI,OAAO,gBAAgB,aAAa;AACtC,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB,SAAS,WAAW;MACxC,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,MAAI,OAAO,UAAU,SAAS,KAAK,OAAO,YAAY,cAAc,UAAU,CAAC,MAAM,oBAAoB;AACvG,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,QAAQ,QAAQ;MACpD,oBAAoB,cAAc,QAAQ,IAAI;MAC9C,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,QAAM,cAAc,eAAc;AAClC,MAAI,aAAa;AACf,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB;MACpB,uBAAuB,WAAW,YAAY,OAAO;MACrD,+BAA+B,YAAY;;;AAK/C,SAAO;IACL,oBAAoB;IACpB,+BAA+B;IAC/B,kBAAkB;IAClB,oBAAoB;IACpB,uBAAuB;IACvB,+BAA+B;;AAEnC,GAvD8B;AAiE9B,SAAS,iBAAc;AACrB,MAAI,OAAO,cAAc,eAAe,CAAC,WAAW;AAClD,WAAO;;AAIT,QAAM,kBAAkB;IACtB,EAAE,KAAK,QAAiB,SAAS,uCAAsC;IACvE,EAAE,KAAK,MAAe,SAAS,uCAAsC;IACrE,EAAE,KAAK,MAAe,SAAS,6CAA4C;IAC3E,EAAE,KAAK,UAAmB,SAAS,yCAAwC;IAC3E,EAAE,KAAK,WAAoB,SAAS,0CAAyC;IAC7E,EAAE,KAAK,UAAmB,SAAS,oEAAmE;;AAIxG,aAAW,EAAE,KAAK,QAAO,KAAM,iBAAiB;AAC9C,UAAM,QAAQ,QAAQ,KAAK,oBAAmB;AAC9C,QAAI,OAAO;AACT,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAE1B,aAAO,EAAE,SAAS,KAAK,SAAS,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,GAAE;;;AAIhE,SAAO;AACT;AA5BS;AA8BT,IAAM,gBAAgB,wBAAC,SAAsB;AAK3C,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,YAAY,SAAS;AAAO,WAAO;AAChD,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,aAAa,SAAS;AAAS,WAAO;AACnD,MAAI;AAAM,WAAO,SAAS,IAAI;AAC9B,SAAO;AACT,GAXsB;AAatB,IAAM,oBAAoB,wBAAC,aAAkC;AAO3D,aAAW,SAAS,YAAW;AAM/B,MAAI,SAAS,SAAS,KAAK;AAAG,WAAO;AACrC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAU,WAAO;AAClC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI;AAAU,WAAO,SAAS,QAAQ;AACtC,SAAO;AACT,GAtB0B;AAwB1B,IAAI;AACJ,IAAM,qBAAqB,6BAAK;AAC9B,SAAQ,qBAAA,mBAAqB,sBAAqB;AACpD,GAF2B;AAIpB,IAAM,WAAW,wBAAC,SAAgB;AACvC,MAAI;AACF,WAAO,KAAK,MAAM,IAAI;WACf,KAAK;AACZ,WAAO;;AAEX,GANwB;AASxB,IAAM,yBAAyB;AAC/B,IAAM,gBAAgB,wBAAC,QAAwB;AAC7C,SAAO,uBAAuB,KAAK,GAAG;AACxC,GAFsB;AAIf,IAAM,QAAQ,wBAAC,OAAe,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC,GAAhE;AAErB,IAAM,0BAA0B,wBAAC,MAAc,MAAsB;AACnE,MAAI,OAAO,MAAM,YAAY,CAAC,OAAO,UAAU,CAAC,GAAG;AACjD,UAAM,IAAI,YAAY,GAAG,IAAI,qBAAqB;;AAEpD,MAAI,IAAI,GAAG;AACT,UAAM,IAAI,YAAY,GAAG,IAAI,6BAA6B;;AAE5D,SAAO;AACT,GARgC;AAUzB,IAAM,cAAc,wBAAC,QAAmB;AAC7C,MAAI,eAAe;AAAO,WAAO;AACjC,MAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AAC3C,QAAI;AACF,aAAO,IAAI,MAAM,KAAK,UAAU,GAAG,CAAC;YAC9B;IAAA;;AAEV,SAAO,IAAI,MAAM,GAAG;AACtB,GAR2B;AAsBpB,IAAM,UAAU,wBAAC,QAAmC;AACzD,MAAI,OAAO,YAAY,aAAa;AAClC,WAAO,QAAQ,MAAM,GAAG,GAAG,KAAI,KAAM;;AAEvC,MAAI,OAAO,SAAS,aAAa;AAC/B,WAAO,KAAK,KAAK,MAAM,GAAG,GAAG,KAAI;;AAEnC,SAAO;AACT,GARuB;AAoDjB,SAAU,WAAW,KAA8B;AACvD,MAAI,CAAC;AAAK,WAAO;AACjB,aAAW,MAAM;AAAK,WAAO;AAC7B,SAAO;AACT;AAJgB;AAOV,SAAU,OAAO,KAAa,KAAW;AAC7C,SAAO,OAAO,UAAU,eAAe,KAAK,KAAK,GAAG;AACtD;AAFgB;AAUhB,SAAS,gBAAgB,eAAwB,YAAmB;AAClE,aAAW,KAAK,YAAY;AAC1B,QAAI,CAAC,OAAO,YAAY,CAAC;AAAG;AAC5B,UAAM,WAAW,EAAE,YAAW;AAC9B,QAAI,CAAC;AAAU;AAEf,UAAM,MAAM,WAAW,CAAC;AAExB,QAAI,QAAQ,MAAM;AAChB,aAAO,cAAc,QAAQ;eACpB,QAAQ,QAAW;AAC5B,oBAAc,QAAQ,IAAI;;;AAGhC;AAdS;AAgBT,IAAM,oBAAoB,oBAAI,IAAI,CAAC,iBAAiB,SAAS,CAAC;AAExD,SAAU,MAAM,WAAmB,MAAW;AAClD,MAAI,OAAO,YAAY,eAAe,SAAS,MAAM,OAAO,MAAM,QAAQ;AACxE,UAAM,eAAe,KAAK,IAAI,CAAC,QAAO;AACpC,UAAI,CAAC,KAAK;AACR,eAAO;;AAIT,UAAI,IAAI,SAAS,GAAG;AAElB,cAAMK,eAAc,EAAE,GAAG,KAAK,SAAS,EAAE,GAAG,IAAI,SAAS,EAAC,EAAE;AAE5D,mBAAW,UAAU,IAAI,SAAS,GAAG;AACnC,cAAI,kBAAkB,IAAI,OAAO,YAAW,CAAE,GAAG;AAC/C,YAAAA,aAAY,SAAS,EAAE,MAAM,IAAI;;;AAIrC,eAAOA;;AAGT,UAAI,cAAc;AAGlB,iBAAW,UAAU,KAAK;AACxB,YAAI,kBAAkB,IAAI,OAAO,YAAW,CAAE,GAAG;AAE/C,0BAAA,cAAgB,EAAE,GAAG,IAAG;AACxB,sBAAY,MAAM,IAAI;;;AAI1B,aAAO,eAAe;IACxB,CAAC;AACD,YAAQ,IAAI,gBAAgB,MAAM,IAAI,GAAG,YAAY;;AAEzD;AApCgB;AAyChB,IAAM,QAAQ,6BAAK;AACjB,SAAO,uCAAuC,QAAQ,SAAS,CAAC,MAAK;AACnE,UAAM,IAAK,KAAK,OAAM,IAAK,KAAM;AACjC,UAAM,IAAI,MAAM,MAAM,IAAK,IAAI,IAAO;AACtC,WAAO,EAAE,SAAS,EAAE;EACtB,CAAC;AACH,GANc;AAQP,IAAM,qBAAqB,6BAAK;AACrC;;IAEE,OAAO,WAAW;IAElB,OAAO,OAAO,aAAa;IAE3B,OAAO,cAAc;;AAEzB,GATkC;AAgB3B,IAAM,oBAAoB,wBAAC,YAA4C;AAC5E,SAAO,OAAO,SAAS,QAAQ;AACjC,GAFiC;AAY1B,IAAM,YAAY,wBAAC,SAAgC,WAAsC;AAC9F,QAAM,mBAAmB,OAAO,YAAW;AAC3C,MAAI,kBAAkB,OAAO,GAAG;AAE9B,UAAM,kBACJ,OAAO,CAAC,GAAG,YAAW,IACtB,OAAO,UAAU,CAAC,EAAE,QAAQ,gBAAgB,CAAC,IAAI,IAAI,OAAO,KAAK,GAAG,YAAW,CAAE;AACnF,eAAW,OAAO,CAAC,QAAQ,kBAAkB,OAAO,YAAW,GAAI,eAAe,GAAG;AACnF,YAAM,QAAQ,QAAQ,IAAI,GAAG;AAC7B,UAAI,OAAO;AACT,eAAO;;;;AAKb,aAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,OAAO,GAAG;AAClD,QAAI,IAAI,YAAW,MAAO,kBAAkB;AAC1C,UAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,YAAI,MAAM,UAAU;AAAG,iBAAO,MAAM,CAAC;AACrC,gBAAQ,KAAK,YAAY,MAAM,MAAM,oBAAoB,MAAM,iCAAiC;AAChG,eAAO,MAAM,CAAC;;AAEhB,aAAO;;;AAIX,SAAO;AACT,GA3ByB;AA6CnB,SAAU,MAAM,KAAY;AAChC,SAAO,OAAO,QAAQ,OAAO,QAAQ,YAAY,CAAC,MAAM,QAAQ,GAAG;AACrE;AAFgB;;;ACvvCV,IAAO,OAAP,cAA0B,aAAkB;EAblD,OAakD;;;EAKhD,YAAY,QAAmB,UAAoB,MAA0BC,UAA4B;AACvG,UAAM,QAAQ,UAAU,MAAMA,QAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;AACzB,SAAK,SAAS,KAAK;EACrB;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;;;;;EAOA,iBAAc;AACZ,WAAO;EACT;EAEA,eAAY;AACV,WAAO;EACT;;AAeI,IAAO,aAAP,cACI,aAAkB;EAxD5B,OAwD4B;;;EAO1B,YACE,QACA,UACA,MACAA,UAA4B;AAE5B,UAAM,QAAQ,UAAU,MAAMA,QAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;AACzB,SAAK,WAAW,KAAK,YAAY;EACnC;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;EAES,cAAW;AAClB,QAAI,KAAK,aAAa,OAAO;AAC3B,aAAO;;AAGT,WAAO,MAAM,YAAW;EAC1B;;EAGA,iBAAc;AACZ,UAAM,OAAO,KAAK,aAAY;AAC9B,QAAI,CAAC;AAAM,aAAO;AAClB,QAAI,YAAY;AAAM,aAAO,KAAK;AAClC,UAAM,SAAS,OAAO,YAAY,KAAK,IAAI,YAAY;AACvD,QAAI,CAAC,OAAO,KAAK,MAAM,EAAE;AAAQ,aAAO;AACxC,WAAO;EACT;EAEA,eAAY;AACV,UAAM,OAAO,KAAK,kBAAiB;AACnC,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;;AAGT,UAAM,KAAK,KAAK,KAAK,SAAS,CAAC,GAAG;AAClC,QAAI,CAAC,IAAI;AACP,aAAO;;AAGT,WAAO,EAAE,QAAQ,EAAE,OAAO,GAAE,EAAE;EAChC;;;;ACzGI,IAAO,cAAP,MAAkB;EAJxB,OAIwB;;;EAGtB,YAAY,QAAc;AACxB,SAAK,UAAU;EACjB;;;;ACAI,IAAO,WAAP,cAAwB,YAAW;EATzC,OASyC;;;EAcvC,KACE,cACA,QAAiD,CAAA,GACjDC,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,cAAc,CAAA,GAAI,KAAK;;AAE1C,WAAO,KAAK,QAAQ,WAClB,qBAAqB,YAAY,aACjC,iCACA,EAAE,OAAO,GAAGA,SAAO,CAAE;EAEzB;;;;ACtBI,IAAO,cAAP,cAA2B,YAAW;EAd5C,OAc4C;;;EAA5C,cAAA;;AACE,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;EAyFxE;EAxDE,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAGA,UAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAGlG;;;;;EAMA,SAAS,cAAsBA,UAA6B;AAC1D,WAAO,KAAK,QAAQ,IAAI,qBAAqB,YAAY,IAAIA,QAAO;EACtE;;;;;;EAOA,OACE,cACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,qBAAqB,YAAY,IAAI,EAAE,MAAM,GAAGA,SAAO,CAAE;EACpF;EAWA,KACE,QAAwD,CAAA,GACxDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,qBAAqB,qBAAqB,EAAE,OAAO,GAAGA,SAAO,CAAE;EAChG;;;;;EAMA,IAAI,cAAsBA,UAA6B;AACrD,WAAO,KAAK,QAAQ,OAAO,qBAAqB,YAAY,IAAIA,QAAO;EACzE;;AAGI,IAAO,sBAAP,cAAmC,WAA0B;EA1GnE,OA0GmE;;;;AAE7D,IAAO,kCAAP,cAA+C,WAAsC;EA5G3F,OA4G2F;;;;AA46C3F,YAAY,sBAAsB;AAClC,YAAY,WAAW;;;ACt+CjB,IAAO,OAAP,cAAoB,YAAW;EAnDrC,OAmDqC;;;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EACvF;;AAIA,KAAK,cAAc;AACnB,KAAK,sBAAsB;;;ACpDrB,IAAO,SAAP,cAAsB,YAAW;EANvC,OAMuC;;;;;;EAIrC,OAAO,MAA0BC,UAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,iBAAiB;MACxC;MACA,GAAGA;MACH,SAAS,EAAE,QAAQ,4BAA4B,GAAGA,UAAS,QAAO;MAClE,kBAAkB;KACnB;EACH;;;;ACXI,IAAO,iBAAP,cAA8B,YAAW;EAN/C,OAM+C;;;EAiB7C,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAClB,yBACK,4BAA4B,EAAE,MAAM,GAAGA,UAAS,YAAY,EAAE,OAAO,KAAK,MAAK,EAAE,CAAE,CAAC;EAE7F;;;;ACxBI,IAAO,eAAP,cAA4B,YAAW;EAP7C,OAO6C;;;EAiB3C,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAClB,uBACK,4BAA4B,EAAE,MAAM,GAAGA,UAAS,YAAY,EAAE,OAAO,KAAK,MAAK,EAAE,CAAE,CAAC;EAE7F;;;;ACRI,IAAO,QAAP,cAAqB,YAAW;EAxBtC,OAwBsC;;;EAAtC,cAAA;;AACE,SAAA,iBAAmD,IAAsB,eAAe,KAAK,OAAO;AACpG,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,SAA2B,IAAc,OAAO,KAAK,OAAO;EAC9D;;AAUA,MAAM,iBAAiB;AACvB,MAAM,eAAe;AACrB,MAAM,SAAS;;;AC/BT,IAAO,UAAP,cAAuB,YAAW;EATxC,OASwC;;;;;;EAItC,OAAO,MAAyBC,UAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,YAAY,EAAE,MAAM,GAAGA,SAAO,CAAE;EAC3D;;;;EAKA,SAAS,SAAiBA,UAA6B;AACrD,WAAO,KAAK,QAAQ,IAAI,YAAY,OAAO,IAAIA,QAAO;EACxD;EAOA,KACE,QAA+C,CAAA,GAC/CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,YAAY,aAAa,EAAE,OAAO,GAAGA,SAAO,CAAE;EAC/E;;;;;;EAOA,OAAO,SAAiBA,UAA6B;AACnD,WAAO,KAAK,QAAQ,KAAK,YAAY,OAAO,WAAWA,QAAO;EAChE;;AAGI,IAAO,cAAP,cAA2B,WAAiB;EAjDlD,OAiDkD;;;;AA6MlD,QAAQ,cAAc;;;AClPhB,IAAO,aAAP,cAA0B,YAAW;EAZ3C,OAY2C;;;;;;EAIzC,OAAO,MAA6BC,UAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,eAAe;MACtC;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,aAAqBA,UAA6B;AACzD,WAAO,KAAK,QAAQ,IAAI,eAAe,WAAW,IAAI;MACpD,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,aACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,WAAW,IAAI;MACrD;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAmD,CAAA,GACnDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,eAAe,gBAAgB;MAC5D;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,aAAqBA,UAA6B;AACpD,WAAO,KAAK,QAAQ,OAAO,eAAe,WAAW,IAAI;MACvD,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,iBAAP,cAA8B,WAAqB;EAlFzD,OAkFyD;;;;AAm4CzD,WAAW,iBAAiB;;;ACt4CtB,SAAU,4BACd,IAAO;AAEP,SAAO,OAAQ,GAAW,UAAU;AACtC;AAJgB;;;ACxET,IAAM,qBAAqB,wBAChC,YACkD;AAClD,SAAO,SAAS,SAAS;AAC3B,GAJkC;AAM3B,IAAM,oBAAoB,wBAC/B,YACiD;AACjD,SAAO,SAAS,SAAS;AAC3B,GAJiC;AAM1B,IAAM,gBAAgB,wBAC3B,YAC6C;AAC7C,SAAO,SAAS,SAAS;AAC3B,GAJ6B;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjBvB,IAAO,cAAP,MAAkB;SAAA;;;EAoBtB,cAAA;;AAnBA,SAAA,aAA8B,IAAI,gBAAe;AAEjD,kCAAA,IAAA,MAAA,MAAA;AACA,yCAAA,IAAA,MAAuC,MAAK;IAAE,CAAC;AAC/C,wCAAA,IAAA,MAAwD,MAAK;IAAE,CAAC;AAEhE,4BAAA,IAAA,MAAA,MAAA;AACA,mCAAA,IAAA,MAAiC,MAAK;IAAE,CAAC;AACzC,kCAAA,IAAA,MAAkD,MAAK;IAAE,CAAC;AAE1D,2BAAA,IAAA,MAEI,CAAA,CAAE;AAEN,uBAAA,IAAA,MAAS,KAAK;AACd,yBAAA,IAAA,MAAW,KAAK;AAChB,yBAAA,IAAA,MAAW,KAAK;AAChB,wCAAA,IAAA,MAA0B,KAAK;AAG7B,IAAAC,wBAAA,MAAI,+BAAqB,IAAI,QAAc,CAAC,SAAS,WAAU;AAC7D,MAAAA,wBAAA,MAAI,sCAA4B,SAAO,GAAA;AACvC,MAAAA,wBAAA,MAAI,qCAA2B,QAAM,GAAA;IACvC,CAAC,GAAC,GAAA;AAEF,IAAAA,wBAAA,MAAI,yBAAe,IAAI,QAAc,CAAC,SAAS,WAAU;AACvD,MAAAA,wBAAA,MAAI,gCAAsB,SAAO,GAAA;AACjC,MAAAA,wBAAA,MAAI,+BAAqB,QAAM,GAAA;IACjC,CAAC,GAAC,GAAA;AAMF,IAAAC,wBAAA,MAAI,+BAAA,GAAA,EAAmB,MAAM,MAAK;IAAE,CAAC;AACrC,IAAAA,wBAAA,MAAI,yBAAA,GAAA,EAAa,MAAM,MAAK;IAAE,CAAC;EACjC;EAEU,KAAoC,UAA4B;AAGxE,eAAW,MAAK;AACd,eAAQ,EAAG,KAAK,MAAK;AACnB,aAAK,WAAU;AACf,aAAK,MAAM,KAAK;MAClB,GAAGA,wBAAA,MAAI,wBAAA,KAAA,wBAAA,EAAc,KAAK,IAAI,CAAC;IACjC,GAAG,CAAC;EACN;EAEU,aAAU;AAClB,QAAI,KAAK;AAAO;AAChB,IAAAA,wBAAA,MAAI,sCAAA,GAAA,EAAyB,KAA7B,IAAI;AACJ,SAAK,MAAM,SAAS;EACtB;EAEA,IAAI,QAAK;AACP,WAAOA,wBAAA,MAAI,oBAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,sBAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,sBAAA,GAAA;EACb;EAEA,QAAK;AACH,SAAK,WAAW,MAAK;EACvB;;;;;;;;EASA,GAAmC,OAAc,UAA0C;AACzF,UAAM,YACJA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,SAAQ,CAAE;AAC3B,WAAO;EACT;;;;;;;;EASA,IAAoC,OAAc,UAA0C;AAC1F,UAAM,YAAYA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK;AACvC,QAAI,CAAC;AAAW,aAAO;AACvB,UAAM,QAAQ,UAAU,UAAU,CAAC,MAAM,EAAE,aAAa,QAAQ;AAChE,QAAI,SAAS;AAAG,gBAAU,OAAO,OAAO,CAAC;AACzC,WAAO;EACT;;;;;;EAOA,KAAqC,OAAc,UAA0C;AAC3F,UAAM,YACJA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,UAAU,MAAM,KAAI,CAAE;AACvC,WAAO;EACT;;;;;;;;;;;;EAaA,QACE,OAAY;AAMZ,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,MAAAD,wBAAA,MAAI,qCAA2B,MAAI,GAAA;AACnC,UAAI,UAAU;AAAS,aAAK,KAAK,SAAS,MAAM;AAChD,WAAK,KAAK,OAAO,OAAc;IACjC,CAAC;EACH;EAEA,MAAM,OAAI;AACR,IAAAA,wBAAA,MAAI,qCAA2B,MAAI,GAAA;AACnC,UAAMC,wBAAA,MAAI,yBAAA,GAAA;EACZ;EAyBA,MAEE,UACG,MAAwC;AAG3C,QAAIA,wBAAA,MAAI,oBAAA,GAAA,GAAS;AACf;;AAGF,QAAI,UAAU,OAAO;AACnB,MAAAD,wBAAA,MAAI,oBAAU,MAAI,GAAA;AAClB,MAAAC,wBAAA,MAAI,gCAAA,GAAA,EAAmB,KAAvB,IAAI;;AAGN,UAAM,YAA2DA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK;AACtF,QAAI,WAAW;AACb,MAAAA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,UAAU,OAAO,CAAC,MAAM,CAAC,EAAE,IAAI;AACxD,gBAAU,QAAQ,CAAC,EAAE,SAAQ,MAAY,SAAS,GAAI,IAAY,CAAC;;AAGrE,QAAI,UAAU,SAAS;AACrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,qCAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AACvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,qCAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,+BAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;AAChB;;AAGF,QAAI,UAAU,SAAS;AAGrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,qCAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AAOvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,qCAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,+BAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;;EAEpB;EAEU,aAAU;EAAU;;4yBA1Ec,OAAc;AACxD,EAAAD,wBAAA,MAAI,sBAAY,MAAI,GAAA;AACpB,MAAI,iBAAiB,SAAS,MAAM,SAAS,cAAc;AACzD,YAAQ,IAAI,kBAAiB;;AAE/B,MAAI,iBAAiB,mBAAmB;AACtC,IAAAA,wBAAA,MAAI,sBAAY,MAAI,GAAA;AACpB,WAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,MAAI,iBAAiB,aAAa;AAChC,WAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,MAAI,iBAAiB,OAAO;AAC1B,UAAM,cAA2B,IAAI,YAAY,MAAM,OAAO;AAE9D,gBAAY,QAAQ;AACpB,WAAO,KAAK,MAAM,SAAS,WAAW;;AAExC,SAAO,KAAK,MAAM,SAAS,IAAI,YAAY,OAAO,KAAK,CAAC,CAAC;AAC3D;;;ACnFI,SAAU,6BACd,iBAAoB;AAEpB,SAAO,kBAAkB,QAAQ,MAAM;AACzC;AAJgB;AAuDV,SAAU,mBAAmB,MAAS;AAC1C,SAAO,OAAO,QAAQ,MAAM;AAC9B;AAFgB;AAIV,SAAU,yBAGd,YAA4B,QAAc;AAC1C,MAAI,CAAC,UAAU,CAAC,sBAAsB,MAAM,GAAG;AAC7C,WAAO;MACL,GAAG;MACH,SAAS,WAAW,QAAQ,IAAI,CAAC,YAAY;QAC3C,GAAG;QACH,SAAS;UACP,GAAG,OAAO;UACV,QAAQ;UACR,GAAI,OAAO,QAAQ,aACjB;YACE,YAAY,OAAO,QAAQ;cAE7B;;QAEJ;;;AAIN,SAAO,oBAAoB,YAAY,MAAM;AAC/C;AAvBgB;AAyBV,SAAU,oBAGd,YAA4B,QAAc;AAC1C,QAAM,UAAwC,WAAW,QAAQ,IAAI,CAAC,WAAiC;AACrG,QAAI,OAAO,kBAAkB,UAAU;AACrC,YAAM,IAAI,wBAAuB;;AAGnC,QAAI,OAAO,kBAAkB,kBAAkB;AAC7C,YAAM,IAAI,+BAA8B;;AAG1C,WAAO;MACL,GAAG;MACH,SAAS;QACP,GAAG,OAAO;QACV,GAAI,OAAO,QAAQ,aACjB;UACE,YACE,OAAO,QAAQ,YAAY,IAAI,CAAC,aAAa,cAAc,QAAQ,QAAQ,CAAC,KAAK;YAErF;QACF,QACE,OAAO,QAAQ,WAAW,CAAC,OAAO,QAAQ,UACxC,oBAAoB,QAAQ,OAAO,QAAQ,OAAO,IAClD;;;EAGV,CAAC;AAED,SAAO,EAAE,GAAG,YAAY,QAAO;AACjC;AAhCgB;AAkChB,SAAS,oBAGP,QAAgB,SAAe;AAC/B,MAAI,OAAO,iBAAiB,SAAS,eAAe;AAClD,WAAO;;AAGT,MAAI,OAAO,iBAAiB,SAAS,eAAe;AAClD,QAAI,eAAe,OAAO,iBAAiB;AACzC,YAAM,kBAAkB,OAAO;AAE/B,aAAO,gBAAgB,UAAU,OAAO;;AAG1C,WAAO,KAAK,MAAM,OAAO;;AAG3B,SAAO;AACT;AAnBS;AAqBT,SAAS,cACP,QACA,UAAuC;AAEvC,QAAM,YAAY,OAAO,OAAO,KAAK,CAACE,eAAcA,WAAU,UAAU,SAAS,SAAS,SAAS,IAAI;AACvG,SAAO;IACL,GAAG;IACH,UAAU;MACR,GAAG,SAAS;MACZ,kBACE,mBAAmB,SAAS,IAAI,UAAU,UAAU,SAAS,SAAS,SAAS,IAC7E,WAAW,SAAS,SAAS,KAAK,MAAM,SAAS,SAAS,SAAS,IACnE;;;AAGV;AAfS;AAiBH,SAAU,oBACd,QACA,UAAuC;AAEvC,MAAI,CAAC,QAAQ;AACX,WAAO;;AAGT,QAAM,YAAY,OAAO,OAAO,KAAK,CAACA,eAAcA,WAAU,UAAU,SAAS,SAAS,SAAS,IAAI;AACvG,SAAO,mBAAmB,SAAS,KAAK,WAAW,SAAS,UAAU;AACxE;AAVgB;AAYV,SAAU,sBAAsB,QAAqC;AACzE,MAAI,6BAA6B,OAAO,eAAe,GAAG;AACxD,WAAO;;AAGT,SACE,OAAO,OAAO,KACZ,CAAC,MAAM,mBAAmB,CAAC,KAAM,EAAE,SAAS,cAAc,EAAE,SAAS,WAAW,IAAK,KAClF;AAET;AAVgB;AAYV,SAAU,mBAAmB,OAAuC;AACxE,aAAW,QAAQ,SAAS,CAAA,GAAI;AAC9B,QAAI,KAAK,SAAS,YAAY;AAC5B,YAAM,IAAI,YACR,2EAA2E,KAAK,IAAI,IAAI;;AAI5F,QAAI,KAAK,SAAS,WAAW,MAAM;AACjC,YAAM,IAAI,YACR,SAAS,KAAK,SAAS,IAAI,4FAA4F;;;AAI/H;AAdgB;;;;;;;;;;;;;;;;AC1OhB,IAAM,+BAA+B;AAM/B,IAAO,+BAAP,cAGI,YAAuB;SAAA;;;EAHjC,cAAA;;;AAIY,SAAA,mBAAoD,CAAA;AAC9D,SAAA,WAAyC,CAAA;EAmc3C;EAjcY,mBAER,gBAA6C;AAE7C,SAAK,iBAAiB,KAAK,cAAc;AACzC,SAAK,MAAM,kBAAkB,cAAc;AAC3C,UAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,QAAI;AAAS,WAAK,YAAY,OAAqC;AACnE,WAAO;EACT;EAEU,YAER,SACA,OAAO,MAAI;AAEX,QAAI,EAAE,aAAa;AAAU,cAAQ,UAAU;AAE/C,SAAK,SAAS,KAAK,OAAO;AAE1B,QAAI,MAAM;AACR,WAAK,MAAM,WAAW,OAAO;AAC7B,WAAK,kBAAkB,OAAO,KAAK,cAAc,OAAO,MAAM,QAAQ,SAAS;AAE7E,aAAK,MAAM,sBAAsB,QAAQ,OAAiB;iBACjD,mBAAmB,OAAO,KAAK,QAAQ,eAAe;AAC/D,aAAK,MAAM,gBAAgB,QAAQ,aAAa;iBACvC,mBAAmB,OAAO,KAAK,QAAQ,YAAY;AAC5D,mBAAW,aAAa,QAAQ,YAAY;AAC1C,cAAI,UAAU,SAAS,YAAY;AACjC,iBAAK,MAAM,gBAAgB,UAAU,QAAQ;;;;;EAKvD;;;;;EAMA,MAAM,sBAAmB;AACvB,UAAM,KAAK,KAAI;AACf,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI,CAAC;AAAY,YAAM,IAAI,YAAY,iDAAiD;AACxF,WAAO;EACT;;;;;EAUA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOC,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EA4BA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAoBA,MAAM,oBAAiB;AACrB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;EACb;EAyBA,MAAM,0BAAuB;AAC3B,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;EACb;EAkBA,MAAM,aAAU;AACd,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI;EACb;EAEA,qBAAkB;AAChB,WAAO,CAAC,GAAG,KAAK,gBAAgB;EAClC;EAEmB,aAAU;AAG3B,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI;AAAY,WAAK,MAAM,uBAAuB,UAAU;AAC5D,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AACzD,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AAEzD,UAAM,oBAAoBA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;AAC9B,QAAI;AAAmB,WAAK,MAAM,qBAAqB,iBAAiB;AAExE,UAAM,0BAA0BA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;AACpC,QAAI,2BAA2B;AAAM,WAAK,MAAM,2BAA2B,uBAAuB;AAElG,QAAI,KAAK,iBAAiB,KAAK,CAAC,MAAM,EAAE,KAAK,GAAG;AAC9C,WAAK,MAAM,cAAcA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI,CAAuB;;EAExD;EAUU,MAAM,sBACd,QACA,QACAC,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAD,wBAAA,MAAI,yCAAA,KAAA,4CAAA,EAAgB,KAApB,MAAqB,MAAM;AAE3B,UAAM,iBAAiB,MAAM,OAAO,KAAK,YAAY,OACnD,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAGC,UAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,mBAAmB,oBAAoB,gBAAgB,MAAM,CAAC;EAC5E;EAEU,MAAM,mBACd,QACA,QACAA,UAA6B;AAE7B,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAEjC,WAAO,MAAM,KAAK,sBAAsB,QAAQ,QAAQA,QAAO;EACjE;EAEU,MAAM,cACd,QACA,QAGAA,UAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,gBAAgB,QAAQ,QAAQ,GAAG,WAAU,IAAK;AAC1D,UAAM,uBAAuB,OAAO,kBAAkB,YAAY,eAAe;AACjF,UAAM,EAAE,qBAAqB,6BAA4B,IAAKA,YAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,WAAW;AAChC,sBAAgB,EAAE,QAAQ,EAAE,SAAS,IAAI,IAAI;;AAG/C,UAAM,YAAmD,OAAO,UAAU,IACxE,CAAC,OAA4C;MAC3C,MAAM,EAAE,QAAQ,EAAE,SAAS;MAC3B,YAAY,EAAE;MACd,aAAa,EAAE;MACf;AAGJ,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,QACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7BA,QAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ;AAAe;AAC5B,YAAM,EAAE,MAAM,WAAW,KAAI,IAAK,QAAQ;AAC1C,YAAM,KAAK,gBAAgB,IAAI;AAC/B,UAAI,CAAC,IAAI;AACP,cAAMC,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,4BAA4B,UACvF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC,EACjC,KAAK,IAAI,CAAC;AAEb,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;iBACS,wBAAwB,yBAAyB,MAAM;AAChE,cAAMA,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UACtE,oBAAoB,CACrB;AAED,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;;AAGF,UAAI;AACJ,UAAI;AACF,iBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;eAC3D,OAAO;AACd,aAAK,YAAY;UACf;UACA;UACA,SAAS,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;SAC/D;AACD;;AAIF,YAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,YAAM,UAAUF,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAE5D,WAAK,YAAY,EAAE,MAAM,MAAM,QAAO,CAAE;AAExC,UAAI;AAAsB;;EAE9B;EAEU,MAAM,UACd,QACA,QAGAC,UAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,cAAc,QAAQ,QAAQ,GAAG,WAAU,IAAK;AACxD,UAAM,uBAAuB,OAAO,gBAAgB,YAAY,aAAa,UAAU;AACvF,UAAM,EAAE,qBAAqB,6BAA4B,IAAKA,YAAW,CAAA;AAGzE,UAAM,aAAa,OAAO,MAAM,IAAI,CAAC,SAAmC;AACtE,UAAI,mBAAmB,IAAI,GAAG;AAC5B,YAAI,CAAC,KAAK,WAAW;AACnB,gBAAM,IAAI,YAAY,uEAAuE;;AAG/F,eAAO;UACL,MAAM;UACN,UAAU;YACR,UAAU,KAAK;YACf,MAAM,KAAK,SAAS;YACpB,aAAa,KAAK,SAAS,eAAe;YAC1C,YAAY,KAAK,SAAS;YAC1B,OAAO,KAAK;YACZ,QAAQ;;;;AAKd,aAAO;IACT,CAAC;AAED,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,YAAY;AAC1B,UAAI,EAAE,SAAS,YAAY;AACzB,wBAAgB,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS,IAAI,IAAI,EAAE;;;AAIrE,UAAM,QACJ,WAAW,SACT,WAAW,IAAI,CAAC,MACd,EAAE,SAAS,aACT;MACE,MAAM;MACN,UAAU;QACR,MAAM,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS;QAC7C,YAAY,EAAE,SAAS;QACvB,aAAa,EAAE,SAAS;QACxB,QAAQ,EAAE,SAAS;;QAGtB,CAAmC,IAEvC;AAEL,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,QACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7BA,QAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ,YAAY,QAAQ;AAC/B;;AAGF,iBAAW,aAAa,QAAQ,YAAY;AAC1C,YAAI,UAAU,SAAS;AAAY;AACnC,cAAM,eAAe,UAAU;AAC/B,cAAM,EAAE,MAAM,WAAW,KAAI,IAAK,UAAU;AAC5C,cAAM,KAAK,gBAAgB,IAAI;AAE/B,YAAI,CAAC,IAAI;AACP,gBAAMC,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,4BAA4B,OAAO,KAC3F,eAAe,EAEd,IAAI,CAACC,UAAS,KAAK,UAAUA,KAAI,CAAC,EAClC,KAAK,IAAI,CAAC;AAEb,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAD,SAAO,CAAE;AAChD;mBACS,wBAAwB,yBAAyB,MAAM;AAChE,gBAAMA,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UAClE,oBAAoB,CACrB;AAED,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAGF,YAAI;AACJ,YAAI;AACF,mBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;iBAC3D,OAAO;AACd,gBAAMA,WAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACrE,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAIF,cAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,cAAM,UAAUF,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAC5D,aAAK,YAAY,EAAE,MAAM,cAAc,QAAO,CAAE;AAEhD,YAAI,sBAAsB;AACxB;;;;AAKN;EACF;;;AAvYE,SAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI,EAAoB,WAAW;AAC5C,qDAAC,gDAAA,gCAAAI,iDAAA;AAYC,MAAI,IAAI,KAAK,SAAS;AACtB,SAAO,MAAM,GAAG;AACd,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,GAAG;AAC/B,YAAM,EAAE,eAAe,GAAG,KAAI,IAAK;AAGnC,YAAM,MAA4C;QAChD,GAAG;QACH,SAAU,QAAkC,WAAW;QACvD,SAAU,QAAkC,WAAW;;AAEzD,UAAI,eAAe;AACjB,YAAI,gBAAgB;;AAEtB,aAAO;;;AAGX,QAAM,IAAI,YAAY,4EAA4E;AACpG,GA/BC,kDA+BA,qDAAA,gCAAAC,sDAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,KAAK,SAAS,eAAe;AACzD,aAAO,QAAQ;;AAEjB,QAAI,mBAAmB,OAAO,KAAK,SAAS,YAAY,QAAQ;AAC9D,aAAO,QAAQ,WAAW,GAAG,EAAE,GAAG;;;AAItC;AACF,GAvBC,uDAuBA,2DAAA,gCAAAC,4DAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,kBAAkB,OAAO,KAAK,QAAQ,WAAW,MAAM;AACzD,aAAO,QAAQ;;AAEjB,QACE,cAAc,OAAO,KACrB,QAAQ,WAAW,QACnB,OAAO,QAAQ,YAAY,YAC3B,KAAK,SAAS,KACZ,CAAC,MACC,EAAE,SAAS,eACX,EAAE,YAAY,KAAK,CAAC,MAAM,EAAE,SAAS,cAAc,EAAE,OAAO,QAAQ,YAAY,CAAC,GAErF;AACA,aAAO,QAAQ;;;AAInB;AACF,GAhCC,6DAgCA,oDAAA,gCAAAC,qDAAA;AAQC,QAAM,QAAyB;IAC7B,mBAAmB;IACnB,eAAe;IACf,cAAc;;AAEhB,aAAW,EAAE,MAAK,KAAM,KAAK,kBAAkB;AAC7C,QAAI,OAAO;AACT,YAAM,qBAAqB,MAAM;AACjC,YAAM,iBAAiB,MAAM;AAC7B,YAAM,gBAAgB,MAAM;;;AAGhC,SAAO;AACT,GArBC,sDAqBA,+CAAA,gCAAAC,8CAgCe,QAAkC;AAChD,MAAI,OAAO,KAAK,QAAQ,OAAO,IAAI,GAAG;AACpC,UAAM,IAAI,YACR,8HAA8H;;AAGpI,GAtCC,iDAsCA,4DAAA,gCAAAC,2DAuP4B,YAAmB;AAC9C,SACE,OAAO,eAAe,WAAW,aAC/B,eAAe,SAAY,cAC3B,KAAK,UAAU,UAAU;AAE/B,GA7PC;;;AC3MG,IAAO,uBAAP,MAAO,8BAA6C,6BAGzD;SAAA;;;;EAEC,OAAO,aACL,QACA,QACAC,UAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,QAAQ,QAAQ,IAAI,CAAC;AAC5D,WAAO;EACT;EAEA,OAAO,SACL,QACA,QACAA,UAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,QAAQ,QAAQ,IAAI,CAAC;AACxD,WAAO;EACT;EAES,YAEP,SACA,OAAgB,MAAI;AAEpB,UAAM,YAAY,SAAS,IAAI;AAC/B,QAAI,mBAAmB,OAAO,KAAK,QAAQ,SAAS;AAClD,WAAK,MAAM,WAAW,QAAQ,OAAiB;;EAEnD;;;;AC1EF,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,OAAO;AACb,IAAM,OAAO;AACb,IAAM,MAAM;AACZ,IAAM,WAAW;AACjB,IAAM,iBAAiB;AAEvB,IAAM,MAAM,WAAW;AACvB,IAAM,UAAU,OAAO,OAAO,MAAM;AACpC,IAAM,OAAO,MAAM,MAAM;AACzB,IAAM,aAAa,MAAM;AACzB,IAAM,MAAM,OAAO;AAEnB,IAAM,QAAQ;EACZ;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;AAIF,IAAM,cAAN,cAA0B,MAAK;EAlC/B,OAkC+B;;;;AAE/B,IAAM,gBAAN,cAA4B,MAAK;EApCjC,OAoCiC;;;;AAUjC,SAAS,UAAU,YAAoB,eAAuB,MAAM,KAAG;AACrE,MAAI,OAAO,eAAe,UAAU;AAClC,UAAM,IAAI,UAAU,sBAAsB,OAAO,UAAU,EAAE;;AAE/D,MAAI,CAAC,WAAW,KAAI,GAAI;AACtB,UAAM,IAAI,MAAM,GAAG,UAAU,WAAW;;AAE1C,SAAO,WAAW,WAAW,KAAI,GAAI,YAAY;AACnD;AARS;AAUT,IAAM,aAAa,wBAAC,YAAoB,UAAiB;AACvD,QAAM,SAAS,WAAW;AAC1B,MAAI,QAAQ;AAEZ,QAAM,kBAAkB,wBAAC,QAAe;AACtC,UAAM,IAAI,YAAY,GAAG,GAAG,gBAAgB,KAAK,EAAE;EACrD,GAFwB;AAIxB,QAAM,sBAAsB,wBAAC,QAAe;AAC1C,UAAM,IAAI,cAAc,GAAG,GAAG,gBAAgB,KAAK,EAAE;EACvD,GAF4B;AAI5B,QAAM,WAAsB,6BAAK;AAC/B,cAAS;AACT,QAAI,SAAS;AAAQ,sBAAgB,yBAAyB;AAC9D,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,UAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,OAAO,WAAW,WAAW,UAAU,KAAK,CAAC,GAC1F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,UAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,OAAO,WAAW,WAAW,UAAU,KAAK,CAAC,GAC1F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,WAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,QAAQ,WAAW,WAAW,UAAU,KAAK,CAAC,GAC3F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,cAC1C,MAAM,WAAW,SAAS,SAAS,QAAQ,KAAK,WAAW,WAAW,WAAW,UAAU,KAAK,CAAC,GAClG;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,eAC1C,MAAM,iBAAiB,SACtB,IAAI,SAAS,SACb,SAAS,QAAQ,KACjB,YAAY,WAAW,WAAW,UAAU,KAAK,CAAC,GACpD;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,SAC1C,MAAM,MAAM,SAAS,SAAS,QAAQ,KAAK,MAAM,WAAW,WAAW,UAAU,KAAK,CAAC,GACxF;AACA,eAAS;AACT,aAAO;;AAET,WAAO,SAAQ;EACjB,GApD4B;AAsD5B,QAAM,WAAyB,6BAAK;AAClC,UAAM,QAAQ;AACd,QAAIC,UAAS;AACb;AACA,WAAO,QAAQ,WAAW,WAAW,KAAK,MAAM,OAAQA,WAAU,WAAW,QAAQ,CAAC,MAAM,OAAQ;AAClG,MAAAA,UAAS,WAAW,KAAK,MAAM,OAAO,CAACA,UAAS;AAChD;;AAEF,QAAI,WAAW,OAAO,KAAK,KAAK,KAAK;AACnC,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,EAAE,QAAQ,OAAOA,OAAM,CAAC,CAAC;eAChE,GAAG;AACV,4BAAoB,OAAO,CAAC,CAAC;;eAEtB,MAAM,MAAM,OAAO;AAC5B,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,QAAQ,OAAOA,OAAM,CAAC,IAAI,GAAG;eACpE,GAAG;AAEV,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,WAAW,YAAY,IAAI,CAAC,IAAI,GAAG;;;AAGrF,oBAAgB,6BAA6B;EAC/C,GAvB+B;AAyB/B,QAAM,WAAW,6BAAK;AACpB;AACA,cAAS;AACT,UAAM,MAA2B,CAAA;AACjC,QAAI;AACF,aAAO,WAAW,KAAK,MAAM,KAAK;AAChC,kBAAS;AACT,YAAI,SAAS,UAAU,MAAM,MAAM;AAAO,iBAAO;AACjD,cAAM,MAAM,SAAQ;AACpB,kBAAS;AACT;AACA,YAAI;AACF,gBAAM,QAAQ,SAAQ;AACtB,iBAAO,eAAe,KAAK,KAAK,EAAE,OAAO,UAAU,MAAM,YAAY,MAAM,cAAc,KAAI,CAAE;iBACxF,GAAG;AACV,cAAI,MAAM,MAAM;AAAO,mBAAO;;AACzB,kBAAM;;AAEb,kBAAS;AACT,YAAI,WAAW,KAAK,MAAM;AAAK;;aAE1B,GAAG;AACV,UAAI,MAAM,MAAM;AAAO,eAAO;;AACzB,wBAAgB,+BAA+B;;AAEtD;AACA,WAAO;EACT,GA3BiB;AA6BjB,QAAM,WAAW,6BAAK;AACpB;AACA,UAAM,MAAM,CAAA;AACZ,QAAI;AACF,aAAO,WAAW,KAAK,MAAM,KAAK;AAChC,YAAI,KAAK,SAAQ,CAAE;AACnB,kBAAS;AACT,YAAI,WAAW,KAAK,MAAM,KAAK;AAC7B;;;aAGG,GAAG;AACV,UAAI,MAAM,MAAM,OAAO;AACrB,eAAO;;AAET,sBAAgB,8BAA8B;;AAEhD;AACA,WAAO;EACT,GAnBiB;AAqBjB,QAAM,WAAW,6BAAK;AACpB,QAAI,UAAU,GAAG;AACf,UAAI,eAAe,OAAO,MAAM,MAAM;AAAO,wBAAgB,sBAAsB;AACnF,UAAI;AACF,eAAO,KAAK,MAAM,UAAU;eACrB,GAAG;AACV,YAAI,MAAM,MAAM,OAAO;AACrB,cAAI;AACF,gBAAI,QAAQ,WAAW,WAAW,SAAS,CAAC;AAC1C,qBAAO,KAAK,MAAM,WAAW,UAAU,GAAG,WAAW,YAAY,GAAG,CAAC,CAAC;AACxE,mBAAO,KAAK,MAAM,WAAW,UAAU,GAAG,WAAW,YAAY,GAAG,CAAC,CAAC;mBAC/DC,IAAG;UAAA;;AAEd,4BAAoB,OAAO,CAAC,CAAC;;;AAIjC,UAAM,QAAQ;AAEd,QAAI,WAAW,KAAK,MAAM;AAAK;AAC/B,WAAO,WAAW,KAAK,KAAK,CAAC,MAAM,SAAS,WAAW,KAAK,CAAE;AAAG;AAEjE,QAAI,SAAS,UAAU,EAAE,MAAM,MAAM;AAAQ,sBAAgB,6BAA6B;AAE1F,QAAI;AACF,aAAO,KAAK,MAAM,WAAW,UAAU,OAAO,KAAK,CAAC;aAC7C,GAAG;AACV,UAAI,WAAW,UAAU,OAAO,KAAK,MAAM,OAAO,MAAM,MAAM;AAC5D,wBAAgB,sBAAsB;AACxC,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,WAAW,YAAY,GAAG,CAAC,CAAC;eACnEA,IAAG;AACV,4BAAoB,OAAOA,EAAC,CAAC;;;EAGnC,GAnCiB;AAqCjB,QAAM,YAAY,6BAAK;AACrB,WAAO,QAAQ,UAAU,SAAU,SAAS,WAAW,KAAK,CAAE,GAAG;AAC/D;;EAEJ,GAJkB;AAMlB,SAAO,SAAQ;AACjB,GAzLmB;AA4LnB,IAAM,eAAe,wBAAC,UAAkB,UAAU,OAAO,MAAM,MAAM,MAAM,GAAG,GAAzD;;;;;;;;;;;;;;;;;;;;;;;;;;ACrHf,IAAO,uBAAP,MAAO,8BACH,6BAA0E;SAAA;;;EAOlF,YAAY,QAAyC;AACnD,UAAK;;AALP,iCAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;AACA,wDAAA,IAAA,MAAA,MAAA;AAIE,IAAAC,wBAAA,MAAI,8BAAW,QAAM,GAAA;AACrB,IAAAA,wBAAA,MAAI,yCAAsB,CAAA,GAAE,GAAA;EAC9B;EAEA,IAAI,gCAA6B;AAC/B,WAAOC,wBAAA,MAAI,qDAAA,GAAA;EACb;;;;;;;;EASA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,sBAAqB,IAAI;AAC5C,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEA,OAAO,qBACL,QACA,QACAC,UAA6B;AAE7B,UAAM,SAAS,IAAI,sBAA8B,MAA6C;AAC9F,WAAO,KAAK,MACV,OAAO,mBACL,QACA,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAGA,UAAS,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,SAAQ,EAAE,CAAE,CACxF;AAEH,WAAO;EACT;EAoMmB,MAAM,sBACvB,QACA,QACAA,UAA6B;AAE7B,UAAM;AACN,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAD,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AAEJ,UAAM,SAAS,MAAM,OAAO,KAAK,YAAY,OAC3C,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAGC,UAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,qBAAiB,SAAS,QAAQ;AAChC,MAAAD,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAEU,MAAM,oBACd,gBACAC,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAD,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAwC,gBAAgB,KAAK,UAAU;AAC7F,QAAI;AACJ,qBAAiB,SAAS,QAAQ;AAChC,UAAI,UAAU,WAAW,MAAM,IAAI;AAEjC,aAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;;AAG5C,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;AACpB,eAAS,MAAM;;AAEjB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAuHA,EAAA,+BAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,sDAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,qCAAA,gCAAAE,sCAAA;AA7WE,QAAI,KAAK;AAAO;AAChB,IAAAH,wBAAA,MAAI,qDAAkC,QAAS,GAAA;EACjD,GA2WA,uCA3WC,4CAAA,gCAAAI,2CAEoB,QAAqC;AACxD,QAAI,QAAQH,wBAAA,MAAI,yCAAA,GAAA,EAAoB,OAAO,KAAK;AAChD,QAAI,OAAO;AACT,aAAO;;AAGT,YAAQ;MACN,cAAc;MACd,cAAc;MACd,uBAAuB;MACvB,uBAAuB;MACvB,iBAAiB,oBAAI,IAAG;MACxB,yBAAyB;;AAE3B,IAAAA,wBAAA,MAAI,yCAAA,GAAA,EAAoB,OAAO,KAAK,IAAI;AACxC,WAAO;EACT,GAlBC,8CAkBA,iCAAA,gCAAAI,gCAE8C,OAA0B;AACvE,QAAI,KAAK;AAAO;AAEhB,UAAM,aAAaJ,wBAAA,MAAI,iCAAA,KAAA,8CAAA,EAA0B,KAA9B,MAA+B,KAAK;AACvD,SAAK,MAAM,SAAS,OAAO,UAAU;AAErC,eAAW,UAAU,MAAM,SAAS;AAClC,YAAM,iBAAiB,WAAW,QAAQ,OAAO,KAAK;AAEtD,UACE,OAAO,MAAM,WAAW,QACxB,eAAe,SAAS,SAAS,eACjC,eAAe,SAAS,SACxB;AACA,aAAK,MAAM,WAAW,OAAO,MAAM,SAAS,eAAe,QAAQ,OAAO;AAC1E,aAAK,MAAM,iBAAiB;UAC1B,OAAO,OAAO,MAAM;UACpB,UAAU,eAAe,QAAQ;UACjC,QAAQ,eAAe,QAAQ;SAChC;;AAGH,UACE,OAAO,MAAM,WAAW,QACxB,eAAe,SAAS,SAAS,eACjC,eAAe,SAAS,SACxB;AACA,aAAK,MAAM,iBAAiB;UAC1B,OAAO,OAAO,MAAM;UACpB,UAAU,eAAe,QAAQ;SAClC;;AAGH,UAAI,OAAO,UAAU,WAAW,QAAQ,eAAe,SAAS,SAAS,aAAa;AACpF,aAAK,MAAM,0BAA0B;UACnC,SAAS,OAAO,UAAU;UAC1B,UAAU,eAAe,UAAU,WAAW,CAAA;SAC/C;;AAGH,UAAI,OAAO,UAAU,WAAW,QAAQ,eAAe,SAAS,SAAS,aAAa;AACpF,aAAK,MAAM,0BAA0B;UACnC,SAAS,OAAO,UAAU;UAC1B,UAAU,eAAe,UAAU,WAAW,CAAA;SAC/C;;AAGH,YAAM,QAAQA,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AAEtD,UAAI,eAAe,eAAe;AAChC,QAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,cAAc;AAE1C,YAAI,MAAM,2BAA2B,MAAM;AACzC,UAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,gBAAgB,MAAM,uBAAuB;;;AAI7E,iBAAW,YAAY,OAAO,MAAM,cAAc,CAAA,GAAI;AACpD,YAAI,MAAM,4BAA4B,SAAS,OAAO;AACpD,UAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,cAAc;AAG1C,cAAI,MAAM,2BAA2B,MAAM;AACzC,YAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,gBAAgB,MAAM,uBAAuB;;;AAI7E,cAAM,0BAA0B,SAAS;;AAG3C,iBAAW,iBAAiB,OAAO,MAAM,cAAc,CAAA,GAAI;AACzD,cAAM,mBAAmB,eAAe,QAAQ,aAAa,cAAc,KAAK;AAChF,YAAI,CAAC,kBAAkB,MAAM;AAC3B;;AAGF,YAAI,kBAAkB,SAAS,YAAY;AACzC,eAAK,MAAM,uCAAuC;YAChD,MAAM,iBAAiB,UAAU;YACjC,OAAO,cAAc;YACrB,WAAW,iBAAiB,SAAS;YACrC,kBAAkB,iBAAiB,SAAS;YAC5C,iBAAiB,cAAc,UAAU,aAAa;WACvD;eACI;AACL,sBAAY,kBAAkB,IAAI;;;;EAI1C,GA3FC,mCA2FA,8CAAA,gCAAAK,6CAEsB,gBAA+C,eAAqB;AACzF,UAAM,QAAQL,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AACtD,QAAI,MAAM,gBAAgB,IAAI,aAAa,GAAG;AAE5C;;AAGF,UAAM,mBAAmB,eAAe,QAAQ,aAAa,aAAa;AAC1E,QAAI,CAAC,kBAAkB;AACrB,YAAM,IAAI,MAAM,uBAAuB;;AAEzC,QAAI,CAAC,iBAAiB,MAAM;AAC1B,YAAM,IAAI,MAAM,mCAAmC;;AAGrD,QAAI,iBAAiB,SAAS,YAAY;AACxC,YAAM,YAAYA,wBAAA,MAAI,8BAAA,GAAA,GAAU,OAAO,KACrC,CAAC,SAAS,KAAK,SAAS,cAAc,KAAK,SAAS,SAAS,iBAAiB,SAAS,IAAI;AAG7F,WAAK,MAAM,sCAAsC;QAC/C,MAAM,iBAAiB,SAAS;QAChC,OAAO;QACP,WAAW,iBAAiB,SAAS;QACrC,kBACE,mBAAmB,SAAS,IAAI,UAAU,UAAU,iBAAiB,SAAS,SAAS,IACrF,WAAW,SAAS,SAAS,KAAK,MAAM,iBAAiB,SAAS,SAAS,IAC3E;OACL;WACI;AACL,kBAAY,iBAAiB,IAAI;;EAErC,GAlCC,gDAkCA,8CAAA,gCAAAM,6CAEsB,gBAA6C;AAClE,UAAM,QAAQN,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AAEtD,QAAI,eAAe,QAAQ,WAAW,CAAC,MAAM,cAAc;AACzD,YAAM,eAAe;AAErB,YAAM,iBAAiBA,wBAAA,MAAI,iCAAA,KAAA,oDAAA,EAAgC,KAApC,IAAI;AAE3B,WAAK,MAAM,gBAAgB;QACzB,SAAS,eAAe,QAAQ;QAChC,QAAQ,iBAAiB,eAAe,UAAU,eAAe,QAAQ,OAAO,IAAK;OACtF;;AAGH,QAAI,eAAe,QAAQ,WAAW,CAAC,MAAM,cAAc;AACzD,YAAM,eAAe;AAErB,WAAK,MAAM,gBAAgB,EAAE,SAAS,eAAe,QAAQ,QAAO,CAAE;;AAGxE,QAAI,eAAe,UAAU,WAAW,CAAC,MAAM,uBAAuB;AACpE,YAAM,wBAAwB;AAE9B,WAAK,MAAM,yBAAyB,EAAE,SAAS,eAAe,SAAS,QAAO,CAAE;;AAGlF,QAAI,eAAe,UAAU,WAAW,CAAC,MAAM,uBAAuB;AACpE,YAAM,wBAAwB;AAE9B,WAAK,MAAM,yBAAyB,EAAE,SAAS,eAAe,SAAS,QAAO,CAAE;;EAEpF,GAjCC,gDAiCA,mCAAA,gCAAAO,oCAAA;AAGC,QAAI,KAAK,OAAO;AACd,YAAM,IAAI,YAAY,yCAAyC;;AAEjE,UAAM,WAAWP,wBAAA,MAAI,qDAAA,GAAA;AACrB,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YAAY,0CAA0C;;AAElE,IAAAD,wBAAA,MAAI,qDAAkC,QAAS,GAAA;AAC/C,IAAAA,wBAAA,MAAI,yCAAsB,CAAA,GAAE,GAAA;AAC5B,WAAO,uBAAuB,UAAUC,wBAAA,MAAI,8BAAA,GAAA,CAAQ;EACtD,GAbC,qCAaA,uDAAA,gCAAAQ,wDAAA;AA0DC,UAAM,iBAAiBR,wBAAA,MAAI,8BAAA,GAAA,GAAU;AACrC,QAAI,6BAAsC,cAAc,GAAG;AACzD,aAAO;;AAGT,WAAO;EACT,GAhEC,yDAgEA,iDAAA,gCAAAS,gDAEyB,OAA0B;;AAClD,QAAI,WAAWT,wBAAA,MAAI,qDAAA,GAAA;AACnB,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,QAAI,CAAC,UAAU;AACb,iBAAWD,wBAAA,MAAI,qDAAkC;QAC/C,GAAG;QACH,SAAS,CAAA;SACV,GAAA;WACI;AACL,aAAO,OAAO,UAAU,IAAI;;AAG9B,eAAW,EAAE,OAAO,eAAe,OAAO,WAAW,MAAM,GAAGW,OAAK,KAAM,MAAM,SAAS;AACtF,UAAI,SAAS,SAAS,QAAQ,KAAK;AACnC,UAAI,CAAC,QAAQ;AACX,iBAAS,SAAS,QAAQ,KAAK,IAAI,EAAE,eAAe,OAAO,SAAS,CAAA,GAAI,UAAU,GAAGA,OAAK;;AAG5F,UAAI,UAAU;AACZ,YAAI,CAAC,OAAO,UAAU;AACpB,iBAAO,WAAW,OAAO,OAAO,CAAA,GAAI,QAAQ;eACvC;AACL,gBAAM,EAAE,SAAAC,UAAS,SAAAC,UAAS,GAAGC,MAAI,IAAK;AACtC,wBAAcA,KAAI;AAClB,iBAAO,OAAO,OAAO,UAAUA,KAAI;AAEnC,cAAIF,UAAS;AACX,aAAAG,MAAA,OAAO,UAAS,YAAOA,IAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGH,QAAO;;AAGzC,cAAIC,UAAS;AACX,aAAA,KAAA,OAAO,UAAS,YAAO,GAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGA,QAAO;;;;AAK7C,UAAI,eAAe;AACjB,eAAO,gBAAgB;AAEvB,YAAIZ,wBAAA,MAAI,8BAAA,GAAA,KAAY,sBAAsBA,wBAAA,MAAI,8BAAA,GAAA,CAAQ,GAAG;AACvD,cAAI,kBAAkB,UAAU;AAC9B,kBAAM,IAAI,wBAAuB;;AAGnC,cAAI,kBAAkB,kBAAkB;AACtC,kBAAM,IAAI,+BAA8B;;;;AAK9C,aAAO,OAAO,QAAQU,MAAK;AAE3B,UAAI,CAAC;AAAO;AAEZ,YAAM,EAAE,SAAS,SAAS,eAAe,MAAM,YAAY,GAAGG,MAAI,IAAK;AACvE,oBAAcA,KAAI;AAClB,aAAO,OAAO,OAAO,SAASA,KAAI;AAElC,UAAI,SAAS;AACX,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;;AAG5D,UAAI;AAAM,eAAO,QAAQ,OAAO;AAChC,UAAI,eAAe;AACjB,YAAI,CAAC,OAAO,QAAQ,eAAe;AACjC,iBAAO,QAAQ,gBAAgB;eAC1B;AACL,cAAI,cAAc;AAAM,mBAAO,QAAQ,cAAc,OAAO,cAAc;AAC1E,cAAI,cAAc,WAAW;AAC3B,aAAA,KAAA,OAAO,QAAQ,eAAc,cAAS,GAAT,YAAc;AAC3C,mBAAO,QAAQ,cAAc,aAAa,cAAc;;;;AAI9D,UAAI,SAAS;AACX,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;AAE1D,YAAI,CAAC,OAAO,QAAQ,WAAWb,wBAAA,MAAI,iCAAA,KAAA,oDAAA,EAAgC,KAApC,IAAI,GAAoC;AACrE,iBAAO,QAAQ,SAAS,aAAa,OAAO,QAAQ,OAAO;;;AAI/D,UAAI,YAAY;AACd,YAAI,CAAC,OAAO,QAAQ;AAAY,iBAAO,QAAQ,aAAa,CAAA;AAE5D,mBAAW,EAAE,OAAAe,QAAO,IAAI,MAAM,UAAU,IAAI,GAAGF,MAAI,KAAM,YAAY;AACnE,gBAAM,aAAY,KAAC,OAAO,QAAQ,YAAWE,MAAK,MAAA,GAALA,MAAK,IAChD,CAAA;AACF,iBAAO,OAAO,WAAWF,KAAI;AAC7B,cAAI;AAAI,sBAAU,KAAK;AACvB,cAAI;AAAM,sBAAU,OAAO;AAC3B,cAAI;AAAI,sBAAU,aAAV,UAAU,WAAa,EAAE,MAAM,GAAG,QAAQ,IAAI,WAAW,GAAE;AACnE,cAAI,IAAI;AAAM,sBAAU,SAAU,OAAO,GAAG;AAC5C,cAAI,IAAI,WAAW;AACjB,sBAAU,SAAU,aAAa,GAAG;AAEpC,gBAAI,oBAAoBb,wBAAA,MAAI,8BAAA,GAAA,GAAU,SAAS,GAAG;AAChD,wBAAU,SAAU,mBAAmB,aAAa,UAAU,SAAU,SAAS;;;;;;AAM3F,WAAO;EACT,GA5GC,mDA8GA,OAAO,cAAa,IAAC;AACpB,UAAM,YAAmC,CAAA;AACzC,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAEX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,mCAAyD;AAC7D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAAyC,CAAC,SAAS,WAC5D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACgB,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC,GAXM;MAYN,QAAQ,mCAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC,GAHQ;;EAKZ;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;;AAGF,SAAS,uBACP,UACA,QAAyC;AAEzC,QAAM,EAAE,IAAI,SAAS,SAAS,OAAO,oBAAoB,GAAG,KAAI,IAAK;AACrE,QAAM,aAA6B;IACjC,GAAG;IACH;IACA,SAAS,QAAQ,IACf,CAAC,EAAE,SAAS,eAAe,OAAO,UAAU,GAAG,WAAU,MAA6B;AACpF,UAAI,CAAC,eAAe;AAClB,cAAM,IAAI,YAAY,oCAAoC,KAAK,EAAE;;AAGnE,YAAM,EAAE,UAAU,MAAM,eAAe,YAAY,GAAG,YAAW,IAAK;AACtE,YAAM,OAAO,QAAQ;AACrB,UAAI,CAAC,MAAM;AACT,cAAM,IAAI,YAAY,2BAA2B,KAAK,EAAE;;AAG1D,UAAI,eAAe;AACjB,cAAM,EAAE,WAAW,MAAM,KAAI,IAAK;AAClC,YAAI,QAAQ,MAAM;AAChB,gBAAM,IAAI,YAAY,8CAA8C,KAAK,EAAE;;AAG7E,YAAI,CAAC,MAAM;AACT,gBAAM,IAAI,YAAY,yCAAyC,KAAK,EAAE;;AAGxE,eAAO;UACL,GAAG;UACH,SAAS;YACP;YACA,eAAe,EAAE,WAAW,MAAM,KAAI;YACtC;YACA,SAAS,QAAQ,WAAW;;UAE9B;UACA;UACA;;;AAIJ,UAAI,YAAY;AACd,eAAO;UACL,GAAG;UACH;UACA;UACA;UACA,SAAS;YACP,GAAG;YACH;YACA;YACA,SAAS,QAAQ,WAAW;YAC5B,YAAY,WAAW,IAAI,CAAC,WAAW,MAAK;AAC1C,oBAAM,EAAE,UAAU,IAAI,MAAM,IAAAC,KAAI,GAAG,SAAQ,IAAK;AAChD,oBAAM,EAAE,WAAW,MAAM,MAAM,GAAG,OAAM,IAAK,MAAM,CAAA;AACnD,kBAAIA,OAAM,MAAM;AACd,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAS,IAAI,QAAQ,CAAC,EAAE;;AAEzF,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAW,IAAI,QAAQ,CAAC,EAAE;;AAE3F,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAoB,IAAI,QAAQ,CAAC,EAAE;;AAGhF,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAyB,IAAI,QAAQ,CAAC,EAAE;;AAIrF,qBAAO,EAAE,GAAG,UAAU,IAAAA,KAAI,MAAM,UAAU,EAAE,GAAG,QAAQ,MAAM,WAAW,KAAI,EAAE;YAChF,CAAC;;;;AAIP,aAAO;QACL,GAAG;QACH,SAAS,EAAE,GAAG,aAAa,SAAS,MAAM,SAAS,QAAQ,WAAW,KAAI;QAC1E;QACA;QACA;;IAEJ,CAAC;IAEH;IACA;IACA,QAAQ;IACR,GAAI,qBAAqB,EAAE,mBAAkB,IAAK,CAAA;;AAGpD,SAAO,yBAAyB,YAAY,MAAM;AACpD;AAhGS;AAkGT,SAAS,IAAI,GAAU;AACrB,SAAO,KAAK,UAAU,CAAC;AACzB;AAFS;AAiKT,SAAS,cAA4B,KAAqB;AACxD;AACF;AAFS;AAIT,SAAS,YAAY,IAAS;AAAG;AAAxB;;;ACx0BH,IAAO,gCAAP,MAAO,uCACH,qBAA6B;SAAA;;;EAGrC,OAAgB,mBAAmB,QAAsB;AACvD,UAAM,SAAS,IAAI,+BAA8B,IAAI;AACrD,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;;EAGA,OAAO,aACL,QACA,QACAC,UAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA8B,IAAI;AACrD,UAAM,OAAO;MACX,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,QAAQ,QAAQ,IAAI,CAAC;AAC5D,WAAO;EACT;EAEA,OAAO,SACL,QACA,QACAA,UAAuB;AAEvB,UAAM,SAAS,IAAI;;MAEjB;IAAM;AAER,UAAM,OAAO;MACX,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,QAAQ,QAAQ,IAAI,CAAC;AACxD,WAAO;EACT;;;;ACLI,IAAOC,eAAP,cAA2B,YAAW;EAjE5C,OAiE4C;;;EAC1C,MACE,MACAC,UAA6B;AAE7B,uBAAmB,KAAK,KAAK;AAE7B,WAAO,KAAK,QAAQ,KAAK,YACtB,OAAO,MAAM;MACZ,GAAGA;MACH,SAAS;QACP,GAAGA,UAAS;QACZ,6BAA6B;;KAEhC,EACA,YAAY,CAAC,eAAe,oBAAoB,YAAY,IAAI,CAAC;EACtE;EAaA,aACE,MAGAA,UAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,aACnC,KAAK,SACL,MACAA,QAAO;;AAGX,WAAO,qBAAqB,aAC1B,KAAK,SACL,MACAA,QAAO;EAEX;EAqBA,SAIE,MACAA,UAAuB;AAEvB,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,SACnC,KAAK,SACL,MACAA,QAAO;;AAIX,WAAO,qBAAqB,SAAS,KAAK,SAAS,MAA6CA,QAAO;EACzG;;;;EAKA,OACE,MACAA,UAA6B;AAE7B,WAAO,qBAAqB,qBAAqB,KAAK,SAAS,MAAMA,QAAO;EAC9E;;;;AC1JI,IAAOC,QAAP,cAAoB,YAAW;EALrC,OAKqC;;;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmBC,aAAY,KAAK,OAAO;EACvF;;CAEA,SAAiBD,OAAI;AACL,EAAAA,MAAA,cAA6BC;AAC7C,GAFiBD,UAAAA,QAAI,CAAA,EAAA;;;ACJf,IAAO,WAAP,cAAwB,YAAW;EALzC,OAKyC;;;;;;;;;;;;EAUvC,OAAO,MAA2BE,UAA6B;AAC7D,WAAO,KAAK,QAAQ,KAAK,sBAAsB;MAC7C;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;ACRI,IAAO,WAAP,cAAwB,YAAW;EAbzC,OAayC;;;EAAzC,cAAA;;AACE,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;EACxE;;AAi/DA,SAAS,WAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACx7Dd,IAAO,kBAAP,MAAO,yBACH,YAAkC;SAAA;;;EAD5C,cAAA;;;AAKE,4BAAA,IAAA,MAAkC,CAAA,CAAE;AAIpC,sCAAA,IAAA,MAAoD,CAAA,CAAE;AACtD,sCAAA,IAAA,MAA+C,CAAA,CAAE;AACjD,qCAAA,IAAA,MAAA,MAAA;AACA,8BAAA,IAAA,MAAA,MAAA;AACA,yCAAA,IAAA,MAAA,MAAA;AACA,oCAAA,IAAA,MAAA,MAAA;AACA,0CAAA,IAAA,MAAA,MAAA;AACA,qCAAA,IAAA,MAAA,MAAA;AAGA,kCAAA,IAAA,MAAA,MAAA;AACA,wCAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;EA2qBF;EAzqBE,EAAA,0BAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,4BAAA,oBAAA,QAAA,GAAA,uCAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,wCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,gCAAA,oBAAA,QAAA,GAAA,sCAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,6BAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAoC,CAAA;AAC1C,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAGX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,mCAA0D;AAC9D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAA0C,CAAC,SAAS,WAC7D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACC,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC,GAXM;MAYN,QAAQ,mCAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC,GAHQ;;EAKZ;EAEA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEU,MAAM,oBACd,gBACAC,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAyC,gBAAgB,KAAK,UAAU;AAC9F,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;EAEA,OAAO,0BACL,UACA,OACA,MACA,QACAD,UAAmC;AAEnC,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,wBAAwB,UAAU,OAAO,MAAM,QAAQ;MAC5D,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEU,MAAM,2BACd,KACA,UACA,OACA,QACAA,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAA4C,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAC3E,UAAM,SAAS,MAAM,IAAI,kBAAkB,UAAU,OAAO,MAAM;MAChE,GAAGA;MACH,QAAQ,KAAK,WAAW;KACzB;AAED,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,OAAO,4BACL,QACA,QACAD,UAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,uBAAuB,QAAQ,QAAQ;MAC5C,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,OAAO,sBACL,UACA,MACA,QACAA,UAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,oBAAoB,UAAU,MAAM,QAAQ;MACjD,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,eAAY;AACV,WAAOC,wBAAA,MAAI,+BAAA,GAAA;EACb;EAEA,aAAU;AACR,WAAOA,wBAAA,MAAI,qCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,kCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,yCAAA,GAAA;EACb;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,WAAQ;AACZ,UAAM,KAAK,KAAI;AACf,QAAI,CAACA,wBAAA,MAAI,2BAAA,GAAA;AAAY,YAAM,MAAM,6BAA6B;AAE9D,WAAOA,wBAAA,MAAI,2BAAA,GAAA;EACb;EAEU,MAAM,6BACd,QACA,QACAD,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,OAAO,aAAa,MAAM,EAAE,GAAGA,UAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE7F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEU,MAAM,uBACd,KACA,UACA,QACAD,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,IAAI,OAAO,UAAU,MAAM,EAAE,GAAGA,UAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE9F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAgTA,OAAO,gBAAgB,KAA0B,OAA0B;AACzE,eAAW,CAAC,KAAK,UAAU,KAAK,OAAO,QAAQ,KAAK,GAAG;AACrD,UAAI,CAAC,IAAI,eAAe,GAAG,GAAG;AAC5B,YAAI,GAAG,IAAI;AACX;;AAGF,UAAI,WAAW,IAAI,GAAG;AACtB,UAAI,aAAa,QAAQ,aAAa,QAAW;AAC/C,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,QAAQ,WAAW,QAAQ,QAAQ;AACrC,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AAClE,oBAAY;iBACH,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AACzE,oBAAY;iBACE,MAAM,QAAQ,KAAU,MAAM,UAAU,GAAG;AACzD,mBAAW,KAAK,gBAAgB,UAAiC,UAAiC;iBACzF,MAAM,QAAQ,QAAQ,KAAK,MAAM,QAAQ,UAAU,GAAG;AAC/D,YAAI,SAAS,MAAM,CAAC,MAAM,OAAO,MAAM,YAAY,OAAO,MAAM,QAAQ,GAAG;AACzE,mBAAS,KAAK,GAAG,UAAU;AAC3B;;AAGF,mBAAW,cAAc,YAAY;AACnC,cAAI,CAAM,MAAM,UAAU,GAAG;AAC3B,kBAAM,IAAI,MAAM,uDAAuD,UAAU,EAAE;;AAGrF,gBAAM,QAAQ,WAAW,OAAO;AAChC,cAAI,SAAS,MAAM;AACjB,oBAAQ,MAAM,UAAU;AACxB,kBAAM,IAAI,MAAM,wDAAwD;;AAG1E,cAAI,OAAO,UAAU,UAAU;AAC7B,kBAAM,IAAI,MAAM,wEAAwE,KAAK,EAAE;;AAGjG,gBAAM,WAAW,SAAS,KAAK;AAC/B,cAAI,YAAY,MAAM;AACpB,qBAAS,KAAK,UAAU;iBACnB;AACL,qBAAS,KAAK,IAAI,KAAK,gBAAgB,UAAU,UAAU;;;AAG/D;aACK;AACL,cAAM,MAAM,0BAA0B,GAAG,iBAAiB,UAAU,eAAe,QAAQ,EAAE;;AAE/F,UAAI,GAAG,IAAI;;AAGb,WAAO;EACT;EA2BU,QAAQ,KAAQ;AACxB,WAAO;EACT;EAEU,MAAM,uBACd,QACA,QACAD,UAA6B;AAE7B,WAAO,MAAM,KAAK,6BAA6B,QAAQ,QAAQA,QAAO;EACxE;EAEU,MAAM,oBACd,UACA,MACA,QACAA,UAA6B;AAE7B,WAAO,MAAM,KAAK,uBAAuB,MAAM,UAAU,QAAQA,QAAO;EAC1E;EAEU,MAAM,wBACd,UACA,OACA,MACA,QACAA,UAA6B;AAE7B,WAAO,MAAM,KAAK,2BAA2B,MAAM,UAAU,OAAO,QAAQA,QAAO;EACrF;;uFApaU,OAA2B;AACnC,MAAI,KAAK;AAAO;AAEhB,EAAAE,wBAAA,MAAI,+BAAiB,OAAK,GAAA;AAE1B,EAAAD,wBAAA,MAAI,4BAAA,KAAA,4BAAA,EAAa,KAAjB,MAAkB,KAAK;AAEvB,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,0BAAA,EAAW,KAAf,MAAgB,KAAK;AACrB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;AAEH,YAAM,IAAI,MACR,qFAAqF;IAEzF;AACE,MAAAE,aAAY,KAAK;;AAEvB,iCAAC,8BAAA,gCAAAC,+BAAA;AAGC,MAAI,KAAK,OAAO;AACd,UAAM,IAAI,YAAY,yCAAyC;;AAGjE,MAAI,CAACH,wBAAA,MAAI,2BAAA,GAAA;AAAY,UAAM,MAAM,iCAAiC;AAElE,SAAOA,wBAAA,MAAI,2BAAA,GAAA;AACb,GAVC,gCAUA,iCAAA,gCAAAI,gCAEqC,OAAyB;AAC7D,QAAM,CAAC,oBAAoB,UAAU,IAAIJ,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,OAAOA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC7F,EAAAC,wBAAA,MAAI,kCAAoB,oBAAkB,GAAA;AAC1C,EAAAD,wBAAA,MAAI,mCAAA,GAAA,EAAmB,mBAAmB,EAAE,IAAI;AAEhD,aAAW,WAAW,YAAY;AAChC,UAAM,kBAAkB,mBAAmB,QAAQ,QAAQ,KAAK;AAChE,QAAI,iBAAiB,QAAQ,QAAQ;AACnC,WAAK,MAAM,eAAe,gBAAgB,IAAI;;;AAIlD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IAEF,KAAK;AACH;IAEF,KAAK;AACH,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAE/D,UAAI,MAAM,KAAK,MAAM,SAAS;AAC5B,mBAAW,WAAW,MAAM,KAAK,MAAM,SAAS;AAE9C,cAAI,QAAQ,QAAQ,UAAU,QAAQ,MAAM;AAC1C,gBAAI,YAAY,QAAQ;AACxB,gBAAI,WAAW,mBAAmB,QAAQ,QAAQ,KAAK;AACvD,gBAAI,YAAY,SAAS,QAAQ,QAAQ;AACvC,mBAAK,MAAM,aAAa,WAAW,SAAS,IAAI;mBAC3C;AACL,oBAAM,MAAM,qEAAqE;;;AAIrF,cAAI,QAAQ,SAASA,wBAAA,MAAI,sCAAA,GAAA,GAAuB;AAE9C,gBAAIA,wBAAA,MAAI,iCAAA,GAAA,GAAkB;AACxB,sBAAQA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAM;gBACjC,KAAK;AACH,uBAAK,MAAM,YAAYA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACvE;gBACF,KAAK;AACH,uBAAK,MAAM,iBAAiBA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAClF;;;AAIN,YAAAC,wBAAA,MAAI,sCAAwB,QAAQ,OAAK,GAAA;;AAG3C,UAAAA,wBAAA,MAAI,iCAAmB,mBAAmB,QAAQ,QAAQ,KAAK,GAAC,GAAA;;;AAIpE;IAEF,KAAK;IACL,KAAK;AAEH,UAAID,wBAAA,MAAI,sCAAA,GAAA,MAA0B,QAAW;AAC3C,cAAM,iBAAiB,MAAM,KAAK,QAAQA,wBAAA,MAAI,sCAAA,GAAA,CAAqB;AACnE,YAAI,gBAAgB;AAClB,kBAAQ,eAAe,MAAM;YAC3B,KAAK;AACH,mBAAK,MAAM,iBAAiB,eAAe,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC5E;YACF,KAAK;AACH,mBAAK,MAAM,YAAY,eAAe,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACjE;;;;AAKR,UAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,eAAe,MAAM,IAAI;;AAGtC,MAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEvC,GAnFC,mCAmFA,iCAAA,gCAAAI,gCAEqC,OAAyB;AAC7D,QAAM,qBAAqBL,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,KAAK;AACxD,EAAAC,wBAAA,MAAI,yCAA2B,oBAAkB,GAAA;AAEjD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IACF,KAAK;AACH,YAAM,QAAQ,MAAM,KAAK;AACzB,UACE,MAAM,gBACN,MAAM,aAAa,QAAQ,gBAC3B,MAAM,aAAa,cACnB,mBAAmB,aAAa,QAAQ,cACxC;AACA,mBAAW,YAAY,MAAM,aAAa,YAAY;AACpD,cAAI,SAAS,SAASD,wBAAA,MAAI,uCAAA,GAAA,GAAwB;AAChD,iBAAK,MACH,iBACA,UACA,mBAAmB,aAAa,WAAW,SAAS,KAAK,CAAa;iBAEnE;AACL,gBAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,mBAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;AAGlD,YAAAC,wBAAA,MAAI,uCAAyB,SAAS,OAAK,GAAA;AAC3C,YAAAA,wBAAA,MAAI,kCAAoB,mBAAmB,aAAa,WAAW,SAAS,KAAK,GAAC,GAAA;AAClF,gBAAID,wBAAA,MAAI,kCAAA,GAAA;AAAmB,mBAAK,MAAM,mBAAmBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;;;AAKpF,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAC/D;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAC,wBAAA,MAAI,yCAA2B,QAAS,GAAA;AACxC,YAAM,UAAU,MAAM,KAAK;AAC3B,UAAI,QAAQ,QAAQ,cAAc;AAChC,YAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,eAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAA6B;AAC5D,UAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;;AAGrC,WAAK,MAAM,eAAe,MAAM,MAAM,kBAAkB;AACxD;IACF,KAAK;AACH;;AAEN,GAxDC,mCAwDA,+BAAA,gCAAAK,8BAEmC,OAA2B;AAC7D,EAAAN,wBAAA,MAAI,yBAAA,GAAA,EAAS,KAAK,KAAK;AACvB,OAAK,MAAM,SAAS,KAAK;AAC3B,GALC,iCAKA,qCAAA,gCAAAO,oCAEkB,OAAyB;AAC1C,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,MAAAP,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C,aAAO,MAAM;IAEf,KAAK;AACH,UAAI,WAAWA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACnD,UAAI,CAAC,UAAU;AACb,cAAM,MAAM,uDAAuD;;AAGrE,UAAI,OAAO,MAAM;AAEjB,UAAI,KAAK,OAAO;AACd,cAAM,cAAc,gBAAgB,gBAAgB,UAAU,KAAK,KAAK;AACxE,QAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI;;AAG1C,aAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;IAE7C,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C;;AAGJ,MAAIA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AAAG,WAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACtF,QAAM,IAAI,MAAM,uBAAuB;AACzC,GAlCC,uCAkCA,qCAAA,gCAAAQ,oCAGC,OACA,UAA6B;AAE7B,MAAI,aAAoC,CAAA;AAExC,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH,aAAO,CAAC,MAAM,MAAM,UAAU;IAEhC,KAAK;AACH,UAAI,CAAC,UAAU;AACb,cAAM,MACJ,wFAAwF;;AAI5F,UAAI,OAAO,MAAM;AAGjB,UAAI,KAAK,MAAM,SAAS;AACtB,mBAAW,kBAAkB,KAAK,MAAM,SAAS;AAC/C,cAAI,eAAe,SAAS,SAAS,SAAS;AAC5C,gBAAI,iBAAiB,SAAS,QAAQ,eAAe,KAAK;AAC1D,qBAAS,QAAQ,eAAe,KAAK,IAAIR,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MACvC,gBACA,cAAc;iBAEX;AACL,qBAAS,QAAQ,eAAe,KAAK,IAAI;AAEzC,uBAAW,KAAK,cAAc;;;;AAKpC,aAAO,CAAC,UAAU,UAAU;IAE9B,KAAK;IACL,KAAK;IACL,KAAK;AAEH,UAAI,UAAU;AACZ,eAAO,CAAC,UAAU,UAAU;aACvB;AACL,cAAM,MAAM,yDAAyD;;;AAG3E,QAAM,MAAM,yCAAyC;AACvD,GApDC,uCAoDA,qCAAA,gCAAAS,oCAGC,gBACA,gBAA0C;AAE1C,SAAO,gBAAgB,gBAAgB,gBAA+C,cAAc;AAGtG,GATC,uCASA,6BAAA,gCAAAC,4BAkEiC,OAAqB;AACrD,EAAAT,wBAAA,MAAI,qCAAuB,MAAM,MAAI,GAAA;AACrC,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,2BAAa,MAAM,MAAI,GAAA;AAC3B,UAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAChD,QAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEnC;IACF,KAAK;AACH;;AAEN,GAzFC;AA2HH,SAASC,aAAY,IAAS;AAAG;AAAxB,OAAAA,cAAA;;;ACjwBH,IAAOS,YAAP,cAAwB,YAAW;EATzC,OASyC;;;;;;EAIvC,OACE,UACA,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa;MACxD;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,WAAmBA,UAA6B;AACzE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,aAAa,SAAS,IAAI;MACpE,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,WACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,SAAS,IAAI;MACrE;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAAiD,CAAA,GACjDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,aAAa,cAAc;MAC5E;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,WAAmBA,UAA6B;AACpE,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,aAAa,SAAS,IAAI;MACvE,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;EAtFrD,OAsFqD;;;;AAooBrDD,UAAS,eAAe;;;ACjtBlB,IAAO,QAAP,cAAqB,YAAW;EATtC,OASsC;;;EAiBpC,SACE,UACA,OACA,QACA,QAAkD,CAAA,GAClDE,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,SAAS,UAAU,OAAO,QAAQ,CAAA,GAAI,KAAK;;AAEzD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,UAAU,MAAM,IAAI;MAC5E;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAgBA,KACE,UACA,OACA,QAA8C,CAAA,GAC9CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,OAAO,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,KAAK,UAAU,cAAc;MACvF;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;EA1ErD,OA0EqD;;;;AA6pBrD,MAAM,eAAe;;;AC7rBf,IAAO,OAAP,cAAoB,YAAW;EA1CrC,OA0CqC;;;EAArC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EA+PzD;EA3OE,OACE,UACA,QACAC,UAA6B;AAE7B,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS;MACpD,OAAO,EAAE,QAAO;MAChB;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;MAC9D,QAAQ,OAAO,UAAU;KAC1B;EACH;;;;EAKA,SAAS,UAAkB,OAAeA,UAA6B;AACrE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC5D,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,OACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC7D;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAA6C,CAAA,GAC7CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,UAAU;MACpE;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,OAAeA,UAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,WAAW;MACpE,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;;;EAOA,MAAM,cACJ,UACA,MACAA,UAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,OAAO,UAAU,MAAMA,QAAO;AACrD,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAIA,QAAO;EAClD;;;;;;EAOA,gBACE,UACA,MACAA,UAA6B;AAE7B,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAMA,QAAO;EACtG;;;;;;EAOA,MAAM,KACJ,UACA,OACAA,UAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAGA,UAAS,SAAS,2BAA2B,OAAM;AAEnG,QAAIA,UAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAIA,SAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,KAAK,SAAQ,IAAK,MAAM,KAAK,SAAS,UAAU,OAAO;QACnE,GAAGA;QACH,SAAS,EAAE,GAAGA,UAAS,SAAS,GAAG,QAAO;OAC3C,EAAE,aAAY;AAEf,cAAQ,IAAI,QAAQ;;QAElB,KAAK;QACL,KAAK;QACL,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAIA,UAAS,gBAAgB;AAC3B,4BAAgBA,SAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;EAKA,OAAO,UAAkB,MAAiCA,UAA6B;AACrF,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAMA,QAAO;EACtG;EA0BA,kBACE,UACA,OACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,wBAAwB;MACjF;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,yBACJ,UACA,OACA,MACAA,UAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,kBAAkB,UAAU,OAAO,MAAMA,QAAO;AACvE,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAIA,QAAO;EAClD;;;;;;EAOA,wBACE,UACA,OACA,MACAA,UAA6B;AAE7B,WAAO,gBAAgB,0BACrB,UACA,OACA,KAAK,QAAQ,KAAK,QAAQ,MAC1B,MACAA,QAAO;EAEX;;AAGI,IAAO,WAAP,cAAwB,WAAe;EA5S7C,OA4S6C;;;;AAm1C7C,KAAK,WAAW;AAChB,KAAK,QAAQ;AACb,KAAK,eAAe;;;AC5jDd,IAAO,UAAP,cAAuB,YAAW;EArExC,OAqEwC;;;EAAxC,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;AAClD,SAAA,WAAiC,IAAgBC,UAAS,KAAK,OAAO;EAqGxE;EA9FE,OACE,OAAiD,CAAA,GACjDC,UAA6B;AAE7B,QAAI,iBAAiB,IAAI,GAAG;AAC1B,aAAO,KAAK,OAAO,CAAA,GAAI,IAAI;;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY;MACnC;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkBA,UAA6B;AACtD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,IAAI;MAC9C,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,MAA0BA,UAA6B;AAC9E,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,IAAI;MAC/C;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkBA,UAA6B;AACjD,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,IAAI;MACjD,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAiBA,aACE,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,iBAAiB;MACxC;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,iBACJ,MACAA,UAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,aAAa,MAAMA,QAAO;AACjD,WAAO,MAAM,KAAK,KAAK,KAAK,IAAI,WAAW,IAAI,IAAIA,QAAO;EAC5D;;;;EAKA,mBACE,MACAA,UAA6B;AAE7B,WAAO,gBAAgB,4BAA4B,MAAM,KAAK,QAAQ,KAAK,SAASA,QAAO;EAC7F;;AA+7CF,QAAQ,OAAO;AACf,QAAQ,WAAW;AACnB,QAAQ,WAAWD;AACnB,QAAQ,eAAe;;;ACjkDjB,IAAO,OAAP,cAAoB,YAAW;EA5CrC,OA4CqC;;;EAArC,cAAA;;AACE,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;AACtE,SAAA,OAAqB,IAAYE,MAAK,KAAK,OAAO;AAClD,SAAA,aAAuC,IAAkB,WAAW,KAAK,OAAO;AAChF,SAAA,UAA8B,IAAe,QAAQ,KAAK,OAAO;EACnE;;AAEA,KAAK,WAAW;AAChB,KAAK,aAAa;AAClB,KAAK,iBAAiB;AACtB,KAAK,UAAU;;;AC7CT,IAAOC,eAAP,cAA2B,YAAW;EAT5C,OAS4C;;;EAa1C,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAGA,UAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAG7F;;;;ACxBI,IAAO,aAAP,cAA0B,YAAW;EAL3C,OAK2C;;;;;;EAIzC,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,EAAE,MAAM,GAAGA,SAAO,CAAE;EAC9D;;;;ACJI,IAAO,QAAP,cAAqB,YAAW;EAVtC,OAUsC;;;;;;;;;;;;;;;;;;;;;;;;;;EAwBpC,OAAO,MAAwBC,UAA6B;AAC1D,WAAO,KAAK,QAAQ,KAAK,UAAe,4BAA4B,EAAE,MAAM,GAAGA,SAAO,CAAE,CAAC;EAC3F;;;;EAKA,SAAS,QAAgBA,UAA6B;AACpD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,IAAIA,QAAO;EACrD;EAOA,KACE,QAA8C,CAAA,GAC9CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,UAAU,iBAAiB,EAAE,OAAO,GAAGA,SAAO,CAAE;EACjF;;;;EAKA,IAAI,QAAgBA,UAA6B;AAC/C,WAAO,KAAK,QAAQ,OAAO,UAAU,MAAM,IAAIA,QAAO;EACxD;;;;EAKA,QAAQ,QAAgBA,UAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY;MAClD,GAAGA;MACH,SAAS,EAAE,QAAQ,sBAAsB,GAAGA,UAAS,QAAO;MAC5D,kBAAkB;KACnB;EACH;;;;;;EAOA,gBAAgB,QAAgBA,UAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAYA,QAAO;EAC7D;;;;EAKA,MAAM,kBACJ,IACA,EAAE,eAAe,KAAM,UAAU,KAAK,KAAK,IAAI,IAAkD,CAAA,GAAE;AAEnG,UAAM,kBAAkB,oBAAI,IAAI,CAAC,aAAa,SAAS,SAAS,CAAC;AAEjE,UAAM,QAAQ,KAAK,IAAG;AACtB,QAAI,OAAO,MAAM,KAAK,SAAS,EAAE;AAEjC,WAAO,CAAC,KAAK,UAAU,CAAC,gBAAgB,IAAI,KAAK,MAAM,GAAG;AACxD,YAAM,MAAM,YAAY;AAExB,aAAO,MAAM,KAAK,SAAS,EAAE;AAC7B,UAAI,KAAK,IAAG,IAAK,QAAQ,SAAS;AAChC,cAAM,IAAI,0BAA0B;UAClC,SAAS,iCAAiC,EAAE,+BAA+B,OAAO;SACnF;;;AAIL,WAAO;EACT;;AAGI,IAAO,kBAAP,cAA+B,WAAsB;EAlH3D,OAkH2D;;;;AA6G3D,MAAM,kBAAkB;;;ACxNlB,IAAO,cAAP,cAA2B,YAAW;EAP5C,OAO4C;;;EAa1C,KACE,iBACA,QAAoD,CAAA,GACpDC,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,iBAAiB,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAClB,qBAAqB,eAAe,gBACpC,8BACA,EAAE,OAAO,GAAGA,SAAO,CAAE;EAEzB;;AAGI,IAAO,+BAAP,cAA4C,WAAmC;EApCrF,OAoCqF;;;;AAkErF,YAAY,+BAA+B;;;ACxFrC,IAAO,OAAP,cAAoB,YAAW;EAdrC,OAcqC;;;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EA0EvF;;;;;;;;;;EA/DE,OAAO,MAAuBC,UAA6B;AACzD,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAGA,SAAO,CAAE;EACpE;;;;;;EAOA,SAAS,iBAAyBA,UAA6B;AAC7D,WAAO,KAAK,QAAQ,IAAI,qBAAqB,eAAe,IAAIA,QAAO;EACzE;EAUA,KACE,QAA6C,CAAA,GAC7CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,qBAAqB,oBAAoB,EAAE,OAAO,GAAGA,SAAO,CAAE;EAC/F;;;;EAKA,OAAO,iBAAyBA,UAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,qBAAqB,eAAe,WAAWA,QAAO;EACjF;EAcA,WACE,iBACA,QAAmD,CAAA,GACnDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,WAAW,iBAAiB,CAAA,GAAI,KAAK;;AAEnD,WAAO,KAAK,QAAQ,WAAW,qBAAqB,eAAe,WAAW,yBAAyB;MACrG;MACA,GAAGA;KACJ;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;EA3FjE,OA2FiE;;;;AAE3D,IAAO,0BAAP,cAAuC,WAA8B;EA7F3E,OA6F2E;;;;AA2lB3E,KAAK,qBAAqB;AAC1B,KAAK,0BAA0B;AAC/B,KAAK,cAAc;AACnB,KAAK,+BAA+B;;;ACzqB9B,IAAO,aAAP,cAA0B,YAAW;EAlB3C,OAkB2C;;;EAA3C,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;EACpD;;AAEA,WAAW,OAAO;AAClB,WAAW,qBAAqB;AAChC,WAAW,0BAA0B;;;ACnB/B,IAAO,SAAP,cAAsB,YAAW;EALvC,OAKuC;;;;;;EAIrC,gBACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,sBAA2B,4BAA4B,EAAE,MAAM,GAAGA,SAAO,CAAE,CAAC;EACvG;;;;EAKA,KAAK,MAAuBA,UAA6B;AACvD,WAAO,KAAK,QAAQ,KAAK,iBAAsB,4BAA4B,EAAE,MAAM,GAAGA,SAAO,CAAE,CAAC;EAClG;;;;EAKA,SAAS,MAA2BA,UAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,uBAAuB,EAAE,MAAM,GAAGA,SAAO,CAAE;EACtE;;;;ACtBI,IAAO,SAAP,cAAsB,YAAW;EANvC,OAMuC;;;;;;;EAKrC,SAAS,OAAeC,UAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,WAAW,KAAK,IAAIA,QAAO;EACrD;;;;;EAMA,KAAKA,UAA6B;AAChC,WAAO,KAAK,QAAQ,WAAW,WAAW,YAAYA,QAAO;EAC/D;;;;;EAMA,IAAI,OAAeA,UAA6B;AAC9C,WAAO,KAAK,QAAQ,OAAO,WAAW,KAAK,IAAIA,QAAO;EACxD;;AAMI,IAAO,aAAP,cAA0B,KAAW;EAnC3C,OAmC2C;;;;AAmC3C,OAAO,aAAa;;;ACjEd,IAAO,cAAP,cAA2B,YAAW;EAL5C,OAK4C;;;;;;;EAK1C,OACE,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAGA,SAAO,CAAE;EAC/D;;;;ACUI,SAAU,mBAGd,UAAoB,QAAc;AAClC,MAAI,CAAC,UAAU,CAACC,uBAAsB,MAAM,GAAG;AAC7C,WAAO;MACL,GAAG;MACH,eAAe;MACf,QAAQ,SAAS,OAAO,IAAI,CAAC,SAAQ;AACnC,YAAI,KAAK,SAAS,iBAAiB;AACjC,iBAAO;YACL,GAAG;YACH,kBAAkB;;;AAItB,YAAI,KAAK,SAAS,WAAW;AAC3B,iBAAO;YACL,GAAG;YACH,SAAS,KAAK,QAAQ,IAAI,CAAC,aAAa;cACtC,GAAG;cACH,QAAQ;cACR;;eAEC;AACL,iBAAO;;MAEX,CAAC;;;AAIL,SAAO,cAAc,UAAU,MAAM;AACvC;AAhCgB;AAkCV,SAAU,cAGd,UAAoB,QAAc;AAClC,QAAM,SAAmD,SAAS,OAAO,IACvE,CAAC,SAA2C;AAC1C,QAAI,KAAK,SAAS,iBAAiB;AACjC,aAAO;QACL,GAAG;QACH,kBAAkBC,eAAc,QAAQ,IAAI;;;AAGhD,QAAI,KAAK,SAAS,WAAW;AAC3B,YAAM,UAAyC,KAAK,QAAQ,IAAI,CAACC,aAAW;AAC1E,YAAIA,SAAQ,SAAS,eAAe;AAClC,iBAAO;YACL,GAAGA;YACH,QAAQ,gBAAgB,QAAQA,SAAQ,IAAI;;;AAIhD,eAAOA;MACT,CAAC;AAED,aAAO;QACL,GAAG;QACH;;;AAIJ,WAAO;EACT,CAAC;AAGH,QAAM,SAAyD,OAAO,OAAO,CAAA,GAAI,UAAU,EAAE,OAAM,CAAE;AACrG,MAAI,CAAC,OAAO,yBAAyB,UAAU,aAAa,GAAG;AAC7D,kBAAc,MAAM;;AAGtB,SAAO,eAAe,QAAQ,iBAAiB;IAC7C,YAAY;IACZ,MAAG;AACD,iBAAWC,WAAU,OAAO,QAAQ;AAClC,YAAIA,QAAO,SAAS,WAAW;AAC7B;;AAGF,mBAAW,WAAWA,QAAO,SAAS;AACpC,cAAI,QAAQ,SAAS,iBAAiB,QAAQ,WAAW,MAAM;AAC7D,mBAAO,QAAQ;;;;AAKrB,aAAO;IACT;GACD;AAED,SAAO;AACT;AA3DgB;AA6DhB,SAAS,gBAGP,QAAgB,SAAe;AAC/B,MAAI,OAAO,MAAM,QAAQ,SAAS,eAAe;AAC/C,WAAO;;AAGT,MAAI,eAAe,OAAO,MAAM,QAAQ;AACtC,UAAM,cAAc,OAAO,MAAM;AACjC,WAAO,YAAY,UAAU,OAAO;;AAGtC,SAAO,KAAK,MAAM,OAAO;AAC3B;AAdS;AAgBH,SAAUH,uBAAsB,QAAqC;AACzE,MAAI,6BAA6B,OAAO,MAAM,MAAM,GAAG;AACrD,WAAO;;AAGT,SAAO;AACT;AANgB,OAAAA,wBAAA;AAwDV,SAAUI,oBAAmB,MAAS;AAC1C,SAAO,OAAO,QAAQ,MAAM;AAC9B;AAFgB,OAAAA,qBAAA;AAIhB,SAAS,mBAAmB,aAA0B,MAAY;AAChE,SAAO,YAAY,KAAK,CAAC,SAAS,KAAK,SAAS,cAAc,KAAK,SAAS,IAAI;AAGlF;AAJS;AAMT,SAASC,eACP,QACA,UAAkC;AAElC,QAAM,YAAY,mBAAmB,OAAO,SAAS,CAAA,GAAI,SAAS,IAAI;AAEtE,SAAO;IACL,GAAG;IACH,GAAG;IACH,kBACED,oBAAmB,SAAS,IAAI,UAAU,UAAU,SAAS,SAAS,IACpE,WAAW,SAAS,KAAK,MAAM,SAAS,SAAS,IACjD;;AAER;AAdS,OAAAC,gBAAA;AA4CH,SAAU,cAAc,KAAa;AACzC,QAAM,QAAkB,CAAA;AACxB,aAAW,UAAU,IAAI,QAAQ;AAC/B,QAAI,OAAO,SAAS,WAAW;AAC7B;;AAGF,eAAW,WAAW,OAAO,SAAS;AACpC,UAAI,QAAQ,SAAS,eAAe;AAClC,cAAM,KAAK,QAAQ,IAAI;;;;AAK7B,MAAI,cAAc,MAAM,KAAK,EAAE;AACjC;AAfgB;;;AC9OV,IAAO,aAAP,cAA0B,YAAW;EAR3C,OAQ2C;;;EAiCzC,KACE,YACA,QAAmD,CAAA,GACnDC,UAA6B;AAY7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,YAAY,CAAA,GAAI,KAAK;;AAExC,WAAO,KAAK,QAAQ,WAAW,cAAc,UAAU,gBAAgB,0BAA0B;MAC/F;MACA,GAAGA;KACJ;EACH;;AAGI,IAAO,2BAAP,cAAwC,WAS7C;EA3ED,OA2EC;;;;AAgMD,WAAW,2BAA2B;;;;;;;;;;;;;;;;;;;;;;ACzOhC,IAAO,iBAAP,MAAO,wBACH,YAA2B;SAAA;;;EAOnC,YAAY,QAAsC;AAChD,UAAK;;AALP,2BAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;AACA,kCAAA,IAAA,MAAA,MAAA;AAIE,IAAAC,wBAAA,MAAI,wBAAW,QAAM,GAAA;EACvB;EAEA,OAAO,eACL,QACA,QACAC,UAA6B;AAE7B,UAAM,SAAS,IAAI,gBAAwB,MAAuC;AAClF,WAAO,KAAK,MACV,OAAO,gBAAgB,QAAQ,QAAQ;MACrC,GAAGA;MACH,SAAS,EAAE,GAAGA,UAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAsEU,MAAM,gBACd,QACA,QACAA,UAA6B;AAE7B,UAAM,SAASA,UAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAC,wBAAA,MAAI,2BAAA,KAAA,4BAAA,EAAc,KAAlB,IAAI;AAEJ,UAAM,SAAS,MAAM,OAAO,UAAU,OACpC,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAGD,UAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,2BAAA,KAAA,wBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAOA,wBAAA,MAAI,2BAAA,KAAA,0BAAA,EAAY,KAAhB,IAAI;EACb;EAiEA,EAAA,yBAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,gCAAA,oBAAA,QAAA,GAAA,4BAAA,oBAAA,QAAA,GAAA,+BAAA,gCAAAC,gCAAA;AA5JE,QAAI,KAAK;AAAO;AAChB,IAAAH,wBAAA,MAAI,yCAA4B,QAAS,GAAA;EAC3C,GA0JA,iCA1JC,2BAAA,gCAAAI,0BAEwC,OAA0B;AACjE,QAAI,KAAK;AAAO;AAEhB,UAAM,WAAWF,wBAAA,MAAI,2BAAA,KAAA,kCAAA,EAAoB,KAAxB,MAAyB,KAAK;AAC/C,SAAK,MAAM,SAAS,KAAK;AAEzB,YAAQ,MAAM,MAAM;MAClB,KAAK,8BAA8B;AACjC,cAAM,SAAS,SAAS,OAAO,MAAM,YAAY;AACjD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,YAAY,2BAA2B,MAAM,YAAY,EAAE;;AAEvE,YAAI,OAAO,SAAS,WAAW;AAC7B,gBAAM,UAAU,OAAO,QAAQ,MAAM,aAAa;AAClD,cAAI,CAAC,SAAS;AACZ,kBAAM,IAAI,YAAY,4BAA4B,MAAM,aAAa,EAAE;;AAEzE,cAAI,QAAQ,SAAS,eAAe;AAClC,kBAAM,IAAI,YAAY,6CAA6C,QAAQ,IAAI,EAAE;;AAGnF,eAAK,MAAM,8BAA8B;YACvC,GAAG;YACH,UAAU,QAAQ;WACnB;;AAEH;;MAEF,KAAK,0CAA0C;AAC7C,cAAM,SAAS,SAAS,OAAO,MAAM,YAAY;AACjD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,YAAY,2BAA2B,MAAM,YAAY,EAAE;;AAEvE,YAAI,OAAO,SAAS,iBAAiB;AACnC,eAAK,MAAM,0CAA0C;YACnD,GAAG;YACH,UAAU,OAAO;WAClB;;AAEH;;MAEF;AAEE,aAAK,MAAM,MAAM,MAAM,KAAK;AAC5B;;EAEN,GAhDC,6BAgDA,6BAAA,gCAAAG,8BAAA;AAGC,QAAI,KAAK,OAAO;AACd,YAAM,IAAI,YAAY,yCAAyC;;AAEjE,UAAM,WAAWH,wBAAA,MAAI,yCAAA,GAAA;AACrB,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YAAY,0CAA0C;;AAElE,IAAAF,wBAAA,MAAI,yCAA4B,QAAS,GAAA;AACzC,UAAM,iBAAiB,iBAA0B,UAAUE,wBAAA,MAAI,wBAAA,GAAA,CAAQ;AACvE,IAAAF,wBAAA,MAAI,+BAAkB,gBAAc,GAAA;AAEpC,WAAO;EACT,GAfC,+BAeA,qCAAA,gCAAAM,oCA4BmB,OAA0B;AAC5C,QAAI,WAAWJ,wBAAA,MAAI,yCAAA,GAAA;AACnB,QAAI,CAAC,UAAU;AACb,UAAI,MAAM,SAAS,oBAAoB;AACrC,cAAM,IAAI,YACR,6EAA6E,MAAM,IAAI,EAAE;;AAG7F,iBAAWF,wBAAA,MAAI,yCAA4B,MAAM,UAAQ,GAAA;AACzD,aAAO;;AAGT,YAAQ,MAAM,MAAM;MAClB,KAAK,8BAA8B;AACjC,iBAAS,OAAO,KAAK,MAAM,IAAI;AAC/B;;MAEF,KAAK,+BAA+B;AAClC,cAAM,SAAS,SAAS,OAAO,MAAM,YAAY;AACjD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,YAAY,2BAA2B,MAAM,YAAY,EAAE;;AAEvE,YAAI,OAAO,SAAS,WAAW;AAC7B,iBAAO,QAAQ,KAAK,MAAM,IAAI;;AAEhC;;MAEF,KAAK,8BAA8B;AACjC,cAAM,SAAS,SAAS,OAAO,MAAM,YAAY;AACjD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,YAAY,2BAA2B,MAAM,YAAY,EAAE;;AAEvE,YAAI,OAAO,SAAS,WAAW;AAC7B,gBAAM,UAAU,OAAO,QAAQ,MAAM,aAAa;AAClD,cAAI,CAAC,SAAS;AACZ,kBAAM,IAAI,YAAY,4BAA4B,MAAM,aAAa,EAAE;;AAEzE,cAAI,QAAQ,SAAS,eAAe;AAClC,kBAAM,IAAI,YAAY,6CAA6C,QAAQ,IAAI,EAAE;;AAEnF,kBAAQ,QAAQ,MAAM;;AAExB;;MAEF,KAAK,0CAA0C;AAC7C,cAAM,SAAS,SAAS,OAAO,MAAM,YAAY;AACjD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,YAAY,2BAA2B,MAAM,YAAY,EAAE;;AAEvE,YAAI,OAAO,SAAS,iBAAiB;AACnC,iBAAO,aAAa,MAAM;;AAE5B;;MAEF,KAAK,sBAAsB;AACzB,QAAAA,wBAAA,MAAI,yCAA4B,MAAM,UAAQ,GAAA;AAC9C;;;AAIJ,WAAO;EACT,GAzFC,uCA2FA,OAAO,cAAa,IAAC;AACpB,UAAM,YAAmC,CAAA;AACzC,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAEX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,mCAAyD;AAC7D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAAyC,CAAC,SAAS,WAC5D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACO,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC,GAXM;MAYN,QAAQ,mCAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC,GAHQ;;EAKZ;;;;;EAMA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AACf,UAAM,WAAWL,wBAAA,MAAI,+BAAA,GAAA;AACrB,QAAI,CAAC;AAAU,YAAM,IAAI,YAAY,iDAAiD;AACtF,WAAO;EACT;;AAGF,SAAS,iBACP,UACA,QAAsC;AAEtC,SAAO,mBAAmB,UAAU,MAAM;AAC5C;AALS;;;ACrPH,IAAO,YAAP,cAAyB,YAAW;EA/C1C,OA+C0C;;;EAA1C,cAAA;;AACE,SAAA,aAAuC,IAAkB,WAAW,KAAK,OAAO;EAyFlF;EAjEE,OACE,MACAM,UAA6B;AAE7B,WACE,KAAK,QAAQ,KAAK,cAAc,EAAE,MAAM,GAAGA,UAAS,QAAQ,KAAK,UAAU,MAAK,CAAE,EAGlF,YAAY,CAAC,QAAO;AACpB,UAAI,YAAY,OAAO,IAAI,WAAW,YAAY;AAChD,sBAAc,GAAe;;AAG/B,aAAO;IACT,CAAC;EACH;EAWA,SACE,YACA,QAAsD,CAAA,GACtDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,SAAS,YAAY,CAAA,GAAI,KAAK;;AAE5C,WAAO,KAAK,QAAQ,IAAI,cAAc,UAAU,IAAI,EAAE,OAAO,GAAGA,SAAO,CAAE;EAC3E;;;;EAKA,IAAI,YAAoBA,UAA6B;AACnD,WAAO,KAAK,QAAQ,OAAO,cAAc,UAAU,IAAI;MACrD,GAAGA;MACH,SAAS,EAAE,QAAQ,OAAO,GAAGA,UAAS,QAAO;KAC9C;EACH;EAEA,MACE,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,UACjB,OAAO,MAAMA,QAAO,EACpB,YAAY,CAAC,aAAa,cAAc,UAAsB,IAAI,CAAC;EACxE;;;;EAKA,OACE,MACAA,UAA6B;AAE7B,WAAO,eAAe,eAAwB,KAAK,SAAS,MAAMA,QAAO;EAC3E;;AA2gFF,UAAU,aAAa;AACvB,UAAU,2BAA2B;;;AC/oF/B,IAAO,QAAP,cAAqB,YAAW;EALtC,OAKsC;;;;;;;;;;;;;;;;EAcpC,OACE,UACA,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAClB,YAAY,QAAQ,UACf,4BAA4B,EAAE,MAAM,GAAGA,SAAO,CAAE,CAAC;EAE1D;;;;ACpBI,IAAO,UAAP,cAAuB,YAAW;EARxC,OAQwC;;;EAAxC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EAwDzD;;;;;;;;;;;;;;;;;;;;;;EAjCE,OAAO,MAA0BC,UAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,YAAY,EAAE,MAAM,GAAGA,SAAO,CAAE;EAC3D;;;;EAKA,OAAO,UAAkBA,UAA6B;AACpD,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,WAAWA,QAAO;EACjE;;;;;;;;;;;;;;;;EAiBA,SACE,UACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,EAAE,MAAM,GAAGA,SAAO,CAAE;EAChF;;AAgGF,QAAQ,QAAQ;;;AC7JT,IAAM,sBAAsB,8BAAU,aAAwC;AACnF,QAAM,UAAU,MAAM,QAAQ,WAAW,QAAQ;AACjD,QAAM,WAAW,QAAQ,OAAO,CAAC,WAA4C,OAAO,WAAW,UAAU;AACzG,MAAI,SAAS,QAAQ;AACnB,eAAW,UAAU,UAAU;AAC7B,cAAQ,MAAM,OAAO,MAAM;;AAG7B,UAAM,IAAI,MAAM,GAAG,SAAS,MAAM,2CAA2C;;AAI/E,QAAM,SAAc,CAAA;AACpB,aAAW,UAAU,SAAS;AAC5B,QAAI,OAAO,WAAW,aAAa;AACjC,aAAO,KAAK,OAAO,KAAK;;;AAG5B,SAAO;AACT,GAnBmC;;;ACK7B,IAAOC,SAAP,cAAqB,YAAW;EARtC,OAQsC;;;;;;;;EAMpC,OACE,eACA,MACAC,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,UAAU;MAChE;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,QACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,UAAU,MAAM,IAAI;MACzE,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,eACA,QACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,UAAU,MAAM,IAAI;MAC1E;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAcA,KACE,eACA,QAA8C,CAAA,GAC9CA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,eAAe,CAAA,GAAI,KAAK;;AAE3C,WAAO,KAAK,QAAQ,WAAW,kBAAkB,aAAa,UAAU,sBAAsB;MAC5F;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;;;;EAQA,IACE,eACA,QACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,UAAU,MAAM,IAAI;MAC5E,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACAA,UAA2D;AAE3D,UAAM,OAAO,MAAM,KAAK,OAAO,eAAe,MAAMA,QAAO;AAC3D,WAAO,MAAM,KAAK,KAAK,eAAe,KAAK,IAAIA,QAAO;EACxD;;;;;;;EAQA,MAAM,KACJ,eACA,QACAA,UAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAGA,UAAS,SAAS,2BAA2B,OAAM;AACnG,QAAIA,UAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAIA,SAAQ,eAAe,SAAQ;;AAE/E,WAAO,MAAM;AACX,YAAM,eAAe,MAAM,KAAK,SAAS,eAAe,QAAQ;QAC9D,GAAGA;QACH;OACD,EAAE,aAAY;AAEf,YAAM,OAAO,aAAa;AAE1B,cAAQ,KAAK,QAAQ;QACnB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAIA,UAAS,gBAAgB;AAC3B,4BAAgBA,SAAQ;iBACnB;AACL,kBAAM,iBAAiB,aAAa,SAAS,QAAQ,IAAI,sBAAsB;AAC/E,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;;EAQA,MAAM,OACJ,eACA,MACAA,UAA6B;AAE7B,UAAM,WAAW,MAAM,KAAK,QAAQ,MAAM,OAAO,EAAE,MAAY,SAAS,aAAY,GAAIA,QAAO;AAC/F,WAAO,KAAK,OAAO,eAAe,EAAE,SAAS,SAAS,GAAE,GAAIA,QAAO;EACrE;;;;EAKA,MAAM,cACJ,eACA,MACAA,UAA2D;AAE3D,UAAM,WAAW,MAAM,KAAK,OAAO,eAAe,MAAMA,QAAO;AAC/D,WAAO,MAAM,KAAK,KAAK,eAAe,SAAS,IAAIA,QAAO;EAC5D;;;;EAKA,QACE,eACA,QACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,WAClB,kBAAkB,aAAa,UAAU,MAAM,YAC/C,0BACA,EAAE,GAAGA,UAAS,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO,EAAE,CAAE;EAEpF;;AAGI,IAAO,uBAAP,cAAoC,WAA2B;EA1MrE,OA0MqE;;;;AAK/D,IAAO,2BAAP,cAAwC,KAAyB;EA/MvE,OA+MuE;;;;AA6JvED,OAAM,uBAAuB;AAC7BA,OAAM,2BAA2B;;;AChW3B,IAAO,cAAP,cAA2B,YAAW;EAb5C,OAa4C;;;;;;EAI1C,OACE,eACA,MACAE,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB;MACvE;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,SACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,iBAAiB,OAAO,IAAI;MACjF,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;;EAMA,OACE,eACA,SACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB,OAAO,WAAW;MACzF,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACAA,UAA2D;AAE3D,UAAM,QAAQ,MAAM,KAAK,OAAO,eAAe,IAAI;AACnD,WAAO,MAAM,KAAK,KAAK,eAAe,MAAM,IAAIA,QAAO;EACzD;EAgBA,UACE,eACA,SACA,QAAwD,CAAA,GACxDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,UAAU,eAAe,SAAS,CAAA,GAAI,KAAK;;AAEzD,WAAO,KAAK,QAAQ,WAClB,kBAAkB,aAAa,iBAAiB,OAAO,UACvD,sBACA,EAAE,OAAO,GAAGA,UAAS,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO,EAAE,CAAE;EAE3F;;;;;;;EAQA,MAAM,KACJ,eACA,SACAA,UAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAGA,UAAS,SAAS,2BAA2B,OAAM;AACnG,QAAIA,UAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAIA,SAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,OAAO,SAAQ,IAAK,MAAM,KAAK,SAAS,eAAe,SAAS;QAC5E,GAAGA;QACH;OACD,EAAE,aAAY;AAEf,cAAQ,MAAM,QAAQ;QACpB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAIA,UAAS,gBAAgB;AAC3B,4BAAgBA,SAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;EAOA,MAAM,cACJ,eACA,EAAE,OAAO,UAAU,CAAA,EAAE,GACrBA,UAAoF;AAEpF,QAAI,SAAS,QAAQ,MAAM,UAAU,GAAG;AACtC,YAAM,IAAI,MACR,gHAAgH;;AAIpH,UAAM,wBAAwBA,UAAS,kBAAkB;AAGzD,UAAM,mBAAmB,KAAK,IAAI,uBAAuB,MAAM,MAAM;AAErE,UAAM,SAAS,KAAK;AACpB,UAAM,eAAe,MAAM,OAAM;AACjC,UAAM,aAAuB,CAAC,GAAG,OAAO;AAIxC,mBAAe,aAAa,UAAsC;AAChE,eAAS,QAAQ,UAAU;AACzB,cAAM,UAAU,MAAM,OAAO,MAAM,OAAO,EAAE,MAAM,MAAM,SAAS,aAAY,GAAIA,QAAO;AACxF,mBAAW,KAAK,QAAQ,EAAE;;IAE9B;AALe;AAQf,UAAM,UAAU,MAAM,gBAAgB,EAAE,KAAK,YAAY,EAAE,IAAI,YAAY;AAG3E,UAAM,oBAAoB,OAAO;AAEjC,WAAO,MAAM,KAAK,cAAc,eAAe;MAC7C,UAAU;KACX;EACH;;;;ACnKI,IAAO,eAAP,cAA4B,YAAW;EA3B7C,OA2B6C;;;EAA7C,cAAA;;AACE,SAAA,QAAwB,IAAaC,OAAM,KAAK,OAAO;AACvD,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EAsFvF;;;;EAjFE,OAAO,MAA+BC,UAA6B;AACjE,WAAO,KAAK,QAAQ,KAAK,kBAAkB;MACzC;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,eAAuBA,UAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,IAAI;MACzD,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,eACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,IAAI;MAC1D;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAqD,CAAA,GACrDA,UAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,kBAAkB,kBAAkB;MACjE;MACA,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,eAAuBA,UAA6B;AACtD,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,IAAI;MAC5D,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;;;;EAMA,OACE,eACA,MACAA,UAA6B;AAE7B,WAAO,KAAK,QAAQ,WAAW,kBAAkB,aAAa,WAAW,gCAAgC;MACvG;MACA,QAAQ;MACR,GAAGA;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAGA,UAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,mBAAP,cAAgC,WAAuB;EArH7D,OAqH6D;;;;AAKvD,IAAO,iCAAP,cAA8C,KAA+B;EA1HnF,OA0HmF;;;;AA+XnF,aAAa,mBAAmB;AAChC,aAAa,iCAAiC;AAC9C,aAAa,QAAQD;AACrB,aAAa,uBAAuB;AACpC,aAAa,2BAA2B;AACxC,aAAa,cAAc;;;;ACvSrB,IAAO,SAAP,cAA2B,UAAS;EAvN1C,OAuN0C;;;;;;;;;;;;;;;;;;EAsBxC,YAAY,EACV,UAAe,QAAQ,iBAAiB,GACxC,SAAc,QAAQ,gBAAgB,GACtC,eAAoB,QAAQ,eAAe,KAAK,MAChD,UAAe,QAAQ,mBAAmB,KAAK,MAC/C,GAAG,KAAI,IACU,CAAA,GAAE;AACnB,QAAI,WAAW,QAAW;AACxB,YAAM,IAAW,YACf,oLAAoL;;AAIxL,UAAME,WAAyB;MAC7B;MACA;MACA;MACA,GAAG;MACH,SAAS,WAAW;;AAGtB,QAAI,CAACA,SAAQ,2BAAgC,mBAAkB,GAAI;AACjE,YAAM,IAAW,YACf,obAAob;;AAIxb,UAAM;MACJ,SAASA,SAAQ;MACjB,SAASA,SAAQ,WAAW;MAC5B,WAAWA,SAAQ;MACnB,YAAYA,SAAQ;MACpB,OAAOA,SAAQ;KAChB;AASH,SAAA,cAA+B,IAAQC,aAAY,IAAI;AACvD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,QAAmB,IAAQ,MAAM,IAAI;AACrC,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,QAAmB,IAAQ,MAAM,IAAI;AACrC,SAAA,cAA+B,IAAQ,YAAY,IAAI;AACvD,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,eAAiC,IAAQ,aAAa,IAAI;AAC1D,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,UAAuB,IAAQ,QAAQ,IAAI;AAC3C,SAAA,UAAuB,IAAQ,QAAQ,IAAI;AAC3C,SAAA,YAA2B,IAAQ,UAAU,IAAI;AApB/C,SAAK,WAAWD;AAEhB,SAAK,SAAS;AACd,SAAK,eAAe;AACpB,SAAK,UAAU;EACjB;EAiBmB,eAAY;AAC7B,WAAO,KAAK,SAAS;EACvB;EAEmB,eAAe,MAA8B;AAC9D,WAAO;MACL,GAAG,MAAM,eAAe,IAAI;MAC5B,uBAAuB,KAAK;MAC5B,kBAAkB,KAAK;MACvB,GAAG,KAAK,SAAS;;EAErB;EAEmB,YAAY,MAA8B;AAC3D,WAAO,EAAE,eAAe,UAAU,KAAK,MAAM,GAAE;EACjD;EAEmB,eAAe,OAA8B;AAC9D,WAAU,UAAU,OAAO,EAAE,aAAa,WAAU,CAAE;EACxD;;;AAEO,OAAA,SAAS;AACT,OAAA,kBAAkB;AAElB,OAAA,cAAqB;AACrB,OAAA,WAAkB;AAClB,OAAA,qBAA4B;AAC5B,OAAA,4BAAmC;AACnC,OAAA,oBAA2B;AAC3B,OAAA,gBAAuB;AACvB,OAAA,gBAAuB;AACvB,OAAA,iBAAwB;AACxB,OAAA,kBAAyB;AACzB,OAAA,sBAA6B;AAC7B,OAAA,sBAA6B;AAC7B,OAAA,wBAA+B;AAC/B,OAAA,2BAAkC;AAElC,OAAA,SAAiB;AACjB,OAAA,eAAuB;AAGhC,OAAO,cAAcC;AACrB,OAAO,OAAO;AACd,OAAO,sBAAsB;AAC7B,OAAO,aAAa;AACpB,OAAO,QAAQ;AACf,OAAO,kBAAkB;AACzB,OAAO,SAAS;AAChB,OAAO,QAAQ;AACf,OAAO,cAAc;AACrB,OAAO,SAAS;AAChB,OAAO,aAAa;AACpB,OAAO,aAAa;AACpB,OAAO,eAAe;AACtB,OAAO,mBAAmB;AAC1B,OAAO,iCAAiC;AACxC,OAAO,OAAO;AACd,OAAO,UAAU;AACjB,OAAO,cAAc;AACrB,OAAO,UAAU;AACjB,OAAO,YAAY;;;ACzVnB,IAAM,cAAc;AAAA,EAClB,+BAA+B;AAAA,EAC/B,gCAAgC;AAAA,EAChC,gCACE;AACJ;AAGA,IAAM,sBAAsB;AAAA,EAC1B,iBAAiB;AAAA,EACjB,eAAe;AAAA,EACf,eAAe;AAAA;AAAA,EACf,oBAAoB;AAAA;AAAA,EACpB,kBAAkB;AAAA;AACpB;AAGA,IAAM,uBAAuB;AAAA,EAC3B,eAAe;AAAA,IACb;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,EACF;AAAA,EACA,iBAAiB,CAAC,OAAO,OAAO,QAAQ,SAAS,QAAQ,OAAO,QAAQ;AAAA,EACxE,eAAe,CAAC,OAAO,OAAO,QAAQ,SAAS,QAAQ,OAAO,QAAQ;AAAA,EACtE,oBAAoB,CAAC,OAAO,OAAO,QAAQ,SAAS,QAAQ,OAAO,QAAQ;AAAA,EAC3E,kBAAkB,CAAC,OAAO,OAAO,QAAQ,SAAS,QAAQ,OAAO,QAAQ;AAC3E;AAGA,SAAS,qBAAqB,WAAW,YAAY;AACnD,QAAM,gBAAgB,qBAAqB,UAAU;AACrD,SAAO,iBAAiB,cAAc,SAAS,UAAU,YAAY,CAAC;AACxE;AAHS;AAMT,SAAS,mBAAmB,QAAQ;AAElC,QAAM,cAAc,OAAO,MAAM,GAAG;AACpC,MAAI,YAAY,UAAU,GAAG;AAC3B,UAAM,aAAa,YAAY,MAAM,EAAE,EAAE,KAAK,GAAG;AACjD,WAAO,oBAAoB,UAAU;AAAA,EACvC;AACA,SAAO;AACT;AARS;AAUT,IAAM,iBAAiB,wBAAC,MAAM,SAAS,KAAK,UAAU,CAAC,MAAM;AAC3D,SAAO,IAAI,SAAS,MAAM;AAAA,IACxB;AAAA,IACA,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,aAAa,GAAG,QAAQ;AAAA,EAC5E,CAAC;AACH,GALuB;AAOvB,IAAM,sBAAsB,wBAAC,SAAS,WAAW;AAC/C,UAAQ,MAAM,OAAO;AACrB,SAAO,eAAe,KAAK,UAAU,EAAE,OAAO,QAAQ,CAAC,GAAG,MAAM;AAClE,GAH4B;AAM5B,IAAM,6BAA6B,8BAAO,SAAS,QAAQ;AACzD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,UAAU,IAAI,aAAa,IAAI,SAAS;AAE9C,MAAI,CAAC,SAAS;AACZ,WAAO,oBAAoB,oCAAoC,GAAG;AAAA,EACpE;AAEA,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,0CAA0C,GAAG;AAAA,EAC1E;AAEA,QAAM,SAAS;AAAA,0GACyF,OAAO;AAAA;AAAA,8EAEnC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oGAQe,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gKAQqD,OAAO;AAAA;AAAA;AAIrK,QAAM,WAAW,MAAM,MAAM,8CAA8C;AAAA,IACzE,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,eAAe,UAAU,MAAM;AAAA,IACjC;AAAA,IACA,MAAM,KAAK,UAAU;AAAA,MACnB,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SAAS,oGAAoG,OAAO;AAAA,QACtH;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAAA,EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,UAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,MAAM,SAAS,EAAE;AAAA,EACvE;AAEA,QAAM,OAAO,MAAM,SAAS,KAAK;AACjC,QAAM,YAAY,KAAK,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAGvD,UAAQ,IAAI,kCAAkC,SAAS;AAEvD,MAAI;AACF,UAAM,aAAa,KAAK,MAAM,SAAS;AACvC,UAAM,UACJ,WAAW,MAAM,MAAM,CAAC,SAAS,KAAK,SAAS,MAAM,KACrD,WAAW,MAAM,MAAM,CAAC,SAAS,KAAK,SAAS,MAAM;AACvD,QAAI,CAAC,SAAS;AACZ,YAAM,IAAI,MAAM,kCAAkC;AAAA,IACpD;AACA,WAAO,eAAe,SAAS;AAAA,EACjC,QAAQ;AACN,YAAQ,MAAM,8CAA8C;AAE5D,WAAO,eAAe,WAAW,GAAG;AAAA,EACtC;AACF,GAjFmC;AAoFnC,IAAM,8BAA8B,8BAAO,SAAS,QAAQ;AAC1D,MAAI;AACF,UAAM,EAAE,QAAQ,WAAW,KAAK,IAAI,MAAM,QAAQ,KAAK;AAEvD,QAAI,CAAC,QAAQ;AACX,aAAO,oBAAoB,sBAAsB,GAAG;AAAA,IACtD;AAEA,UAAM,SAAS,IAAI;AACnB,QAAI,CAAC,QAAQ;AACX,aAAO,oBAAoB,0CAA0C,GAAG;AAAA,IAC1E;AAGA,UAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAiBP,QAAQ,cAAc;AAAA;AAAA,kCAEN,aAAa,SAAS;AAAA;AAGpD,UAAM,WAAW,MAAM,MAAM,8CAA8C;AAAA,MACzE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,MAAM;AAAA,QAC/B,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,UAAU;AAAA,UACR,EAAE,MAAM,UAAU,SAAS,aAAa;AAAA,UACxC,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,QAClC;AAAA,QACA,YAAY;AAAA,QACZ,aAAa;AAAA,MACf,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,qBAAqB,SAAS,QAAQ,SAAS;AAC7D,YAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,MAAM,SAAS,EAAE;AAAA,IACvE;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,UAAM,mBAAmB,KAAK,QAAQ,CAAC,GAAG,SAAS;AAEnD,QAAI,CAAC,kBAAkB;AACrB,YAAM,IAAI,MAAM,kCAAkC;AAAA,IACpD;AAGA,QAAI;AACJ,QAAI;AACF,sBAAgB,KAAK,MAAM,gBAAgB;AAAA,IAC7C,SAAS,YAAY;AACnB,cAAQ,MAAM,0CAA0C,UAAU;AAClE,cAAQ,IAAI,iBAAiB,gBAAgB;AAG7C,YAAM,YAAY,iBAAiB,MAAM,aAAa;AACtD,UAAI,WAAW;AACb,YAAI;AACF,0BAAgB,KAAK,MAAM,UAAU,CAAC,CAAC;AAAA,QACzC,SAAS,GAAG;AACV,gBAAM,IAAI,MAAM,+BAA+B;AAAA,QACjD;AAAA,MACF,OAAO;AACL,cAAM,IAAI,MAAM,oCAAoC;AAAA,MACtD;AAAA,IACF;AAGA,QAAI,CAAC,cAAc,gBAAgB,CAAC,cAAc,WAAW,CAAC,cAAc,MAAM;AAChF,YAAM,IAAI,MAAM,qCAAqC;AAAA,IACvD;AAEA,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,UAAU;AAAA,MACZ,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,oCAAoC,KAAK;AACvD,WAAO,oBAAoB,oCAAoC,MAAM,OAAO,IAAI,GAAG;AAAA,EACrF;AACF,GAtGoC;AAwGpC,IAAM,aAAa,8BAAO,SAAS,QAAQ;AACzC,QAAM,EAAE,IAAI,UAAU,WAAW,MAAM,IAAI,MAAM,QAAQ,KAAK;AAE9D,MAAI,CAAC,YAAY,CAAC,OAAO;AACvB,WAAO,oBAAoB,wCAAwC,GAAG;AAAA,EACxE;AAEA,QAAM,YAAY,YAAY,SAAS;AACvC,QAAM,SAAS,MAAM,OAAO,WAAW;AACvC,QAAM,SACJ,MAAM,GAAG,SAAS,IAAI,KAAK,EAAE,IAAI,GAAG,SAAS,GAAG,EAAE,KAAK,GAAG,SAAS,GAAG,MAAM,IAAI,KAAK;AAEvF,MAAI,IAAI;AACN,UAAM,QAAQ,IAAI,CAAC,IAAI,aAAa,OAAO,OAAO,EAAE,EAAE,GAAG,IAAI,aAAa,OAAO,OAAO,EAAE,EAAE,CAAC,CAAC;AAAA,EAChG;AAEA,QAAM,IAAI,aAAa,IAAI,QAAQ,UAAU,EAAE,UAAU,EAAE,UAAU,QAAQ,EAAE,CAAC;AAChF,QAAM,gBAAgB,gCAAgC,MAAM;AAE5D,SAAO,eAAe,KAAK,UAAU,EAAE,MAAM,cAAc,CAAC,CAAC;AAC/D,GApBmB;AAsBnB,IAAM,aAAa,8BAAO,SAAS,QAAQ;AACzC,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,KAAK,IAAI,SAAS,MAAM,GAAG,EAAE,IAAI;AACvC,QAAM,MAAM,IAAI,aAAa,IAAI,KAAK,MAAM;AAE5C,QAAM,OAAO,MAAM,IAAI,aAAa,KAAK;AACzC,QAAM,cAAc,KAAK,KAAK;AAAA,IAC5B,CAAC,QAAQ,IAAI,KAAK,SAAS,EAAE,MAAM,IAAI,KAAK,WAAW,MAAM,KAAK,IAAI,KAAK,WAAW,MAAM;AAAA,EAC9F;AAEA,MAAI,CAAC,aAAa;AAChB,WAAO,oBAAoB,aAAa,GAAG;AAAA,EAC7C;AAEA,QAAM,WAAW,MAAM,IAAI,aAAa,IAAI,YAAY,IAAI;AAC5D,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,aAAa,GAAG;AAAA,EAC7C;AAEA,MAAI,KAAK;AACP,WAAO,eAAe,UAAU,KAAK,EAAE,gBAAgB,aAAa,CAAC;AAAA,EACvE;AAEA,QAAM,UAAU,gCAAgC,EAAE;AAClD,QAAM,cAAc,OAAO,MAAM,QAAQ;AACzC,QAAM,cAAc;AAAA,8DACwC,mBAAmB,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA;AAKvF,QAAM,YAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAWZ,WAAW;AAAA,QACX,WAAW;AAAA;AAAA;AAAA;AAKjB,SAAO,eAAe,WAAW,KAAK,EAAE,gBAAgB,YAAY,CAAC;AACvE,GAjDmB;AAmDnB,IAAM,kBAAkB,8BAAO,SAAS,KAAK,aAAa,UAAU;AAClE,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,kBAAkB,IAAI,aAAa,IAAI,QAAQ,MAAM;AAC3D,QAAM,SAAS,cAAc,kBAAkB,SAAS;AAExD,QAAM,OAAO,MAAM,IAAI,aAAa,KAAK;AACzC,QAAM,QAAQ,CAAC;AAEf,aAAW,OAAO,KAAK,MAAM;AAC3B,QAAI,CAAC,IAAI,KAAK,WAAW,MAAM,EAAG;AAElC,UAAM,WAAW,MAAM,IAAI,aAAa,IAAI,IAAI,IAAI;AACpD,QAAI,UAAU;AACZ,YAAM,QAAQ,SAAS,MAAM,IAAI;AACjC,YAAM,YAAY,MAAM,KAAK,CAAC,SAAS,KAAK,WAAW,GAAG,KAAK,CAAC,KAAK,SAAS,IAAI,CAAC;AACnF,YAAM,QAAQ,YAAY,UAAU,QAAQ,SAAS,EAAE,IAAI;AAE3D,YAAM,aAAa,SAAS,MAAM,mBAAmB;AACrD,YAAM,WAAW,aAAa,WAAW,CAAC,IAAI;AAE9C,YAAM,eAAe,MAAM;AAAA,QACzB,CAAC,SAAS,KAAK,KAAK,KAAK,CAAC,KAAK,WAAW,GAAG,KAAK,CAAC,KAAK,SAAS,IAAI;AAAA,MACvE;AACA,YAAM,WAAW,eAAe,aAAa,MAAM,GAAG,GAAG,IAAI,QAAQ;AAErE,YAAM,KAAK;AAAA,QACT,IAAI,IAAI,KAAK,QAAQ,gBAAgB,EAAE;AAAA,QACvC;AAAA,QACA,SAAS,MAAM,MAAM,GAAG,CAAC,EAAE,KAAK,GAAG;AAAA,QACnC;AAAA,QACA,OAAO;AAAA,MACT,CAAC;AAAA,IACH;AAAA,EACF;AAEA,SAAO,eAAe,KAAK,UAAU,KAAK,CAAC;AAC7C,GApCwB;AAsCxB,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,QAAM,KAAK,QAAQ,IAAI,MAAM,GAAG,EAAE,IAAI;AAEtC,MAAI,CAAC,IAAI;AACP,WAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC5D;AAEA,QAAM,OAAO,MAAM,IAAI,aAAa,KAAK;AACzC,QAAM,cAAc,KAAK,KAAK;AAAA,IAC5B,CAAC,QAAQ,IAAI,KAAK,SAAS,EAAE,MAAM,IAAI,KAAK,WAAW,MAAM,KAAK,IAAI,KAAK,WAAW,MAAM;AAAA,EAC9F;AAEA,MAAI,CAAC,aAAa;AAChB,WAAO,oBAAoB,aAAa,GAAG;AAAA,EAC7C;AAEA,QAAM,IAAI,aAAa,OAAO,YAAY,IAAI;AAC9C,SAAO,eAAe,gCAAgC;AACxD,GAlB6B;AAoB7B,IAAM,mBAAmB,8BAAO,SAAS,QAAQ;AAC/C,QAAM,EAAE,IAAI,QAAQ,IAAI,MAAM,QAAQ,KAAK;AAE3C,MAAI,CAAC,MAAM,CAAC,SAAS;AACnB,WAAO,oBAAoB,+BAA+B,GAAG;AAAA,EAC/D;AAEA,QAAM,IAAI,SAAS,IAAI,IAAI,OAAO;AAClC,SAAO,eAAe,4BAA4B;AACpD,GATyB;AAWzB,IAAM,mBAAmB,8BAAO,SAAS,QAAQ;AAC/C,QAAM,KAAK,QAAQ,IAAI,MAAM,GAAG,EAAE,IAAI;AACtC,QAAM,UAAU,MAAM,IAAI,SAAS,IAAI,EAAE;AAEzC,MAAI,CAAC,SAAS;AACZ,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,SAAO,eAAe,KAAK,UAAU,EAAE,IAAI,SAAS,QAAQ,CAAC,CAAC;AAChE,GATyB;AAWzB,IAAM,sBAAsB,8BAAO,SAAS,QAAQ;AAClD,QAAM,KAAK,QAAQ,IAAI,MAAM,GAAG,EAAE,IAAI;AACtC,QAAM,IAAI,SAAS,OAAO,EAAE;AAC5B,SAAO,eAAe,8BAA8B;AACtD,GAJ4B;AAM5B,IAAM,oBAAoB,8BAAO,SAAS,QAAQ;AAChD,QAAM,OAAO,MAAM,IAAI,SAAS,KAAK;AACrC,SAAO,eAAe,KAAK,UAAU,EAAE,MAAM,KAAK,QAAQ,CAAC,EAAE,CAAC,CAAC;AACjE,GAH0B;AAK1B,IAAM,eAAe,8BAAO,SAAS,QAAQ;AAC3C,QAAM,EAAE,aAAa,IAAI;AACzB,QAAM,WAAW,MAAM,QAAQ,SAAS;AACxC,QAAM,OAAO,SAAS,IAAI,MAAM;AAEhC,MAAI,CAAC,MAAM;AACT,WAAO,oBAAoB,gBAAgB,GAAG;AAAA,EAChD;AAEA,QAAM,gBAAgB,KAAK,OAAO,KAAK,KAAK,MAAM,GAAG,EAAE,IAAI,IAAI;AAC/D,MAAI,CAAC,eAAe;AAClB,WAAO,oBAAoB,kCAAkC,GAAG;AAAA,EAClE;AAEA,QAAM,WAAW,GAAG,KAAK,IAAI,CAAC,IAAI,aAAa;AAC/C,QAAM,cAAc,kBAAkB,QAAQ,kBAAkB,KAAK;AAErE,QAAM,aAAa,IAAI,UAAU,KAAK,OAAO,GAAG;AAAA,IAC9C,cAAc,EAAE,YAAY;AAAA,EAC9B,CAAC;AAED,QAAM,UAAU,4BAA4B,QAAQ;AACpD,SAAO,eAAe,KAAK,UAAU,EAAE,KAAK,QAAQ,CAAC,CAAC;AACxD,GAvBqB;AAyBrB,IAAM,eAAe,8BAAO,SAAS,QAAQ;AAC3C,QAAM,QAAQ,IAAI,IAAI,QAAQ,GAAG,EAAE,aAAa,IAAI,OAAO,GAAG,YAAY;AAE1E,MAAI,CAAC,OAAO;AACV,WAAO,oBAAoB,2BAA2B,GAAG;AAAA,EAC3D;AAEA,QAAM,OAAO,MAAM,IAAI,aAAa,KAAK;AACzC,QAAM,UAAU,CAAC;AAEjB,aAAW,OAAO,KAAK,MAAM;AAC3B,UAAM,WAAW,MAAM,IAAI,aAAa,IAAI,IAAI,IAAI;AACpD,QAAI,YAAY,SAAS,YAAY,EAAE,SAAS,KAAK,GAAG;AACtD,YAAM,QAAQ,SAAS,MAAM,IAAI;AACjC,YAAM,YAAY,MAAM,KAAK,CAAC,SAAS,KAAK,WAAW,GAAG,KAAK,CAAC,KAAK,SAAS,IAAI,CAAC;AACnF,YAAM,QAAQ,YAAY,UAAU,QAAQ,UAAU,EAAE,IAAI;AAE5D,YAAM,aAAa,SAAS,MAAM,mBAAmB;AACrD,YAAM,WAAW,aAAa,WAAW,CAAC,IAAI;AAE9C,YAAM,eAAe,MAAM;AAAA,QACzB,CAAC,SAAS,KAAK,KAAK,KAAK,CAAC,KAAK,WAAW,GAAG,KAAK,CAAC,KAAK,SAAS,IAAI;AAAA,MACvE;AACA,YAAM,WAAW,eAAe,aAAa,MAAM,GAAG,GAAG,IAAI,QAAQ;AAErE,cAAQ,KAAK;AAAA,QACX,IAAI,IAAI,KAAK,QAAQ,gBAAgB,EAAE;AAAA,QACvC;AAAA,QACA,SAAS,MAAM,MAAM,GAAG,CAAC,EAAE,KAAK,GAAG;AAAA,QACnC;AAAA,QACA,OAAO;AAAA,MACT,CAAC;AAAA,IACH;AAAA,EACF;AAEA,SAAO,eAAe,KAAK,UAAU,OAAO,CAAC;AAC/C,GApCqB;AAsCrB,IAAM,yBAAyB,8BAAO,SAAS,QAAQ;AACrD,QAAM,EAAE,IAAI,UAAU,IAAI,MAAM,QAAQ,KAAK;AAE7C,MAAI,CAAC,IAAI;AACP,WAAO,oBAAoB,2BAA2B,GAAG;AAAA,EAC3D;AAEA,QAAM,aAAa,YAAY,OAAO,EAAE,KAAK,OAAO,EAAE;AACtD,QAAM,SAAS,YAAY,OAAO,EAAE,KAAK,OAAO,EAAE;AAElD,QAAM,WAAW,MAAM,IAAI,aAAa,IAAI,UAAU;AACtD,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,uDAAuD,GAAG;AAAA,EACvF;AAEA,QAAM,IAAI,aAAa,OAAO,UAAU;AACxC,QAAM,IAAI,aAAa,IAAI,QAAQ,UAAU,EAAE,UAAU,EAAE,UAAU,QAAQ,EAAE,CAAC;AAEhF,SAAO,eAAe,2CAA2C;AACnE,GAnB+B;AAqB/B,IAAM,iBAAiB,8BAAO,SAAS,QAAQ;AAC7C,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,YAAY,IAAI,aAAa,IAAI,MAAM;AAE7C,MAAI,CAAC,WAAW;AACd,WAAO,oBAAoB,yBAAyB,GAAG;AAAA,EACzD;AAEA,QAAM,QAAQ,MAAM,IAAI,aAAa,IAAI,SAAS;AAElD,MAAI,CAAC,OAAO;AACV,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AAEA,QAAM,UAAU;AAAA,IACd,gBAAgB,MAAM,cAAc,eAAe;AAAA,IACnD,GAAG;AAAA,EACL;AAEA,SAAO,IAAI,SAAS,MAAM,MAAM,EAAE,QAAQ,KAAK,QAAQ,CAAC;AAC1D,GApBuB;AAsBvB,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,WAAW,IAAI,aAAa,IAAI,MAAM;AAE5C,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,8BAA8B,GAAG;AAAA,EAC9D;AAEA,QAAM,QAAQ,MAAM,IAAI,aAAa,IAAI,QAAQ;AAEjD,MAAI,CAAC,OAAO;AACV,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AAEA,QAAM,UAAU;AAAA,IACd,gBAAgB,MAAM,cAAc,eAAe;AAAA,IACnD,iBAAiB;AAAA,IACjB,gCAAgC;AAAA,IAChC,uBAAuB;AAAA,IACvB,+BAA+B;AAAA,IAC/B,0BAA0B;AAAA,EAC5B;AAEA,SAAO,IAAI,SAAS,MAAM,MAAM,EAAE,QAAQ,KAAK,QAAQ,CAAC;AAC1D,GAxB6B;AA0B7B,IAAM,wBAAwB,8BAAO,SAAS,QAAQ;AACpD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,WAAW,IAAI,aAAa,IAAI,MAAM;AAE5C,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,8BAA8B,GAAG;AAAA,EAC9D;AAEA,QAAM,QAAQ,MAAM,IAAI,aAAa,IAAI,QAAQ;AAEjD,MAAI,CAAC,OAAO;AACV,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AAEA,QAAM,UAAU;AAAA,IACd,gBAAgB,MAAM,cAAc,eAAe;AAAA,IACnD,iBAAiB;AAAA,IACjB,gCAAgC;AAAA,IAChC,uBAAuB;AAAA,IACvB,+BAA+B;AAAA,IAC/B,0BAA0B;AAAA,IAC1B,iBAAiB,MAAM,cAAc,iBAAgB,oBAAI,KAAK,GAAE,YAAY;AAAA,IAC5E,kBAAkB,MAAM;AAAA;AAAA,EAC1B;AAEA,SAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,KAAK,QAAQ,CAAC;AACpD,GA1B8B;AA4B9B,IAAM,kBAAkB,8BAAO,SAAS,QAAQ;AAC9C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,0CAA0C,GAAG;AAAA,EAC1E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,KAAK,IAAI;AACjB,MAAI,CAAC,QAAQ,OAAO,SAAS,UAAU;AACrC,WAAO,oBAAoB,oCAAoC,GAAG;AAAA,EACpE;AAEA,QAAM,SAAS;AAAA,MACX,IAAI;AAAA;AAGR,QAAM,WAAW,MAAM,MAAM,8CAA8C;AAAA,IACzE,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,eAAe,UAAU,MAAM;AAAA,IACjC;AAAA,IACA,MAAM,KAAK,UAAU;AAAA,MACnB,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SAAS;AAAA,QACX;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAAA,EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,WAAO,oBAAoB,qBAAqB,SAAS,MAAM,MAAM,SAAS,IAAI,GAAG;AAAA,EACvF;AAEA,QAAM,OAAO,MAAM,SAAS,KAAK;AACjC,QAAM,UAAU,KAAK,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAErD,SAAO;AAAA,IACL,KAAK,UAAU;AAAA,MACb,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,MAC1B,OAAO;AAAA,MACP,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,IACT,CAAC;AAAA,IACD;AAAA,EACF;AACF,GA5DwB;AA8DxB,IAAM,iBAAiB,8BAAO,SAAS,QAAQ;AAC7C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,QAAQ,aAAa,YAAY,aAAa,IAAI;AAC1D,MAAI,CAAC,UAAU,OAAO,WAAW,UAAU;AACzC,WAAO,oBAAoB,sCAAsC,GAAG;AAAA,EACtE;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,MAAI;AAEF,QAAI,cAAc;AAClB,QAAI,gBAAgB,aAAa,KAAK,GAAG;AACvC,oBAAc;AAAA,EAAkC,YAAY;AAAA;AAAA,YAAiB,MAAM;AAAA,IACrF;AAGA,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SAAS,eACL,4LACA;AAAA,QACN;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,MACvC;AAAA,IACF,CAAC;AAED,UAAM,eAAe,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAChE,QAAI,CAAC,cAAc;AACjB,aAAO,oBAAoB,0BAA0B,GAAG;AAAA,IAC1D;AAGA,UAAM,iBAAiB,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MAC1D,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,sCAAsC,MAAM,GAAG;AAAA,MAC1E;AAAA,IACF,CAAC;AAED,UAAM,WAAW,eAAe,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAEhE,UAAM,iBAAiB,SACpB,MAAM,IAAI,EACV,OAAO,CAAC,QAAQ,IAAI,KAAK,CAAC,EAC1B,IAAI,CAAC,QAAQ,IAAI,KAAK,CAAC;AAG1B,QAAI,eAAe,UAAU;AAE3B,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,UACxB,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,MAAM;AAAA,QACR,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,GAAG;AAAA,YACH,gBAAgB;AAAA,UAClB;AAAA,QACF;AAAA,MACF;AAAA,IACF,WAAW,eAAe,QAAQ;AAEhC,YAAM,qBAAqB,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,QAC9D,OAAO;AAAA,QACP,aAAa;AAAA,QACb,YAAY;AAAA,QACZ,UAAU;AAAA,UACR;AAAA,YACE,MAAM;AAAA,YACN,SACE;AAAA,UACJ;AAAA,UACA;AAAA,YACE,MAAM;AAAA,YACN,SAAS,oBAAoB,YAAY;AAAA;AAAA;AAAA,UAC3C;AAAA,QACF;AAAA,MACF,CAAC;AAED,YAAM,mBAAmB,mBAAmB,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAG5E,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,MAAM;AAAA,UACN,UAAU;AAAA,YACR,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,YAC1B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,YACP,MAAM;AAAA,UACR;AAAA,UACA,QAAQ;AAAA,YACN,IAAI,UAAU,KAAK,IAAI,IAAI,CAAC;AAAA,YAC5B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,UACT;AAAA,QACF,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,GAAG;AAAA,YACH,gBAAgB;AAAA,UAClB;AAAA,QACF;AAAA,MACF;AAAA,IACF,OAAO;AAEL,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,UAC1B,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,MAAM;AAAA,QACR,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,GAAG;AAAA,YACH,gBAAgB;AAAA,UAClB;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,2BAA2B,KAAK;AAC9C,WAAO,oBAAoB,mBAAmB,MAAM,WAAW,eAAe,IAAI,GAAG;AAAA,EACvF;AACF,GAtKuB;AAwKvB,IAAM,mBAAmB,8BAAO,SAAS,QAAQ;AAC/C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,wDAAwD,GAAG;AAAA,EACxF;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,MAAM,QAAQ,aAAa,YAAY,aAAa,IAAI;AAChE,QAAM,YAAY,QAAQ;AAC1B,MAAI,CAAC,aAAa,OAAO,cAAc,UAAU;AAC/C,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AAEF,QAAI,iBAAiB;AACrB,QAAI,gBAAgB,aAAa,KAAK,GAAG;AACvC,uBAAiB;AAAA,EAAkC,YAAY;AAAA;AAAA,YAAiB,SAAS;AAAA,IAC3F;AAEA,UAAM,WAAW,MAAM;AAAA,MACrB,gGAAgG,MAAM;AAAA,MACtG;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACnB,UAAU;AAAA,YACR;AAAA,cACE,OAAO;AAAA,gBACL;AAAA,kBACE,MAAM;AAAA,gBACR;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAEA,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,aAAO,oBAAoB,qBAAqB,SAAS,MAAM,MAAM,SAAS,IAAI,GAAG;AAAA,IACvF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AAGjC,UAAM,gBAAgB,KAAK,aAAa,CAAC,GAAG,SAAS,QAAQ,CAAC,GAAG,QAAQ;AAGzE,QAAI,eAAe,UAAU;AAE3B,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,UACxB,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,OAAO;AAAA,UACP,QAAQ;AAAA,QACV,CAAC;AAAA,MACH;AAAA,IACF,WAAW,eAAe,QAAQ;AAEhC,YAAM,mBAAmB,MAAM;AAAA,QAC7B,gGAAgG,MAAM;AAAA,QACtG;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,UAClB;AAAA,UACA,MAAM,KAAK,UAAU;AAAA,YACnB,UAAU;AAAA,cACR;AAAA,gBACE,OAAO;AAAA,kBACL;AAAA,oBACE,MAAM,0BAA0B,aAAa;AAAA,kBAC/C;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAEA,UAAI,mBAAmB;AACvB,UAAI,iBAAiB,IAAI;AACvB,cAAM,eAAe,MAAM,iBAAiB,KAAK;AACjD,2BACE,aAAa,aAAa,CAAC,GAAG,SAAS,QAAQ,CAAC,GAAG,QAAQ;AAAA,MAC/D;AAGA,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,MAAM;AAAA,UACN,UAAU;AAAA,YACR,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,YAC1B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,YACP,OAAO;AAAA,YACP,QAAQ;AAAA,UACV;AAAA,UACA,QAAQ;AAAA,YACN,IAAI,UAAU,KAAK,IAAI,IAAI,CAAC;AAAA,YAC5B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,UACT;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF,OAAO;AAEL,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,UACxB,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,OAAO;AAAA,UACP,QAAQ;AAAA,QACV,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,WAAO,oBAAoB,qBAAqB,MAAM,OAAO,IAAI,GAAG;AAAA,EACtE;AACF,GA5IyB;AA8IzB,IAAM,mBAAmB,8BAAO,SAAS,QAAQ;AAC/C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,oDAAoD,GAAG;AAAA,EACpF;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,QAAQ,aAAa,YAAY,aAAa,IAAI;AAC1D,MAAI,CAAC,UAAU,OAAO,WAAW,UAAU;AACzC,WAAO,oBAAoB,sCAAsC,GAAG;AAAA,EACtE;AAEA,MAAI;AAEF,QAAI,iBAAiB;AACrB,QAAI,gBAAgB,aAAa,KAAK,GAAG;AACvC,uBAAiB;AAAA,EAAkC,YAAY;AAAA;AAAA,YAAiB,MAAM;AAAA;AAAA;AAAA,IACxF;AAEA,UAAM,WAAW,MAAM,MAAM,yCAAyC;AAAA,MACpE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,aAAa;AAAA,QACb,qBAAqB;AAAA,MACvB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,YAAY;AAAA,QACZ,UAAU;AAAA,UACR;AAAA,YACE,MAAM;AAAA,YACN,SAAS;AAAA,UACX;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,aAAO,oBAAoB,qBAAqB,SAAS,MAAM,MAAM,SAAS,IAAI,GAAG;AAAA,IACvF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AAGjC,UAAM,gBAAgB,KAAK,UAAU,CAAC,GAAG,QAAQ;AAGjD,QAAI,eAAe,UAAU;AAE3B,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,UACxB,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,OAAO;AAAA,UACP;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF,WAAW,eAAe,QAAQ;AAEhC,YAAM,mBAAmB,MAAM,MAAM,yCAAyC;AAAA,QAC5E,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,UAChB,aAAa;AAAA,UACb,qBAAqB;AAAA,QACvB;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACnB,OAAO;AAAA,UACP,YAAY;AAAA,UACZ,UAAU;AAAA,YACR;AAAA,cACE,MAAM;AAAA,cACN,SAAS,0BAA0B,aAAa;AAAA,YAClD;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH,CAAC;AAED,UAAI,mBAAmB;AACvB,UAAI,iBAAiB,IAAI;AACvB,cAAM,eAAe,MAAM,iBAAiB,KAAK;AACjD,2BAAmB,aAAa,UAAU,CAAC,GAAG,QAAQ;AAAA,MACxD;AAGA,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,MAAM;AAAA,UACN,UAAU;AAAA,YACR,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,YAC1B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,YACP,OAAO;AAAA,YACP;AAAA,UACF;AAAA,UACA,QAAQ;AAAA,YACN,IAAI,UAAU,KAAK,IAAI,IAAI,CAAC;AAAA,YAC5B,OAAO;AAAA,YACP,MAAM;AAAA,YACN,MAAM;AAAA,YACN,OAAO;AAAA,UACT;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF,OAAO;AAEL,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,UACxB,OAAO;AAAA,UACP,MAAM;AAAA,UACN,MAAM;AAAA,UACN,OAAO;AAAA,UACP,OAAO;AAAA,UACP;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,WAAO,oBAAoB,qBAAqB,MAAM,OAAO,IAAI,GAAG;AAAA,EACtE;AACF,GAtIyB;AAyIzB,IAAM,iBAAiB,8BAAO,SAAS,QAAQ;AAC7C,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,IAAI;AACJ,MACE,CAAC,UACD,CAAC,gBACD,CAAC,WACD,CAAC,SACD,CAAC,eACD,CAAC,cACD,CAAC,eACD,CAAC,iBACD;AACA,WAAO,oBAAoB,+BAA+B,GAAG;AAAA,EAC/D;AAEA,MAAI;AACJ,UAAQ,YAAY,YAAY,GAAG;AAAA,IACjC,KAAK;AACH,eAAS,IAAI;AACb;AAAA,IACF,KAAK;AACH,eAAS,IAAI;AACb;AAAA,IACF,KAAK;AACH,eAAS,IAAI;AACb;AAAA,IACF;AACE,aAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC9D;AAEA,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,0BAA0B,WAAW,oBAAoB,GAAG;AAAA,EACzF;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA;AAAA,EACF,CAAC;AAED,MAAI;AACF,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD;AAAA,MACA;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR,EAAE,MAAM,UAAU,SAAS,aAAa;AAAA,QACxC,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,eAAe,WAAW,QAAQ,CAAC,EAAE,QAAQ;AACnD,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,IAAI,QAAQ,KAAK,IAAI,CAAC;AAAA,QACtB,OAAO,gBAAgB,SAAS;AAAA,QAChC,MAAM,gBAAgB,QAAQ;AAAA,QAC9B,MAAM;AAAA,QACN,OAAO,gBAAgB,SAAS;AAAA,QAChC,GAAG,gBAAgB;AAAA,MACrB,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,yBAAyB,KAAK;AAC5C,WAAO,oBAAoB,iBAAiB,MAAM,WAAW,eAAe,IAAI,GAAG;AAAA,EACrF;AACF,GAlFuB;AAoFvB,IAAM,wBAAwB,8BAAO,SAAS,QAAQ;AACpD,QAAM,SAAS,IAAI;AACnB,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,YAAY,IAAI,aAAa,IAAI,KAAK;AAE5C,MAAI,CAAC,aAAa,cAAc,IAAI,WAAW;AAC7C,WAAO,oBAAoB,EAAE,UAAU,GAAG,GAAG;AAAA,EAC/C;AAEA,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,iDAAiD,GAAG;AAAA,EACjF;AAEA,SAAO,eAAe,KAAK,UAAU,EAAE,OAAO,CAAC,GAAG,GAAG;AACvD,GAd8B;AAgB9B,IAAM,kBAAkB,8BAAO,SAAS,QAAQ;AAE9C,QAAM,aAAa,QAAQ,QAAQ,IAAI,eAAe,KAAK;AAC3D,QAAM,QAAQ,WAAW,QAAQ,WAAW,EAAE,EAAE,KAAK;AACrD,MAAI,UAAU,IAAI,WAAW;AAC3B,WAAO,oBAAoB,+BAA+B,GAAG;AAAA,EAC/D;AAGA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAGA,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA,cAAc;AAAA,IACd;AAAA,IACA;AAAA,IACA,WAAW;AAAA,IACX;AAAA,IACA,SAAS,CAAC;AAAA,EACZ,IAAI;AACJ,MAAI,CAAC,QAAQ,cAAc,UAAa,aAAa,QAAW;AAC9D,WAAO,oBAAoB,kCAAkC,GAAG;AAAA,EAClE;AAGA,QAAM,YAAY,MAAM,IAAI,WAAW,IAAI,iBAAiB;AAC5D,MAAI,UAAU;AACd,MAAI,WAAW;AACb,cAAU,MAAM,UAAU,KAAK;AAAA,EACjC,OAAO;AACL,cAAU;AAAA;AAAA;AAAA;AAAA;AAAA,EACZ;AAGA,MAAI,cAAc;AAClB,MAAI,OAAO,KAAK,MAAM,EAAE,SAAS,GAAG;AAClC,kBAAc;AAAA;AAAA,mBAAoC,OAAO,aAAa,SAAS;AAAA,kBAAiC,OAAO,YAAY,QAAQ;AAAA,kBAAgC,OAAO,YAAY,QAAQ;AAAA,iBAA+B,OAAO,WAAW,CAAC;AAAA,cAA2B,OAAO,QAAQ,CAAC;AAAA,iBAA2B,OAAO,QAAQ,EAAE;AAAA,eAA4B,OAAO,SAAS,GAAI;AAAA,sBAAiC,OAAO,gBAAgB,UAAU;AAAA;AAAA,EACnc;AAGA,MAAI,gBAAgB,WAAW;AAAA,gBAAmB,QAAQ,gBAAgB;AAG1E,MAAI,SAAS,KAAK,QAAQ,EAAE,MAAM;AAGlC,QAAM,YAAY;AAAA,cAAiB,MAAM;AAAA,YAAgB,IAAI;AAAA,mBAA6B,WAAW,iBAAiB,WAAW,GAAG,aAAa;AAAA;AAAA,qBAAqC,SAAS,IAAI,QAAQ,IAAI,QAAQ;AAAA;AAAA;AAAA;AAGvN,YAAU,QAAQ,QAAQ,gBAAgB,GAAG,SAAS;AAAA,YAAe;AAGrE,QAAM,IAAI,WAAW,IAAI,mBAAmB,SAAS;AAAA,IACnD,cAAc,EAAE,aAAa,uCAAuC;AAAA,EACtE,CAAC;AAED,SAAO,eAAe,KAAK,UAAU,EAAE,SAAS,MAAM,SAAS,cAAc,CAAC,CAAC;AACjF,GAhEwB;AAkExB,IAAM,qBAAqB,8BAAO,SAAS,QAAQ;AACjD,UAAQ,IAAI,mCAAmC;AAC/C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,YAAQ,MAAM,qBAAqB;AACnC,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAC1B,YAAQ,IAAI,iBAAiB,KAAK,UAAU,IAAI,CAAC;AAAA,EACnD,QAAQ;AACN,YAAQ,MAAM,oBAAoB;AAClC,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,OAAO,MAAM,IAAI;AACzB,MAAI,CAAC,MAAM,QAAQ,KAAK,KAAK,CAAC,MAAM,QAAQ,KAAK,GAAG;AAClD,YAAQ,MAAM,uBAAuB,EAAE,OAAO,MAAM,CAAC;AACrD,WAAO,oBAAoB,sBAAsB,GAAG;AAAA,EACtD;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,MAAI;AAEF,UAAM,eAAe,MAClB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,OAAO,CAAC,SAAS,QAAQ,OAAO,SAAS,YAAY,KAAK,KAAK,EAAE,SAAS,CAAC,EAC3E,KAAK,IAAI;AAEZ,UAAM,SAAS;AAAA;AAAA;AAAA,MAGb,YAAY;AAAA;AAAA;AAAA;AAKd,YAAQ,IAAI,2BAA2B,MAAM;AAE7C,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,QAAQ,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AACzD,YAAQ,IAAI,oBAAoB,KAAK;AACrC,WAAO,eAAe,KAAK,UAAU,EAAE,MAAM,CAAC,CAAC;AAAA,EACjD,QAAQ;AACN,YAAQ,MAAM,iBAAiB;AAC/B,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AACF,GAlE2B;AAoE3B,IAAM,2BAA2B,8BAAO,SAAS,QAAQ;AACvD,UAAQ,IAAI,yCAAyC;AACrD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,YAAQ,MAAM,qBAAqB;AACnC,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAC1B,YAAQ,IAAI,iBAAiB,KAAK,UAAU,IAAI,CAAC;AAAA,EACnD,QAAQ;AACN,YAAQ,MAAM,oBAAoB;AAClC,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,OAAO,MAAM,IAAI;AACzB,MAAI,CAAC,MAAM,QAAQ,KAAK,KAAK,CAAC,MAAM,QAAQ,KAAK,GAAG;AAClD,YAAQ,MAAM,uBAAuB,EAAE,OAAO,MAAM,CAAC;AACrD,WAAO,oBAAoB,sBAAsB,GAAG;AAAA,EACtD;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,MAAI;AAEF,UAAM,eAAe,MAClB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,OAAO,CAAC,SAAS,QAAQ,OAAO,SAAS,YAAY,KAAK,KAAK,EAAE,SAAS,CAAC,EAC3E,KAAK,IAAI;AAEZ,UAAM,SAAS;AAAA;AAAA;AAAA,MAGb,YAAY;AAAA;AAAA;AAAA;AAAA;AAMd,YAAQ,IAAI,2BAA2B,MAAM;AAE7C,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,cAAc,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC/D,YAAQ,IAAI,0BAA0B,WAAW;AACjD,WAAO,eAAe,KAAK,UAAU,EAAE,YAAY,CAAC,CAAC;AAAA,EACvD,QAAQ;AACN,YAAQ,MAAM,iBAAiB;AAC/B,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AACF,GAnEiC;AAqEjC,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AACtD,UAAQ,IAAI,wCAAwC;AACpD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,YAAQ,MAAM,qBAAqB;AACnC,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAC1B,YAAQ,IAAI,iBAAiB,KAAK,UAAU,IAAI,CAAC;AAAA,EACnD,QAAQ;AACN,YAAQ,MAAM,oBAAoB;AAClC,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,OAAO,MAAM,IAAI;AACzB,MAAI,CAAC,MAAM,QAAQ,KAAK,KAAK,CAAC,MAAM,QAAQ,KAAK,GAAG;AAClD,YAAQ,MAAM,uBAAuB,EAAE,OAAO,MAAM,CAAC;AACrD,WAAO,oBAAoB,sBAAsB,GAAG;AAAA,EACtD;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,MAAI;AAEF,UAAM,eAAe,MAClB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,OAAO,CAAC,SAAS,QAAQ,OAAO,SAAS,YAAY,KAAK,KAAK,EAAE,SAAS,CAAC,EAC3E,KAAK,IAAI;AAEZ,UAAM,SAAS;AAAA;AAAA;AAAA,MAGb,YAAY;AAAA;AAAA;AAAA;AAAA;AAMd,YAAQ,IAAI,2BAA2B,MAAM;AAE7C,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,aAAa,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC9D,YAAQ,IAAI,yBAAyB,UAAU;AAC/C,WAAO,eAAe,KAAK,UAAU,EAAE,WAAW,CAAC,CAAC;AAAA,EACtD,QAAQ;AACN,YAAQ,MAAM,iBAAiB;AAC/B,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AACF,GAnEgC;AAqEhC,IAAM,6BAA6B,8BAAO,SAAS,QAAQ;AACzD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,OAAO,aAAa,MAAM,UAAU,QAAQ,KAAK,IAAI;AAG7D,MACE,CAAC,QACD,CAAC,CAAC,wBAAwB,wBAAwB,oBAAoB,EAAE,SAAS,IAAI,GACrF;AACA,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAGA,QAAM,kBAAkB,eAAe;AAGvC,MAAI,SAAS,2BAA2B,CAAC,SAAS,OAAO,UAAU,WAAW;AAC5E,WAAO,oBAAoB,mDAAmD,GAAG;AAAA,EACnF;AACA,OACG,SAAS,0BAA0B,SAAS,0BAC5C,CAAC,mBAAmB,OAAO,oBAAoB,WAChD;AACA,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,MAAI;AACF,QAAI,YAAY;AAChB,QAAI,MAAM,QAAQ,MAAM,KAAK,OAAO,SAAS,GAAG;AAC9C,kBAAY,WAAW,OAAO,KAAK,IAAI,CAAC;AAAA,IAC1C;AAEA,QAAI,QAAQ,eAAe;AAC3B,YAAQ,MAAM;AAAA,MACZ,KAAK;AACH,iBAAS;AAAA,SAA2G,KAAK;AAAA,EAAK,SAAS;AAAA;AACvI,wBACE;AACF,oBAAY;AACZ;AAAA,MACF,KAAK;AACH,iBAAS;AAAA,EAAqF,eAAe;AAAA,EAAK,SAAS;AAAA;AAC3H,wBACE;AACF,oBAAY;AACZ;AAAA,MACF,KAAK;AACH,iBAAS;AAAA,EAAyF,eAAe;AAAA,EAAK,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAC/H,wBACE;AACF,oBAAY;AACZ;AAAA,IACJ;AAEA,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR,EAAE,MAAM,UAAU,SAAS,cAAc;AAAA,QACzC,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,SAAS,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC1D,WAAO;AAAA,MACL,KAAK,UAAU,SAAS,yBAAyB,EAAE,OAAO,OAAO,IAAI,EAAE,aAAa,OAAO,CAAC;AAAA,IAC9F;AAAA,EACF,QAAQ;AACN,WAAO,oBAAoB,kBAAkB,GAAG;AAAA,EAClD;AACF,GA7FmC;AA+FnC,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AAEtD,QAAM,WAAW,QAAQ,QAAQ,IAAI,aAAa,KAAK;AACvD,MAAI,aAAa,cAAc;AAC7B,WAAO,oBAAoB,uCAAuC,GAAG;AAAA,EACvE;AAGA,UAAQ,IAAI,kCAAkC;AAC9C,QAAM,WAAW,MAAM,MAAM,6CAA6C;AAC1E,UAAQ,IAAI,kCAAkC,SAAS,MAAM;AAC7D,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAQ,IAAI,gCAAgC,IAAI;AAChD,WAAO,oBAAoB,0BAA0B,GAAG;AAAA,EAC1D;AACA,QAAM,OAAO,MAAM,SAAS,KAAK;AACjC,MAAI,CAAC,KAAK,QAAS,QAAO,oBAAoB,mBAAmB,GAAG;AAGpE,aAAW,SAAS,KAAK,SAAS;AAChC,UAAM,gBAAgB,MAAM,MAAM,iDAAiD,MAAM,EAAE,EAAE;AAC7F,QAAI,CAAC,cAAc,GAAI;AACvB,UAAM,YAAY,MAAM,cAAc,KAAK;AAG3C,UAAM,OAAO,UAAU,UAAU;AACjC,QAAI,OAAO,SAAS,YAAY,KAAK,KAAK,EAAE,SAAS,GAAG;AACtD,cAAQ,IAAI,kBAAkB,MAAM,EAAE,4BAA4B,IAAI,IAAI;AAC1E;AAAA,IACF;AAGA,UAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAAosB,UAAU,UAAU,SAAS,EAAE;AAAA,EAAK,UAAU,UAAU,eAAe,EAAE;AAAA,EAAK,UAAU,UAAU,YAAY,EAAE;AAAA,EAAK,UAAU,OAAO,IAAI,CAAC,MAAM,EAAE,QAAQ,OAAO,EAAE,QAAQ,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAG74B,QAAI,WAAW;AACf,QAAI;AACF,YAAM,SAAS,IAAI,OAAO;AAAA,QACxB,QAAQ,IAAI;AAAA,QACZ,SAAS;AAAA,MACX,CAAC;AACD,YAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,QACtD,OAAO;AAAA,QACP,aAAa;AAAA,QACb,YAAY;AAAA,QACZ,UAAU;AAAA,UACR;AAAA,YACE,MAAM;AAAA,YACN,SACE;AAAA,UACJ;AAAA,UACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,QAClC;AAAA,MACF,CAAC;AACD,iBAAW,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK,EAAE,MAAM,KAAK,EAAE,CAAC,EAAE,YAAY;AAEpF,YAAM,aAAa;AAAA,QACjB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,UAAI,WAAW,SAAS,QAAQ,GAAG;AACjC,gBAAQ;AAAA,UACN,oBAAoB,QAAQ,yBAAyB,MAAM,EAAE;AAAA,QAC/D;AACA;AAAA,MACF;AAAA,IACF,QAAQ;AACN;AAAA,IACF;AAGA,UAAM,MAAM,iDAAiD;AAAA,MAC3D,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU;AAAA,QACnB,IAAI,MAAM;AAAA,QACV,WAAW;AAAA,UACT,GAAG;AAAA,UACH,UAAU;AAAA,YACR,GAAG,UAAU;AAAA,YACb;AAAA,UACF;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,SAAO,eAAe,KAAK,UAAU,EAAE,SAAS,KAAK,CAAC,CAAC;AACzD,GAlGgC;AAqGhC,IAAM,gBAAgB,8BAAO,SAAS,QAAQ;AAC5C,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,MAAI,EAAE,SAAS,SAAS,IAAI;AAC5B,MAAI,CAAC,WAAW,OAAO,YAAY,UAAU;AAC3C,WAAO,oBAAoB,4CAA4C,GAAG;AAAA,EAC5E;AACA,MAAI,CAAC,YAAY,OAAO,aAAa,YAAY,CAAC,SAAS,KAAK,GAAG;AACjE,WAAO,oBAAoB,uDAAuD,GAAG;AAAA,EACvF;AAGA,MAAI,eAAe;AACnB,MAAI;AAEF,UAAMC,QAAO,OAAO,MAAM,OAAO;AACjC,mBAAeA,MACZ,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;AAAA,EACV,QAAQ;AACN,mBAAe;AAAA,EACjB;AAEA,QAAM,SAAS,IAAI,OAAO;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AAED,QAAM,SAAS;AAAA;AAAA;AAAA,EAAmF,YAAY;AAAA;AAAA,YAAiB,QAAQ;AACvI,QAAM,gBACJ;AAEF,MAAI;AACF,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR,EAAE,MAAM,UAAU,SAAS,cAAc;AAAA,QACzC,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AACD,UAAM,SAAS,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC1D,WAAO,eAAe,KAAK,UAAU,EAAE,OAAO,CAAC,GAAG,GAAG;AAAA,EACvD,QAAQ;AACN,WAAO,oBAAoB,kBAAkB,GAAG;AAAA,EAClD;AACF,GA1DsB;AA6DtB,IAAM,4BAA4B,8BAAO,SAAS,QAAQ;AACxD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,iDAAiD,GAAG;AAAA,EACjF;AACA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AACA,MAAI,EAAE,OAAO,IAAI;AACjB,MAAI,CAAC,UAAU,OAAO,WAAW,YAAY,CAAC,OAAO,KAAK,GAAG;AAC3D,WAAO,oBAAoB,qDAAqD,GAAG;AAAA,EACrF;AAEA,WAAS,SAAS;AAGlB,MAAI;AACJ,MAAI;AACF,UAAM,YAAY,MAAM,MAAM,gDAAgD;AAAA,MAC5E,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe,UAAU,MAAM;AAAA,MACjC;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP;AAAA,QACA,GAAG;AAAA,QACH,MAAM;AAAA;AAAA,QACN,iBAAiB;AAAA,MACnB,CAAC;AAAA,IACH,CAAC;AACD,QAAI,CAAC,UAAU,IAAI;AACjB,YAAM,MAAM,MAAM,UAAU,KAAK;AACjC,aAAO,oBAAoB,mBAAmB,KAAK,GAAG;AAAA,IACxD;AACA,UAAM,aAAa,MAAM,UAAU,KAAK;AACxC,eAAW,WAAW,KAAK,CAAC,EAAE;AAAA,EAChC,QAAQ;AACN,WAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC5D;AAGA,MAAI;AACJ,MAAI;AACF,UAAM,SAAS,MAAM,MAAM,QAAQ;AACnC,QAAI,CAAC,OAAO,GAAI,OAAM,IAAI,MAAM,0BAA0B;AAC1D,kBAAc,MAAM,OAAO,YAAY;AAAA,EACzC,QAAQ;AACN,WAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC5D;AAGA,QAAM,UAAU,KAAK,IAAI,IAAI,MAAM,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,MAAM,GAAG,EAAE;AACzE,QAAM,WAAW,GAAG,OAAO;AAC3B,MAAI;AACF,UAAM,IAAI,aAAa,IAAI,UAAU,aAAa;AAAA,MAChD,cAAc,EAAE,aAAa,YAAY;AAAA,IAC3C,CAAC;AAAA,EACH,QAAQ;AACN,WAAO,oBAAoB,gCAAgC,GAAG;AAAA,EAChE;AAGA,QAAM,YAAY,6BAA6B,QAAQ;AACvD,QAAM,WAAW,oFAAoF,SAAS;AAC9G,SAAO,eAAe,KAAK,UAAU,EAAE,UAAU,KAAK,UAAU,CAAC,GAAG,GAAG;AACzE,GAtEkC;AAyElC,IAAM,4BAA4B,8BAAO,SAAS,QAAQ;AACxD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,iDAAiD,GAAG;AAAA,EACjF;AACA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AACA,QAAM,EAAE,QAAQ,IAAI;AACpB,MAAI,CAAC,WAAW,OAAO,YAAY,YAAY,CAAC,QAAQ,KAAK,GAAG;AAC9D,WAAO,oBAAoB,sDAAsD,GAAG;AAAA,EACtF;AAGA,QAAM,eAAe;AACrB,QAAM,aAAa,YAAY,OAAO;AAAA;AAAA;AAEtC,MAAI;AACF,UAAM,YAAY,MAAM,MAAM,8CAA8C;AAAA,MAC1E,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe,UAAU,MAAM;AAAA,MACjC;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,aAAa;AAAA,QACb,YAAY;AAAA,QACZ,UAAU;AAAA,UACR,EAAE,MAAM,UAAU,SAAS,aAAa;AAAA,UACxC,EAAE,MAAM,QAAQ,SAAS,WAAW;AAAA,QACtC;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AACD,QAAI,CAAC,UAAU,IAAI;AACjB,YAAM,MAAM,MAAM,UAAU,KAAK;AACjC,aAAO,oBAAoB,mBAAmB,KAAK,GAAG;AAAA,IACxD;AACA,UAAM,aAAa,MAAM,UAAU,KAAK;AACxC,QAAI,SAAS,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAExD,QAAI,OAAO,WAAW,GAAG,KAAK,OAAO,SAAS,GAAG,EAAG,UAAS,OAAO,MAAM,GAAG,EAAE;AAC/E,WAAO,eAAe,KAAK,UAAU,EAAE,OAAO,CAAC,GAAG,GAAG;AAAA,EACvD,QAAQ;AACN,WAAO,oBAAoB,mCAAmC,GAAG;AAAA,EACnE;AACF,GAjDkC;AAmDlC,IAAM,qBAAqB,8BAAO,SAAS,QAAQ;AACjD,QAAMC,QAAO,MAAM,IAAI,aAAa,KAAK;AAEzC,QAAM,SAASA,MAAK,QACjB,OAAO,CAAC,QAAQ,2BAA2B,KAAK,IAAI,GAAG,CAAC,EACxD,IAAI,CAAC,SAAS;AAAA,IACb,KAAK,IAAI;AAAA,IACT,KAAK,6BAA6B,IAAI,GAAG;AAAA,EAC3C,EAAE;AACJ,SAAO,eAAe,KAAK,UAAU,EAAE,OAAO,CAAC,GAAG,GAAG;AACvD,GAV2B;AAa3B,IAAM,sBAAsB,8BAAO,SAAS,QAAQ;AAClD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,kDAAkD,GAAG;AAAA,EAClF;AAEA,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,QAAQ,IAAI,aAAa,IAAI,GAAG;AAEtC,MAAI,CAAC,OAAO;AACV,WAAO,oBAAoB,0CAA0C,GAAG;AAAA,EAC1E;AAEA,UAAQ,IAAI,qCAA8B,EAAE,MAAM,CAAC;AAEnD,MAAI;AAEF,UAAM,YAAY,IAAI,IAAI,8CAA8C;AACxE,cAAU,aAAa,IAAI,QAAQ,YAAY;AAC/C,cAAU,aAAa,IAAI,KAAK,KAAK;AACrC,cAAU,aAAa,IAAI,cAAc,IAAI;AAC7C,cAAU,aAAa,IAAI,OAAO,MAAM;AACxC,cAAU,aAAa,IAAI,QAAQ,OAAO;AAE1C,YAAQ,IAAI,kCAA2B,UAAU,SAAS,CAAC;AAE3D,UAAM,cAAc,MAAM,MAAM,UAAU,SAAS,CAAC;AAEpD,QAAI,CAAC,YAAY,IAAI;AACnB,YAAM,YAAY,MAAM,YAAY,KAAK;AACzC,cAAQ,MAAM,6BAAwB,SAAS;AAC/C,aAAO;AAAA,QACL,sBAAsB,YAAY,MAAM,MAAM,SAAS;AAAA,QACvD,YAAY;AAAA,MACd;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,YAAY,KAAK;AACpC,YAAQ,IAAI,kCAA6B,EAAE,OAAO,KAAK,OAAO,UAAU,EAAE,CAAC;AAG3E,UAAM,WAAW,KAAK,MAAM,IAAI,CAAC,SAAS,KAAK,GAAG,OAAO,EAAE,KAAK,GAAG;AACnE,UAAM,aAAa,gEAAgE,QAAQ,QAAQ,MAAM;AACzG,UAAM,kBAAkB,MAAM,MAAM,UAAU;AAC9C,UAAM,cAAc,MAAM,gBAAgB,KAAK;AAC/C,UAAM,aAAa,CAAC;AACpB,QAAI,YAAY,OAAO;AACrB,iBAAW,QAAQ,YAAY,OAAO;AACpC,mBAAW,KAAK,EAAE,IAAI,KAAK,SAAS,eAAe;AAAA,MACrD;AAAA,IACF;AAGA,UAAM,UACJ,KAAK,OAAO,IAAI,CAAC,UAAU;AAAA,MACzB,SAAS,KAAK,GAAG;AAAA,MACjB,OAAO,KAAK,QAAQ;AAAA,MACpB,aAAa,WAAW,KAAK,GAAG,OAAO,KAAK,KAAK,QAAQ;AAAA,MACzD,cAAc,KAAK,QAAQ;AAAA,MAC3B,aAAa,KAAK,QAAQ;AAAA,MAC1B,YAAY,KAAK,QAAQ;AAAA,IAC3B,EAAE,KAAK,CAAC;AAEV,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT;AAAA,QACA;AAAA,QACA,cAAc,QAAQ;AAAA,MACxB,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,gCAA2B,KAAK;AAC9C,WAAO,oBAAoB,sCAAsC,MAAM,SAAS,GAAG;AAAA,EACrF;AACF,GA3E4B;AA8E5B,IAAM,4BAA4B,8BAAO,SAAS,QAAQ;AACxD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,UAAU,IAAI,SAAS,MAAM,GAAG,EAAE,IAAI;AAE5C,MAAI,CAAC,SAAS;AACZ,WAAO,oBAAoB,wBAAwB,GAAG;AAAA,EACxD;AAEA,QAAM,WAAW,IAAI;AACrB,MAAI,CAAC,UAAU;AACb,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAEA,UAAQ,IAAI,4CAAqC,EAAE,QAAQ,CAAC;AAE5D,MAAI;AAEF,UAAM,WAAW,MAAM,MAAM,qDAAqD;AAAA,MAChF,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,SAAS,QAAQ;AAAA,QAChC,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,KAAK,CAAC,OAAO;AAAA,MACf,CAAC;AAAA,IACH,CAAC;AAED,YAAQ,IAAI,wDAAiD,SAAS,MAAM;AAE5E,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,2CAAsC,SAAS;AAC7D,aAAO;AAAA,QACL,oCAAoC,SAAS,MAAM,MAAM,SAAS;AAAA,QAClE,SAAS;AAAA,MACX;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAQ,IAAI,yCAAoC,EAAE,SAAS,SAAS,CAAC,CAAC,KAAK,CAAC;AAE5E,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT;AAAA,QACA,YAAY;AAAA,MACd,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,uCAAkC,KAAK;AACrD,WAAO,oBAAoB,uCAAuC,MAAM,SAAS,GAAG;AAAA,EACtF;AACF,GAxDkC;AA2DlC,IAAM,6BAA6B,8BAAO,SAAS,QAAQ;AACzD,QAAM,WAAW,IAAI;AACrB,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,oDAAoD,GAAG;AAAA,EACpF;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,IAAI,IAAI;AAChB,MAAI,CAAC,KAAK;AACR,WAAO,oBAAoB,mBAAmB,GAAG;AAAA,EACnD;AAEA,UAAQ,IAAI,kCAA2B,EAAE,IAAI,CAAC;AAE9C,MAAI;AAEF,UAAM,WAAW,MAAM,MAAM,oCAAoC;AAAA,MAC/D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,QAAQ;AAAA,QACjC,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,YAAQ,IAAI,0CAAmC,SAAS,MAAM;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,6BAAwB,SAAS;AAC/C,aAAO;AAAA,QACL,sBAAsB,SAAS,MAAM,MAAM,SAAS;AAAA,QACpD,SAAS;AAAA,MACX;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAQ,IAAI,+BAA0B,EAAE,KAAK,SAAS,CAAC,CAAC,KAAK,CAAC;AAE9D,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,aAAa;AAAA,QACb,YAAY;AAAA,MACd,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,6BAAwB,KAAK;AAC3C,WAAO,oBAAoB,uCAAuC,MAAM,SAAS,GAAG;AAAA,EACtF;AACF,GA1DmC;AA6DnC,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AACtD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,UAAU,IAAI,SAAS,MAAM,GAAG,EAAE,IAAI;AAE5C,MAAI,CAAC,SAAS;AACZ,WAAO,oBAAoB,wBAAwB,GAAG;AAAA,EACxD;AAEA,QAAM,WAAW,IAAI;AACrB,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,oDAAoD,GAAG;AAAA,EACpF;AAGA,QAAM,aAAa,mCAAmC,OAAO;AAE7D,UAAQ,IAAI,8BAAuB,EAAE,SAAS,WAAW,CAAC;AAE1D,MAAI;AAEF,UAAM,WAAW,MAAM,MAAM,oCAAoC;AAAA,MAC/D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,QAAQ;AAAA,QACjC,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,KAAK;AAAA,MACP,CAAC;AAAA,IACH,CAAC;AAED,YAAQ,IAAI,0CAAmC,SAAS,MAAM;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,6BAAwB,SAAS;AAC/C,aAAO;AAAA,QACL,sBAAsB,SAAS,MAAM,MAAM,SAAS;AAAA,QACpD,SAAS;AAAA,MACX;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAQ,IAAI,2BAAsB,EAAE,SAAS,SAAS,CAAC,CAAC,KAAK,CAAC;AAE9D,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT;AAAA,QACA;AAAA,QACA,YAAY;AAAA,MACd,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,yBAAoB,KAAK;AACvC,WAAO,oBAAoB,uCAAuC,MAAM,SAAS,GAAG;AAAA,EACtF;AACF,GAzDgC;AA4DhC,eAAe,oBAAoB,SAAS;AAC1C,QAAM,WAAW,QAAQ,QAAQ,IAAI,aAAa;AAClD,MAAI,CAAC,UAAU;AACb,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,oBAAoB,CAAC,GAAG;AAAA,MAClE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,+BAA+B;AAAA,QAC/B,gBAAgB;AAAA,MAClB;AAAA,IACF,CAAC;AAAA,EACH;AAEA,MAAI;AACF,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,UAAM,WAAW,MAAM,MAAM,iDAAiD;AAAA,MAC5E,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe;AAAA,MACjB;AAAA,MACA,MAAM,KAAK,UAAU,IAAI;AAAA,IAC3B,CAAC;AAED,QAAI;AACJ,UAAM,cAAc,SAAS,QAAQ,IAAI,cAAc,KAAK;AAC5D,QAAI,YAAY,SAAS,kBAAkB,GAAG;AAC5C,eAAS,MAAM,SAAS,KAAK;AAAA,IAC/B,OAAO;AACL,YAAM,OAAO,MAAM,SAAS,KAAK;AACjC,cAAQ,IAAI,6BAA6B,IAAI;AAC7C,eAAS,EAAE,OAAO,mCAAmC,QAAQ,SAAS,QAAQ,KAAK,KAAK;AAAA,IAC1F;AAEA,WAAO,IAAI,SAAS,KAAK,UAAU,MAAM,GAAG;AAAA,MAC1C,QAAQ,SAAS;AAAA,MACjB,SAAS;AAAA,QACP,+BAA+B;AAAA,QAC/B,gBAAgB;AAAA,MAClB;AAAA,IACF,CAAC;AAAA,EACH,QAAQ;AACN,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,yCAAyC,CAAC,GAAG;AAAA,MACvF,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,+BAA+B;AAAA,QAC/B,gBAAgB;AAAA,MAClB;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAjDe;AAoDf,IAAM,wBAAwB,8BAAO,SAAS,QAAQ;AACpD,MAAI,CAAC,IAAI,gBAAgB;AACvB,WAAO,oBAAoB,iCAAiC,GAAG;AAAA,EACjE;AAEA,MAAI;AACF,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,QAAI,EAAE,QAAQ,QAAQ,YAAY,OAAO,YAAY,IAAI;AAEzD,YAAQ,IAAI,8CAA8C;AAC1D,YAAQ,IAAI,4BAA4B,KAAK;AAC7C,YAAQ,IAAI,2BAA2B,IAAI;AAC3C,YAAQ,IAAI,kBAAkB,QAAQ,UAAU,CAAC;AACjD,YAAQ,IAAI,mBAAmB,QAAQ,UAAU,GAAG,GAAG,IAAI,KAAK;AAEhE,QAAI,CAAC,QAAQ;AACX,aAAO,oBAAoB,sBAAsB,GAAG;AAAA,IACtD;AAGA,QAAI,UAAU;AACd,QAAI,OAAO,SAAS,GAAG,GAAG;AACxB,YAAM,QAAQ,OAAO,MAAM,GAAG;AAC9B,YAAM,YAAY,MAAM,KAAK,CAAC,MAAM,EAAE,WAAW,QAAQ,CAAC;AAC1D,YAAM,WAAW,MAAM,KAAK,CAAC,MAAM,EAAE,WAAW,OAAO,CAAC;AACxD,YAAM,cAAc,MAAM,KAAK,CAAC,MAAM,EAAE,WAAW,UAAU,CAAC;AAE9D,UAAI,WAAW;AACb,cAAM,cAAc,UAAU,QAAQ,UAAU,EAAE,EAAE,KAAK;AACzD,gBAAQ,IAAI,oCAA6B,WAAW;AACpD,gBAAQ;AAAA,MACV;AAEA,UAAI,UAAU;AACZ,cAAM,aAAa,SAAS,QAAQ,SAAS,EAAE,EAAE,KAAK;AACtD,gBAAQ,IAAI,mCAA4B,UAAU;AAClD,eAAO;AAAA,MACT;AAEA,UAAI,aAAa;AACf,cAAM,gBAAgB,YAAY,QAAQ,YAAY,EAAE,EAAE,KAAK;AAC/D,gBAAQ,IAAI,sCAA+B,aAAa;AACxD,kBAAU;AAAA,MACZ;AAAA,IACF;AAGA,QAAI,YAAY,QAAQ;AACtB,UAAI,UAAU,eAAe;AAC3B,kBAAU;AAAA,MACZ,WAAW,UAAU,YAAY;AAC/B,kBAAU;AAAA,MACZ,WAAW,UAAU,YAAY;AAC/B,kBAAU;AAAA,MACZ;AAAA,IACF;AAGA,UAAM,oBAAoB;AAAA,MACxB,eAAe,CAAC,QAAQ,QAAQ,UAAU,KAAK;AAAA,MAC/C,YAAY,CAAC,MAAM,UAAU;AAAA,MAC7B,YAAY,CAAC,UAAU;AAAA,IACzB;AAEA,QAAI,CAAC,kBAAkB,KAAK,EAAE,SAAS,OAAO,GAAG;AAC/C,cAAQ,MAAM,qCAAgC;AAAA,QAC5C;AAAA,QACA;AAAA,QACA,OAAO,kBAAkB,KAAK;AAAA,MAChC,CAAC;AACD,aAAO;AAAA,QACL,oBAAoB,OAAO,gBAAgB,KAAK,qBAAqB,kBAAkB,KAAK,EAAE,KAAK,IAAI,CAAC;AAAA,QACxG;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,IAAI,iCAA0B,KAAK;AAC3C,YAAQ,IAAI,gCAAyB,IAAI;AACzC,YAAQ,IAAI,mCAA4B,OAAO;AAG/C,UAAM,cAAc,CAAC,YAAY,YAAY,aAAa;AAC1D,QAAI,CAAC,YAAY,SAAS,KAAK,GAAG;AAChC,cAAQ,MAAM,mCAA8B,KAAK;AACjD,aAAO,oBAAoB,oCAAoC,YAAY,KAAK,IAAI,GAAG,GAAG;AAAA,IAC5F;AAEA,YAAQ,IAAI,uCAAkC,KAAK;AAGnD,UAAM,aAAa;AAAA,MACjB,YAAY,CAAC,WAAW,WAAW,WAAW;AAAA,MAC9C,YAAY,CAAC,aAAa,aAAa,WAAW;AAAA,MAClD,eAAe,CAAC,aAAa,aAAa,aAAa,MAAM;AAAA,IAC/D;AAEA,QAAI,CAAC,WAAW,KAAK,EAAE,SAAS,IAAI,GAAG;AACrC,aAAO;AAAA,QACL,0BAA0B,KAAK,qBAAqB,WAAW,KAAK,EAAE,KAAK,IAAI,CAAC;AAAA,QAChF;AAAA,MACF;AAAA,IACF;AAGA,UAAM,cAAc;AAAA,MAClB;AAAA,MACA;AAAA,MACA;AAAA,MACA,GAAG;AAAA,IACL;AAGA,QAAI,UAAU,cAAc,UAAU,eAAe;AACnD,kBAAY,UAAU;AACtB,cAAQ,IAAI,0CAAmC,OAAO;AAAA,IACxD,OAAO;AACL,cAAQ,IAAI,4CAAqC,OAAO,iBAAiB;AAAA,IAC3E;AAGA,QAAI,MAAM,WAAW,QAAQ,GAAG;AAC9B,kBAAY,kBAAkB;AAC9B,cAAQ,IAAI,uDAAgD;AAAA,IAC9D,OAAO;AACL,cAAQ,IAAI,6DAAsD;AAAA,IACpE;AAEA,YAAQ,IAAI,2BAAoB,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAGpE,YAAQ,IAAI,kDAA2C;AACvD,UAAM,WAAW,MAAM,MAAM,gDAAgD;AAAA,MAC3E,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe,UAAU,IAAI,cAAc;AAAA,MAC7C;AAAA,MACA,MAAM,KAAK,UAAU,WAAW;AAAA,IAClC,CAAC;AAED,YAAQ,IAAI,yCAAkC,SAAS,QAAQ,SAAS,UAAU;AAElF,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,aAAO;AAAA,QACL,MAAM,OAAO,WAAW;AAAA,QACxB,SAAS;AAAA,MACX;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAQ,IAAI,gCAAyB,OAAO,KAAK,IAAI,CAAC;AACtD,YAAQ,IAAI,gCAAyB,KAAK,MAAM,UAAU,CAAC;AAC3D,QAAI,KAAK,OAAO,CAAC,GAAG;AAClB,cAAQ,IAAI,mCAA4B,OAAO,KAAK,KAAK,KAAK,CAAC,CAAC,CAAC;AAAA,IACnE;AAGA,QAAI,YAAY;AAChB,QAAI,cAAc;AAGlB,QAAI,OAAO,SAAS,GAAG,GAAG;AACxB,YAAM,QAAQ,OAAO,MAAM,GAAG;AAC9B,YAAM,aAAa,MAAM,KAAK,CAAC,MAAM,EAAE,WAAW,SAAS,CAAC;AAC5D,YAAM,WAAW,MAAM,KAAK,CAAC,MAAM,EAAE,WAAW,OAAO,CAAC;AAExD,UAAI,YAAY;AACd,sBAAc,WAAW,QAAQ,WAAW,EAAE;AAAA,MAChD;AACA,UAAI,UAAU;AACZ,oBAAY,SAAS,QAAQ,SAAS,EAAE;AAAA,MAC1C;AAAA,IACF;AAGA,QAAI,MAAM,WAAW,QAAQ,GAAG;AAC9B,cAAQ,IAAI,mDAA4C;AACxD,YAAM,WAAW,KAAK,KAAK,CAAC,EAAE;AAC9B,cAAQ,IAAI,iCAA0B,UAAU,UAAU,GAAG,EAAE,IAAI,KAAK;AAGxE,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,mBAAmB,KAAK,IAAI,CAAC;AAAA,UACjC,OAAO,aAAa,UAAU,OAAO,CAAC,EAAE,YAAY,IAAI,UAAU,MAAM,CAAC,CAAC;AAAA,UAC1E,MAAM;AAAA,UACN,MAAM;AAAA;AAAA,UACN,OAAO;AAAA,UACP,MAAM,CAAC,mBAAmB,KAAK,KAAK,OAAO,2BAA2B,WAAW,GAAG;AAAA,UACpF,YAAY;AAAA,UACZ,aAAa;AAAA,UACb,UAAU;AAAA,YACR,iBAAiB;AAAA;AAAA,YACjB,gBAAgB;AAAA,YAChB;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA,eAAe;AAAA;AAAA,UACjB;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF,OAAO;AACL,cAAQ,IAAI,yDAAkD;AAC9D,YAAM,aAAa,KAAK,KAAK,CAAC,EAAE;AAChC,cAAQ,IAAI,iCAA0B,YAAY,UAAU,CAAC;AAE7D,UAAI,CAAC,YAAY;AACf,gBAAQ,MAAM,+CAA0C;AACxD,eAAO,oBAAoB,mCAAmC,GAAG;AAAA,MACnE;AAGA,YAAM,iBAAiB,yBAAyB,UAAU;AAG1D,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,IAAI,mBAAmB,KAAK,IAAI,CAAC;AAAA,UACjC,OAAO,aAAa,UAAU,OAAO,CAAC,EAAE,YAAY,IAAI,UAAU,MAAM,CAAC,CAAC;AAAA,UAC1E,MAAM;AAAA,UACN,MAAM;AAAA;AAAA,UACN,OAAO;AAAA,UACP,MAAM,CAAC,mBAAmB,KAAK,KAAK,OAAO,2BAA2B,WAAW,GAAG;AAAA,UACpF,YAAY;AAAA,UACZ,aAAa;AAAA,UACb,UAAU;AAAA,YACR,iBAAiB;AAAA;AAAA,YACjB;AAAA;AAAA,YACA,gBAAgB;AAAA,YAChB;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA,eAAe;AAAA;AAAA,UACjB;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,mCAAmC,KAAK;AACtD,WAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC5D;AACF,GApP8B;AAuP9B,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AACtD,MAAI,CAAC,IAAI,cAAc;AACrB,WAAO,oBAAoB,4BAA4B,GAAG;AAAA,EAC5D;AAEA,MAAI;AACF,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,UAAM,EAAE,UAAU,IAAI;AAEtB,QAAI,CAAC,aAAa,CAAC,UAAU,UAAU;AACrC,aAAO,oBAAoB,+BAA+B,GAAG;AAAA,IAC/D;AAEA,UAAM,EAAE,iBAAiB,YAAY,gBAAgB,WAAW,OAAO,MAAM,QAAQ,IACnF,UAAU;AAEZ,YAAQ,IAAI,kCAAkC;AAC9C,YAAQ,IAAI,UAAU,KAAK;AAC3B,YAAQ,IAAI,eAAe,SAAS;AACpC,YAAQ,IAAI,SAAS,IAAI;AAEzB,QAAI;AACJ,QAAI,cAAc;AAGlB,QAAI,YAAY;AAEd,cAAQ,IAAI,2CAAoC;AAChD,YAAM,aAAa,KAAK,UAAU;AAClC,YAAM,QAAQ,IAAI,WAAW,WAAW,MAAM;AAC9C,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,cAAM,CAAC,IAAI,WAAW,WAAW,CAAC;AAAA,MACpC;AACA,oBAAc;AACd,cAAQ,IAAI,4CAAuC,MAAM,QAAQ,OAAO;AAAA,IAC1E,WAAW,mBAAmB,gBAAgB,WAAW,MAAM,GAAG;AAEhE,cAAQ,IAAI,4CAAkC;AAC9C,YAAM,WAAW,MAAM,MAAM,eAAe;AAC5C,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI,MAAM,2CAA2C;AAAA,MAC7D;AACA,YAAM,cAAc,MAAM,SAAS,YAAY;AAC/C,oBAAc,IAAI,WAAW,WAAW;AACxC,cAAQ,IAAI,yCAAoC,YAAY,QAAQ,OAAO;AAAA,IAC7E,OAAO;AACL,YAAM,IAAI,MAAM,6BAA6B;AAAA,IAC/C;AAGA,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,WAAW,gBAAgB,SAAS,IAAI,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,GAAG,EAAE,CAAC;AACzF,YAAQ,IAAI,iCAA0B,QAAQ;AAG9C,YAAQ,IAAI,wCAA8B;AAC1C,UAAM,IAAI,aAAa,IAAI,UAAU,aAAa;AAAA,MAChD,cAAc;AAAA,QACZ;AAAA,MACF;AAAA,IACF,CAAC;AACD,YAAQ,IAAI,2BAAsB;AAGlC,UAAM,gBAAgB,6BAA6B,QAAQ;AAC3D,QAAI,gBAAgB;AAEpB,YAAQ,UAAU,YAAY,GAAG;AAAA,MAC/B,KAAK;AACH,wBAAgB,wFAAwF,aAAa;AACrH;AAAA,MACF,KAAK;AACH,wBAAgB,6FAA6F,aAAa;AAC1H;AAAA,MACF,KAAK;AACH,wBAAgB,8FAA8F,aAAa;AAC3H;AAAA,MACF;AACE,wBAAgB,sEAAsE,aAAa;AAAA,IACvG;AAEA,YAAQ,IAAI,8CAAuC;AACnD,YAAQ,IAAI,8BAAuB,aAAa;AAGhD,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,IAAI,kBAAkB,KAAK,IAAI,CAAC;AAAA,QAChC,OAAO,aAAa,UAAU,OAAO,CAAC,EAAE,YAAY,IAAI,UAAU,MAAM,CAAC,CAAC;AAAA,QAC1E,MAAM;AAAA,QACN,MAAM;AAAA,QACN,OAAO;AAAA,QACP,MAAM,CAAC,mBAAmB,KAAK,KAAK,OAAO,2BAA2B,cAAc,GAAG;AAAA,QACvF,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,UAAU;AAAA,UACR,mBAAmB;AAAA,UACnB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,UAAU;AAAA,UACV,UAAS,oBAAI,KAAK,GAAE,YAAY;AAAA,QAClC;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,qCAAqC,KAAK;AACxD,WAAO,oBAAoB,oCAAoC,MAAM,SAAS,GAAG;AAAA,EACnF;AACF,GA/GgC;AAkHhC,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AACtD,MAAI;AACF,YAAQ,IAAI,wCAAwC;AAEpD,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,YAAQ,IAAI,sBAAsB,OAAO,KAAK,IAAI,CAAC;AAEnD,UAAM,EAAE,YAAY,gBAAgB,eAAe,IAAI;AAEvD,QAAI,CAAC,YAAY;AACf,cAAQ,MAAM,oCAAoC;AAClD,aAAO,oBAAoB,2BAA2B,GAAG;AAAA,IAC3D;AAEA,YAAQ,IAAI,+BAA+B;AAC3C,YAAQ,IAAI,sBAAsB,WAAW,MAAM;AACnD,YAAQ,IAAI,oBAAoB,cAAc;AAC9C,YAAQ,IAAI,oBAAoB,cAAc;AAG9C,UAAM,SAAS,IAAI;AACnB,QAAI,CAAC,QAAQ;AACX,cAAQ,MAAM,uCAAuC;AACrD,aAAO,oBAAoB,+BAA+B,GAAG;AAAA,IAC/D;AACA,YAAQ,IAAI,uBAAuB,OAAO,UAAU,GAAG,EAAE,IAAI,KAAK;AAGlE,UAAM,kBAAkB,WAAW,MAAM,KAAK,EAAE;AAChD,YAAQ,IAAI,0BAA0B,eAAe;AAErD,QAAI;AACJ,QAAI,YAAY;AAEhB,QAAI,mBAAmB,YAAY;AAEjC,cAAQ,IAAI,kCAAkC;AAC9C,kBAAY;AAEZ,eAAS;AAAA;AAAA,mBAEI,mBAAmB,SAAS,gBAAgB,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAa3E,UAAU;AAAA;AAAA;AAAA,IAGR,OAAO;AAEL,UAAI,kBAAkB,KAAM;AAE1B,gBAAQ;AAAA,UACN;AAAA,QACF;AACA,oBAAY;AAEZ,iBAAS;AAAA;AAAA,UAEP,mBAAmB,SAAS,gBAAgB,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAalE,UAAU;AAAA;AAAA;AAAA,MAGN,OAAO;AAEL,gBAAQ;AAAA,UACN;AAAA,QACF;AAEA,iBAAS;AAAA;AAAA,UAEP,mBAAmB,SAAS,gBAAgB,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAgBlE,UAAU;AAAA;AAAA;AAAA,MAGN;AAAA,IACF;AAEA,YAAQ,IAAI,wBAAwB;AAEpC,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB;AAAA,MACA,SAAS;AAAA,IACX,CAAC;AAED,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,YAAQ,IAAI,4CAA4C;AACxD,UAAM,qBAAqB,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAEtE,YAAQ,IAAI,qCAAqC,mBAAmB,MAAM;AAG1E,QAAI;AACF,YAAM,cAAc,KAAK,MAAM,kBAAkB;AAGjD,UAAI,CAAC,YAAY,SAAS,CAAC,MAAM,QAAQ,YAAY,KAAK,GAAG;AAC3D,cAAM,IAAI,MAAM,wDAAwD;AAAA,MAC1E;AAGA,kBAAY,QAAQ,YAAY,MAAM,IAAI,CAAC,UAAU;AAAA,QACnD,GAAG;AAAA,QACH,IAAI,KAAK,MAAM,YAAY,KAAK,IAAI,CAAC,IAAI,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,OAAO,GAAG,CAAC,CAAC;AAAA,QAChF,SAAS;AAAA,QACT,MAAM;AAAA,MACR,EAAE;AAEF,cAAQ,IAAI,0BAA0B,YAAY,MAAM,QAAQ,OAAO;AAEvE,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,gBAAgB;AAAA,UAChB,OAAO;AAAA,YACL,YAAY,YAAY,MAAM;AAAA,YAC9B,gBAAgB,KAAK,IAAI;AAAA,YACzB;AAAA,YACA;AAAA,YACA,WAAW;AAAA,YACX;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF,SAAS,YAAY;AACnB,cAAQ,MAAM,iCAAiC,UAAU;AACzD,cAAQ,IAAI,iBAAiB,kBAAkB;AAG/C,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,gBAAgB,EAAE,OAAO,CAAC,GAAG,OAAO,CAAC,EAAE;AAAA,UACvC,OAAO;AAAA,UACP,aAAa;AAAA,QACf,CAAC;AAAA,QACD;AAAA,MACF;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,qCAAqC,KAAK;AACxD,WAAO,oBAAoB,MAAM,WAAW,yBAAyB,GAAG;AAAA,EAC1E;AACF,GA9LgC;AAiMhC,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,EAAE,aAAa,SAAS,UAAU,aAAa,YAAY,IAAI,MAAM,QAAQ,KAAK;AAExF,YAAQ,IAAI,gCAAgC;AAC5C,YAAQ,IAAI,gBAAgB,WAAW;AACvC,YAAQ,IAAI,YAAY,OAAO;AAC/B,YAAQ,IAAI,aAAa,QAAQ;AACjC,YAAQ,IAAI,gBAAgB,WAAW;AACvC,YAAQ,IAAI,gBAAgB,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAChE,YAAQ,IAAI,qBAAqB,OAAO,WAAW;AACnD,YAAQ;AAAA,MACN;AAAA,MACA,cAAc,OAAO,KAAK,WAAW,EAAE,SAAS;AAAA,IAClD;AACA,YAAQ,IAAI,iCAAiC;AAE7C,QAAI,CAAC,aAAa;AAChB,aAAO,oBAAoB,iCAAiC,GAAG;AAAA,IACjE;AAGA,QAAI;AACJ,QAAI;AACF,cAAQ,IAAI,0DAA0D;AACtE,UAAI,CAAC,IAAI,WAAW;AAClB,gBAAQ,MAAM,oCAAoC;AAClD,cAAM,IAAI,MAAM,oCAAoC;AAAA,MACtD;AAEA,YAAM,oBAAoB,MAAM,IAAI,UAAU;AAAA,QAC5C;AAAA,MACF;AACA,cAAQ,IAAI,8BAA8B,kBAAkB,MAAM;AAElE,UAAI,CAAC,kBAAkB,IAAI;AACzB,cAAM,YAAY,MAAM,kBAAkB,KAAK;AAC/C,gBAAQ,MAAM,6BAA6B,SAAS;AACpD,cAAM,IAAI,MAAM,8BAA8B,kBAAkB,MAAM,MAAM,SAAS,EAAE;AAAA,MACzF;AAEA,YAAM,gBAAgB,MAAM,kBAAkB,KAAK;AACnD,UAAI,CAAC,cAAc,WAAW,CAAC,MAAM,QAAQ,cAAc,OAAO,GAAG;AACnE,cAAM,IAAI,MAAM,uDAAuD;AAAA,MACzE;AACA,kBAAY,cAAc;AAC1B,cAAQ,IAAI,mCAAmC,SAAS;AAAA,IAC1D,SAAS,OAAO;AACd,cAAQ,MAAM,sCAAsC,KAAK;AACzD,aAAO,oBAAoB,8BAA8B,MAAM,OAAO,IAAI,GAAG;AAAA,IAC/E;AAGA,QAAI,eAAe;AACnB,QAAI,SAAS;AACX,UAAI;AACF,cAAM,gBAAgB,MAAM,IAAI,UAAU;AAAA,UACxC,iDAAiD,OAAO;AAAA,QAC1D;AACA,YAAI,cAAc,IAAI;AACpB,gBAAM,YAAY,MAAM,cAAc,KAAK;AAC3C,cAAI,WAAW,OAAO;AACpB,2BAAe,UAAU,MACtB,OAAO,CAACC,UAASA,MAAK,YAAY,KAAK,EACvC,IAAI,CAACA,UAAS,SAASA,MAAK,KAAK;AAAA,QAAWA,MAAK,IAAI;AAAA,QAAWA,MAAK,QAAQ,EAAE,EAAE,EACjF,KAAK,MAAM;AAAA,UAChB;AAAA,QACF;AAAA,MACF,SAAS,OAAO;AACd,gBAAQ,MAAM,iCAAiC,KAAK;AAAA,MACtD;AAAA,IACF;AAGA,QAAI,eAAe;AACnB,QAAI,gBAAgB,aAAa,aAAa;AAC5C,qBAAe;AAAA,EAA0B,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAAA,IAC/E,WAAW,gBAAgB,SAAS,aAAa;AAC/C,qBAAe;AAAA,EAAuB,YAAY;AAAA,IACpD;AAGA,UAAM,SAAS;AAAA;AAAA,gBAEH,WAAW;AAAA,EACzB,WAAW,cAAc,QAAQ,KAAK,EAAE;AAAA;AAAA;AAAA,EAGxC,UACC;AAAA,MACC,CAAC,MAAM,aAAa,EAAE,KAAK;AAAA,QACvB,EAAE,IAAI;AAAA,gBACE,KAAK,UAAU,EAAE,OAAO,MAAM,CAAC,CAAC;AAAA,mBAC7B,EAAE,mBAAmB,oCAAoC;AAAA,IAC1E,EACC,KAAK,IAAI,CAAC;AAAA;AAAA,EAEX,eAAe;AAAA;AAAA,EAA8B,YAAY,KAAK,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAW9D,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB,QAAQ,IAAI;AAAA,MACZ,SAAS;AAAA,IACX,CAAC;AAED,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,SAAS,KAAK,MAAM,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK,CAAC;AACtE,UAAM,mBAAmB,UAAU,KAAK,CAAC,MAAM,EAAE,OAAO,OAAO,QAAQ,KAAK,UAAU,CAAC;AAGvF,UAAM,OAAO;AAAA,MACX,IAAI,OAAO,WAAW;AAAA,MACtB,OAAO,iBAAiB,MAAM;AAAA,MAC9B,OAAO,iBAAiB,MAAM;AAAA,MAC9B,MAAM,iBAAiB,MAAM;AAAA,MAC7B,MAAM,OAAO;AAAA,MACb,MAAM,iBAAiB,MAAM,QAAQ,CAAC;AAAA,MACtC,YAAY,iBAAiB,MAAM;AAAA,MACnC,aAAa,iBAAiB,MAAM;AAAA,MACpC,SAAS;AAAA,MACT,MAAM,iBAAiB,MAAM,QAAQ;AAAA,IACvC;AAGA,QAAI,OAAO,KAAK,SAAS,YAAY,KAAK,SAAS,MAAM;AACvD,YAAM,UAAU,KAAK;AACrB,WAAK,OAAO,QAAQ,QAAQ;AAC5B,WAAK,QAAQ,QAAQ,SAAS,KAAK;AACnC,WAAK,QAAQ,QAAQ,SAAS,KAAK;AACnC,WAAK,OAAO,QAAQ,QAAQ,KAAK;AACjC,WAAK,OAAO,QAAQ,QAAQ,KAAK;AACjC,WAAK,aAAa,QAAQ,cAAc,KAAK;AAC7C,WAAK,cAAc,QAAQ,eAAe,KAAK;AAC/C,WAAK,OAAO,QAAQ,QAAQ,KAAK;AAAA,IACnC;AAEA,WAAO,eAAe,KAAK,UAAU,EAAE,KAAK,CAAC,CAAC;AAAA,EAChD,SAAS,OAAO;AACd,YAAQ,MAAM,kCAAkC,KAAK;AACrD,WAAO,oBAAoB,MAAM,WAAW,yBAAyB,GAAG;AAAA,EAC1E;AACF,GAlK6B;AAqK7B,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,EAAE,WAAW,aAAa,gBAAgB,IAAI,MAAM,QAAQ,KAAK;AAEvE,YAAQ,IAAI,gCAAgC;AAC5C,YAAQ,IAAI,gBAAgB,WAAW;AACvC,YAAQ,IAAI,oBAAoB,WAAW,OAAO,UAAU,CAAC;AAC7D,YAAQ,IAAI,uBAAuB,WAAW,YAAY,CAAC,CAAC;AAC5D,YAAQ,IAAI,oBAAoB,eAAe;AAC/C,YAAQ,IAAI,iCAAiC;AAE7C,QAAI,CAAC,aAAa,CAAC,UAAU,SAAS,CAAC,MAAM,QAAQ,UAAU,KAAK,GAAG;AACrE,aAAO,oBAAoB,0CAA0C,GAAG;AAAA,IAC1E;AAGA,YAAQ,IAAI,gDAAgD;AAC5D,UAAM,qBAAqB,CAAC;AAC5B,QAAI;AACF,YAAM,iBAAiB;AACvB,YAAM,kBAAkB,MAAM,IAAI,YAAY,QAAQ,cAAc,EAAE,IAAI;AAE1E,cAAQ,IAAI,SAAS,gBAAgB,SAAS,UAAU,CAAC,wBAAwB;AAEjF,iBAAW,YAAY,gBAAgB,WAAW,CAAC,GAAG;AACpD,YAAI;AACF,gBAAM,gBAAgB,KAAK,MAAM,SAAS,SAAS,IAAI;AACvD,kBAAQ,IAAI,YAAY,SAAS,IAAI,QAAQ,cAAc,MAAM,QAAQ;AAEzE,cAAI,cAAc,SAAS,GAAG;AAC5B,kBAAM,WAAW,cAAc,CAAC,EAAE;AAClC,oBAAQ,IAAI,YAAY,SAAS,IAAI,iBAAiB,QAAQ,EAAE;AAEhE,gBAAI,UAAU;AACZ,iCAAmB,KAAK;AAAA,gBACtB;AAAA,gBACA,MAAM,SAAS;AAAA,gBACf,IAAI,SAAS;AAAA,cACf,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF,SAAS,GAAG;AACV,kBAAQ,KAAK,0BAA0B,SAAS,EAAE,KAAK,EAAE,OAAO;AAAA,QAClE;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,cAAQ,MAAM,8BAA8B,KAAK;AAAA,IACnD;AAEA,YAAQ,IAAI,6CAA6C;AACzD,uBAAmB,QAAQ,CAAC,MAAM;AAChC,cAAQ,IAAI,OAAO,EAAE,QAAQ,KAAK,EAAE,IAAI,GAAG;AAAA,IAC7C,CAAC;AAGD,UAAM,gBAAgB,UAAU,YAAY,CAAC;AAC7C,UAAM,aAAa,UAAU,SAAS,CAAC;AAEvC,UAAM,aAAa,cAAc,WAC7B,cAAc,SACX,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,EACnB,OAAO,CAAC,MAAM,CAAC,IAClB,CAAC;AACL,UAAM,YAAY,cAAc,WAC5B,cAAc,SACX,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,EACnB,OAAO,CAAC,MAAM,CAAC,IAClB,CAAC;AAEL,YAAQ,IAAI,6BAA6B,UAAU;AACnD,YAAQ,IAAI,4BAA4B,SAAS;AAGjD,UAAM,gBAAgB,CAAC;AACvB,QAAI,WAAW,SAAS,KAAK,UAAU,SAAS,GAAG;AACjD,UAAI;AACF,cAAM,cAAc;AACpB,cAAM,eAAe,MAAM,IAAI,YAAY,QAAQ,WAAW,EAAE,IAAI;AAEpE,mBAAW,SAAS,aAAa,WAAW,CAAC,GAAG;AAC9C,cAAI;AACF,kBAAMC,aAAY,KAAK,MAAM,MAAM,QAAQ,IAAI;AAC/C,kBAAMC,iBAAgBD,WAAU,YAAY,CAAC;AAE7C,kBAAM,kBAAkBC,eAAc,WAClCA,eAAc,SACX,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,EACnB,OAAO,CAAC,MAAM,CAAC,IAClB,CAAC;AACL,kBAAM,iBAAiBA,eAAc,WACjCA,eAAc,SACX,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,EACnB,OAAO,CAAC,MAAM,CAAC,IAClB,CAAC;AAGL,kBAAM,kBAAkB,WAAW;AAAA,cAAK,CAAC,QACvC,gBAAgB,KAAK,CAAC,OAAO,GAAG,YAAY,EAAE,SAAS,IAAI,YAAY,CAAC,CAAC;AAAA,YAC3E;AACA,kBAAM,kBAAkB,UAAU;AAAA,cAAK,CAAC,SACtC,eAAe,KAAK,CAAC,OAAO,GAAG,YAAY,EAAE,SAAS,KAAK,YAAY,CAAC,CAAC;AAAA,YAC3E;AAEA,gBAAI,mBAAmB,iBAAiB;AACtC,4BAAc,KAAK;AAAA,gBACjB,IAAI,MAAM;AAAA,gBACV,OAAO,MAAM;AAAA,gBACb,YAAY;AAAA,gBACZ,WAAW;AAAA,cACb,CAAC;AAAA,YACH;AAAA,UACF,SAAS,GAAG;AACV,oBAAQ,KAAK,uBAAuB,MAAM,EAAE,KAAK,EAAE,OAAO;AAAA,UAC5D;AAAA,QACF;AAAA,MACF,SAAS,OAAO;AACd,gBAAQ,MAAM,kCAAkC,KAAK;AAAA,MACvD;AAAA,IACF;AAEA,YAAQ,IAAI,yBAAyB,cAAc,MAAM;AACzD,YAAQ,IAAI,mBAAmB,cAAc,IAAI,CAAC,MAAM,GAAG,EAAE,KAAK,KAAK,EAAE,EAAE,GAAG,EAAE,KAAK,IAAI,CAAC;AAG1F,UAAM,gBAAgB,WACnB,OAAO,CAAC,SAAS,KAAK,YAAY,SAAS,KAAK,IAAI,EACpD,IAAI,CAAC,UAAU;AAAA,MACd,OAAO,KAAK,SAAS;AAAA,MACrB,MAAM,KAAK,QAAQ;AAAA,MACnB,SAAS,KAAK,KAAK,UAAU,GAAG,GAAG,IAAI;AAAA,MACvC,YAAY,CAAC,CAAC,KAAK;AAAA,IACrB,EAAE,EACD,MAAM,GAAG,EAAE;AAGd,UAAM,kBAAkB;AAAA,MACtB,EAAE,MAAM,KAAK,OAAO,QAAQ,MAAM,YAAK;AAAA,MACvC,EAAE,MAAM,iBAAiB,OAAO,UAAU,MAAM,eAAK;AAAA,MACrD,EAAE,MAAM,iBAAiB,OAAO,UAAU,MAAM,YAAK;AAAA,MACrD,EAAE,MAAM,oBAAoB,OAAO,aAAa,MAAM,YAAK;AAAA,MAC3D,EAAE,MAAM,iBAAiB,OAAO,UAAU,MAAM,kBAAM;AAAA,MACtD,EAAE,MAAM,WAAW,OAAO,UAAU,MAAM,YAAK;AAAA,MAC/C,EAAE,MAAM,SAAS,OAAO,aAAa,MAAM,YAAK;AAAA,MAChD,EAAE,MAAM,kBAAkB,OAAO,WAAW,MAAM,kBAAM;AAAA,MACxD,EAAE,MAAM,gBAAgB,OAAO,eAAe,MAAM,aAAM,cAAc,CAAC,YAAY,EAAE;AAAA,MACvF,EAAE,MAAM,YAAY,OAAO,WAAW,MAAM,aAAM,cAAc,CAAC,YAAY,EAAE;AAAA,IACjF;AAGA,UAAM,gBAAgB;AAAA;AAAA;AAAA,WAGf,cAAc,SAAS,gBAAgB;AAAA,iBACjC,cAAc,eAAe,gBAAgB;AAAA,gBAC9C,WAAW,KAAK,IAAI,KAAK,MAAM;AAAA,gBAC/B,UAAU,KAAK,IAAI,KAAK,MAAM;AAAA,iBAC7B,WAAW,MAAM;AAAA,oBACd,cAAc,IAAI,CAAC,MAAM,GAAG,EAAE,KAAK,KAAK,EAAE,IAAI,GAAG,EAAE,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA,EAG/E,cAAc,IAAI,CAAC,UAAU,KAAK,MAAM,KAAK,KAAK,MAAM,OAAO,EAAE,EAAE,KAAK,IAAI,CAAC;AAAA;AAAA,gCAE/C,cAAc,MAAM;AAAA,EAClD,cACC,MAAM,GAAG,CAAC,EACV;AAAA,MACC,CAAC,OAAO,MACN,GAAG,IAAI,CAAC,MAAM,MAAM,KAAK,UAAU,MAAM,EAAE,mBAAmB,MAAM,WAAW,KAAK,IAAI,CAAC,kBAAkB,MAAM,UAAU,KAAK,IAAI,CAAC;AAAA,IACzI,EACC,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA,EAGX,gBAAgB,IAAI,CAAC,UAAU,KAAK,MAAM,IAAI,KAAK,MAAM,KAAK,KAAK,MAAM,IAAI,GAAG,MAAM,eAAe,kBAAkB,MAAM,aAAa,KAAK,IAAI,IAAI,EAAE,EAAE,EAAE,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA,EAGvK,mBAAmB,IAAI,CAAC,SAAS,KAAK,KAAK,QAAQ,KAAK,KAAK,IAAI,GAAG,EAAE,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAShF,cAAc;AAAA,gBAAmB,WAAW,KAAK,EAAE;AAAA;AAAA;AAAA,EAGnD,kBAAkB,KAAK,UAAU,iBAAiB,MAAM,CAAC,IAAI,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA6D5E,YAAQ,IAAI,4BAA4B,cAAc,MAAM;AAG5D,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB,QAAQ,IAAI;AAAA,MACZ,SAAS;AAAA,IACX,CAAC;AAED,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,cAAc;AAAA,MACzC;AAAA,IACF,CAAC;AAED,YAAQ,IAAI,kCAAkC;AAE9C,UAAM,SAAS,KAAK,MAAM,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK,CAAC;AAGtE,QAAI,CAAC,OAAO,kBAAkB,CAAC,OAAO,eAAe,OAAO;AAC1D,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,iBAAiB,OAAO,eAAe,MAC1C,IAAI,CAAC,MAAM,UAAU;AACpB,YAAM,YAAY;AAAA,QAChB,IAAI,KAAK,MAAM,aAAa,QAAQ,CAAC;AAAA,QACrC,OAAO,KAAK,SAAS,aAAa,QAAQ,CAAC;AAAA,QAC3C,MAAM,KAAK,QAAQ;AAAA,QACnB,MAAM,KAAK,QAAQ;AAAA,QACnB,cAAc,KAAK,gBAAgB;AAAA,QACnC,aAAa,KAAK,eAAe;AAAA,MACnC;AAGA,cAAQ,KAAK,MAAM;AAAA,QACjB,KAAK;AAEH,gBAAM,aAAa,gBAAgB,KAAK,CAAC,UAAU,MAAM,SAAS,KAAK,IAAI;AAC3E,cAAI,YAAY;AACd,sBAAU,OAAO,KAAK;AACtB,sBAAU,eAAe,WAAW,gBAAgB;AAAA,UACtD,OAAO;AACL,oBAAQ,KAAK,uBAAuB,KAAK,IAAI,mBAAmB;AAChE,sBAAU,OAAO;AAAA,UACnB;AACA;AAAA,QAEF,KAAK;AAEH,gBAAM,aAAa,cAAc,KAAK,CAAC,UAAU,MAAM,OAAO,KAAK,OAAO;AAC1E,cAAI,YAAY;AACd,sBAAU,UAAU,KAAK;AAAA,UAC3B,OAAO;AACL,oBAAQ,KAAK,qBAAqB,KAAK,OAAO,iBAAiB;AAC/D,mBAAO;AAAA,UACT;AACA;AAAA,QAEF,KAAK;AAEH,gBAAM,gBAAgB,mBAAmB,KAAK,CAAC,SAAS,KAAK,aAAa,KAAK,QAAQ;AACvF,cAAI,eAAe;AACjB,sBAAU,WAAW,KAAK;AAE1B,gBAAI,KAAK,gBAAgB,MAAM,QAAQ,KAAK,YAAY,GAAG;AACzD,wBAAU,eAAe,KAAK;AAAA,YAChC,WAAW,KAAK,gBAAgB,OAAO,KAAK,iBAAiB,UAAU;AACrE,wBAAU,eAAe,CAAC,KAAK,YAAY;AAAA,YAC7C,OAAO;AACL,wBAAU,eAAe,CAAC,SAAS,YAAY;AAAA,YACjD;AAAA,UACF,OAAO;AACL,oBAAQ,KAAK,sBAAsB,KAAK,QAAQ,iBAAiB;AACjE,mBAAO;AAAA,UACT;AACA;AAAA,QAEF,KAAK;AAEH,cAAI,KAAK,QAAQ,KAAK,IAAI,WAAW,SAAS,KAAK,KAAK,IAAI,WAAW,UAAU,IAAI;AACnF,sBAAU,MAAM,KAAK;AAAA,UACvB,OAAO;AACL,oBAAQ,KAAK,yBAAyB,KAAK,GAAG,iBAAiB;AAC/D,mBAAO;AAAA,UACT;AACA;AAAA,QAEF;AACE,kBAAQ,KAAK,2BAA2B,KAAK,IAAI,uBAAuB;AACxE,oBAAU,OAAO;AACjB,oBAAU,OAAO;AACjB;AAAA,MACJ;AAEA,aAAO;AAAA,IACT,CAAC,EACA,OAAO,CAAC,SAAS,SAAS,IAAI;AAEjC,UAAM,gBAAgB;AAAA,MACpB,GAAG,OAAO;AAAA,MACV,OAAO;AAAA,IACT;AAEA,YAAQ,IAAI,uCAAkC,aAAa;AAC3D,YAAQ,IAAI,8BAAyB;AAAA,MACnC,eAAe,OAAO,eAAe,MAAM;AAAA,MAC3C,gBAAgB,eAAe;AAAA,MAC/B,cAAc,OAAO,eAAe,MAAM,SAAS,eAAe;AAAA,IACpE,CAAC;AAED,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,gBAAgB;AAAA,QAChB,qBAAqB,OAAO,uBAAuB,CAAC;AAAA,QACpD,kBAAkB,OAAO,oBAAoB,CAAC;AAAA,QAC9C,UAAU;AAAA,UACR,aAAa,WAAW;AAAA,UACxB,oBAAoB;AAAA,UACpB,mBAAmB;AAAA,UACnB,cAAa,oBAAI,KAAK,GAAE,YAAY;AAAA,UACpC,OAAO;AAAA,QACT;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,kCAAkC,KAAK;AACrD,WAAO,oBAAoB,MAAM,WAAW,yBAAyB,GAAG;AAAA,EAC1E;AACF,GAtY6B;AAyY7B,IAAM,yBAAyB,8BAAO,SAAS,QAAQ;AACrD,MAAI;AACF,UAAM,EAAE,cAAc,aAAa,SAAS,SAAS,IAAI,MAAM,QAAQ,KAAK;AAE5E,YAAQ,IAAI,kCAAkC;AAC9C,YAAQ,IAAI,gBAAgB,WAAW;AACvC,YAAQ,IAAI,YAAY,OAAO;AAC/B,YAAQ,IAAI,aAAa,QAAQ;AACjC,YAAQ,IAAI,uBAAuB,eAAe,aAAa,SAAS,gBAAgB;AACxF,YAAQ,IAAI,kCAAkC;AAE9C,QAAI,CAAC,gBAAgB,CAAC,MAAM,QAAQ,YAAY,KAAK,aAAa,WAAW,GAAG;AAC9E,aAAO,oBAAoB,2CAA2C,GAAG;AAAA,IAC3E;AAGA,UAAM,iBAAiB,aACpB,IAAI,CAAC,SAAS;AACb,YAAM,cAAc,UAAU,KAAK,SAAS,UAAU;AAAA,WAAc,KAAK,QAAQ,YAAY;AAC7F,aAAO;AAAA,IACT,CAAC,EACA,KAAK,aAAa;AAErB,YAAQ,IAAI,qCAAqC,eAAe,MAAM;AAGtE,UAAM,SAAS;AAAA;AAAA;AAAA,EAGjB,cAAc;AAAA;AAAA,EAEd,cAAc,uBAAuB,WAAW,KAAK,EAAE;AAAA,EACvD,WAAW,cAAc,QAAQ,KAAK,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAoBtC,YAAQ,IAAI,4BAA4B,OAAO,MAAM;AAGrD,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB,QAAQ,IAAI;AAAA,MACZ,SAAS;AAAA,IACX,CAAC;AAED,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,YAAQ,IAAI,kCAAkC;AAE9C,UAAM,SAAS,KAAK,MAAM,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK,CAAC;AAGtE,QAAI,CAAC,OAAO,UAAU,CAAC,MAAM,QAAQ,OAAO,MAAM,GAAG;AACnD,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,kBAAkB,OAAO,OAAO,IAAI,CAAC,OAAO,WAAW;AAAA,MAC3D,MAAM,MAAM,QAAQ,MAAM,SAAS,SAAS,QAAQ,CAAC;AAAA,MACrD,UAAU,MAAM,YAAY,MAAM,UAAU;AAAA,MAC5C,QAAQ,MAAM,UAAU,oBAAoB,QAAQ,CAAC;AAAA,IACvD,EAAE;AAEF,YAAQ,IAAI,yCAAoC,gBAAgB,MAAM;AAEtE,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,QAAQ;AAAA,QACR,UAAU;AAAA,UACR,aAAa,aAAa;AAAA,UAC1B,cAAa,oBAAI,KAAK,GAAE,YAAY;AAAA,UACpC,OAAO;AAAA,QACT;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,oCAAoC,KAAK;AACvD,WAAO,oBAAoB,MAAM,WAAW,yBAAyB,GAAG;AAAA,EAC1E;AACF,GA1G+B;AA6G/B,IAAM,0BAA0B,8BAAO,YAAY;AACjD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAM,WAAW,IAAI,aAAa,IAAI,UAAU;AAGhD,QAAM,eAAe;AAAA,IACnB;AAAA,MACE,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aACE;AAAA,MACF,WAAW,CAAC,YAAY,OAAO;AAAA,MAC/B,qBAAqB;AAAA,QACnB,iBAAiB;AAAA,QACjB,aAAa;AAAA,QACb,WAAW;AAAA,QACX,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,eAAe;AAAA,UACb,UAAU;AAAA,UACV,WAAW;AAAA,UACX,YAAY;AAAA,QACd;AAAA,MACF;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aACE;AAAA,MACF,WAAW,CAAC,YAAY,UAAU;AAAA,MAClC,qBAAqB;AAAA,QACnB,gBAAgB;AAAA,QAChB,eAAe;AAAA,UACb,UAAU;AAAA,UACV,WAAW;AAAA,UACX,YAAY;AAAA,QACd;AAAA,QACA,cAAc;AAAA,QACd,aAAa;AAAA,MACf;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aACE;AAAA,MACF,WAAW,CAAC,YAAY,UAAU;AAAA,MAClC,qBAAqB;AAAA,QACnB,cAAc;AAAA,QACd,eAAe;AAAA,UACb,WAAW;AAAA,UACX,YAAY;AAAA,QACd;AAAA,QACA,aAAa;AAAA,MACf;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,WAAW,CAAC,YAAY,SAAS,UAAU;AAAA,MAC3C,qBAAqB;AAAA,QACnB,iBAAiB;AAAA,QACjB,aAAa;AAAA,QACb,gBAAgB;AAAA,MAClB;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aACE;AAAA,MACF,WAAW,CAAC,YAAY,SAAS,YAAY,gBAAgB;AAAA,MAC7D,qBAAqB;AAAA,QACnB,iBAAiB;AAAA,QACjB,aAAa;AAAA,QACb,WAAW;AAAA,MACb;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AAAA,EACF;AAGA,QAAM,YAAY,WACd,aAAa,OAAO,CAAC,MAAM,EAAE,UAAU,SAAS,QAAQ,KAAK,EAAE,QAAQ,IACvE,aAAa,OAAO,CAAC,MAAM,EAAE,QAAQ;AAEzC,SAAO,eAAe,KAAK,UAAU,EAAE,UAAU,CAAC,CAAC;AACrD,GAlGgC;AAqGhC,IAAM,2BAA2B,8BAAO,SAAS,QAAQ;AACvD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,oBAAoB,8CAA8C,GAAG;AAAA,EAC9E;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA,SAAAC,WAAU,CAAC;AAAA,IACX,aAAa;AAAA,IACb,kBAAkB;AAAA,EACpB,IAAI;AAEJ,MAAI,CAAC,eAAe,CAAC,cAAc,CAAC,UAAU;AAC5C,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAEA,UAAQ,IAAI,8BAA8B;AAC1C,UAAQ,IAAI,gBAAgB,UAAU;AACtC,UAAQ,IAAI,cAAc,QAAQ;AAClC,UAAQ,IAAI,mBAAmB,YAAY,MAAM;AACjD,UAAQ,IAAI,YAAY,KAAK,UAAUA,QAAO,CAAC;AAC/C,UAAQ,IAAI,gBAAgB,aAAa,WAAW,OAAO,SAAS;AACpE,UAAQ,IAAI,qBAAqB,KAAK,UAAU,eAAe,CAAC;AAGhE,QAAM,YAAY;AAAA,IAChB;AAAA,MACE,IAAI;AAAA,MACJ,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IA0BlB;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAYlB;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAUlB;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IASlB;AAAA,IACA;AAAA,MACE,IAAI;AAAA,MACJ,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IA4BlB;AAAA,EACF;AAEA,QAAM,WAAW,UAAU,KAAK,CAAC,MAAM,EAAE,OAAO,UAAU;AAC1D,MAAI,CAAC,UAAU;AACb,WAAO,oBAAoB,sBAAsB,GAAG;AAAA,EACtD;AAEA,MAAI;AACF,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB;AAAA,MACA,SAAS;AAAA,IACX,CAAC;AAGD,QAAI,oBAAoB;AACxB,QAAI,YAAY;AACd,0BAAoB;AAAA,gBACV,WAAW,IAAI;AAAA;AAAA,mBAEZ,WAAW,OAAO;AAAA,qBAChB,WAAW,SAAS;AAAA,kBACvB,WAAW,MAAM;AAAA,sBACb,WAAW,UAAU;AAAA,oBACvB,WAAW,SAAS,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA,4CAIN,WAAW,SAAS,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA,IAGtE;AAGA,QAAI,uBAAuB;AAC3B,QAAI,iBAAiB,SAAS,iBAAiB,gBAAgB,kBAAkB;AAC/E,UAAI,gBAAgB,qBAAqB,WAAW;AAClD,+BAAuB;AAAA,4DAC6B,gBAAgB,gBAAgB;AAAA;AAAA,iDAE3C,gBAAgB,gBAAgB;AAAA,qDAC5B,gBAAgB,gBAAgB;AAAA;AAAA,MAE/E,OAAO;AACL,+BAAuB;AAAA;AAAA;AAAA;AAAA;AAAA,MAKzB;AAAA,IACF,WAAW,iBAAiB,SAAS,gBAAgB;AACnD,6BAAuB;AAAA;AAAA;AAAA;AAAA;AAAA,IAKzB;AAEA,UAAM,SAAS,GAAG,SAAS,cAAc;AAAA;AAAA,EAE3C,iBAAiB;AAAA;AAAA,EAEjB,oBAAoB;AAAA;AAAA;AAAA,EAGpB,WAAW;AAAA;AAAA,sBAES,KAAK,UAAUA,QAAO,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAYzC,YAAQ,IAAI,kCAAkC;AAC9C,QAAI,sBAAsB;AACxB,cAAQ,IAAI,iCAAiC,gBAAgB,IAAI;AACjE,cAAQ,IAAI,6BAA6B,gBAAgB,oBAAoB,KAAK;AAAA,IACpF,OAAO;AACL,cAAQ,IAAI,kCAAkC;AAAA,IAChD;AAEA,YAAQ,IAAI,2BAA2B,MAAM;AAE7C,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,QAAI,mBAAmB,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAGlE,QAAI,IAAI,gBAAgB;AACtB,cAAQ,IAAI,yDAAyD;AACrE,yBAAmB,MAAM,yBAAyB,kBAAkB,aAAa,GAAG;AAAA,IACtF,OAAO;AACL,cAAQ,IAAI,sDAAsD;AAElE,yBAAmB,iBAChB,QAAQ,6BAA6B,iDAAiD,EACtF,QAAQ,+BAA+B,8CAA8C,EACrF,QAAQ,gCAAgC,+CAA+C;AAAA,IAC5F;AAEA,YAAQ,IAAI,uCAAuC;AACnD,YAAQ,IAAI,6BAA6B,iBAAiB,MAAM;AAEhE,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb;AAAA,QACA,cAAc;AAAA,QACd,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,kCAAkC,KAAK;AACrD,WAAO,oBAAoB,qCAAqC,MAAM,SAAS,GAAG;AAAA,EACpF;AACF,GA9QiC;AAiRjC,IAAM,qBAAqB,8BAAO,OAAO,KAAK,QAAQ,MAAM;AAC1D,MAAI,CAAC,IAAI,gBAAgB;AACvB,UAAM,IAAI,MAAM,+BAA+B;AAAA,EACjD;AAEA,MAAI;AACF,YAAQ,IAAI,0BAA0B,KAAK,MAAM,KAAK,UAAU;AAEhE,UAAM,WAAW,MAAM;AAAA,MACrB,0CAA0C,mBAAmB,KAAK,CAAC,aAAa,KAAK;AAAA,MACrF;AAAA,QACE,SAAS;AAAA,UACP,eAAe,IAAI;AAAA,QACrB;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,EAAE;AAAA,IACxD;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,QAAI,KAAK,UAAU,KAAK,OAAO,SAAS,GAAG;AACzC,aAAO,KAAK,OAAO,IAAI,CAAC,WAAW;AAAA,QACjC,KAAK,MAAM,IAAI;AAAA;AAAA,QACf,KAAK,MAAM,OAAO;AAAA,QAClB,cAAc,MAAM;AAAA,QACpB,IAAI,MAAM;AAAA,MACZ,EAAE;AAAA,IACJ,OAAO;AACL,cAAQ,IAAI,qCAAqC,KAAK;AACtD,aAAO,CAAC;AAAA,IACV;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,2BAA2B,KAAK;AAC9C,WAAO,CAAC;AAAA,EACV;AACF,GAtC2B;AAwC3B,IAAM,6BAA6B,8BAAO,SAAS,QAAQ;AACzD,QAAM,SAAS,IAAI;AACnB,MAAI,CAAC,QAAQ;AACX,WAAO,CAAC,UAAU,YAAY,UAAU;AAAA,EAC1C;AAEA,MAAI;AACF,UAAM,SAAS,IAAI,OAAO;AAAA,MACxB;AAAA,MACA,SAAS;AAAA,IACX,CAAC;AAED,UAAM,SAAS;AAAA;AAAA,WAER,QAAQ,UAAU,GAAG,GAAG,CAAC;AAAA;AAAA;AAIhC,UAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,MACtD,OAAO;AAAA,MACP,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,IACF,CAAC;AAED,UAAM,WAAW,WAAW,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC5D,UAAM,UAAU,SACb,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,EACnB,OAAO,CAAC,MAAM,EAAE,SAAS,CAAC;AAE7B,YAAQ,IAAI,mCAAmC,OAAO;AACtD,WAAO,QAAQ,SAAS,IAAI,UAAU,CAAC,YAAY,WAAW,QAAQ;AAAA,EACxE,SAAS,OAAO;AACd,YAAQ,MAAM,mCAAmC,KAAK;AACtD,WAAO,CAAC,UAAU,YAAY,UAAU;AAAA,EAC1C;AACF,GA5CmC;AA8CnC,IAAM,2BAA2B,8BAAO,SAAS,iBAAiB,QAAQ;AACxE,MAAI;AAEF,UAAM,gBAAgB,MAAM,2BAA2B,iBAAiB,GAAG;AAE3E,QAAI,iBAAiB;AAGrB,QAAI,QAAQ,SAAS,0BAA0B,GAAG;AAChD,cAAQ,IAAI,uCAAuC;AACnD,YAAM,eAAe,MAAM,mBAAmB,cAAc,CAAC,KAAK,mBAAmB,KAAK,CAAC;AAC3F,UAAI,aAAa,SAAS,GAAG;AAC3B,yBAAiB,eAAe,QAAQ,6BAA6B,aAAa,CAAC,EAAE,GAAG;AACxF,gBAAQ,IAAI,+BAA+B,aAAa,CAAC,EAAE,GAAG;AAAA,MAChE,OAAO;AACL,yBAAiB,eAAe;AAAA,UAC9B;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,QAAQ,SAAS,4BAA4B,GAAG;AAClD,cAAQ,IAAI,yCAAyC;AACrD,YAAM,iBAAiB,MAAM;AAAA,QAC3B,cAAc,CAAC,KAAK,cAAc,CAAC,KAAK;AAAA,QACxC;AAAA,QACA;AAAA,MACF;AACA,UAAI,eAAe,SAAS,GAAG;AAC7B,yBAAiB,eAAe;AAAA,UAC9B;AAAA,UACA,eAAe,CAAC,EAAE;AAAA,QACpB;AACA,gBAAQ,IAAI,iCAAiC,eAAe,CAAC,EAAE,GAAG;AAAA,MACpE,OAAO;AACL,yBAAiB,eAAe;AAAA,UAC9B;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,QAAQ,SAAS,6BAA6B,GAAG;AACnD,cAAQ,IAAI,0CAA0C;AACtD,YAAM,kBAAkB,MAAM;AAAA,QAC5B,cAAc,CAAC,KAAK,cAAc,CAAC,KAAK;AAAA,QACxC;AAAA,QACA;AAAA,MACF;AACA,UAAI,gBAAgB,SAAS,GAAG;AAC9B,yBAAiB,eAAe;AAAA,UAC9B;AAAA,UACA,gBAAgB,CAAC,EAAE;AAAA,QACrB;AACA,gBAAQ,IAAI,kCAAkC,gBAAgB,CAAC,EAAE,GAAG;AAAA,MACtE,OAAO;AACL,yBAAiB,eAAe;AAAA,UAC9B;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,uCAAuC,KAAK;AAE1D,WAAO,QACJ,QAAQ,6BAA6B,iDAAiD,EACtF,QAAQ,+BAA+B,8CAA8C,EACrF,QAAQ,gCAAgC,+CAA+C;AAAA,EAC5F;AACF,GA3EiC;AA8EjC,IAAM,0BAA0B,8BAAO,SAAS,QAAQ;AACtD,MAAI,CAAC,IAAI,gBAAgB;AACvB,WAAO,oBAAoB,iCAAiC,GAAG;AAAA,EACjE;AAEA,MAAI;AACJ,MAAI;AACF,WAAO,MAAM,QAAQ,KAAK;AAAA,EAC5B,QAAQ;AACN,WAAO,oBAAoB,qBAAqB,GAAG;AAAA,EACrD;AAEA,QAAM,EAAE,OAAO,QAAQ,GAAG,IAAI;AAE9B,MAAI,CAAC,SAAS,OAAO,UAAU,UAAU;AACvC,WAAO,oBAAoB,oDAAoD,GAAG;AAAA,EACpF;AAEA,MAAI;AACF,UAAM,SAAS,MAAM,mBAAmB,OAAO,KAAK,KAAK,IAAI,OAAO,EAAE,CAAC;AAEvE,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb;AAAA,QACA,OAAO,OAAO;AAAA,QACd;AAAA,QACA,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,oCAAoC,KAAK;AACvD,WAAO,oBAAoB,qCAAqC,MAAM,SAAS,GAAG;AAAA,EACpF;AACF,GAjCgC;AAoChC,IAAM,4BAA4B,mCAAY;AAC5C,UAAQ,IAAI,4CAAqC;AAEjD,QAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAoNrB,UAAQ,IAAI,iDAA4C,aAAa,MAAM;AAE3E,SAAO,IAAI,SAAS,cAAc;AAAA,IAChC,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,GAAG;AAAA,IACL;AAAA,EACF,CAAC;AACH,GAhOkC;AAkOlC,IAAM,yBAAyB,8BAAO,SAAS,QAAQ;AACrD,MAAI;AACF,UAAM,EAAE,KAAK,IAAI,MAAM,QAAQ,KAAK;AAEpC,QAAI,CAAC,MAAM;AACT,aAAO,oBAAoB,kCAAkC,GAAG;AAAA,IAClE;AAEA,YAAQ,IAAI,6DAAsD;AAGlE,UAAM,gBAAgB,MAAM,MAAM,uCAAuC;AAAA,MACvE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,WAAW,IAAI;AAAA,QACf,eAAe,IAAI;AAAA,QACnB;AAAA,QACA,YAAY;AAAA,QACZ,cACE,QAAQ,IAAI,SAAS,WAAW,KAAK,QAAQ,IAAI,SAAS,WAAW,IACjE,QAAQ,IAAI,SAAS,WAAW,IAC9B,oDACA,oDACF;AAAA,MACR,CAAC;AAAA,IACH,CAAC;AAED,UAAM,YAAY,MAAM,cAAc,KAAK;AAE3C,QAAI,CAAC,cAAc,IAAI;AACrB,cAAQ,MAAM,iCAA4B,SAAS;AACnD,aAAO;AAAA,QACL,UAAU,qBAAqB;AAAA,QAC/B;AAAA,MACF;AAAA,IACF;AAEA,QAAI,UAAU,cAAc;AAC1B,cAAQ,IAAI,gDAA2C;AAEvD,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,SAAS;AAAA,UACT,cAAc,UAAU;AAAA,UACxB,YAAY,UAAU;AAAA,QACxB,CAAC;AAAA,MACH;AAAA,IACF,OAAO;AACL,aAAO,oBAAoB,4BAA4B,GAAG;AAAA,IAC5D;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,oCAA+B,KAAK;AAClD,WAAO,oBAAoB,MAAM,SAAS,GAAG;AAAA,EAC/C;AACF,GAzD+B;AA2D/B,IAAM,2BAA2B,8BAAO,YAAY;AAClD,MAAI;AACF,UAAM,EAAE,cAAc,aAAa,IAAI,MAAM,QAAQ,KAAK;AAE1D,QAAI,CAAC,cAAc;AACjB,aAAO,oBAAoB,4BAA4B,GAAG;AAAA,IAC5D;AAEA,YAAQ,IAAI,sCAA+B;AAE3C,UAAM,WAAW,MAAM,MAAM,6DAA6D;AAAA,MACxF,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,YAAY;AAAA,QACrC,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,UAAU;AAAA,QACV,SAAS;AAAA,UACP,iBAAiB;AAAA,YACf,YAAY,CAAC,OAAO;AAAA,UACtB;AAAA;AAAA,UAEA,GAAI,cAAc,qBAAqB;AAAA,YACrC,eAAe;AAAA,cACb,2BAA2B,aAAa;AAAA,YAC1C;AAAA,UACF;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,UAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,QAAI,CAAC,SAAS,IAAI;AAChB,cAAQ,MAAM,uCAAkC,IAAI;AACpD,aAAO,oBAAoB,KAAK,OAAO,WAAW,kCAAkC,GAAG;AAAA,IACzF;AAEA,YAAQ,IAAI,gBAAW,KAAK,YAAY,UAAU,CAAC,SAAS;AAE5D,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,YAAY,KAAK,cAAc,CAAC;AAAA,QAChC,eAAe,KAAK;AAAA,MACtB,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,sCAAiC,KAAK;AACpD,WAAO,oBAAoB,MAAM,SAAS,GAAG;AAAA,EAC/C;AACF,GApDiC;AAsDjC,IAAM,2BAA2B,8BAAO,YAAY;AAClD,MAAI;AACF,UAAM,EAAE,aAAa,IAAI,MAAM,QAAQ,KAAK;AAE5C,QAAI,CAAC,cAAc;AACjB,aAAO,oBAAoB,4BAA4B,GAAG;AAAA,IAC5D;AAEA,YAAQ,IAAI,2CAAoC;AAEhD,UAAM,WAAW,MAAM,MAAM,sDAAsD;AAAA,MACjF,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,YAAY;AAAA,QACrC,gBAAgB;AAAA,MAClB;AAAA,IACF,CAAC;AAED,UAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,QAAI,CAAC,SAAS,IAAI;AAChB,cAAQ,MAAM,uCAAkC,IAAI;AACpD,aAAO,oBAAoB,KAAK,OAAO,WAAW,+BAA+B,GAAG;AAAA,IACtF;AAEA,YAAQ,IAAI,oBAAe,KAAK,YAAY,UAAU,CAAC,gBAAgB;AAEvE,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,YAAY,KAAK,cAAc,CAAC;AAAA,QAChC,eAAe,KAAK;AAAA,MACtB,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,+BAA0B,KAAK;AAC7C,WAAO,oBAAoB,MAAM,SAAS,GAAG;AAAA,EAC/C;AACF,GAtCiC;AAyCjC,eAAe,yBAAyB,SAAS,KAAK;AACpD,UAAQ,IAAI,8DAAuD;AACnE,UAAQ,IAAI,mBAAmB,QAAQ,MAAM;AAC7C,UAAQ,IAAI,gBAAgB,QAAQ,GAAG;AAEvC,MAAI,QAAQ,WAAW,WAAW;AAChC,YAAQ,IAAI,wCAAmC;AAC/C,WAAO,IAAI,SAAS,MAAM;AAAA,MACxB,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,+BAA+B;AAAA,QAC/B,gCAAgC;AAAA,QAChC,gCAAgC;AAAA,QAChC,0BAA0B;AAAA,MAC5B;AAAA,IACF,CAAC;AAAA,EACH;AAEA,MAAI,QAAQ,WAAW,QAAQ;AAC7B,QAAI;AACF,cAAQ,IAAI,8DAAuD;AAEnE,YAAM,cAAc,MAAM,QAAQ,KAAK;AACvC,cAAQ,IAAI,oCAA6B,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAE7E,YAAM,EAAE,WAAW,YAAY,OAAO,IAAI;AAG1C,UAAI;AACJ,UAAI;AAEJ,cAAQ,IAAI,6BAAsB;AAClC,cAAQ,IAAI,kBAAkB,SAAS;AACvC,cAAQ,IAAI,mBAAmB,UAAU;AACzC,cAAQ,IAAI,eAAe,MAAM;AAEjC,UAAI,CAAC,WAAW;AACd,gBAAQ,IAAI,4DAAuD;AACnE,eAAO,IAAI;AAAA,UACT,KAAK,UAAU;AAAA,YACb,OAAO;AAAA,UACT,CAAC;AAAA,UACD;AAAA,YACE,QAAQ;AAAA,YACR,SAAS;AAAA,cACP,gBAAgB;AAAA,cAChB,+BAA+B;AAAA,YACjC;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAGA,YAAM,mBAAmB,cAAc;AACvC,cAAQ,IAAI,4CAAqC,gBAAgB;AAGjE,UAAI,qBAAqB,WAAW,gBAAgB,GAAG;AACrD,gBAAQ;AAAA,UACN,sEAA+D,SAAS,IAAI,gBAAgB;AAAA,QAC9F;AACA,eAAO,IAAI;AAAA,UACT,KAAK,UAAU;AAAA,YACb,OAAO,cAAc,SAAS,+DAA+D,qBAAqB,gBAAgB,GAAG,KAAK,IAAI,KAAK,MAAM;AAAA,YACzJ,oBAAoB;AAAA,YACpB,wBAAwB,qBAAqB,gBAAgB,KAAK,CAAC;AAAA,UACrE,CAAC;AAAA,UACD;AAAA,YACE,QAAQ;AAAA,YACR,SAAS;AAAA,cACP,gBAAgB;AAAA,cAChB,+BAA+B;AAAA,YACjC;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAGA,qBAAe,GAAG,SAAS,IAAI,gBAAgB;AAC/C,cAAQ,IAAI,iCAA0B,YAAY;AAGlD,qBAAe,UAAU,oBAAoB,gBAAgB;AAC7D,cAAQ,IAAI,2BAAoB;AAChC,cAAQ,IAAI,gCAAgC,KAAK,UAAU,qBAAqB,MAAM,CAAC,CAAC;AACxF,cAAQ,IAAI,yBAAyB,YAAY;AAEjD,UAAI,CAAC,cAAc;AACjB,gBAAQ,IAAI,gEAA2D;AACvE,eAAO,IAAI;AAAA,UACT,KAAK,UAAU;AAAA,YACb,OAAO,gCAAgC,YAAY,wBAAwB,OAAO,KAAK,mBAAmB,EAAE,KAAK,IAAI,CAAC;AAAA,UACxH,CAAC;AAAA,UACD;AAAA,YACE,QAAQ;AAAA,YACR,SAAS;AAAA,cACP,gBAAgB;AAAA,cAChB,+BAA+B;AAAA,YACjC;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAEA,cAAQ,IAAI,oCAA+B,YAAY,kBAAkB,YAAY,EAAE;AAGvF,UAAI,CAAC,IAAI,cAAc;AACrB,gBAAQ,IAAI,qDAAgD;AAC5D,eAAO,IAAI;AAAA,UACT,KAAK,UAAU;AAAA,YACb,OAAO;AAAA,YACP,gBAAgB;AAAA,UAClB,CAAC;AAAA,UACD;AAAA,YACE,QAAQ;AAAA,YACR,SAAS;AAAA,cACP,gBAAgB;AAAA,cAChB,+BAA+B;AAAA,YACjC;AAAA,UACF;AAAA,QACF;AAAA,MACF;AACA,cAAQ,IAAI,kCAA6B;AAGzC,cAAQ,IAAI,kCAA2B;AACvC,YAAM,aAAa;AAAA,QACjB,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SAAS;AAAA,MACX;AACA,cAAQ,IAAI,0BAAmB,KAAK,UAAU,YAAY,MAAM,CAAC,CAAC;AAElE,YAAM,cAAc,MAAM;AAAA,QACxB,8CAA8C,YAAY;AAAA,QAC1D;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,eAAe,UAAU,IAAI,YAAY;AAAA,YACzC,gBAAgB;AAAA,UAClB;AAAA,UACA,MAAM,KAAK,UAAU,UAAU;AAAA,QACjC;AAAA,MACF;AAEA,cAAQ,IAAI,kCAA2B,YAAY,QAAQ,YAAY,UAAU;AACjF,YAAM,YAAY,MAAM,YAAY,KAAK;AACzC,cAAQ,IAAI,gCAAyB,KAAK,UAAU,WAAW,MAAM,CAAC,CAAC;AAEvE,YAAM,WAAW;AAAA,QACf,SAAS,UAAU;AAAA,QACnB,QAAQ,UAAU;AAAA,QAClB,QAAQ,UAAU;AAAA,MACpB;AAGA,cAAQ,IAAI,oCAA6B;AACzC,YAAM,gBAAgB;AAAA,QACpB,SAAS,GAAG,YAAY;AAAA,QACxB,QAAQ;AAAA,MACV;AACA,cAAQ,IAAI,mCAA4B,KAAK,UAAU,eAAe,MAAM,CAAC,CAAC;AAE9E,YAAM,iBAAiB,MAAM;AAAA,QAC3B,8CAA8C,YAAY;AAAA,QAC1D;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,eAAe,UAAU,IAAI,YAAY;AAAA,YACzC,gBAAgB;AAAA,UAClB;AAAA,UACA,MAAM,KAAK,UAAU,aAAa;AAAA,QACpC;AAAA,MACF;AAEA,cAAQ;AAAA,QACN;AAAA,QACA,eAAe;AAAA,QACf,eAAe;AAAA,MACjB;AACA,YAAM,eAAe,MAAM,eAAe,KAAK;AAC/C,cAAQ,IAAI,yCAAkC,KAAK,UAAU,cAAc,MAAM,CAAC,CAAC;AAEnF,YAAM,cAAc;AAAA,QAClB,SAAS,aAAa;AAAA,QACtB,QAAQ,aAAa;AAAA,QACrB,QAAQ,aAAa;AAAA,MACvB;AAEA,YAAM,iBAAiB,SAAS,WAAW,YAAY;AACvD,cAAQ,IAAI,8BAAuB,cAAc;AACjD,cAAQ,IAAI,0BAA0B,SAAS,OAAO;AACtD,cAAQ,IAAI,6BAA6B,YAAY,OAAO;AAE5D,YAAM,eAAe;AAAA,QACnB;AAAA,QACA,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,QACA,OAAO;AAAA,UACL;AAAA,UACA;AAAA,UACA,kBAAkB,OAAO,KAAK,mBAAmB;AAAA,QACnD;AAAA,MACF;AAEA,cAAQ,IAAI,6BAAsB,KAAK,UAAU,cAAc,MAAM,CAAC,CAAC;AAEvE,aAAO,IAAI,SAAS,KAAK,UAAU,YAAY,GAAG;AAAA,QAChD,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,UAChB,+BAA+B;AAAA,QACjC;AAAA,MACF,CAAC;AAAA,IACH,SAAS,OAAO;AACd,cAAQ,IAAI,6CAAwC,KAAK;AACzD,cAAQ,IAAI,uBAAkB,MAAM,KAAK;AAEzC,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,MAAM;AAAA,UACb,OAAO,MAAM;AAAA,UACb,gBAAgB;AAAA,QAClB,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,+BAA+B;AAAA,UACjC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAGA,UAAQ,IAAI,8BAAyB,QAAQ,MAAM;AACnD,SAAO,IAAI,SAAS,sBAAsB,EAAE,QAAQ,IAAI,CAAC;AAC3D;AAjPe;AAoPf,eAAe,yBAAyB,SAAS,KAAK;AACpD,UAAQ,IAAI,iDAAqC;AAEjD,MAAI,QAAQ,WAAW,QAAQ;AAC7B,WAAO,IAAI,SAAS,sBAAsB,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC3D;AAEA,MAAI;AACF,UAAM,cAAc,MAAM,QAAQ,KAAK;AACvC,YAAQ,IAAI,kCAA2B,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAE3E,UAAM,EAAE,WAAW,WAAW,IAAI;AAElC,QAAI,CAAC,aAAa,CAAC,YAAY;AAC7B,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,gBAAgB;AAAA,QAClB,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,+BAA+B;AAAA,UACjC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,eAAe,GAAG,SAAS,IAAI,UAAU;AAC/C,YAAQ,IAAI,sCAA+B,YAAY;AAGvD,QAAI,qBAAqB,WAAW,UAAU,GAAG;AAC/C,cAAQ;AAAA,QACN,sEAA+D,SAAS,IAAI,UAAU;AAAA,MACxF;AACA,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,cAAc,SAAS,+DAA+D,qBAAqB,UAAU,GAAG,KAAK,IAAI,KAAK,MAAM;AAAA,UACnJ,oBAAoB;AAAA,UACpB,gBAAgB;AAAA,QAClB,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,+BAA+B;AAAA,UACjC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,UAAM,eAAe,mBAAmB,UAAU;AAClD,QAAI,CAAC,cAAc;AACjB,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,4BAA4B,UAAU,wBAAwB,OAAO,KAAK,mBAAmB,EAAE,KAAK,IAAI,CAAC;AAAA,UAChH,gBAAgB;AAAA,QAClB,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,+BAA+B;AAAA,UACjC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,IAAI,kCAAsB,YAAY;AAG9C,YAAQ,IAAI,qCAA8B,YAAY;AAEtD,UAAM,kBAAkB,MAAM;AAAA,MAC5B,8CAA8C,YAAY,qBAAqB,YAAY;AAAA,MAC3F;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,IAAI,YAAY;AAAA,UACzC,gBAAgB;AAAA,QAClB;AAAA,MACF;AAAA,IACF;AAEA,UAAM,gBAAgB,MAAM,gBAAgB,KAAK;AACjD,YAAQ,IAAI,gCAAyB,KAAK,UAAU,eAAe,MAAM,CAAC,CAAC;AAE3E,QAAI,WAAW,EAAE,SAAS,MAAM,QAAQ,CAAC,GAAG,SAAS,MAAM;AAE3D,QAAI,cAAc,UAAU,cAAc,OAAO,SAAS,GAAG;AAC3D,YAAM,YAAY,cAAc,OAAO,CAAC;AACxC,cAAQ,IAAI,yCAAkC,UAAU,EAAE;AAE1D,YAAM,oBAAoB,MAAM;AAAA,QAC9B,8CAA8C,YAAY,gBAAgB,UAAU,EAAE;AAAA,QACtF;AAAA,UACE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,eAAe,UAAU,IAAI,YAAY;AAAA,YACzC,gBAAgB;AAAA,UAClB;AAAA,QACF;AAAA,MACF;AAEA,YAAM,kBAAkB,MAAM,kBAAkB,KAAK;AACrD,cAAQ,IAAI,wCAA4B,KAAK,UAAU,iBAAiB,MAAM,CAAC,CAAC;AAEhF,iBAAW;AAAA,QACT,SAAS,gBAAgB;AAAA,QACzB,QAAQ,gBAAgB,UAAU,CAAC;AAAA,QACnC,SAAS,gBAAgB;AAAA,QACzB,UAAU,UAAU;AAAA,MACtB;AAAA,IACF,OAAO;AACL,cAAQ,IAAI,gDAAsC,YAAY;AAC9D,eAAS,UAAU;AACnB,eAAS,UAAU;AAAA,IACrB;AAGA,YAAQ,IAAI,uCAAgC,GAAG,YAAY,IAAI;AAE/D,UAAM,qBAAqB,MAAM;AAAA,MAC/B,8CAA8C,YAAY;AAAA,MAC1D;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,IAAI,YAAY;AAAA,UACzC,gBAAgB;AAAA,QAClB;AAAA,MACF;AAAA,IACF;AAEA,UAAM,mBAAmB,MAAM,mBAAmB,KAAK;AACvD,YAAQ,IAAI,mCAA4B,KAAK,UAAU,kBAAkB,MAAM,CAAC,CAAC;AAEjF,QAAI,cAAc,EAAE,SAAS,MAAM,QAAQ,CAAC,GAAG,SAAS,MAAM;AAE9D,QAAI,iBAAiB,UAAU,iBAAiB,OAAO,SAAS,GAAG;AAEjE,YAAM,cAAc,iBAAiB,OAAO;AAAA,QAC1C,CAAC,UAAU,MAAM,YAAY,GAAG,YAAY;AAAA,MAC9C;AAEA,UAAI,aAAa;AACf,gBAAQ,IAAI,2CAAoC,YAAY,EAAE;AAE9D,cAAM,sBAAsB,MAAM;AAAA,UAChC,8CAA8C,YAAY,mBAAmB,YAAY,EAAE;AAAA,UAC3F;AAAA,YACE,QAAQ;AAAA,YACR,SAAS;AAAA,cACP,eAAe,UAAU,IAAI,YAAY;AAAA,cACzC,gBAAgB;AAAA,YAClB;AAAA,UACF;AAAA,QACF;AAEA,cAAM,oBAAoB,MAAM,oBAAoB,KAAK;AACzD,gBAAQ,IAAI,0CAA8B,KAAK,UAAU,mBAAmB,MAAM,CAAC,CAAC;AAEpF,sBAAc;AAAA,UACZ,SAAS,kBAAkB;AAAA,UAC3B,QAAQ,kBAAkB,UAAU,CAAC;AAAA,UACrC,SAAS,kBAAkB;AAAA,UAC3B,SAAS,YAAY;AAAA,QACvB;AAAA,MACF,OAAO;AACL,gBAAQ,IAAI,mDAAyC,GAAG,YAAY,IAAI;AACxE,oBAAY,UAAU;AACtB,oBAAY,UAAU;AAAA,MACxB;AAAA,IACF,OAAO;AACL,cAAQ,IAAI,6CAAmC;AAC/C,kBAAY,UAAU;AACtB,kBAAY,UAAU;AAAA,IACxB;AAGA,YAAQ,IAAI,gDAAoC,eAAe,YAAY,EAAE;AAE7E,QAAI,UAAU,EAAE,SAAS,MAAM,QAAQ,CAAC,GAAG,SAAS,MAAM;AAE1D,QAAI;AACF,UAAI,CAAC,IAAI,cAAc;AACrB,cAAM,IAAI,MAAM,yCAAyC;AAAA,MAC3D;AAEA,YAAM,IAAI,aAAa,OAAO,eAAe,YAAY,EAAE;AAC3D,cAAQ,UAAU;AAClB,cAAQ,UAAU;AAClB,cAAQ,IAAI,sCAAiC;AAAA,IAC/C,SAAS,SAAS;AAChB,cAAQ,MAAM,mCAA8B,OAAO;AACnD,cAAQ,UAAU;AAClB,cAAQ,OAAO,KAAK,EAAE,SAAS,QAAQ,QAAQ,CAAC;AAChD,cAAQ,UAAU;AAAA,IACpB;AAEA,UAAM,iBAAiB,SAAS,WAAW,YAAY,WAAW,QAAQ;AAC1E,YAAQ,IAAI,uCAAgC,cAAc;AAC1D,YAAQ,IAAI,6BAA6B,SAAS,OAAO;AACzD,YAAQ,IAAI,gCAAgC,YAAY,OAAO;AAC/D,YAAQ,IAAI,4BAA4B,QAAQ,OAAO;AAEvD,UAAM,eAAe;AAAA,MACnB;AAAA,MACA,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,MACA,OAAO;AAAA,QACL;AAAA,QACA,kBAAkB;AAAA,QAClB,kBAAkB,OAAO,KAAK,mBAAmB;AAAA,MACnD;AAAA,IACF;AAEA,YAAQ,IAAI,sCAA+B,KAAK,UAAU,cAAc,MAAM,CAAC,CAAC;AAEhF,WAAO,IAAI,SAAS,KAAK,UAAU,YAAY,GAAG;AAAA,MAChD,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,+BAA+B;AAAA,MACjC;AAAA,IACF,CAAC;AAAA,EACH,SAAS,OAAO;AACd,YAAQ,IAAI,6CAAwC,KAAK;AACzD,YAAQ,IAAI,uBAAkB,MAAM,KAAK;AAEzC,WAAO,IAAI;AAAA,MACT,KAAK,UAAU;AAAA,QACb,OAAO,MAAM;AAAA,QACb,OAAO,MAAM;AAAA,QACb,gBAAgB;AAAA,MAClB,CAAC;AAAA,MACD;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,UAChB,+BAA+B;AAAA,QACjC;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AA1Pe;AA6Pf,IAAM,wBAAwB,8BAAO,SAAS,UAAU,QAAQ;AAC9D,MAAI;AACF,UAAM,gBAAgB,qDAAqD,QAAQ;AAEnF,YAAQ,IAAI,yCAAyC,aAAa,EAAE;AAEpE,UAAM,WAAW,MAAM,MAAM,eAAe;AAAA,MAC1C,QAAQ,QAAQ;AAAA,MAChB,SAAS,QAAQ;AAAA,MACjB,MAAM,QAAQ;AAAA,IAChB,CAAC;AAED,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,iCAAiC,KAAK;AACpD,WAAO,oBAAoB,qBAAqB,MAAM,OAAO,IAAI,GAAG;AAAA,EACtE;AACF,GAjB8B;AAoB9B,IAAM,sBAAsB,8BAAO,SAAS,QAAQ;AAClD,MAAI;AACF,UAAM,EAAE,WAAW,KAAK,IAAI,MAAM,QAAQ,KAAK;AAC/C,QAAI,CAAC,aAAa,CAAC,MAAM;AACvB,aAAO,oBAAoB,6BAA6B,GAAG;AAAA,IAC7D;AAGA,UAAM,iBAAiB,UAAU,QAAQ,iBAAiB,EAAE,EAAE,YAAY;AAC1E,UAAM,aAAa,WAAW,cAAc,GAAG,UAAU,GAAG,EAAE;AAE9D,UAAM,YAAY,IAAI;AACtB,UAAM,WAAW,IAAI;AACrB,UAAM,mBAAmB,IAAI;AAG7B,YAAQ,IAAI,0CAA0C,UAAU,EAAE;AAClE,YAAQ,IAAI,wBAAwB,KAAK,UAAU,GAAG,GAAG,IAAI,KAAK;AAGlE,YAAQ,IAAI,mCAA4B;AACxC,YAAQ,IAAI,aAAa,KAAK,MAAM;AACpC,YAAQ,IAAI,sBAAsB,KAAK,UAAU,KAAK,UAAU,GAAG,GAAG,CAAC,CAAC;AACxE,YAAQ,IAAI,8BAA8B,KAAK,SAAS,gBAAgB,CAAC;AACzE,YAAQ,IAAI,gCAAgC,KAAK,SAAS,kBAAkB,CAAC;AAG7E,QAAI,YAAY,KACb,QAAQ,qBAAqB,EAAE,EAC/B,QAAQ,aAAa,EAAE,EACvB,QAAQ,WAAW,EAAE,EACrB,QAAQ,SAAS,IAAI,EACrB,QAAQ,OAAO,IAAI,EACnB,KAAK;AAER,YAAQ,IAAI,2BAAoB;AAChC,YAAQ,IAAI,aAAa,UAAU,MAAM;AACzC,YAAQ,IAAI,sBAAsB,KAAK,UAAU,UAAU,UAAU,GAAG,GAAG,CAAC,CAAC;AAC7E,YAAQ,IAAI,8BAA8B,UAAU,SAAS,gBAAgB,CAAC;AAC9E,YAAQ,IAAI,gCAAgC,UAAU,SAAS,kBAAkB,CAAC;AAGlF,QAAI,UAAU,SAAS,gBAAgB,GAAG;AACxC,aAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAEA,QACE,CAAC,UAAU,SAAS,0BAA0B,KAC9C,CAAC,UAAU,SAAS,0BAA0B,GAC9C;AACA,aAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAGA,UAAM,cAAc,UAAU,MAAM,IAAI,KAAK,CAAC,GAAG;AACjD,UAAM,eAAe,UAAU,MAAM,IAAI,KAAK,CAAC,GAAG;AAClD,QAAI,eAAe,aAAa;AAC9B,cAAQ,IAAI,sCAAiC,EAAE,YAAY,YAAY,CAAC;AACxE,aAAO;AAAA,QACL,2CAA2C,UAAU,UAAU,WAAW;AAAA,QAC1E;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,IAAI,6CAAwC;AACpD,YAAQ,IAAI,iCAA0B;AACtC,YAAQ,IAAI,aAAa,UAAU,MAAM;AACzC,YAAQ,IAAI,cAAc,KAAK,UAAU,UAAU,UAAU,GAAG,GAAG,IAAI,KAAK,CAAC;AAC7E,YAAQ,IAAI,kDAA2C;AACvD,YAAQ,IAAI,kBAAkB,KAAK,UAAU,UAAU,UAAU,IAAI,EAAE,CAAC,CAAC;AACzE,YAAQ,IAAI,iBAAiB,KAAK,UAAU,UAAU,OAAO,EAAE,CAAC,CAAC;AACjE,YAAQ,IAAI,sBAAsB,UAAU,WAAW,EAAE,CAAC;AAG1D,YAAQ;AAAA,MACN;AAAA,MACA,iDAAiD,SAAS,oBAAoB,UAAU;AAAA,IAC1F;AACA,UAAM,YAAY,MAAM;AAAA,MACtB,iDAAiD,SAAS,oBAAoB,UAAU;AAAA,MACxF;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,QAAQ;AAAA,UACjC,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM;AAAA,MACR;AAAA,IACF;AAEA,UAAM,aAAa,MAAM,UAAU,KAAK;AACxC,QAAI,CAAC,WAAW,SAAS;AACvB,aAAO,oBAAoB,2BAA2B,KAAK,UAAU,WAAW,MAAM,GAAG,GAAG;AAAA,IAC9F;AAEA,UAAM,WAAW,WAAW,UAAU,IAAI,gBAAgB;AAG1D,UAAM,kBAAkB;AAAA,MACtB;AAAA,MACA;AAAA,MACA;AAAA,MACA,cAAa,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,aAAa,UAAU,UAAU,GAAG,GAAG;AAAA;AAAA,MACvC,oBAAoB,KAAK;AAAA,MACzB,iBAAiB,UAAU;AAAA,IAC7B;AAEA,UAAM,IAAI,aAAa,IAAI,WAAW,SAAS,IAAI,KAAK,UAAU,eAAe,CAAC;AAElF,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT;AAAA,QACA;AAAA,QACA,SAAS;AAAA,MACX,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,WAAO,oBAAoB,mBAAmB,EAAE,SAAS,GAAG;AAAA,EAC9D;AACF,GAhI4B;AAmI5B,IAAM,4BAA4B,8BAAO,SAAS,QAAQ;AACxD,MAAI;AACF,UAAM,EAAE,UAAU,IAAI,MAAM,QAAQ,KAAK;AACzC,QAAI,CAAC,WAAW;AACd,aAAO,oBAAoB,qBAAqB,GAAG;AAAA,IACrD;AAGA,UAAM,cAAc,MAAM,IAAI,aAAa,IAAI,WAAW,SAAS,EAAE;AACrE,QAAI,CAAC,aAAa;AAChB,aAAO,oBAAoB,wDAAwD,GAAG;AAAA,IACxF;AAEA,UAAM,UAAU,KAAK,MAAM,WAAW;AACtC,UAAM,aAAa,QAAQ;AAG3B,UAAM,kBAAkB,WAAW,QAAQ,YAAY,EAAE;AACzD,UAAM,SAAS,GAAG,eAAe;AACjC,UAAM,SAAS;AACf,UAAM,YAAY,IAAI;AACtB,UAAM,WAAW,IAAI;AACrB,UAAM,mBAAmB,IAAI;AAG7B,UAAM,SAAS,MAAM,MAAM,8CAA8C,MAAM,gBAAgB;AAAA,MAC7F,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,QAAQ;AAAA,QACjC,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS,GAAG,UAAU,IAAI,gBAAgB;AAAA,QAC1C,SAAS;AAAA,MACX,CAAC;AAAA,IACH,CAAC;AACD,UAAM,UAAU,MAAM,OAAO,KAAK;AAClC,QAAI,CAAC,QAAQ,SAAS;AACpB,aAAO,oBAAoB,gBAAgB,KAAK,UAAU,QAAQ,MAAM,GAAG,GAAG;AAAA,IAChF;AAGA,UAAM,YAAY,MAAM;AAAA,MACtB,iDAAiD,SAAS;AAAA,MAC1D;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,QAAQ;AAAA,UACjC,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACnB,UAAU;AAAA,UACV,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAAA,IACF;AACA,UAAM,aAAa,MAAM,UAAU,KAAK;AACxC,QAAI,CAAC,WAAW,SAAS;AACvB,aAAO,oBAAoB,mBAAmB,KAAK,UAAU,WAAW,MAAM,GAAG,GAAG;AAAA,IACtF;AAGA,YAAQ,eAAe,WAAW,MAAM;AACxC,YAAQ,iBAAgB,oBAAI,KAAK,GAAE,YAAY;AAC/C,UAAM,IAAI,aAAa,IAAI,WAAW,SAAS,IAAI,KAAK,UAAU,OAAO,CAAC;AAE1E,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,KAAK,WAAW,MAAM;AAAA,QACtB,WAAW,QAAQ;AAAA,QACnB,SAAS;AAAA,MACX,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,WAAO,oBAAoB,4BAA4B,EAAE,SAAS,GAAG;AAAA,EACvE;AACF,GAhFkC;AAmFlC,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,YAAY,IAAI,aAAa,IAAI,WAAW;AAElD,QAAI,CAAC,WAAW;AACd,aAAO,oBAAoB,+BAA+B,GAAG;AAAA,IAC/D;AAEA,UAAM,cAAc,MAAM,IAAI,aAAa,IAAI,WAAW,SAAS,EAAE;AACrE,QAAI,CAAC,aAAa;AAChB,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,QAAQ;AAAA,UACR,SAAS;AAAA,QACX,CAAC;AAAA,QACD;AAAA,MACF;AAAA,IACF;AAEA,UAAM,UAAU,KAAK,MAAM,WAAW;AACtC,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,YAAY,QAAQ;AAAA,UACpB,UAAU,QAAQ;AAAA,UAClB,cAAc,QAAQ,gBAAgB;AAAA,UACtC,aAAa,QAAQ;AAAA,UACrB,eAAe,QAAQ,iBAAiB;AAAA,QAC1C;AAAA,MACF,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,WAAO,oBAAoB,oCAAoC,EAAE,SAAS,GAAG;AAAA,EAC/E;AACF,GArC6B;AAwC7B,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,YAAY,IAAI,aAAa,IAAI,WAAW;AAElD,QAAI,CAAC,WAAW;AACd,aAAO,oBAAoB,+BAA+B,GAAG;AAAA,IAC/D;AAGA,UAAM,cAAc,MAAM,IAAI,aAAa,IAAI,WAAW,SAAS,EAAE;AACrE,QAAI,CAAC,aAAa;AAChB,aAAO,oBAAoB,wDAAwD,GAAG;AAAA,IACxF;AAEA,UAAM,UAAU,KAAK,MAAM,WAAW;AACtC,UAAM,aAAa,QAAQ;AAE3B,UAAM,YAAY,IAAI;AACtB,UAAM,WAAW,IAAI;AAGrB,YAAQ,IAAI,sCAAsC,UAAU,EAAE;AAE9D,UAAM,UAAU,MAAM;AAAA,MACpB,iDAAiD,SAAS,oBAAoB,UAAU;AAAA,MACxF;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,QAAQ;AAAA,UACjC,QAAQ;AAAA,QACV;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,QAAQ,IAAI;AACf,YAAM,YAAY,MAAM,QAAQ,KAAK;AACrC,cAAQ,MAAM,kCAAkC,SAAS;AACzD,aAAO;AAAA,QACL,uCAAuC,QAAQ,MAAM;AAAA,QACrD,QAAQ;AAAA,MACV;AAAA,IACF;AAEA,UAAM,eAAe,MAAM,QAAQ,KAAK;AAExC,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,MAAM;AAAA,QACN,YAAY,QAAQ;AAAA,QACpB,UAAU,QAAQ;AAAA,QAClB,aAAa,QAAQ;AAAA,QACrB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,YAAQ,MAAM,gCAAgC,CAAC;AAC/C,WAAO,oBAAoB,mCAAmC,EAAE,SAAS,GAAG;AAAA,EAC9E;AACF,GA7D6B;AAgE7B,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,UAAM,EAAE,QAAQ,SAAS,kBAAkB,WAAW,IAAI;AAE1D,QAAI,CAAC,UAAU,CAAC,SAAS;AACvB,aAAO,oBAAoB,mDAAmD,GAAG;AAAA,IACnF;AAGA,QAAI,iBAAiB;AACrB,QAAI,oBAAoB,iBAAiB,SAAS,GAAG;AACnD,uBAAiB;AAAA;AAAA;AAAA,EAAgC,iBAC9C,IAAI,CAAC,OAAO,MAAM,GAAG,KAAK,KAAK,GAAG,QAAQ;AAAA,KAAS,GAAG,WAAW;AAAA,EAAK,GAAG,IAAI,EAAE,EAC/E,KAAK,gBAAgB,CAAC;AAAA,IAC3B;AAEA,UAAM,cAAc;AAAA;AAAA,gBAER,cAAc,uBAAuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYnD,cAAc;AAAA;AAAA;AAIZ,QAAI,QAAQ,SAAS,OAAO;AAG5B,YAAQ,SAAS;AAAA,MACf,KAAK;AACH,iBAAS,IAAI;AACb,YAAI,CAAC,QAAQ;AACX,iBAAO,oBAAoB,8BAA8B,GAAG;AAAA,QAC9D;AAEA,cAAM,aAAa,IAAI,OAAO;AAAA,UAC5B;AAAA,UACA,SAAS;AAAA,QACX,CAAC;AAED,cAAM,iBAAiB,MAAM,WAAW,KAAK,YAAY,OAAO;AAAA,UAC9D,OAAO;AAAA,UACP,aAAa;AAAA,UACb,YAAY;AAAA,UACZ,UAAU;AAAA,YACR;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,UACvC;AAAA,QACF,CAAC;AAED,iBAAS,eAAe,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AACxD;AAAA,MAEF,KAAK;AACH,iBAAS,IAAI;AACb,YAAI,CAAC,QAAQ;AACX,iBAAO,oBAAoB,iCAAiC,GAAG;AAAA,QACjE;AAEA,cAAM,eAAe,IAAI,OAAO;AAAA,UAC9B;AAAA,UACA,SAAS;AAAA,QACX,CAAC;AAED,cAAM,mBAAmB,MAAM,aAAa,KAAK,YAAY,OAAO;AAAA,UAClE,OAAO;AAAA,UACP,aAAa;AAAA,UACb,YAAY;AAAA,UACZ,UAAU;AAAA,YACR;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,UACvC;AAAA,QACF,CAAC;AAED,iBAAS,iBAAiB,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC1D;AAAA,MAEF,KAAK;AACH,iBAAS,IAAI;AACb,YAAI,CAAC,QAAQ;AACX,iBAAO,oBAAoB,wCAAwC,GAAG;AAAA,QACxE;AAEA,cAAM,iBAAiB,MAAM;AAAA,UAC3B,gGAAgG,MAAM;AAAA,UACtG;AAAA,YACE,QAAQ;AAAA,YACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,YAC9C,MAAM,KAAK,UAAU;AAAA,cACnB,UAAU,CAAC,EAAE,OAAO,CAAC,EAAE,MAAM,YAAY,CAAC,EAAE,CAAC;AAAA,cAC7C,kBAAkB;AAAA,gBAChB,aAAa;AAAA,gBACb,iBAAiB;AAAA,cACnB;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF;AAEA,YAAI,CAAC,eAAe,IAAI;AACtB,gBAAM,IAAI,MAAM,qBAAqB,eAAe,MAAM,EAAE;AAAA,QAC9D;AAEA,cAAM,aAAa,MAAM,eAAe,KAAK;AAC7C,iBAAS,WAAW,aAAa,CAAC,GAAG,SAAS,QAAQ,CAAC,GAAG,QAAQ;AAClE;AAAA,MAEF;AACE,eAAO,oBAAoB,8BAA8B,GAAG;AAAA,IAChE;AAGA,QAAI,YAAY,OACb,QAAQ,qBAAqB,EAAE,EAC/B,QAAQ,aAAa,EAAE,EACvB,QAAQ,WAAW,EAAE,EACrB,KAAK;AAGR,QAAI,CAAC,UAAU,SAAS,kBAAkB,KAAK,CAAC,UAAU,SAAS,gBAAgB,GAAG;AACpF,kBAAY;AAAA,EAAmC,SAAS;AAAA,IAC1D;AAEA,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,MAAM;AAAA,QACN,OAAO;AAAA,QACP,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,4BAA4B,KAAK;AAC/C,WAAO,oBAAoB,6BAA6B,MAAM,OAAO,IAAI,GAAG;AAAA,EAC9E;AACF,GAxJ6B;AA2J7B,IAAM,8BAA8B,8BAAO,SAAS,QAAQ;AAC1D,MAAI;AACF,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,IAAI;AAEJ,QAAI,CAAC,UAAU;AACb,aAAO,oBAAoB,wCAAwC,GAAG;AAAA,IACxE;AAGA,QAAI,UAAU;AACd,QAAI,YAAY;AACd,YAAM,WAAW,WAAW;AAAA,QAC1B;AAAA,MACF;AACA,gBAAU,WAAW,SAAS,CAAC,IAAI;AAAA,IACrC;AAGA,UAAM,cAAc,aAAa;AACjC,UAAM,cAAc,cAChB;AAAA;AAAA;AAAA,EAGN,QAAQ;AAAA;AAAA,aAEG,eAAe,UAAU;AAAA,kBACvB,kBAAkB,eAAe;AAAA,eACjC,cAAc,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUzC,oBAAoB,8EAA8E,EAAE;AAAA,EACpG,oBAAoB,uGAA8F,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kLAU9G;AAAA;AAAA;AAAA,EAGN,QAAQ;AAAA;AAAA,eAEK,eAAe,UAAU;AAAA,mBACrB,kBAAkB,cAAc;AAAA,eACpC,cAAc,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUzC,oBAAoB,sEAAsE,EAAE;AAAA,EAC5F,oBAAoB,iFAAiF,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAWrG,QAAI,QAAQ;AAIZ,QAAI,WAAW;AACf,QAAI,eAAe,gBAAgB,eAAe,cAAc;AAC9D,iBAAW;AAAA,IACb,WAAW,CAAC,YAAY;AACtB,iBAAW;AAAA,IACb;AAEA,YAAQ,IAAI,6DAA6D;AAAA,MACvE,kBAAkB;AAAA,MAClB,gBAAgB;AAAA,MAChB,UAAU,YAAY;AAAA,IACxB,CAAC;AAGD,YAAQ,UAAU;AAAA,MAChB,KAAK;AACH,iBAAS,IAAI;AACb,YAAI,CAAC,QAAQ;AACX,iBAAO,oBAAoB,8BAA8B,GAAG;AAAA,QAC9D;AAEA,cAAM,aAAa,IAAI,OAAO;AAAA,UAC5B;AAAA,UACA,SAAS;AAAA,QACX,CAAC;AAED,cAAM,iBAAiB,MAAM,WAAW,KAAK,YAAY,OAAO;AAAA,UAC9D,OAAO;AAAA,UACP,aAAa;AAAA,UACb,YAAY;AAAA,UACZ,UAAU;AAAA,YACR;AAAA,cACE,MAAM;AAAA,cACN,SAAS,cACL,mJACA;AAAA,YACN;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,UACvC;AAAA,QACF,CAAC;AAED,iBAAS,eAAe,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AACxD;AAAA,MAEF,KAAK;AACH,iBAAS,IAAI;AACb,YAAI,CAAC,QAAQ;AACX,iBAAO,oBAAoB,iCAAiC,GAAG;AAAA,QACjE;AAEA,cAAM,eAAe,IAAI,OAAO;AAAA,UAC9B;AAAA,UACA,SAAS;AAAA,QACX,CAAC;AAED,cAAM,mBAAmB,MAAM,aAAa,KAAK,YAAY,OAAO;AAAA,UAClE,OAAO;AAAA,UACP,aAAa;AAAA,UACb,YAAY;AAAA,UACZ,UAAU;AAAA,YACR;AAAA,cACE,MAAM;AAAA,cACN,SAAS,cACL,mJACA;AAAA,YACN;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,UACvC;AAAA,QACF,CAAC;AAED,iBAAS,iBAAiB,QAAQ,CAAC,EAAE,QAAQ,QAAQ,KAAK;AAC1D;AAAA,MAEF;AACE,eAAO,oBAAoB,iCAAiC,GAAG;AAAA,IACnE;AAGA,UAAM,cAAc,OAAO,KAAK;AAEhC,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,QACA,UAAU,YAAY;AAAA,QACtB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,oCAAoC,KAAK;AACvD,WAAO,oBAAoB,qCAAqC,MAAM,OAAO,IAAI,GAAG;AAAA,EACtF;AACF,GAzLoC;AA8LpC,IAAM,sBAAsB,8BAAO,SAAS,QAAQ;AAClD,MAAI;AACF,UAAM,YAAY,IAAI;AACtB,UAAM,WAAW,IAAI;AACrB,UAAM,aAAa;AACnB,UAAM,UAAU;AAGhB,YAAQ;AAAA,MACN;AAAA,MACA,iDAAiD,SAAS,oBAAoB,UAAU;AAAA,IAC1F;AAEA,UAAM,YAAY,MAAM;AAAA,MACtB,iDAAiD,SAAS,oBAAoB,UAAU;AAAA,MACxF;AAAA,QACE,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,eAAe,UAAU,QAAQ;AAAA,UACjC,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM;AAAA,MACR;AAAA,IACF;AACA,UAAM,aAAa,MAAM,UAAU,KAAK;AACxC,QAAI,CAAC,WAAW,SAAS;AACvB,aAAO,oBAAoB,2BAA2B,KAAK,UAAU,WAAW,MAAM,GAAG,GAAG;AAAA,IAC9F;AACA,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,SAAS;AAAA,QACT;AAAA,MACF,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,WAAO,oBAAoB,2BAA2B,EAAE,SAAS,GAAG;AAAA,EACtE;AACF,GAvC4B;AA8C5B,IAAM,yBAAyB,8BAAO,SAAS,OAAO,QAAQ;AAC5D,MAAI;AAEF,UAAM,WAAW,QAAQ,QAAQ,IAAI,aAAa;AAElD,QAAI,CAAC,YAAY,aAAa,cAAc;AAC1C,aAAO,EAAE,OAAO,OAAO,OAAO,0CAA0C;AAAA,IAC1E;AAIA,UAAM,KAAK,IAAI;AACf,UAAM,QAAQ;AACd,UAAM,MAAM,MAAM,GAAG,QAAQ,KAAK,EAAE,KAAK,KAAK,EAAE,MAAM;AAEtD,QAAI,CAAC,OAAO,IAAI,SAAS,cAAc;AACrC,aAAO,EAAE,OAAO,OAAO,OAAO,2BAA2B;AAAA,IAC3D;AAEA,WAAO,EAAE,OAAO,KAAK;AAAA,EACvB,SAAS,OAAO;AACd,YAAQ,MAAM,qCAAqC,KAAK;AACxD,WAAO,EAAE,OAAO,OAAO,OAAO,yBAAyB;AAAA,EACzD;AACF,GAxB+B;AA2B/B,IAAM,qBAAqB,8BAAO,SAAS,QAAQ;AACjD,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,QAAQ,IAAI,aAAa,IAAI,OAAO;AAE1C,QAAI,CAAC,OAAO;AACV,aAAO,oBAAoB,2BAA2B,GAAG;AAAA,IAC3D;AAGA,UAAM,YAAY,MAAM,uBAAuB,SAAS,OAAO,GAAG;AAClE,QAAI,CAAC,UAAU,OAAO;AACpB,aAAO,oBAAoB,UAAU,OAAO,GAAG;AAAA,IACjD;AAGA,UAAM,OAAO,MAAM,IAAI,aAAa,KAAK,EAAE,QAAQ,eAAe,CAAC;AACnE,UAAM,UAAU,CAAC;AAEjB,eAAW,OAAO,KAAK,MAAM;AAC3B,YAAM,SAAS,IAAI,KAAK,QAAQ,gBAAgB,EAAE;AAClD,YAAM,SAAS,MAAM,IAAI,aAAa,IAAI,IAAI,IAAI;AAElD,UAAI,QAAQ;AACV,cAAM,eAAe,KAAK,MAAM,MAAM;AACtC,gBAAQ,KAAK;AAAA,UACX;AAAA,UACA,OAAO,aAAa,SAAS;AAAA,UAC7B,WAAW,aAAa,aAAa;AAAA,UACrC,cAAc,aAAa,gBAAgB;AAAA,UAC3C,SAAS,CAAC,CAAC,aAAa;AAAA,UACxB,mBAAmB,CAAC,CAAC,aAAa;AAAA,UAClC,SAAS,aAAa,WAAW;AAAA,QACnC,CAAC;AAAA,MACH;AAAA,IACF;AAGA,YAAQ,KAAK,CAAC,GAAG,MAAM;AACrB,UAAI,EAAE,UAAU,EAAE,OAAO;AACvB,eAAO,EAAE,MAAM,cAAc,EAAE,KAAK;AAAA,MACtC;AACA,aAAO,EAAE,OAAO,cAAc,EAAE,MAAM;AAAA,IACxC,CAAC;AAED,WAAO,eAAe,KAAK,UAAU,EAAE,QAAQ,CAAC,CAAC;AAAA,EACnD,SAAS,OAAO;AACd,YAAQ,MAAM,gCAAgC,KAAK;AACnD,WAAO,oBAAoB,yBAAyB,GAAG;AAAA,EACzD;AACF,GAlD2B;AAqD3B,IAAM,uBAAuB,8BAAO,SAAS,QAAQ;AACnD,MAAI;AACF,UAAM,EAAE,OAAO,QAAQ,SAAS,IAAI,MAAM,QAAQ,KAAK;AAEvD,QAAI,CAAC,SAAS,CAAC,UAAU,CAAC,UAAU;AAClC,aAAO,oBAAoB,oDAAoD,GAAG;AAAA,IACpF;AAGA,UAAM,YAAY,MAAM,uBAAuB,SAAS,OAAO,GAAG;AAClE,QAAI,CAAC,UAAU,OAAO;AACpB,aAAO,oBAAoB,UAAU,OAAO,GAAG;AAAA,IACjD;AAGA,UAAM,QAAQ,eAAe,MAAM;AACnC,UAAM,gBAAgB,MAAM,IAAI,aAAa,IAAI,KAAK;AAEtD,QAAI,CAAC,eAAe;AAClB,aAAO,oBAAoB,oBAAoB,GAAG;AAAA,IACpD;AAEA,UAAM,eAAe,KAAK,MAAM,aAAa;AAC7C,UAAM,WAAW,aAAa;AAG9B,iBAAa,QAAQ;AACrB,iBAAa,gBAAe,oBAAI,KAAK,GAAE,YAAY;AACnD,iBAAa,kBAAkB,aAAa,mBAAmB,CAAC;AAChE,iBAAa,gBAAgB,KAAK;AAAA,MAChC,MAAM;AAAA,MACN,IAAI;AAAA,MACJ,eAAe;AAAA,MACf,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IACpC,CAAC;AAED,UAAM,IAAI,aAAa,IAAI,OAAO,KAAK,UAAU,YAAY,CAAC;AAG9D,QAAI,UAAU;AACZ,YAAM,eAAe,MAAM,IAAI,YAC5B,QAAQ,yCAAyC,EACjD,KAAK,QAAQ,EACb,MAAM;AACT,UAAI,gBAAgB,aAAa,MAAM;AACrC,cAAMC,YAAW,KAAK,MAAM,aAAa,IAAI;AAC7C,YAAIA,UAAS,eAAe;AAC1B,UAAAA,UAAS,gBAAgBA,UAAS,cAAc,OAAO,CAAC,MAAM,EAAE,WAAW,MAAM;AACjF,gBAAM,IAAI,YACP,QAAQ,4CAA4C,EACpD,KAAK,KAAK,UAAUA,SAAQ,GAAG,QAAQ,EACvC,IAAI;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAGA,UAAM,eAAe,MAAM,IAAI,YAC5B,QAAQ,yCAAyC,EACjD,KAAK,QAAQ,EACb,MAAM;AACT,QAAI,WAAW,EAAE,eAAe,CAAC,EAAE;AAEnC,QAAI,gBAAgB,aAAa,MAAM;AACrC,iBAAW,KAAK,MAAM,aAAa,IAAI;AACvC,UAAI,CAAC,SAAS,eAAe;AAC3B,iBAAS,gBAAgB,CAAC;AAAA,MAC5B;AAAA,IACF;AAGA,QAAI,CAAC,SAAS,cAAc,KAAK,CAAC,MAAM,EAAE,WAAW,MAAM,GAAG;AAC5D,eAAS,cAAc,KAAK;AAAA,QAC1B;AAAA,QACA,OAAO;AAAA,QACP,WAAW,aAAa,cAAa,oBAAI,KAAK,GAAE,YAAY;AAAA,QAC5D,cAAc,aAAa;AAAA,MAC7B,CAAC;AAAA,IACH;AAEA,UAAM,IAAI,YACP;AAAA,MACC;AAAA;AAAA;AAAA;AAAA;AAAA,IAKF,EACC,KAAK,UAAU,KAAK,UAAU,QAAQ,GAAG,KAAK,UAAU,QAAQ,CAAC,EACjE,IAAI;AAEP,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,SAAS,UAAU,MAAM,qBAAqB,QAAQ,OAAO,QAAQ;AAAA,QACrE;AAAA,QACA;AAAA,QACA;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,kCAAkC,KAAK;AACrD,WAAO,oBAAoB,yBAAyB,GAAG;AAAA,EACzD;AACF,GAxG6B;AA2G7B,IAAM,sBAAsB,8BAAO,SAAS,QAAQ;AAClD,MAAI;AACF,UAAM,EAAE,OAAO,cAAc,cAAc,aAAa,eAAe,IAAI,MAAM,QAAQ,KAAK;AAE9F,QAAI,CAAC,SAAS,CAAC,gBAAgB,CAAC,gBAAgB,CAAC,aAAa;AAC5D,aAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAGA,UAAM,YAAY,MAAM,uBAAuB,SAAS,OAAO,GAAG;AAClE,QAAI,CAAC,UAAU,OAAO;AACpB,aAAO,oBAAoB,UAAU,OAAO,GAAG;AAAA,IACjD;AAGA,UAAM,eAAe,MAAM,IAAI,aAAa,IAAI,eAAe,YAAY,EAAE;AAC7E,QAAI,CAAC,cAAc;AACjB,aAAO,oBAAoB,2BAA2B,GAAG;AAAA,IAC3D;AAEA,UAAM,qBAAqB,KAAK,MAAM,YAAY;AAGlD,UAAM,iBAAiB;AAAA,MACrB,QAAQ;AAAA,MACR,OAAO;AAAA,MACP,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MAClC,eAAc,oBAAI,KAAK,GAAE,YAAY;AAAA,MACrC,gBAAgB;AAAA,MAChB,mBAAmB;AAAA,MACnB,MAAM,mBAAmB,QAAQ;AAAA,MACjC,gBAAgB,mBAAmB,kBAAkB;AAAA,MACrD,SAAS,iBAAiB,mBAAmB,UAAU;AAAA,MACvD,iBAAiB;AAAA,QACf;AAAA,UACE,gBAAgB;AAAA,UAChB,WAAW;AAAA,UACX,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,UAClC,gBAAgB,CAAC,CAAC;AAAA,QACpB;AAAA,MACF;AAAA,IACF;AAGA,UAAM,IAAI,aAAa,IAAI,eAAe,YAAY,IAAI,KAAK,UAAU,cAAc,CAAC;AAGxF,UAAM,kBAAkB,MAAM,IAAI,YAC/B,QAAQ,yCAAyC,EACjD,KAAK,WAAW,EAChB,MAAM;AACT,QAAI,WAAW,EAAE,eAAe,CAAC,EAAE;AAEnC,QAAI,mBAAmB,gBAAgB,MAAM;AAC3C,iBAAW,KAAK,MAAM,gBAAgB,IAAI;AAC1C,UAAI,CAAC,SAAS,eAAe;AAC3B,iBAAS,gBAAgB,CAAC;AAAA,MAC5B;AAAA,IACF;AAGA,QAAI,CAAC,SAAS,cAAc,KAAK,CAAC,MAAM,EAAE,WAAW,YAAY,GAAG;AAClE,eAAS,cAAc,KAAK;AAAA,QAC1B,QAAQ;AAAA,QACR,OAAO;AAAA,QACP,WAAW,eAAe;AAAA,QAC1B,cAAc,eAAe;AAAA,QAC7B,gBAAgB;AAAA,MAClB,CAAC;AAAA,IACH;AAEA,UAAM,IAAI,YACP;AAAA,MACC;AAAA;AAAA;AAAA;AAAA;AAAA,IAKF,EACC,KAAK,aAAa,KAAK,UAAU,QAAQ,GAAG,KAAK,UAAU,QAAQ,CAAC,EACpE,IAAI;AAEP,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,SAAS,wBAAwB,YAAY,OAAO,YAAY,QAAQ,WAAW;AAAA,QACnF;AAAA,QACA;AAAA,QACA;AAAA,QACA,gBAAgB,CAAC,CAAC;AAAA,MACpB,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,iCAAiC,KAAK;AACpD,WAAO,oBAAoB,yBAAyB,GAAG;AAAA,EACzD;AACF,GAnG4B;AAsG5B,IAAM,qBAAqB,8BAAO,SAAS,QAAQ;AACjD,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,QAAQ,IAAI,aAAa,IAAI,OAAO;AAC1C,UAAM,SAAS,IAAI,aAAa,IAAI,QAAQ;AAE5C,QAAI,CAAC,SAAS,CAAC,QAAQ;AACrB,aAAO,oBAAoB,8CAA8C,GAAG;AAAA,IAC9E;AAGA,UAAM,YAAY,MAAM,uBAAuB,SAAS,OAAO,GAAG;AAClE,QAAI,CAAC,UAAU,OAAO;AACpB,aAAO,oBAAoB,UAAU,OAAO,GAAG;AAAA,IACjD;AAGA,UAAM,QAAQ,eAAe,MAAM;AACnC,UAAM,gBAAgB,MAAM,IAAI,aAAa,IAAI,KAAK;AAEtD,QAAI,CAAC,eAAe;AAClB,aAAO,oBAAoB,oBAAoB,GAAG;AAAA,IACpD;AAEA,UAAM,eAAe,KAAK,MAAM,aAAa;AAC7C,UAAM,QAAQ,aAAa;AAG3B,UAAM,IAAI,aAAa,OAAO,KAAK;AAGnC,QAAI,OAAO;AACT,YAAM,YAAY,MAAM,IAAI,YACzB,QAAQ,yCAAyC,EACjD,KAAK,KAAK,EACV,MAAM;AACT,UAAI,aAAa,UAAU,MAAM;AAC/B,cAAM,WAAW,KAAK,MAAM,UAAU,IAAI;AAC1C,YAAI,SAAS,eAAe;AAC1B,mBAAS,gBAAgB,SAAS,cAAc,OAAO,CAAC,MAAM,EAAE,WAAW,MAAM;AACjF,gBAAM,IAAI,YACP,QAAQ,4CAA4C,EACpD,KAAK,KAAK,UAAU,QAAQ,GAAG,KAAK,EACpC,IAAI;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,KAAK,UAAU;AAAA,QACb,SAAS;AAAA,QACT,SAAS,UAAU,MAAM;AAAA,QACzB;AAAA,QACA;AAAA,QACA,WAAW;AAAA,MACb,CAAC;AAAA,IACH;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,gCAAgC,KAAK;AACnD,WAAO,oBAAoB,yBAAyB,GAAG;AAAA,EACzD;AACF,GA7D2B;AA+D3B,IAAO,gBAAQ;AAAA,EACb,MAAM,MAAM,SAAS,KAAK;AACxB,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,WAAW,IAAI;AAGrB,YAAQ,IAAI,iCAA0B;AAAA,MACpC,QAAQ,QAAQ;AAAA,MAChB;AAAA,MACA,SAAS,QAAQ;AAAA,MACjB,QAAQ,QAAQ,QAAQ,IAAI,QAAQ;AAAA,MACpC,WAAW,QAAQ,QAAQ,IAAI,YAAY;AAAA,MAC3C,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IACpC,CAAC;AAGD,QAAI,QAAQ,WAAW,WAAW;AAChC,aAAO,IAAI,SAAS,MAAM;AAAA,QACxB,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,GAAG;AAAA,UACH,0BAA0B;AAAA,QAC5B;AAAA,MACF,CAAC;AAAA,IACH;AAEA,QAAI,aAAa,2BAA2B,QAAQ,WAAW,OAAO;AACpE,aAAO,MAAM,2BAA2B,SAAS,GAAG;AAAA,IACtD;AAEA,QAAI,aAAa,4BAA4B,QAAQ,WAAW,QAAQ;AACtE,aAAO,MAAM,4BAA4B,SAAS,GAAG;AAAA,IACvD;AACA,QAAI,aAAa,WAAW,QAAQ,WAAW,QAAQ;AACrD,aAAO,MAAM,WAAW,SAAS,GAAG;AAAA,IACtC;AACA,QAAI,SAAS,WAAW,QAAQ,KAAK,QAAQ,WAAW,OAAO;AAC7D,aAAO,MAAM,WAAW,SAAS,GAAG;AAAA,IACtC;AACA,QAAI,aAAa,iBAAiB,QAAQ,WAAW,OAAO;AAC1D,aAAO,MAAM,gBAAgB,SAAS,GAAG;AAAA,IAC3C;AACA,QAAI,aAAa,wBAAwB,QAAQ,WAAW,OAAO;AACjE,aAAO,MAAM,gBAAgB,SAAS,KAAK,IAAI;AAAA,IACjD;AACA,QAAI,SAAS,WAAW,kBAAkB,KAAK,QAAQ,WAAW,UAAU;AAC1E,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AACA,QAAI,aAAa,iBAAiB,QAAQ,WAAW,QAAQ;AAC3D,aAAO,MAAM,iBAAiB,SAAS,GAAG;AAAA,IAC5C;AACA,QAAI,SAAS,WAAW,YAAY,KAAK,QAAQ,WAAW,OAAO;AACjE,aAAO,MAAM,iBAAiB,SAAS,GAAG;AAAA,IAC5C;AACA,QAAI,aAAa,kBAAkB,QAAQ,WAAW,OAAO;AAC3D,aAAO,MAAM,kBAAkB,SAAS,GAAG;AAAA,IAC7C;AACA,QAAI,SAAS,WAAW,gBAAgB,KAAK,QAAQ,WAAW,UAAU;AACxE,aAAO,MAAM,oBAAoB,SAAS,GAAG;AAAA,IAC/C;AACA,QAAI,aAAa,aAAa,QAAQ,WAAW,QAAQ;AACvD,aAAO,MAAM,aAAa,SAAS,GAAG;AAAA,IACxC;AACA,QAAI,aAAa,aAAa,QAAQ,WAAW,OAAO;AACtD,aAAO,MAAM,aAAa,SAAS,GAAG;AAAA,IACxC;AACA,QAAI,aAAa,cAAc,QAAQ,WAAW,QAAQ;AACxD,aAAO,MAAM,uBAAuB,SAAS,GAAG;AAAA,IAClD;AACA,QAAI,aAAa,eAAe,QAAQ,WAAW,OAAO;AACxD,aAAO,MAAM,eAAe,SAAS,GAAG;AAAA,IAC1C;AACA,QAAI,aAAa,mBAAmB,QAAQ,WAAW,OAAO;AAC5D,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AACA,QAAI,aAAa,mBAAmB,QAAQ,WAAW,QAAQ;AAC7D,aAAO,MAAM,sBAAsB,SAAS,GAAG;AAAA,IACjD;AACA,QAAI,aAAa,gBAAgB,QAAQ,WAAW,QAAQ;AAC1D,aAAO,MAAM,gBAAgB,SAAS,GAAG;AAAA,IAC3C;AACA,QAAI,aAAa,eAAe,QAAQ,WAAW,QAAQ;AACzD,aAAO,MAAM,eAAe,SAAS,GAAG;AAAA,IAC1C;AACA,QAAI,aAAa,kBAAkB,QAAQ,WAAW,QAAQ;AAC5D,aAAO,MAAM,iBAAiB,SAAS,GAAG;AAAA,IAC5C;AACA,QAAI,aAAa,kBAAkB,QAAQ,WAAW,QAAQ;AAC5D,aAAO,MAAM,iBAAiB,SAAS,GAAG;AAAA,IAC5C;AACA,QAAI,aAAa,eAAe,QAAQ,WAAW,QAAQ;AACzD,aAAO,MAAM,eAAe,SAAS,GAAG;AAAA,IAC1C;AACA,QAAI,aAAa,sBAAsB,QAAQ,WAAW,OAAO;AAC/D,aAAO,MAAM,sBAAsB,SAAS,GAAG;AAAA,IACjD;AACA,QAAI,aAAa,gBAAgB,QAAQ,WAAW,QAAQ;AAC1D,aAAO,MAAM,gBAAgB,SAAS,GAAG;AAAA,IAC3C;AACA,QAAI,aAAa,oBAAoB,QAAQ,WAAW,QAAQ;AAC9D,aAAO,MAAM,mBAAmB,SAAS,GAAG;AAAA,IAC9C;AACA,QAAI,aAAa,0BAA0B,QAAQ,WAAW,QAAQ;AACpE,aAAO,MAAM,yBAAyB,SAAS,GAAG;AAAA,IACpD;AACA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,QAAQ;AACnE,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AACA,QAAI,aAAa,6BAA6B,QAAQ,WAAW,QAAQ;AACvE,aAAO,MAAM,2BAA2B,SAAS,GAAG;AAAA,IACtD;AACA,QAAI,aAAa,0BAA0B,QAAQ,WAAW,QAAQ;AACpE,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AACA,QAAI,aAAa,eAAe,QAAQ,WAAW,QAAQ;AACzD,aAAO,MAAM,cAAc,SAAS,GAAG;AAAA,IACzC;AACA,QAAI,aAAa,4BAA4B,QAAQ,WAAW,QAAQ;AACtE,aAAO,MAAM,0BAA0B,SAAS,GAAG;AAAA,IACrD;AACA,QAAI,aAAa,4BAA4B,QAAQ,WAAW,QAAQ;AACtE,aAAO,MAAM,0BAA0B,SAAS,GAAG;AAAA,IACrD;AACA,QAAI,aAAa,qBAAqB,QAAQ,WAAW,OAAO;AAC9D,aAAO,MAAM,mBAAmB,SAAS,GAAG;AAAA,IAC9C;AAEA,QAAI,aAAa,qBAAqB,QAAQ,WAAW,OAAO;AAC9D,aAAO,MAAM,oBAAoB,SAAS,GAAG;AAAA,IAC/C;AAEA,QAAI,SAAS,WAAW,yBAAyB,KAAK,QAAQ,WAAW,OAAO;AAC9E,aAAO,MAAM,0BAA0B,SAAS,GAAG;AAAA,IACrD;AAEA,QAAI,SAAS,WAAW,sBAAsB,KAAK,QAAQ,WAAW,OAAO;AAC3E,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AAEA,QAAI,aAAa,6BAA6B,QAAQ,WAAW,QAAQ;AACvE,aAAO,MAAM,2BAA2B,SAAS,GAAG;AAAA,IACtD;AAEA,QAAI,aAAa,mBAAmB,QAAQ,WAAW,QAAQ;AAC7D,aAAO,oBAAoB,OAAO;AAAA,IACpC;AAEA,QAAI,aAAa,wBAAwB,QAAQ,WAAW,QAAQ;AAClE,aAAO,MAAM,sBAAsB,SAAS,GAAG;AAAA,IACjD;AAEA,QAAI,aAAa,0BAA0B,QAAQ,WAAW,QAAQ;AACpE,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AAEA,QAAI,aAAa,uBAAuB,QAAQ,WAAW,QAAQ;AACjE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AACA,QAAI,aAAa,uBAAuB,QAAQ,WAAW,QAAQ;AACjE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AAEA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,QAAQ;AACnE,aAAO,MAAM,uBAAuB,SAAS,GAAG;AAAA,IAClD;AAEA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,QAAQ;AACnE,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AAEA,QAAI,aAAa,2BAA2B,QAAQ,WAAW,QAAQ;AACrE,aAAO,MAAM,yBAAyB,SAAS,GAAG;AAAA,IACpD;AAEA,QAAI,aAAa,sBAAsB,QAAQ,WAAW,OAAO;AAC/D,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AAEA,QAAI,aAAa,oBAAoB,QAAQ,WAAW,QAAQ;AAC9D,aAAO,MAAM,wBAAwB,SAAS,GAAG;AAAA,IACnD;AAEA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,QAAQ;AACnE,aAAO,MAAM,uBAAuB,SAAS,GAAG;AAAA,IAClD;AAEA,QAAI,aAAa,2BAA2B,QAAQ,WAAW,QAAQ;AACrE,aAAO,MAAM,yBAAyB,OAAO;AAAA,IAC/C;AAEA,QAAI,aAAa,2BAA2B,QAAQ,WAAW,QAAQ;AACrE,aAAO,MAAM,yBAAyB,OAAO;AAAA,IAC/C;AAEA,QAAI,aAAa,gCAAgC,QAAQ,WAAW,OAAO;AACzE,cAAQ,IAAI,wCAAmC;AAAA,QAC7C;AAAA,QACA,QAAQ,QAAQ;AAAA,QAChB,aAAa,IAAI,aAAa,SAAS;AAAA,MACzC,CAAC;AACD,aAAO,MAAM,0BAA0B;AAAA,IACzC;AAGA,QAAI,aAAa,qBAAqB;AACpC,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,SAAS;AAAA,UACT,aAAa,CAAC;AAAA,QAChB,CAAC;AAAA,QACD;AAAA,MACF;AAAA,IACF;AAEA,QAAI,aAAa,oBAAoB;AACnC,aAAO;AAAA,QACL,KAAK,UAAU;AAAA,UACb,SAAS;AAAA,UACT,SAAS,CAAC;AAAA,QACZ,CAAC;AAAA,QACD;AAAA,MACF;AAAA,IACF;AAEA,QAAI,IAAI,aAAa,yBAAyB;AAC5C,aAAO,MAAM,yBAAyB,SAAS,GAAG;AAAA,IACpD;AAEA,QAAI,IAAI,aAAa,yBAAyB;AAC5C,aAAO,MAAM,yBAAyB,SAAS,GAAG;AAAA,IACpD;AAGA,QAAI,aAAa,wBAAwB,QAAQ,WAAW,QAAQ;AAClE,aAAO,MAAM,sBAAsB,SAAS,kBAAkB,GAAG;AAAA,IACnE;AACA,QAAI,aAAa,uBAAuB,QAAQ,WAAW,QAAQ;AACjE,aAAO,MAAM,sBAAsB,SAAS,qBAAqB,GAAG;AAAA,IACtE;AACA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,QAAQ;AACnE,aAAO,MAAM,sBAAsB,SAAS,uBAAuB,GAAG;AAAA,IACxE;AACA,QAAI,aAAa,yBAAyB,QAAQ,WAAW,OAAO;AAClE,aAAO,MAAM,sBAAsB,SAAS,mBAAmB,GAAG;AAAA,IACpE;AAEA,QAAI,aAAa,qBAAqB,QAAQ,WAAW,QAAQ;AAC/D,aAAO,MAAM,oBAAoB,SAAS,GAAG;AAAA,IAC/C;AAEA,QAAI,aAAa,4BAA4B,QAAQ,WAAW,QAAQ;AACtE,aAAO,MAAM,0BAA0B,SAAS,GAAG;AAAA,IACrD;AAEA,QAAI,aAAa,uBAAuB,QAAQ,WAAW,OAAO;AAChE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AAEA,QAAI,aAAa,uBAAuB,QAAQ,WAAW,OAAO;AAChE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AAEA,QAAI,aAAa,sBAAsB,QAAQ,WAAW,QAAQ;AAChE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AAEA,QAAI,aAAa,8BAA8B,QAAQ,WAAW,QAAQ;AACxE,aAAO,MAAM,4BAA4B,SAAS,GAAG;AAAA,IACvD;AAEA,QAAI,aAAa,qBAAqB,QAAQ,WAAW,QAAQ;AAC/D,aAAO,MAAM,oBAAoB,SAAS,GAAG;AAAA,IAC/C;AAGA,QAAI,aAAa,oBAAoB,QAAQ,WAAW,OAAO;AAC7D,aAAO,MAAM,mBAAmB,SAAS,GAAG;AAAA,IAC9C;AAEA,QAAI,aAAa,4BAA4B,QAAQ,WAAW,QAAQ;AACtE,aAAO,MAAM,qBAAqB,SAAS,GAAG;AAAA,IAChD;AAEA,QAAI,aAAa,2BAA2B,QAAQ,WAAW,QAAQ;AACrE,aAAO,MAAM,oBAAoB,SAAS,GAAG;AAAA,IAC/C;AAEA,QAAI,aAAa,0BAA0B,QAAQ,WAAW,UAAU;AACtE,aAAO,MAAM,mBAAmB,SAAS,GAAG;AAAA,IAC9C;AAGA,YAAQ,IAAI,2CAAsC;AAAA,MAChD;AAAA,MACA,QAAQ,QAAQ;AAAA,MAChB,iBAAiB;AAAA,QACf;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA;AAAA,MAEF;AAAA,IACF,CAAC;AACD,WAAO,oBAAoB,aAAa,GAAG;AAAA,EAC7C;AACF;;;AChmMA,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS;AAUT,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAO,2CAAQ;;;ACzBJ,IAAM,mCAAmC;AAAA,EAE9B;AAAA,EAAyB;AAC3C;AACA,IAAO,sCAAQ;;;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": ["escape", "html", "encode", "str", "link", "lexer", "options", "list", "tag", "text", "parser", "tokens", "args", "ret", "walkTokens", "src", "str", "is_array", "options", "fetch", "Request", "Response", "Headers", "FormData", "Blob", "File", "ReadableStream", "options", "newline", "ReadableStream", "str", "options", "File", "FormData", "parseResponse", "fetch", "opts", "Page", "options", "retryMessage", "__classPrivateFieldSet", "__classPrivateFieldGet", "modifiedArg", "options", "options", "options", "options", "options", "options", "options", "options", "__classPrivateFieldSet", "__classPrivateFieldGet", "inputTool", "__classPrivateFieldGet", "options", "content", "name", "_AbstractChatCompletionRunner_getFinalMessage", "_AbstractChatCompletionRunner_getFinalFunctionCall", "_AbstractChatCompletionRunner_getFinalFunctionCallResult", "_AbstractChatCompletionRunner_calculateTotalUsage", "_AbstractChatCompletionRunner_validateParams", "_AbstractChatCompletionRunner_stringifyFunctionCallResult", "options", "escape", "e", "__classPrivateFieldSet", "__classPrivateFieldGet", "options", "_ChatCompletionStream_beginRequest", "_ChatCompletionStream_getChoiceEventState", "_ChatCompletionStream_addChunk", "_ChatCompletionStream_emitToolCallDoneEvent", "_ChatCompletionStream_emitContentDoneEvents", "_ChatCompletionStream_endRequest", "_ChatCompletionStream_getAutoParseableResponseFormat", "_ChatCompletionStream_accumulateChatCompletion", "other", "content", "refusal", "rest", "_a", "index", "chunk", "id", "options", "Completions", "options", "Chat", "Completions", "options", "chunk", "options", "__classPrivateFieldGet", "__classPrivateFieldSet", "assertNever", "_AssistantStream_endRequest", "_AssistantStream_handleMessage", "_AssistantStream_handleRunStep", "_AssistantStream_handleEvent", "_AssistantStream_accumulateRunStep", "_AssistantStream_accumulateMessage", "_AssistantStream_accumulateContent", "_AssistantStream_handleRun", "Messages", "options", "options", "options", "Messages", "options", "Chat", "Completions", "options", "options", "options", "options", "options", "options", "options", "options", "hasAutoParseableInput", "parseToolCall", "content", "output", "isAutoParsableTool", "parseToolCall", "options", "__classPrivateFieldSet", "options", "__classPrivateFieldGet", "_ResponseStream_beginRequest", "_ResponseStream_addEvent", "_ResponseStream_endRequest", "_ResponseStream_accumulateResponse", "event", "options", "options", "options", "Files", "options", "options", "Files", "options", "options", "Completions", "html", "list", "node", "graphData", "graphMetadata", "options", "userData"]
}
